<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>IT Tech </title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray_background {
	background: rgba(248, 248, 247, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(248, 243, 252, 1);
}
.highlight-pink_background {
	background: rgba(252, 241, 246, 1);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(248, 248, 247, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(248, 243, 252, 1);
}
.block-color-pink_background {
	background: rgba(252, 241, 246, 1);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: undefined; }
.select-value-color-pink { background-color: rgba(225, 136, 179, 0.27); }
.select-value-color-purple { background-color: rgba(168, 129, 197, 0.27); }
.select-value-color-green { background-color: rgba(123, 183, 129, 0.27); }
.select-value-color-gray { background-color: rgba(84, 72, 49, 0.15); }
.select-value-color-transparentGray { background-color: undefined; }
.select-value-color-translucentGray { background-color: undefined; }
.select-value-color-orange { background-color: rgba(224, 124, 57, 0.27); }
.select-value-color-brown { background-color: rgba(210, 162, 141, 0.35); }
.select-value-color-red { background-color: rgba(244, 171, 159, 0.4); }
.select-value-color-yellow { background-color: rgba(236, 191, 66, 0.39); }
.select-value-color-blue { background-color: rgba(93, 165, 206, 0.27); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="f69f800e-7bec-4c64-8ffd-f4a3cb6c0a79" class="page sans"><header><h1 class="page-title">IT Tech </h1><p class="page-description"></p></header><div class="page-body"><p id="4d7c68ec-57ec-489b-8ab8-302f7c5c4c89" class="">
</p><p id="ec7d49be-6ab2-46a1-b40c-a16db6100a56" class=""><strong>대규모/고성능 시스템 설계</strong></p><ul id="74301ab1-25c9-4e99-a10c-81411bf750a3" class="toggle"><li><details open=""><summary><mark class="highlight-blue_background">배민 - </mark><mark class="highlight-blue_background"><span style="border-bottom:0.05em solid">대규모 트랜잭션을 처리하는 배민 주문시스템 규모에 따른 진화</span></mark></summary><p id="1e23a4cc-090a-805b-b857-c645a0667e91" class=""><a href="https://www.youtube.com/watch?v=704qQs6KoUk&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=6">https://www.youtube.com/watch?v=704qQs6KoUk&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=6</a></p><hr id="1c43a4cc-090a-80a2-9f26-e119b44d915e"/><ul id="1c43a4cc-090a-80fc-a7a3-da49fc8c37e2" class="bulleted-list"><li style="list-style-type:disc">기존 아키텍처로 성장하는 주문수를 처리 못해 여러가지 문제<ul id="1c43a4cc-090a-804f-861e-d19fc469fc1e" class="bulleted-list"><li style="list-style-type:circle">단일 장애 포인트 - 하나의 장애는 전체 시스템 장애로 </li></ul><ul id="1c43a4cc-090a-8093-b6dc-dcd2e17fa1fe" class="bulleted-list"><li style="list-style-type:circle">RDBMS 조인 연산으로 조회 성능 저하</li></ul><ul id="1c43a4cc-090a-805a-985b-dd36e47e162a" class="bulleted-list"><li style="list-style-type:circle">주문수 증가로 저장소 쓰기 처리량 한계 도달</li></ul><ul id="1c43a4cc-090a-80e3-8ae9-fbaa6e16a50b" class="bulleted-list"><li style="list-style-type:circle">규칙 없는 이벤트 발행으로 서비스 복잡도 증가</li></ul></li></ul><ul id="1c43a4cc-090a-8031-a850-ec76a3742f2a" class="bulleted-list"><li style="list-style-type:disc">해결 방법<ul id="1c43a4cc-090a-8080-8d02-d2852ce1b920" class="bulleted-list"><li style="list-style-type:circle">개별 시스템은 시스템에 맞는 도메인을 모델링하여 중앙 DB 의존성을 제거<ul id="1c43a4cc-090a-8033-8c19-c7334311f368" class="bulleted-list"><li style="list-style-type:square"><span style="border-bottom:0.05em solid">자체 DB 구성으로 MSA 구성 및 Message Queue 를 이용한 이벤트 기반 통신으로 시스템 간 영향도를 분리</span></li></ul><ul id="1c43a4cc-090a-80fb-809a-cd21bf919a9b" class="bulleted-list"><li style="list-style-type:square">특정 시스템 장애는 메시지 발행 실패로 인한 지연 현상만 발생, 시스템 복구시 이벤트 재발행</li></ul></li></ul><ul id="1c43a4cc-090a-805e-8ac3-c4aec2dd5c05" class="bulleted-list"><li style="list-style-type:circle">조회 성능을 높이기 위해 단일 도큐먼트로 역정규화를 진행<ul id="1c43a4cc-090a-808e-9204-cfea0265cef6" class="bulleted-list"><li style="list-style-type:square">주문 도메인 생명주기에 발생되는 도메인 이벤트를 통해 주문이벤트 서비스 처리기에서 Mongo DB에 데이터 동기화</li></ul><ul id="1c43a4cc-090a-801e-9572-f6eabf9491b4" class="bulleted-list"><li style="list-style-type:square"><span style="border-bottom:0.05em solid">CQRS 패턴 적용 커맨드 모델과 조회 모델을 분리</span>, <span style="border-bottom:0.05em solid">조회 모델 역정규화를 통해 조회 성능 개선 (Mongo DB 활용)</span></li></ul></li></ul><ul id="1c43a4cc-090a-8051-be16-c624041b3946" class="bulleted-list"><li style="list-style-type:circle"><span style="border-bottom:0.05em solid">쓰기 요청 증가를 DB 샤딩 분산 처리를 통해 대응</span><ul id="1c43a4cc-090a-80e8-b998-c826212f5ab6" class="bulleted-list"><li style="list-style-type:square">주문 데이터 실시간성 조회 요청은 스케일 아웃으로 대응 (read replica 구성)</li></ul><ul id="1c43a4cc-090a-8029-b65b-fd680ad353e3" class="bulleted-list"><li style="list-style-type:square">주문번호 기반 Hash 함수 로직을 통해 key based 샤딩 (주문순번 % 샤드수 = 샤드번호)</li></ul></li></ul><ul id="1c43a4cc-090a-80ee-a3a1-ed904f7d78d5" class="bulleted-list"><li style="list-style-type:circle">주요 도메인 이벤트는 내부 이벤트로, 서비스 로직은 외부 이벤트로 정의<ul id="1c43a4cc-090a-80c3-9941-d2768ce4c22c" class="bulleted-list"><li style="list-style-type:square"><span style="border-bottom:0.05em solid">주문 내부 이벤트는 zero payload 전략</span></li></ul><ul id="1c43a4cc-090a-802e-983b-e2535c6c865b" class="bulleted-list"><li style="list-style-type:square">이벤트 처리기도 이벤트 처리 단일화</li></ul><ul id="1c43a4cc-090a-8071-882a-ce42ffde800c" class="bulleted-list"><li style="list-style-type:square"><span style="border-bottom:0.05em solid">이벤트 유실은 트랜잭션 아웃박스 패턴(이벤트 스냅샷)을 활용</span>하여 유실 발생 시 어플리케이션을 통해 재발행</li></ul><figure id="1c43a4cc-090a-8031-96ca-f3eb43f4cefc" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.34.56.png"><img style="width:873.984375px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.34.56.png"/></a></figure></li></ul></li></ul><hr id="1c43a4cc-090a-801c-9fce-f9644ea1d131"/><ul id="6297d7a0-5d9c-469f-bffa-d65159ade6c3" class="bulleted-list"><li style="list-style-type:disc">일평균 300만건 주문, 식사 시간에 트래픽 순간 폭증</li></ul><ul id="a9c5dadb-519c-41d6-a4d1-43d628795c44" class="bulleted-list"><li style="list-style-type:disc">시스템간 느슨한 결합을 위한 이벤트 기반 통신</li></ul><ul id="45a9a0d9-dfbb-4734-a829-d4d5c1410595" class="bulleted-list"><li style="list-style-type:disc">기존 아키텍처로 성장하는 주문수를 처리 못해 문제 발생<figure id="bce8e3d2-36ee-404c-895d-4f0e74895aea" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.44.58.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.44.58.png"/></a></figure></li></ul><ul id="ccd04cba-3f94-43d3-9217-d53db816d7c6" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-default"><strong>1- 단일 장애 포인트</strong></mark><ul id="8fcadac8-e955-4398-b496-b2e9e0003ce0" class="bulleted-list"><li style="list-style-type:circle">특정 시스템 장애는 중앙 집중 DB 저장소 부하를 유발하고 전체 시스템 장애로 이어짐<figure id="9fd402df-b3ae-4ba0-9cd2-e479607a3f5e" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.07.01.png"><img style="width:624.0269775390625px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.07.01.png"/></a></figure></li></ul><ul id="fc2f0c01-6627-4d61-90e9-df72a53d8284" class="bulleted-list"><li style="list-style-type:circle">개별 시스템은 시스템에 맞는 도메인을 모델링하여 중앙 DB 의존성을 제거</li></ul><ul id="e98f0d8b-9351-4fae-8034-792d5db1a720" class="bulleted-list"><li style="list-style-type:circle">자체 DB 구성으로 MSA 구성 및 Message Queue 를 이용한 이벤트 기반 통신으로 시스템 간 영향도를 분리<ul id="4507ca2b-d081-451b-a2f2-9418da75b226" class="bulleted-list"><li style="list-style-type:square">특정 시스템 장애는 메시지 발행 실패로 인한 지연 현상만 발생, 시스템 복구시 이벤트 재발행</li></ul><figure id="77fe07c4-28bb-41b7-a40d-e643e4acfe31" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.04.27.png"><img style="width:624.0269775390625px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.04.27.png"/></a></figure><figure id="803c3144-7324-4115-b295-170f42bffa0b" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.03.39.png"><img style="width:624.0269775390625px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.03.39.png"/></a></figure></li></ul></li></ul><ul id="347b7fd1-a174-4cdb-8a22-9e106392f7fd" class="bulleted-list"><li style="list-style-type:disc"><strong>2-대용량 데이터 RDB 조회 성능 저하 문제</strong><ul id="3b5f5968-c16a-421d-a934-5b21343af610" class="bulleted-list"><li style="list-style-type:circle">주문 시스템 아키텍쳐 - 주문 요청 시 주문 API를 통한 이벤트 발행, 주문 데이터 저장 <figure id="bc037e6b-c7d5-4929-97f1-f4f771b1b769" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.10.00.png"><img style="width:596.0369262695312px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.10.00.png"/></a></figure></li></ul><ul id="aa4434ff-26dc-45f7-82ef-e5941afa87bd" class="bulleted-list"><li style="list-style-type:circle">주문 인터널 API를 통한 조회 요청 처리<figure id="c9f448e3-f444-4467-be4f-068381fa3940" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.20.58.png"><img style="width:596.0369262695312px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.20.58.png"/></a></figure></li></ul><ul id="6a7a3fae-3e6e-4b0d-ad69-e4a540f4ab2b" class="bulleted-list"><li style="list-style-type:circle">조인 연산으로 인한 성능 저하<figure id="daee57d9-ceb4-4957-a6c5-9b8cdd3ef1b7" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.23.39.png"><img style="width:568.046875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.23.39.png"/></a></figure></li></ul><ul id="d2209c04-fea8-42c6-b672-9143b5b0b71a" class="bulleted-list"><li style="list-style-type:circle">조회 성능을 높이기 위해 단일 도큐먼트로 역정규화를 진행<figure id="c437b73f-2a92-4f1c-975e-6c788e79fba0" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.24.37.png"><img style="width:568.046875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.24.37.png"/></a></figure></li></ul><ul id="831cc6aa-05cf-4f1d-8cf3-422fa4e30c39" class="bulleted-list"><li style="list-style-type:circle">주문 도메인 생명주기에 발생되는 도메인 이벤트를 통해 주문이벤트 서비스 처리기에서 몽고 DB에 데이터 동기화<figure id="ac4a2dfa-c78e-4be8-a3d6-485f34158976" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.17.31.png"><img style="width:596.0369262695312px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.17.31.png"/></a></figure></li></ul><ul id="cff446ef-eb7c-417d-8040-a4299072c14c" class="bulleted-list"><li style="list-style-type:circle">커맨드 모델과 조회 모델을 분리, 조회 모델 역정규화를 통해 조회 성능 개선<figure id="4596861a-1982-4c7a-bb0c-e57e9a12811d" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.16.13.png"><img style="width:596.0369262695312px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.16.13.png"/></a></figure></li></ul></li></ul><ul id="a6c4b866-ee58-4803-b331-eb596b47ecf5" class="bulleted-list"><li style="list-style-type:disc">3-대규모 트랜잭션 - 주문 DB의 분당 쓰기 처리량 한계치 도달<ul id="519ebbd6-1ebc-4497-8fa9-21c04c1c69bb" class="bulleted-list"><li style="list-style-type:circle">실시간성 조회 요청은 스케일 아웃으로 대응<figure id="4b520490-df34-42ae-8f76-fb3fd8bfd4dd" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.29.50.png"><img style="width:656.0084838867188px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.29.50.png"/></a></figure></li></ul><ul id="021a8052-1556-4623-b5be-e7ea2401f725" class="bulleted-list"><li style="list-style-type:circle">주문 DB 쓰기 부하 분산은 스펙업으로 대응 —&gt; 한계 도달<figure id="00c57e0b-a93c-4433-92ae-c0f5393d98fb" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.29.15.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.29.15.png"/></a></figure></li></ul><ul id="c7ab694e-cf8e-4398-a64b-3abf178a39e3" class="bulleted-list"><li style="list-style-type:circle">쓰기 요청 증가를 DB 샤딩 분산 처리를 통해 스케일 아웃으로 대응 가능<figure id="98dfd62c-c824-4586-be11-6e97a7912f01" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.50.35.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.50.35.png"/></a></figure><figure id="af29b165-a479-4b5d-9da3-9ed778b44409" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.51.40.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.51.40.png"/></a></figure><figure id="0dbe48e5-7d93-4926-b4c3-4dfbdbf8aca2" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.49.53.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.49.53.png"/></a></figure><figure id="5a9b82e5-4fa9-47a6-87de-be63e359a1d7" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.52.29.png"><img style="width:613.99853515625px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.52.29.png"/></a></figure><figure id="3975ba5c-473d-40f9-bbf7-8216134539a9" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.53.00.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.53.00.png"/></a></figure><p id="33a9d6e8-7202-4f0a-b5af-785d5281ff46" class="">
</p></li></ul></li></ul><ul id="dec779d9-066d-43ee-a41b-60b91bd40028" class="bulleted-list"><li style="list-style-type:disc">4-복잡한 이벤트 아키텍처<ul id="677f95ff-1351-4004-897d-c9c8043cedce" class="bulleted-list"><li style="list-style-type:circle">주요 도메인 로직과 서비스 로직을 이벤트를 기반으로 관심사를 분리<figure id="8ab61b13-2a56-4fc9-a48e-68ff01789fc9" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.54.36.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.54.36.png"/></a></figure><figure id="3e539e3d-d74f-4b66-a838-e09137ef7a3c" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.05.31.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.05.31.png"/></a></figure><figure id="4863ef3c-0e44-4b98-b5d6-016738162ef9" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.07.52.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.07.52.png"/></a></figure></li></ul><ul id="5a5ceb02-a882-4e03-a06c-41a1c40a71f6" class="bulleted-list"><li style="list-style-type:circle">이벤트 로직을 단일 애플리케이션에 위임하여 관리 포인트를 집중<figure id="0e958839-b330-4668-a7ee-d5988e523092" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.07.07.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.07.07.png"/></a></figure><figure id="5abd1a4a-b740-4de0-b3cb-ca4fb3c14a6d" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.04.52.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.04.52.png"/></a></figure></li></ul><ul id="0e237d14-dfa4-48a2-821b-f97cdb2aa157" class="bulleted-list"><li style="list-style-type:circle">이벤트 유실은 트랜잭션 아웃박스 패턴을 활용하여 유실 발생 시 어플리케이션을 통해 재발행<figure id="29e550ac-b269-4de1-ab98-184b1f2e7866" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.03.33.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.03.33.png"/></a></figure><figure id="5aa54b91-6855-4d46-a0bb-caee2452a4ee" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.03.11.png"><img style="width:628.0184326171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.03.11.png"/></a></figure></li></ul></li></ul><ul id="868a4652-d0ce-41bd-ae94-79540c59da2f" class="bulleted-list"><li style="list-style-type:disc">최종 아키텍쳐<ul id="2c16b07b-2199-4ae8-840b-f254f2551749" class="bulleted-list"><li style="list-style-type:circle">일평균 300만건 처리</li></ul><figure id="eed830e6-a87e-4800-9dab-07bc234700a3" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.09.57.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.09.57.png"/></a></figure><figure id="4f72f96c-c5a4-4592-90f0-5541da8b96b0"><a href="https://www.youtube.com/watch?v=704qQs6KoUk&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=5" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">대규모 트랜잭션을 처리하는 배민 주문시스템 규모에 따른 진화 #우아콘2023 #우아한형제들</div><div class="bookmark-description">[WOOWACON2023 세션 다시보기]

👉 세션 설명

5년 전 배달의민족에 합류했을 때, 주문시스템은 급격하게 증가하는 주문수를 처리하기 어려운 시스템이었습니다.
5년간 주문시스템은 “주문DB 샤딩“, “CQRS 적용” 등 여러 작업들을 통해 일 300만 건 이상의 주문수를 처리하는 안정적인 시스템이 되었습니다.
대규모 트랜잭션을 처리하는 배민 주문시스템이 변화해간 내용을 공유합니다.ㅤ
ㅤ
👉 발표자 소개ㅤ

푸드주문서버개발팀 강홍구

일 300만 건 이상의 주문수를 처리하는 배민 주문시스템 서버 개발을 하고 있습니다. 내가 만든 서비스를 누군가 사용해주면 보람을 느끼는 개발자입니다. 커머스 도메인은 하나도 몰랐던 제가 5년간 주문서비스를 개발하며 경험한 경험들을 공유하고 싶습니다.

👍 추천 대상

대용량 트래픽을 처리하는 도메인의 아키텍처가 궁금하신 분

🙋🏻‍♀️ 세션에 대해 궁금한 점이 있다면 dev_relations@woowahan.com 으로 문의주시기 바랍니다.</div></div><div class="bookmark-href"><img src="https://www.youtube.com/s/desktop/5766dddc/img/favicon_144x144.png" class="icon bookmark-icon"/>https://www.youtube.com/watch?v=704qQs6KoUk&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=5</div></div><img src="https://i.ytimg.com/vi/704qQs6KoUk/maxresdefault.jpg" class="bookmark-image"/></a></figure></li></ul><p id="c2d0608a-69a4-498b-bef0-bbae6b35fabb" class="">
</p></details></li></ul><ul id="490722ae-9bd1-487f-92b9-9f699aa9773b" class="toggle"><li><details open=""><summary><mark class="highlight-blue_background">배민 - 우리 팀은 카프카를 어떻게 사용하고 있을까</mark></summary><hr id="1c43a4cc-090a-8032-9390-ee70fc1fcab2"/><ul id="1c43a4cc-090a-8088-af37-d3ff355c4879" class="bulleted-list"><li style="list-style-type:disc">주문과 배달의 이벤트 순서가 중요하며, 이벤트가 누락되지 않도록 관리해야 합니다. <ul id="1c43a4cc-090a-80d1-ac14-ead3d1c01a79" class="bulleted-list"><li style="list-style-type:circle"><span style="border-bottom:0.05em solid">카프카를 이벤트 브로커로 사용하고, 이벤트 발생 순서를 보장</span>하고 있습니다. <ul id="1c43a4cc-090a-80e3-a32b-d89e2e827b58" class="bulleted-list"><li style="list-style-type:square">같은 카프카 클러스터에서 주문, 배달, 분석 토픽 등 목적에 따라 토픽을 구성할 수 있으며, </li></ul><ul id="1e23a4cc-090a-8027-a37f-eb26b151452a" class="bulleted-list"><li style="list-style-type:square"><span style="border-bottom:0.05em solid">하나의 토픽은 병렬처리로 처리량을 높이기 위해 여러 개의 파티션으로 구성됩니다. </span></li></ul><ul id="1c43a4cc-090a-80e1-bb50-d590daef3744" class="bulleted-list"><li style="list-style-type:square">카프카에서는 같은 파티션에 대해서 프로듀서가 보낸 데이터의 순서를 보장합니다. </li></ul><ul id="1e23a4cc-090a-803e-a1e0-deda7318a6e8" class="bulleted-list"><li style="list-style-type:square">같은 키를 가진다면 같은 파티션으로 할당되고, 하나의 파티션에 하나의 컨슈머가 할당됩니다. </li></ul><ul id="1e23a4cc-090a-802b-a4b8-cb447c93db78" class="bulleted-list"><li style="list-style-type:square">따라서 같은 키에 대해서는 분산시스템에서도 같은 서버가 소비하게 되어 이벤트 순서가 보장될 수 있습니다. </li></ul></li></ul><ul id="1c43a4cc-090a-8072-b2f1-c10372f28cc6" class="bulleted-list"><li style="list-style-type:circle">배달을 놓치지 않고 처리하기 위해서 T<span style="border-bottom:0.05em solid">ransactional Outbox Pattern을 사용하여 순서를 보장한 재시도를 통해 이벤트 누락이 없도록 처리</span>하고 있습니다.<ul id="1c43a4cc-090a-806c-9e86-d420063372fe" class="bulleted-list"><li style="list-style-type:square">Transactional Outbox Pattern은 분산 시스템에서 데이터베이스 트랜잭션과 메시지 큐를 조합하여 데이터 일관성과 메시지 전송의 원자성을 보장하는 패턴입니다. </li></ul><ul id="1e23a4cc-090a-80a5-90cd-fc201f6b6dc0" class="bulleted-list"><li style="list-style-type:square">분산시스템에서 트랜잭션 완료 후, 이벤트를 보내야 하는 경우에 트랜잭션에 실패할 경우 데이터는 롤백되지만, 이벤트는 발송될 수 있고, 메시지 전송 중 문제가 발생하는 경우 메시지 전송 원자성이 보장되지 않을 수 있습니다. 문제를 해결하기 위한 이 패턴의 핵심 아이디어는 다음과 같은 흐름으로 진행됩니다.<ol type="1" id="1c43a4cc-090a-8028-84a3-cbd968935308" class="numbered-list" start="1"><li><span style="border-bottom:0.05em solid">트랜잭션 데이터베이스에 Outbox 테이블을 도입하여, 트랜잭션 완료 시 변경 사항을 기록</span>합니다.</li></ol><ol type="1" id="1c43a4cc-090a-802a-8296-c461192080c5" class="numbered-list" start="2"><li><span style="border-bottom:0.05em solid">Outbox 테이블에 새로운 레코드가 추가될 때마다 변경 사항을 메시지로 전송</span>합니다.</li></ol></li></ul></li></ul></li></ul><ul id="1c43a4cc-090a-8096-94ff-cdfcd1e06d3a" class="bulleted-list"><li style="list-style-type:disc"><span style="border-bottom:0.05em solid">카프카 스트림즈를 활용하여 실시간 배달 정보를 집계하여 배달 상황을 파악</span>할 수 있도록 한다.<ul id="1c43a4cc-090a-8044-8686-ea82671d3f90" class="bulleted-list"><li style="list-style-type:circle">배치 등을 사용하여 분석을 위한 데이터를 제공할 수도 있지만, 일정 주기로 배치를 수행하기 때문에 실시간 데이터를 반영하기 어려운 문제가 있습니다. </li></ul><ul id="1e23a4cc-090a-80f0-8d4a-ce1babdfaa53" class="bulleted-list"><li style="list-style-type:circle">우리 팀에서는 실시간 혹은 준실시간에 해당하는 데이터를 조회하여 배달현황을 파악하고 서비스에 반영하기를 원했습니다. 요구사항을 만족시킬 기술로 카프카 스트림즈를 활용하고 있습니다.</li></ul><ul id="1c43a4cc-090a-807c-a6f2-f1ae44eac1c6" class="bulleted-list"><li style="list-style-type:circle">카프카 스트림즈는 카프카에서 실행하는 이벤트별 데이터(레코드) 처리를 수행할 수 있게 하는 라이브러리입니다. 간단히 말하자면, 카프카 스트림즈는 메시지를 활용한 실시간 집계, 분석 시스템으로 실시간 데이터 스트리밍 및 분석 시스템에 적합한 플랫폼으로 폭넓게 활용되는 도구입니다</li></ul><ul id="1c43a4cc-090a-8064-8e99-f46af929bc63" class="bulleted-list"><li style="list-style-type:circle">카프카 스트림즈 애플리케이션이 처리하는 것은 데이터의 흐름입니다. 전처리 단계와 스트림 연결로 데이터 스트림을 입력받아 필요한 처리를 수행 후, 새로운 스트림을 생성하여 데이터를 처리하고 결과를 산출하는 방식으로 동작합니다.</li></ul></li></ul><hr id="1c43a4cc-090a-800f-9129-c5508192e51a"/><p id="7c6f4cd9-9d08-4cbe-b140-6878957eaab6" class="">아래와 같은 키워드가 등장합니다. 각 문단에서 개념을 간단하게 설명하며 진행할 예정이나 관련 배경지식이 있다면 더 쉽게 이해할 수 있을 것으로 예상됩니다.</p><ul id="85613f36-824a-4caa-8beb-92b200b7467e" class="bulleted-list"><li style="list-style-type:disc">Kafka</li></ul><ul id="328fdd98-2f27-4d97-9ede-7c23e8a3f3fa" class="bulleted-list"><li style="list-style-type:disc">Transactional Outbox Pattern</li></ul><ul id="39ee58c3-ddf3-478d-91d6-95dc15c64503" class="bulleted-list"><li style="list-style-type:disc">Event Bus</li></ul><ul id="84321346-1408-42d0-ade7-dec23544f672" class="bulleted-list"><li style="list-style-type:disc">Kafka Streams</li></ul><h1 id="915f08de-1d7b-46e0-a226-7daef52fec67" class=""><strong>카프카, 한 섹션 요약</strong></h1><p id="048f2f85-92c3-4b14-8102-ffbf6a671abf" class="">먼저 카프카를 매우 간단하게 알아보겠습니다. 카프카는 분산 스트리밍 플랫폼으로, 대량의 데이터를 처리하고 실시간으로 전송하는 데 사용됩니다. 모든 데이터는 로그 형식으로 파일 시스템에 기록됩니다. 여기서 말하는 로그는 추가만 가능하며, 시간순으로 완전히 정렬된 데이터의 흐름(레코드 시퀀스)을 의미합니다. 로그를 한곳에 모아 처리할 수 있도록 중앙집중화되어 있으며, 대용량 데이터를 수집하고 실시간 스트리밍으로 소비가 가능합니다.</p><p id="bd43e400-e474-4368-b62e-d0800c897211" class="">메시지(레코드)는 발행처(프로듀서)가 보낸 순서로 기록되어 순서가 보장되며, 메시지의 위치 값(offset)으로 소비자(컨슈머)가 소비한 메시지의 위치를 표시합니다. 각 컨슈머 그룹마다 메시지의 위치 값을 가지고 있기 때문에 같은 소스에서 서로 다른 여러 개의 컨슈머 그룹이 개별적으로 소비가 가능합니다. 한 소스(Single Origin)에서 여러 소비자가 손실이나 변형 없이 메시지를 소비할 수 있으며, 원천 데이터를 기반으로 데이터 분석도 가능합니다.</p><p id="2cef9757-d540-4d90-b527-90fda0f8b586" class="">아래는 이 글을 이해하는 데 필요한 카프카의 기본적인 용어와 개념입니다.</p><ul id="8f669a86-5f4c-4a30-8be0-1ffb1b842e75" class="bulleted-list"><li style="list-style-type:disc">토픽(Topic): 데이터의 주제를 나타내며, 이름으로 분리된 로그입니다. 메시지를 보낼 때는 특정 토픽을 지정합니다.</li></ul><ul id="912ea3f0-2ab4-4c64-b82b-64a788f01a43" class="bulleted-list"><li style="list-style-type:disc">파티션(Partition): 토픽은 하나 이상의 파티션으로 나누어질 수 있으며, 각 파티션은 순서가 있는 연속된 메시지의 로그입니다. 파티션은 병렬 처리를 지원하고, 데이터의 분산 및 복제를 관리합니다.</li></ul><ul id="9f09a65f-c39c-4c22-82af-8a7af4fbf685" class="bulleted-list"><li style="list-style-type:disc">레코드(Record): 레코드는 데이터의 기본 단위로 키와 값(key-value pair) 구성입니다.</li></ul><ul id="f6ed4290-8c34-4c9c-98b2-c3f740833a64" class="bulleted-list"><li style="list-style-type:disc">오프셋(Offset): 특정 파티션 내의 레코드 위치를 식별하는 값입니다.</li></ul><ul id="60cef9c8-86f4-4663-8f11-2b086cc94d6b" class="bulleted-list"><li style="list-style-type:disc">프로듀서(Producer): 데이터를 토픽에 보내는 역할을 하며, 메시지를 생성하고 특정 토픽으로 보냅니다.</li></ul><ul id="57eaf13e-b705-4e2b-bac4-d8cfcf1791d3" class="bulleted-list"><li style="list-style-type:disc">컨슈머(Consumer):토픽에서 데이터를 읽는 역할을 하며, 특정 토픽의 메시지를 가져와서(poll) 처리합니다. 컨슈머 그룹은 여러 개의 컨슈머 인스턴스를 그룹화하여 특정 토픽의 파티션을 공유하도록 구성합니다. 이를 통해 데이터를 병렬로 처리하고 처리량을 증가시킬 수 있습니다.</li></ul><ul id="868a9aa1-fe9b-4d7a-8971-2763e659600f" class="bulleted-list"><li style="list-style-type:disc">카프카 커넥터(Connector): 카프카와 외부 시스템을 연동 시 쉽게 연동 가능하도록 하는 프레임워크로 MySQL, S3 등 다양한 프로토콜과 연동을 지원합니다.<ul id="61b92cfa-89dc-4333-a302-20b684037453" class="bulleted-list"><li style="list-style-type:circle">소스커넥터(source connector): 메시지 발행과 관련 있는 커넥터</li></ul><ul id="2e89ef71-5c23-4a50-be56-79715c438f62" class="bulleted-list"><li style="list-style-type:circle">싱크커넥터(sink connector): 메시지 소비와 관련 있는 커넥터</li></ul></li></ul><figure id="b0f06dba-ed4c-4917-a695-e3eff1f212d4" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled.png"/></a></figure><h1 id="2e5d0416-a0ce-4783-a987-2866c64a658d" class=""><strong>우리팀에서 활용하는 방식</strong></h1><p id="7ebc6ac2-1f2a-4c36-9ee2-14b9bd9eb68f" class="">딜리버리서비스팀은 하루 100만 건 이상 생성되는 배민배달(배달의 민족에서 관리하는 자체 배달)을 중계하는 역할을 합니다. 배달의 민족에서 제공하는 여러 주문서비스(배민배달, B마트, 배민스토어)의 배민배달을 받아 여러 배달서비스 중 하나로 분배하고, 배달과정을 중계하고 관리하는 역할을 합니다. 주문과 배달을 처리하는 방식으로 분산시스템 이벤트 기반 아키텍처를 사용하고 있으며, 카프카를 팀에서 주요 기술 중 하나로 사용하고 있습니다. 팀의 분산시스템이 어떻게 나뉘어 있는지 간략하게 설명하고, 카프카를 팀에서 활용하는 방식을 소개하겠습니다.</p><p id="fdc5170e-bef6-45a6-ab7f-88945962c0b8" class="">딜리버리서비스팀의 분산서버 구조에 대해 간략하게 설명하면 아래 그림과 같습니다.</p><figure id="ff833fe2-e22f-4041-96a5-144043c86ae5" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%201.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%201.png"/></a></figure><p id="e6ba4da5-b9a9-48d5-84cc-a526418cacf2" class="">주문이벤트를 받아 배달 프로세스를 관리하는 주문/배달서버, 발행한 이벤트를 기반으로 분석하는 분석서버로 구성되어 있습니다. 처리량을 높이고 성능을 향상시키기 위해 많은 서비스에서 그러하듯 각 서버그룹은 N개의 여러 서버로 구성됩니다.</p><h2 id="b9a39bc6-7d9e-4b9b-af3b-e632368988a5" class=""><strong>[1] 주문-배달을 안전하게 처리하자</strong></h2><h3 id="36c71ad8-e681-4716-8122-3b2ec1d1f61b" class=""><strong>미리보기</strong></h3><p id="05eeebd6-dd25-48d3-8889-b96f8a4c1718" class="">– 도메인 이벤트에 대해 카프카를 이벤트 브로커로 사용하여 이벤트 순서를 보장한다.</p><p id="7e2578f6-e3b8-436d-bb90-f193a1d92598" class="">– MySQL source connector를 이용한 Transactional Outbox Pattern을 사용하여 분산시스템에서 데이터와 메시지 전송을 하나의 트랜잭션으로 관리하여 데이터 정합성을 확보한다.</p><p id="1dda1277-3286-4e97-a0af-7381f7e1a5b2" class="">주문이 발생하면 고객에게 배달이 완료될 때까지 안전하게 처리하는 것이 가장 큰 목표입니다. 그 과정을 혼란스럽지 않게 처리하기 위해서는 주문과 배달의 이벤트 순서가 중요하며, 이벤트가 누락되지 않도록 관리해야 합니다. 카프카를 이벤트 브로커로 사용하고, 이벤트 발생 순서를 보장하고 있습니다. 배달을 놓치지 않고 처리하기 위해서 Transactional Outbox Pattern을 사용하여 순서를 보장한 재시도를 통해 이벤트 누락이 없도록 처리하고 있습니다.</p><h3 id="95604f92-f299-4abc-b137-d4af725c4cd4" class=""><strong>순서보장</strong></h3><p id="b8f33954-31d9-47be-80f2-36886ff7e2cc" class="">배달프로세스를 간략하게 나타내면 아래 그림과 같습니다. 배달이 진행되면서 여러 이벤트가 발행되고, 몇 가지 이벤트는 배달상태를 변경시킵니다. 배달상태는 순서가 있기 때문에 순서대로 진행되며, 특정 이벤트들은 거의 동시에 발생하기도 하고, 배달상태를 변경시기키도 합니다. 혼란스럽지 않은 배달프로세스를 관리하기 위해서는 이벤트 발행과 관련하여 순서를 보장하는 것이 중요합니다.</p><figure id="98d338f1-c811-4966-89fc-abd063b970e7" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%202.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%202.png"/></a></figure><p id="844cb876-4352-4d69-8bcc-24a70e9e29a1" class="">예를 들어, 배차완료와 거의 동시에 픽업준비요청이 발생할 수 있습니다. 프로듀서는 배차완료 이후 픽업준비요청을 발행하였으나 네트워크 등의 이슈로 컨슈머는 픽업준비요청 이후, 배차완료를 수신할 수도 있습니다. 이런 경우, 순서가 보장되지 않는다면 컨슈머 측에서는 거의 동시에 발생한 이벤트에 대해서 어떤 이벤트가 먼저 발생한 것인지 혼란스러워 비즈니스 로직 처리에 문제가 발생할 수 있습니다.</p><p id="5ca475e2-de20-472c-8346-8d016af62d77" class="">카프카는 메시지 발행 순서에 따라 소비할 수 있도록 순서를 보장합니다. 같은 카프카 클러스터에서 주문, 배달, 분석 토픽 등 목적에 따라 토픽을 구성할 수 있으며, 하나의 토픽은 병렬처리로 처리량을 높이기 위해 여러 개의 파티션으로 구성됩니다. 카프카에서는 같은 파티션에 대해서 프로듀서가 보낸 데이터의 순서를 보장합니다. 같은 키를 가진다면 같은 파티션으로 할당되고, 하나의 파티션에 하나의 컨슈머가 할당됩니다. 따라서 같은 키에 대해서는 분산시스템에서도 같은 서버가 소비하게 되어 이벤트 순서가 보장될 수 있습니다. 주문식별자, 배달식별자 등과 같이 순서관리가 필요한 식별자를 키로 관리하여 순서를 보장합니다. 메시지 공급자가 발행 순서를 보장하기에 거의 비슷한 시점에 발행되는 메시지 동시성 이슈 발생 상황을 줄일 수 있습니다.</p><h3 id="ba511d56-3813-4662-b739-cc03f564e69d" class=""><strong>데이터 정합성</strong></h3><p id="121e543b-a9af-4905-b627-4eed86665c3a" class="">비즈니스 로직을 처리하기 위한 데이터를 MySQL 데이터베이스에 저장하고, 카프카로 이벤트를 발행하는 방식으로 데이터와 이벤트를 관리하고 있습니다. 카프카에 문제가 발생할 경우, 데이터베이스에는 변경된 배달상태가 저장되었으나 이벤트는 발행되지 않을 수도 있습니다. 예를 들어 주문취소가 발생한 경우를 생각해 봅시다. 주문취소로 배달취소가 발생하게 되면 데이터베이스에는 해당 배달은 취소된 상태로 저장될 것입니다. 하지만 이벤트 발행에 실패하게 된다면 컨슈머는 메시지를 수신하지 못해 여전히 배달을 진행할 수 있습니다. 취소된 배달이 진행되는 문제가 발생할 수 있습니다. 데이터와 메시지 발행의 트랜잭션을 하나로 관리하여 데이터 정합성을 확보할 필요가 있었습니다.</p><p id="9c5b3cb5-c7ff-4ed1-8b70-2ff25f6684f6" class="">인프라와 커넥션 이슈, 타임아웃 등의 문제로 토픽에 메시지를 넣는 과정에서 실패할 수도 있습니다. 메시지 발행에 실패하는 경우, 메시지가 누락되어 정합성이 보장되지 않기에 누락 방지를 위해서 재시도가 필요했습니다. 재시도 과정에서도 메시지의 순서는 보장되기를 바랐습니다. 하지만, 다른 비즈니스 이벤트 처리에 미치는 영향은 최소화하며 재시도를 하고 싶었습니다. 이벤트 발행에 실패하는 경우, 순서와 영향도를 고려하여 재시도를 시도하는 방법으로 <a href="https://microservices.io/patterns/data/transactional-outbox.html">Transactional Outbox Pattern</a>을 이용하였습니다.</p><p id="96d26e84-6553-4043-bc5d-fc69133b7e81" class=""><span style="border-bottom:0.05em solid">Transactional Outbox Pattern은 분산 시스템에서 데이터베이스 트랜잭션과 메시지 큐를 조합하여 데이터 일관성과 메시지 전송의 원자성을 보장하는 패턴</span>입니다. 분산시스템에서 트랜잭션 완료 후, 이벤트를 보내야 하는 경우에 트랜잭션에 실패할 경우 데이터는 롤백되지만, 이벤트는 발송될 수 있고, 메시지 전송 중 문제가 발생하는 경우 메시지 전송 원자성이 보장되지 않을 수 있습니다. 문제를 해결하기 위한 이 패턴의 핵심 아이디어는 다음과 같은 흐름으로 진행됩니다.</p><ol type="1" id="50b38991-9a57-47fc-9736-3c7321c29cc4" class="numbered-list" start="1"><li>트랜잭션 데이터베이스에 Outbox 테이블을 도입하여, 트랜잭션 완료 시 변경 사항을 기록합니다.</li></ol><ol type="1" id="52fd7c6c-19d0-43fa-a45d-56a220888c76" class="numbered-list" start="2"><li>Outbox 테이블에 새로운 레코드가 추가될 때마다 변경 사항을 메시지로 전송합니다.</li></ol><figure id="284f4065-5233-46af-8332-b030a749cd0e" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%203.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%203.png"/></a></figure><ul id="8844c363-20cd-4ed3-8ecb-8f700d52f0e2" class="bulleted-list"><li style="list-style-type:disc">출처: <a href="https://microservices.io/patterns/data/transaction-log-tailing.html">Pattern: Transaction log tailing</a></li></ul><p id="0b325d2e-1d22-42f5-b195-46abbaf62dba" class="">설명한 패턴을 구현하기 위해 <a href="https://debezium.io/">Debezium</a>이라는 라이브러리에서 지원하는 MySQL 카프카 커넥터를 이용하고 있습니다. </p><ul id="1e23a4cc-090a-8039-8533-c87919e190b6" class="bulleted-list"><li style="list-style-type:disc">Debezium은 데이터베이스의 변경 사항을 감지하고 이벤트 스트림으로 변환하는 오픈 소스 라이브러리입니다. </li></ul><ul id="1e23a4cc-090a-80e0-bdca-ff742cee5e77" class="bulleted-list"><li style="list-style-type:disc">데이터베이스의 기록인 binlog의 변경 사항을 감지(Change Data Capture)하여 읽는 로그 테일링 기법을 사용되어 있습니다. </li></ul><ul id="1e23a4cc-090a-803b-a959-dd0d2da0cc50" class="bulleted-list"><li style="list-style-type:disc">변경사항을 읽어 설정한 토픽으로 보내주는 방식으로 동작합니다. </li></ul><ul id="1e23a4cc-090a-80b0-8fcc-e1af39c24ee4" class="bulleted-list"><li style="list-style-type:disc">트랜잭션의 성공 내역을 binlog 기록하고, 기록을 순서대로 읽어가도록 동작합니다. </li></ul><ul id="1e23a4cc-090a-8090-9b73-ff4ba07233da" class="bulleted-list"><li style="list-style-type:disc">메시지 발행에 실패하면 아웃박스테이블의 데이터도 롤백되기 때문에 하나의 트랜잭션으로 데이터 정합성을 관리하고 있습니다. </li></ul><ul id="1e23a4cc-090a-80c4-8d69-d658db38046a" class="bulleted-list"><li style="list-style-type:disc">Debezium에서 메시지 발행에 사용되는 MySQL source connector는 태스크를 하나만 사용하도록 강제하기 때문에, 단일 커넥터에서 메시지 전송 순서를 보장할 수 있습니다.</li></ul><p id="8a370cde-ec17-4c85-81ad-dca8de2ec943" class="">하나의 태스크로 동작하면 테이블에 데이터가 쌓이는 속도보다 커넥터가 처리하는 속도가 느릴 경우 메시지 지연이 발생할 수 있습니다. </p><ul id="1e23a4cc-090a-80d9-87dd-f9302c29b8bc" class="bulleted-list"><li style="list-style-type:disc">처리량을 높이기 위해 토픽별로 outbox 테이블을 분리하여 만들고, 각 outbox 테이블은 식별자 기반으로 N개의 테이블로 구성하였습니다. </li></ul><ul id="1e23a4cc-090a-801c-9e67-df4158a48d0c" class="bulleted-list"><li style="list-style-type:disc">delivery-outbox1, delivery-outbox2, delivery-outbox3과 같이 여러 개의 outbox 테이블을 구성하고, 각 테이블에 커넥터를 연결하여 한 커넥터가 처리하는 양을 분산하여 처리량을 확보하였습니다. </li></ul><ul id="1e23a4cc-090a-80b0-ba41-e96f31fefd83" class="bulleted-list"><li style="list-style-type:disc">outbox 테이블은 쓰기(insert)만 동작하는 테이블로 저장된 순서대로 이벤트 메시지 발행을 보장하도록 설정되어 있습니다. </li></ul><ul id="1e23a4cc-090a-80ce-bcea-d6fffe25e75e" class="bulleted-list"><li style="list-style-type:disc">같은 키는 같은 테이블에 저장되며, 한 테이블에서는 하나의 커넥터를 사용하기 때문에 같은 키에 대해서는 순서를 보장됩니다.</li></ul><figure id="ae3490bb-ae21-4dfc-959e-e18cf1137a09" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%204.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%204.png"/></a></figure><h2 id="43734534-2b7f-4439-8883-4135ae562c02" class=""><strong>[2] 카프카를 이벤트 버스로도 활용해보자</strong></h2><h3 id="c65543a2-23d4-4117-b5c9-9a512ec5644d" class=""><strong>미리보기</strong></h3><p id="a64499ee-1ec2-4f6c-9baa-c62a59fae309" class="">– 카프카를 이벤트 버스로 활용하여 분산시스템에 알린다.</p><p id="d1962eec-ff14-48a9-bf38-c4245baea94c" class="">분산 시스템에서는 서버 여러 대로 서버군을 이룹니다. 한 서버에서 값을 변경하면 서버군에 속한 모든 서버의 변경된 값을 관리해야 할 때가 있습니다. </p><p id="1e23a4cc-090a-8092-a6fa-ccec3b02124c" class="">배달서버에서 어떤 배달서비스로 분배할지 결정하며, 분배 규칙은 인메모리로 관리합니다. 이 경우, 분배 규칙 이벤트를 소비한 배달서버만 분배규칙이 변경되고 다른 배달서버들은 기존 분배 규칙을 유지할 수 있습니다. </p><p id="1e23a4cc-090a-80e3-9e17-d6a6c0995930" class="">운영자가 필요에 의해 분배 규칙을 변경하면, 모든 배달서버는 해당 변경 값을 알아야 합니다. 카프카를 이벤트버스로 활용하여 값 관리가 필요한 서버군에 변경된 값을 알리고, 변경된 내용을 반영하도록 관리하고 있습니다.</p><p id="7d608367-07e7-4b72-8a6e-c0b0788da833" class="">스프링 클라우드에서 제공하는 RemoteApplicationEvent를 사용하여 <a href="https://cloud.spring.io/spring-cloud-bus/reference/html/index.html">이벤트 버스</a>로 카프카를 사용하고 있습니다. </p><ul id="1e23a4cc-090a-8096-814d-d8a5a96a4f1a" class="bulleted-list"><li style="list-style-type:disc">이벤트 버스 토픽(예: event-bus)을 설정하고, id는 고유해야 하기에 <code>${서버명}:${식별자}</code> 형식으로 설정합니다. </li></ul><ul id="1e23a4cc-090a-801b-ab1d-dddca898351f" class="bulleted-list"><li style="list-style-type:disc">RemoteApplicationEvent를 상속한 이벤트를 정의하고, 원하는 목적지(서버군)를 명시하여 발행하면 이벤트 버스는 목적 서버군에 이벤트를 전달합니다. </li></ul><ul id="1e23a4cc-090a-8037-8b82-fe7c35e84fa9" class="bulleted-list"><li style="list-style-type:disc">스프링 클라우드에서 id 서버명의 인스턴스에 애플리케이션 이벤트를 발행하기 때문에, 목적 서버에서 발행한 팀에서 정의한 이벤트를 구독하여 처리한다면, 정의한 이벤트를 수신하여 변경된 값을 반영할 수 있게 됩니다. </li></ul><ul id="1e23a4cc-090a-802c-843f-dad87f37be95" class="bulleted-list"><li style="list-style-type:disc">이렇게 되면 분산시스템에서 인메모리로 관리되는 값도 변경되어 같은 기준으로 비즈니스 로직을 처리할 수 있습니다.</li></ul><figure id="5adb4410-3f98-4f2a-8563-e8bb843b1f8d" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%205.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%205.png"/></a></figure><p id="5a6119c6-2067-4d66-901c-30d7c505739f" class="">RemoteApplicationEvent를 상속한 DeliveryServiceRemoteApplicationEvent를 추상클래스로 설정하고, 각 특성에 맞게 구현체를 구성하여 이벤트를 발행하여 필요한 곳에서 활용하고 있습니다. </p><p id="1e23a4cc-090a-8043-9d83-e52fdb4545ed" class="">서버군에 속한 서버들이 각자 인메모리로 저장하고 있는 값을 모두 초기화나 변경이 필요한 경우에 사용됩니다. 아래는 분배규칙 변경에 대해 RemoteApplicationEvent를 정의한 예시 코드입니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8b79d3bf-d1ba-4f33-8574-a4bc6a101e7c" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">public abstract class DeliveryServiceRemoteApplicationEvent extends RemoteApplicationEvent {
    protected DeliveryServiceRemoteApplicationEvent(String destination) {
        super(SOURCE, ORIGIN, DESTINATION_FACTORY.getDestination(destination));
    }
}
// 분배규칙 CustomRemoteEvent
public class RouteRuleRemoteEvent extends DeliveryServiceRemoteApplicationEvent {
    public RouteRuleRemoteEvent() {
        super(&quot;delivery&quot;); // destination: 배달서버
    }
}</code></pre><p id="f5d22aee-6c1d-46b9-92f8-f4e81114e1f9" class="">아래는 분배규칙이 변경되어 새롭게 내려받아야 하는 경우, 서버에서 메서드를 수행하고 배달서버군 전체에도 변경된 규칙이 반영될 수 있도록 RemoteApplicationEvent를 발행하고, 소비하는 예시 코드입니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="df5b873c-b939-423a-9962-d7edf6e46c4b" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">public void load() {
    routeRuleSetStore.load();
    remoteApplicationEventPublisher.publishEvent(new RouteRuleRemoteEvent());
}

@EventListener
public void handle(RouteRuleRemoteEvent event) {
    routeRuleSetStore.load();
}</code></pre><p id="e99d2136-a15b-4e21-942d-06c194eb61c2" class="">딜리버리서비스팀에서 이벤트 버스 토픽은 하나의 파티션으로 관리하고 있습니다. </p><p id="1e23a4cc-090a-8088-9571-e88a6dbc3c72" class="">설정값을 변경하는 데 높은 처리량이 필요하지 않고, 같은 서버군은 같은 변경사항을 수신해야 하기 때문입니다. </p><p id="1e23a4cc-090a-80fd-9985-f6c814504a05" class="">파티션에서 같은 컨슈머 그룹은 오프셋을 공유하므로 모든 서버는 다른 컨슈머 그룹 아이디(consumer group id)를 가져야 합니다. </p><p id="1e23a4cc-090a-8018-9254-f1d6acec2234" class="">여러 컨슈머에게 개별적으로 소비될 수 있기 때문에 각 서버가 다른 컨슈머 그룹 아이디를 사용한다면 한 번의 이벤트 발행으로도 여러 서버군의 설정을 바꾸는 것이 가능합니다. </p><p id="1e23a4cc-090a-8084-974b-fc15e474491e" class="">특수하게 컨슈머의 이름을 정하지 않으면, 스프링 클라우드에서는 anomymous라는 프리픽스를 붙여 랜덤하게 컨슈머 그룹 아이디를 설정합니다. </p><p id="1e23a4cc-090a-80ee-a961-e11f42f7d7dc" class="">즉, 연결된 서버만큼 <code>anonymous.{식별자}</code> 형식의 컨슈머 그룹 아이디가 생성되고 있고, 시스템 모니터링 시에는 anomymous 컨슈머는 필터링하고 있습니다.</p><h2 id="fab569db-60e3-40e6-994a-fdf659a62429" class=""><strong>[3] 더 나은 배달을 위해 분석하자</strong></h2><h3 id="04d05522-1270-4953-b1bd-a001419ce47d" class=""><strong>미리보기</strong></h3><p id="0543e5d5-1f82-4321-8a19-752db7d2809e" class="">– 분석에 적합하게 가공된 형태로 데이터를 제공한다.</p><p id="4a7ed02b-741d-4e62-8f1b-14f33b2c86a8" class="">– 카프카 스트림즈를 활용하여 실시간 배달 정보를 집계하여 배달 상황을 파악할 수 있도록 한다.</p><p id="6cc52012-0b6f-4530-9d54-4247b4b7ccde" class="">배치 등을 사용하여 분석을 위한 데이터를 제공할 수도 있지만, 일정 주기로 배치를 수행하기 때문에 실시간 데이터를 반영하기 어려운 문제가 있습니다. </p><ul id="1e23a4cc-090a-804d-bf55-c38194ff946a" class="bulleted-list"><li style="list-style-type:disc">우리 팀에서는 실시간 혹은 준실시간에 해당하는 데이터를 조회하여 배달현황을 파악하고 서비스에 반영하기를 원했습니다. 요구사항을 만족시킬 기술로 카프카 스트림즈를 활용하고 있습니다.</li></ul><p id="3f4177bc-b1a3-4990-8df2-2fd01bab0751" class="">카프카 스트림즈는 카프카에서 실행하는 이벤트별 데이터(레코드) 처리를 수행할 수 있게 하는 라이브러리입니다. </p><ul id="1e23a4cc-090a-802f-9ec3-cf00610aaf9e" class="bulleted-list"><li style="list-style-type:disc">간단히 말하자면, 카프카 스트림즈는 메시지를 활용한 실시간 집계, 분석 시스템으로 실시간 데이터 스트리밍 및 분석 시스템에 적합한 플랫폼으로 폭넓게 활용되는 도구입니다. </li></ul><ul id="1e23a4cc-090a-8085-b5a8-cf50ec024311" class="bulleted-list"><li style="list-style-type:disc">카프카 스트림즈 애플리케이션이 처리하는 것은 데이터의 흐름입니다. </li></ul><ul id="1e23a4cc-090a-80a9-8910-e69782d5d369" class="bulleted-list"><li style="list-style-type:disc">전처리 단계와 스트림 연결로 데이터 스트림을 입력받아 필요한 처리를 수행 후, 새로운 스트림을 생성하여 데이터를 처리하고 결과를 산출하는 방식으로 동작합니다.</li></ul><h3 id="3b5fbd61-aa99-4b22-bd1e-9a6dc4516ee9" class=""><strong>분석용으로 가공한 데이터 제공</strong></h3><p id="53725566-f89f-423d-8ad5-f9e616ffe193" class="">분석 서버에서는 배달 이벤트를 수신한 후 전처리 과정을 거쳐, 조회하기 편한 형태로 가공하여 분석 토픽으로 이벤트를 재발행합니다. </p><ul id="1e23a4cc-090a-8038-acc0-caa153e5e3de" class="bulleted-list"><li style="list-style-type:disc">원본 이벤트를 가공하여 분석할 수 있도록 또 다른 토픽과 스트림으로 생성합니다. </li></ul><ul id="1e23a4cc-090a-8050-80cc-d976bc7204a9" class="bulleted-list"><li style="list-style-type:disc">목적이 다르기에 원본 토픽과 분석용 토픽을 분리하여 사용합니다. </li></ul><ul id="1e23a4cc-090a-8063-952e-db617731c818" class="bulleted-list"><li style="list-style-type:disc">서비스 토픽과 분석용 토픽은 서로 다른 데이터 처리량과 리소스가 필요하기에 토픽과 서버를 분리하여 특성에 맞는 리소스를 사용하고 조정할 수 있도록 구성하였습니다. </li></ul><ul id="1e23a4cc-090a-8082-872e-f7bfc60d7409" class="bulleted-list"><li style="list-style-type:disc">주요한 서비스 로직에 사용되는 토픽과 분석에 사용되는 토픽은 문제가 발행하더라도 영향범위를 분리하여 관리할 수 있습니다.</li></ul><p id="7778f799-67e3-4d37-8c15-9785de3584e5" class="">배달은 생성, 배차, 픽업, 완료 등 순서를 가지고 진행되며, 특정 행위마다 배달이벤트를 발행합니다. </p><ul id="1e23a4cc-090a-8074-a7b0-cf3381dcc347" class="bulleted-list"><li style="list-style-type:disc">분석이 필요한 경우, 배달의 이벤트를 하나하나 보는 것이 아닌 배달 건별로 정리된 정보를 확인하고 싶은 경우가 많습니다. </li></ul><ul id="1e23a4cc-090a-807d-a099-eb084f299d58" class="bulleted-list"><li style="list-style-type:disc">주요 정보는 어떻게 되는지, 언제 생성되어 배차, 완료가 되었는지 등 배달 한 건에 주요 정보를 집계해 확인하고자 하는 수요가 있었습니다. </li></ul><ul id="1e23a4cc-090a-807a-88d6-fee1909d92f5" class="bulleted-list"><li style="list-style-type:disc">분석하기 편하도록 전처리 과정을 거쳐 한 배달건에 대해 발생한 여러 이벤트를 하나로 모아 완료된 배달 건의 요약된 종합 정보를 제공하고 있습니다. </li></ul><ul id="1e23a4cc-090a-80d5-a883-d85fd1f2d0e9" class="bulleted-list"><li style="list-style-type:disc">이때 Redis를 임시저장소로 활용하여 종합데이터를 관리합니다. </li></ul><ul id="1e23a4cc-090a-8029-9b72-df6543680664" class="bulleted-list"><li style="list-style-type:disc">원본 배달 토픽에서 배달생성 이벤트를 수신하면 Redis에 주요한 주문과 배달 정보를 저장합니다. </li></ul><ul id="1e23a4cc-090a-808c-9882-e0c1ef9b22f7" class="bulleted-list"><li style="list-style-type:disc">이후, 배달 진행에 따라 발행된 이벤트를 수신하면 각 배달이벤트 시점 등 주요한 정보를 업데이트합니다. </li></ul><ul id="1e23a4cc-090a-8067-889d-e95a5e50a793" class="bulleted-list"><li style="list-style-type:disc">완료된 배달은 Redis에서 삭제하고, 의미 있는 정보로 구성한 새로운 배달통합이벤트를 분석 토픽에 발행하여 배달 건별 종합데이터를 제공합니다.</li></ul><p id="4fbc016d-af01-4e84-a2d7-275efd193b1d" class="">S3 싱크 커넥터를 사용하여 분석토픽에 들어간 이벤트는 AWS S3 객체저장소에 보내 영구 저장하고 있습니다. </p><ul id="1e23a4cc-090a-8037-b758-de7c1f2839ff" class="bulleted-list"><li style="list-style-type:disc">이벤트 영구 저장소와 비즈니스 로직을 처리하기 위한 저장소를 분리하여, 분석용 서비스와 비즈니스 서비스의 상호 영향을 최소화합니다. </li></ul><ul id="1e23a4cc-090a-80f4-a9a8-fa96b925758f" class="bulleted-list"><li style="list-style-type:disc">S3 객체저장소에 저장된 데이터는 <a href="https://aws.amazon.com/ko/athena/">AWS Athena</a>를 사용해 비즈니스 서비스 저장소에 부하를 주지 않고 오래된 기록까지 조회할 수 있습니다. </li></ul><ul id="1e23a4cc-090a-8007-acef-f1bf1f641b1b" class="bulleted-list"><li style="list-style-type:disc">데이터를 분석할 수 있는 도구를 연동하여 사업이나 운영 부서에서 지난 배달 건을 월단위로 분석하기도 하고, 정산에 활용하기도 합니다.</li></ul><p id="da9749c7-c92b-4adc-81c1-847de469abfb" class="">아래 그림은 통합배달이벤트 흐름과 이후 실시간 데이터 제공과 관련된 다이어그램입니다.</p><figure id="f084bc25-203c-442f-bccc-0979a887c3c8" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%206.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%206.png"/></a></figure><h3 id="7f132602-f7a3-45e1-95ff-4a5cc9646fa1" class=""><strong>실시간 데이터 제공</strong></h3><p id="8470f372-b264-4b0d-948b-9263e38bd229" class="">배차 대기로 남아있는 배달 건이 얼마나 되는지, 현재 배차에 시간이 얼마나 걸리는지, 주문서비스별 유입량은 어떻게 되는지 등 실시간 배달 데이터를 알고 싶었기에 스트림즈 애플리케이션을 활용하여 실시간 배달데이터를 집계하고 있습니다. </p><ul id="1e23a4cc-090a-8099-ae8f-da6bce7b84ea" class="bulleted-list"><li style="list-style-type:disc">실시간 집계된 내용은 그라파나 대시보드로 시각화하여 운영 상황에 대응할 수 있도록 제공하고 있고, 배달인프라 상황을 파악하여 분석하는 데도 사용됩니다.</li></ul><p id="f525b999-0312-4b8c-9a5e-3f20e0c0f7df" class="">각 배달상태에 따른 배달 건수가 얼마나 되는지 실시간 집계하는 한 가지 예시를 들어보겠습니다. </p><ul id="1e23a4cc-090a-8044-bdba-d1fc0f476e69" class="bulleted-list"><li style="list-style-type:disc">분석용 배달토픽에 들어온 레코드 흐름(Stream)을 기반으로 최신 배달 상태저장소(latest-delivery)를 구축합니다. </li></ul><ul id="1e23a4cc-090a-80da-9af8-e1f8b5489206" class="bulleted-list"><li style="list-style-type:disc">상태저장소(statestore)는 키-값 임시저장소입니다. </li></ul><ul id="1e23a4cc-090a-8021-9650-cd0806ab04ce" class="bulleted-list"><li style="list-style-type:disc">최신 배달 상태저장소에는 레코드의 시간을 기준값으로 최신 배달을 판단하며, 키를 배달식별자로 하고 값을 배달데이터로 합니다. 최신 배달을 기준으로 배달 상태별 개수를 집계할 수 있습니다. </li></ul><ul id="1e23a4cc-090a-80ff-bc3b-e84c784daaac" class="bulleted-list"><li style="list-style-type:disc">키는 배달상태, 값은 집계된 배달 상태별 개수로 배달상태별 상태저장소(count-per-status)를 구성합니다. </li></ul><ul id="1e23a4cc-090a-8065-900c-cb4da4288019" class="bulleted-list"><li style="list-style-type:disc">그 결과로 배달상태별 상태저장소에서 실시간으로 배달상태별로 집계된 결과를 빠르게 조회할 수 있습니다.</li></ul><ul id="1e23a4cc-090a-8066-880f-ceb03ffde9ce" class="bulleted-list"><li style="list-style-type:disc"> 배달 상태별 개수를 조회하는 그라파나 게이지를 등록하여 조회한 결과를 대시보드로 시각화하여 나타내고 있습니다. </li></ul><ul id="1e23a4cc-090a-809c-8b17-fb56089379db" class="bulleted-list"><li style="list-style-type:disc">대시보드를 통해 하나의 배달 상태에 몰려있진 않은 지, 배달진행에 문제가 있는 건 아닐지 대시보드를 보며 추이를 실시간으로 파악할 수 있습니다. </li></ul><ul id="1e23a4cc-090a-80ec-9971-f419d00c098b" class="bulleted-list"><li style="list-style-type:disc">아래는 베타 환경에서 구성한 대시보드 예시입니다.</li></ul><figure id="d6bd9310-62aa-435e-9e32-f74888de23fb" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%207.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%207.png"/></a></figure><p id="d9c517a0-79f1-4285-905f-2e2f4908e824" class="">이외에도 다양하게 집계되는 실시간 현황은 현재 배달상황을 파악하고 대응하는 데 도움이 됩니다. </p><p id="1e23a4cc-090a-8087-9116-c19995470787" class="">다양하게 집계되는 데이터를 활용하여 다른 유용한 기능을 제공할 수도 있습니다. </p><p id="1e23a4cc-090a-80aa-b2f5-d006cf59801c" class="">실시간으로 이상 상황으로 감지되는 판단을 자동화하여 알람으로 빠르게 장애인지를 할 수도 있고, 큰 장애로 번지기 전에 주문유입을 최소화하여 장애 범위를 최소화하는 데 활용될 수도 있습니다.</p><p id="ce8249fb-63f8-4d53-8332-dffbfffafc99" class="">
</p></details></li></ul><ul id="230286f7-ff5f-4af3-9943-1c511c0b0f4a" class="toggle"><li><details open=""><summary>배민 -  Kafka를 활용한 이벤트 기반 아키텍쳐 구축 - 우아한형제들</summary><ul id="1e23a4cc-090a-802c-9002-c7493175b695" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.youtube.com/watch?v=DY3sUeGu74M&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=11">https://www.youtube.com/watch?v=DY3sUeGu74M&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=11</a></li></ul><ul id="32de8bfb-3546-4425-8813-af271f63ad4f" class="bulleted-list"><li style="list-style-type:disc">배달 변경 사항 발생 시 알림, 통계 등 기능에 이벤트 알림<figure id="a60e5b0e-a4cb-4ca1-bcf3-89944860f5cc" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.49.24.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.49.24.png"/></a></figure></li></ul><ul id="a453cc94-4d77-456c-9e61-5137f0f49284" class="bulleted-list"><li style="list-style-type:disc">Kafaka 이벤트 브로커를 선택<ul id="d13a4841-c8cb-4fcd-a929-e0cd2c82ce08" class="bulleted-list"><li style="list-style-type:circle">순서보장 <ul id="e3d30962-ea95-4e8b-bc87-b2161408a1fa" class="bulleted-list"><li style="list-style-type:square">kafaka 는 토픽의 파트션별로 이벤트를 소비할 때 순서를 보장</li></ul><ul id="6275de5c-2f76-41b4-9187-c2508ab52cf2" class="bulleted-list"><li style="list-style-type:square">배달번호로 기반으로 이벤트를 발행하면, 배달 이벤트의 순서를 보장할 수 있음</li></ul><figure id="c037d80b-dbcf-47d9-b892-c87d9af25d62" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.53.33.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.53.33.png"/></a></figure></li></ul><ul id="a9cb80c8-28e7-4f2c-a398-d2bdd7131a5c" class="bulleted-list"><li style="list-style-type:circle">고성능/고가용성<ul id="673563da-c7bb-4d57-b833-37337198dba9" class="bulleted-list"><li style="list-style-type:square">실시간 많은 이벤트를 처리하기 위해서 고성능/고가용성 필요</li></ul><ul id="0328b136-ca29-4643-9210-7e219b7ab788" class="bulleted-list"><li style="list-style-type:square">kafka는 파트션 증설을 통한 처리량 증대</li></ul><ul id="d5baaf63-64d7-406c-b4be-a228fa34aff8" class="bulleted-list"><li style="list-style-type:square">메시지 배치 발행, 페이지 캐시를 통해 고성능 제공</li></ul><ul id="d3acfe23-71a6-43c7-a99e-c0d284afd1d2" class="bulleted-list"><li style="list-style-type:square">브로커를 클러스터로 구성, 한대 브로커에서 문제 발생 시 다른 브로커에서 파티션 처리함으로써 고가용성 보장</li></ul><figure id="07088c2a-c96d-46a8-b17c-1040e3af5ac1" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.53.46.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.53.46.png"/></a></figure></li></ul><ul id="55ed31b4-deed-455c-a0bd-9b4587405975" class="bulleted-list"><li style="list-style-type:circle">통합도구<ul id="4d9b9dc6-b146-4454-827a-b7fac390896b" class="bulleted-list"><li style="list-style-type:square">시스템 개선이나 확장이 필요할 때 kafka streams, connect 통합 도구를 활용</li></ul><figure id="f01398bc-003a-429a-be9a-d77df23795fc" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.54.18.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.54.18.png"/></a></figure></li></ul><ul id="044c045a-0245-4f71-9acb-56b166814071" class="bulleted-list"><li style="list-style-type:circle">전담팀 지원<figure id="b063f810-201e-49e7-b1e7-9e2680f7d5fa" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.54.45.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.54.45.png"/></a></figure></li></ul></li></ul><ul id="36cb764d-2e35-422a-9040-2bf6a9ca1880" class="bulleted-list"><li style="list-style-type:disc">이벤트 순서 보장을 위한 Transactional outbox Pattern 의 도입<ul id="bfa5c9de-5c3a-442b-a2fe-51cc8e3d2f2c" class="bulleted-list"><li style="list-style-type:circle">이벤트를 DB outbox table 에 저장</li></ul><ul id="5a4ce567-f029-46f9-a20b-34daaea305e7" class="bulleted-list"><li style="list-style-type:circle">Message Relay가 outbox table에 저장된 이벤트를 순서대로 읽어 발행을 보장</li></ul><ul id="6972332e-c0d4-4dfe-9ab6-48b364c2c8aa" class="bulleted-list"><li style="list-style-type:circle">Message Relay 는 저비용, 안정성, 처리량 고려 → debezium 오픈소스 적용</li></ul><figure id="aaab588d-59eb-47e5-8da4-a89592dd4d58" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.31.09.png"><img style="width:680.007080078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.31.09.png"/></a></figure><figure id="5f1b2b27-2b65-4cfc-ab2a-c9f13dfd0db3" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.36.38.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.36.38.png"/></a></figure></li></ul><ul id="30b57b4c-be60-4bbd-b0fd-69501b33aade" class="bulleted-list"><li style="list-style-type:disc">이벤트 스트림으로 CQRS 적용<ul id="6b8968ae-2647-4ead-a733-ec62e1de969f" class="bulleted-list"><li style="list-style-type:circle">대량의 데이터 조회 쿼리 문제 발생 시 커맨드 쪽에 장애가 가지 않도록 제한</li></ul><figure id="f8ac9c4b-4f5f-404a-9389-9b3901e89ac6" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.41.01.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.41.01.png"/></a></figure></li></ul><ul id="45b54bf7-ba7c-4a23-973c-91c36d53b613" class="bulleted-list"><li style="list-style-type:disc">이벤트 스트림으로 데이터 분석 환경 구축<ul id="7cc92fff-ba89-4b7a-93a8-b69cb627fb41" class="bulleted-list"><li style="list-style-type:circle">서비스 성과 분석을 위한 데이터 분석 환경 제공</li></ul><figure id="dafdd92e-3975-438b-9753-de3070b691e6" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.38.25.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.38.25.png"/></a></figure></li></ul><ul id="b4dfed99-7c52-40f6-8e24-2ef2f4758d24" class="bulleted-list"><li style="list-style-type:disc">이벤트 스트림으로 스트림즈 애플리케이션 구현<ul id="8b82ef66-fe27-4832-a85a-0bc739a320c8" class="bulleted-list"><li style="list-style-type:circle">실시간 데이터를 활용한 모니터링 기능에 활용<ul id="9c74abdc-cf8f-4e91-9419-3b999d7ee140" class="bulleted-list"><li style="list-style-type:square">특정 시간, 특정 지역에 배달 중인 라이더 수가 얼마인지 집계 필요 등</li></ul></li></ul><figure id="e3a760c1-11c1-4a97-8a33-633d15fe9967" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.39.01.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.39.01.png"/></a></figure><figure id="a91f011e-4977-4733-81de-874b12a67ed7"><a href="https://www.youtube.com/watch?v=DY3sUeGu74M&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=10" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Kafka를 활용한 이벤트 기반 아키텍처 구축 #우아콘2023 #우아한형제들</div><div class="bookmark-description">[WOOWACON2023 세션 다시보기]

👉 세션 설명

이벤트 기반 아키텍처를 적용했던 경험담을 공유 드립니다.
이벤트 정의부터 구현 과정 그리고 이후로 더 해볼 수 있는 것들까지, 우리가 고민했던 부분들을 이야기해보려 합니다.ㅤ
ㅤ
👉 발표자 소개

딜리버리서비스팀 임준수
시행착오를 겪으며 계속 고쳐나가려는 개발자입니다. 좋은 서비스를 만들기 위해 노력하고 있습니다.

배차시스템팀 송인태
다양한 도전과 경험을 기반으로 지속 가능한 서비스를 구축 및 제공하는 데 관심이 많은 개발자입니다.

👍 추천 대상

- Kafka를 사용해 봤거나 개념에 대해 아는 개발자
- 늘어가는 시스템 복잡도로 고민이 많은 개발자

🙋🏻‍♀️ 세션에 대해 궁금한 점이 있다면 dev_relations@woowahan.com 으로 문의주시기 바랍니다.</div></div><div class="bookmark-href"><img src="https://www.youtube.com/s/desktop/5766dddc/img/favicon_144x144.png" class="icon bookmark-icon"/>https://www.youtube.com/watch?v=DY3sUeGu74M&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=10</div></div><img src="https://i.ytimg.com/vi/DY3sUeGu74M/maxresdefault.jpg" class="bookmark-image"/></a></figure></li></ul><p id="3f26ac4f-2841-4074-ac6a-745019bbf88f" class="">
</p></details></li></ul><ul id="9169d122-6bfe-4c0b-acd3-292b5e2c6f72" class="toggle"><li><details open=""><summary>배민 - 배민스토어에 최신 기술 한방에 때려넣기: EDA</summary><ul id="3e7ed8a5-baef-4f5e-8498-5230fdef8e13" class="bulleted-list"><li style="list-style-type:disc">EDA<figure id="4312148f-125c-40b1-8fae-06fe93d6dcdc" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.25.04.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.25.04.png"/></a></figure><figure id="e1a36ba4-6d49-4836-a734-b7c5dbaac64a" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.26.23.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.26.23.png"/></a></figure><figure id="95173ec9-8dba-4c20-a487-c50a23886d01" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.27.21.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.27.21.png"/></a></figure><figure id="bfc807c1-9af6-4c6f-90cc-19128b2d53c2" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.28.02.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.28.02.png"/></a></figure></li></ul><ul id="80336adb-f4c1-41d0-a9bc-d90b0959e844" class="bulleted-list"><li style="list-style-type:disc">EDA 설계<figure id="e6e9bc0f-d8b7-4877-81c0-9e1b6a8f0901" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.29.58.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.29.58.png"/></a></figure><figure id="170e0728-84f7-4ed4-9502-306833860c33" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.30.23.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.30.23.png"/></a></figure><ul id="184b3b37-51ba-4a91-9eb1-c81b88293607" class="bulleted-list"><li style="list-style-type:circle">워커에서 데이터를 1차로 dynamo db, 2차 redis update</li></ul><ul id="7be2d09b-5b06-4a02-9cd8-d049f383a722" class="bulleted-list"><li style="list-style-type:circle">api 조회 시 1차 redis에서 응답을 줌, redis에 데이터가 없는 경우 fallback 로직을 통해 2차 dynamo 에서 데이터를 호출</li></ul></li></ul><ul id="e63f767f-afd7-4967-bac1-65e956434d81" class="bulleted-list"><li style="list-style-type:disc">EDA 개선<figure id="1ccc6775-83fc-454a-bd86-ac522b5828e9" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.38.00.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.38.00.png"/></a></figure><figure id="9be42c96-6a75-428c-8bf9-5b7293b818c1" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.36.44.png"><img style="width:680.007080078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.36.44.png"/></a></figure><figure id="eb513926-d73a-497d-9137-61f3f555b257"><a href="https://www.youtube.com/watch?v=pRpryoQphXQ&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=8" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">배민스토어에 최신 기술 한방에 때려넣기: Kotlin, Spring WebFlux, EDA #우아콘2023 #우아한형제들</div><div class="bookmark-description">[WOOWACON2023 세션 다시보기]

👉 세션 설명

배민스토어는 올해 4월, 레거시 코드와 아키텍처를 전부 재작성하고 재설계하는 빅뱅을 겪었습니다.
그 과정에서 생산성과 효율성을 높이기 위해 여러 가지 기술을 한 번에 도입했고, 다양한 시행착오를 겪었습니다.

배민스토어의 전시 도메인 개발자들이 어떤 일을 하는지 소개하면서,
Kotlin, Spring WebFlux, EDA 도입의 이유와 좋았던 점, 나빴던 점,
그리고 각 기술에 대한 개발자들의 생각까지 날것으로 풀어내 보겠습니다.ㅤ
ㅤ
👉 발표자 소개

배민스토어서비스개발팀 김민태
좋은 시스템을 개발해서 밤에 약속을 나가고 싶은 개발자입니다.
배민스토어의 백엔드를 개발하며, 팀에서 광대를 담당하고 있습니다.

배민스토어서비스개발팀 오지산
좋은 코드를 써서 밤에 발 쭉 뻗고 자고 싶은 개발자입니다.
배민스토어의 백엔드를 개발하며, 팀에서 선생님을 담당하고 있습니다.

👍 추천 대상

Kotlin과 Spring WebFlux, EDA를 대략적으로 알고 있으며, 실제로 서비스에 적용한 경험이 궁금한 개발자

🙋🏻‍♀️ 세션에 대해 궁금한 점이 있다면 dev_relations@woowahan.com 으로 문의주시기 바랍니다.</div></div><div class="bookmark-href"><img src="https://www.youtube.com/s/desktop/5766dddc/img/favicon_144x144.png" class="icon bookmark-icon"/>https://www.youtube.com/watch?v=pRpryoQphXQ&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=8</div></div><img src="https://i.ytimg.com/vi/pRpryoQphXQ/maxresdefault.jpg" class="bookmark-image"/></a></figure></li></ul></details></li></ul><ul id="12f57a97-48ab-4c0a-99bb-4c4cc9415b0e" class="toggle"><li><details open=""><summary>배민 - 낯선 서드파티와의 동행: 믿을 만한 배민커넥트 서버 구축하기</summary><ul id="61518d73-cf50-41b3-9f42-29dc22e0295f" class="bulleted-list"><li style="list-style-type:disc">운전면허 검증 절차 : 커넥트 서버 → 공단서버 → 경찰청 서버 연동<ul id="083cc0a6-07b6-4111-98e5-0e983e8f8993" class="bulleted-list"><li style="list-style-type:circle">redis 에 토큰 저장, 토큰 만료 전 refresh 이벤트 발행 해서 업데이트</li></ul><figure id="924efdda-95b6-462d-ac1c-fae9f580db0c" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.56.09.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.56.09.png"/></a></figure></li></ul><ul id="ec7ea1d5-eeb6-4739-bf92-4899703190b3" class="bulleted-list"><li style="list-style-type:disc">비동기 스냅샷을 활용하여 라이더 계정 정보에 업데이트, 다음번 접속 시 변경된 정보 검증</li></ul><ul id="1f3c9a7c-8086-4329-9568-fec7b0fa8592" class="bulleted-list"><li style="list-style-type:disc">써드 파티 의존성 분리 및 영향 최소화<figure id="c9a04f3c-1c88-4729-a2df-cd849c3e7f81" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.51.07.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_2.51.07.png"/></a></figure></li></ul><ul id="7ff4ec08-1e5e-44ee-9dcb-71d84a282e5f" class="bulleted-list"><li style="list-style-type:disc">쌓여 있는 검증 정보는 주기적으로 배치성 작업으로 주기적으로 일괄 검증</li></ul><ul id="437cd1b8-bc4f-422e-9e3a-6bade40688c6" class="bulleted-list"><li style="list-style-type:disc">외부 연동 문제 발생<figure id="29908f08-294a-4b02-85a2-a68428e9cc53" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.01.39.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.01.39.png"/></a></figure><figure id="963ccaff-807d-4010-a619-a2a34968a5e9" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.03.52.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.03.52.png"/></a></figure><figure id="981d2bed-64af-4b5d-baf3-604716bf0f26" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.06.18.png"><img style="width:683.99853515625px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.06.18.png"/></a></figure></li></ul><ul id="9cd0ab6c-c72f-4ad6-997b-09370384e012" class="bulleted-list"><li style="list-style-type:disc">결과<figure id="9f4f40f3-387a-4c61-a45a-711336531f04" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.08.19.png"><img style="width:656.0084838867188px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.08.19.png"/></a></figure></li></ul></details></li></ul><ul id="2682eee6-4ae9-4d13-9675-06cc3e097cb8" class="toggle"><li><details open=""><summary>배민 - Kafka Streams를 활용한 이벤트 스트림 처리 삽질기</summary><ul id="1e23a4cc-090a-80e0-8ae1-c65f0c9f6c66" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.youtube.com/watch?v=YACC1t_oSlA&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=12">https://www.youtube.com/watch?v=YACC1t_oSlA&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=12</a></li></ul><ul id="00e038fa-e642-4046-abac-9c92260d661e" class="bulleted-list"><li style="list-style-type:disc">배달 인프라 상황 정보를 스트림 처리로 전환<figure id="7cd1043d-afba-4732-8a1d-90deb1d51901" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.33.21.png"><img style="width:680.007080078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.33.21.png"/></a></figure></li></ul><ul id="5451d1d5-5657-48d3-b455-4e5bec4ad307" class="bulleted-list"><li style="list-style-type:disc">Kafka Streams 기본 개념<figure id="37cfcc30-23d1-41f6-b510-440d1307ac0a" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.34.24.png"><img style="width:680.007080078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.34.24.png"/></a></figure></li></ul><ul id="e9d8258f-4646-445a-aa54-983667b819d7" class="bulleted-list"><li style="list-style-type:disc">도메인 이벤트<figure id="872e1efe-95a0-4dc4-b565-13f606a49d16" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.35.46.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.35.46.png"/></a></figure></li></ul><ul id="c5ea913c-8c9c-4b50-a42c-af151ee8b08f" class="bulleted-list"><li style="list-style-type:disc">도메인 요구사항 : 1번/2번 기능 요구사항, 3번 비기능 요구사항<figure id="9f134ef7-6f91-423b-b1e8-867b34fb0951" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.24.00.png"><img style="width:707.9971313476562px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.24.00.png"/></a></figure></li></ul><ul id="cfcde965-1d6c-485d-9207-56686c0e098e" class="bulleted-list"><li style="list-style-type:disc">스트림 조인을 이용한 라이더 스냅샷 스트림 생성<figure id="29339370-a3d8-4b4f-b0f8-67c2ac05bfd0" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.27.30.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.27.30.png"/></a></figure></li></ul><ul id="305f089f-2194-494a-9a3f-e395d3317e1f" class="bulleted-list"><li style="list-style-type:disc">여러 인스턴스에 분산 처리<figure id="e52a85cc-b39e-4f1a-99b9-4937bc1e0dc0" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.28.29.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.28.29.png"/></a></figure></li></ul><ul id="763b08a6-2f8a-482e-bd61-22c6f4cd78cc" class="bulleted-list"><li style="list-style-type:disc">데이터 조회<figure id="17ec07f4-1d59-4fef-8ddb-b61050d5e7d4" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.29.20.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.29.20.png"/></a></figure></li></ul><ul id="9055b26d-fadd-40bb-9c7f-23029e3cb7ad" class="bulleted-list"><li style="list-style-type:disc">백업 저장소 구축<figure id="ebb7e235-6196-436f-a07e-34f696acef31" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.30.55.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.30.55.png"/></a></figure><figure id="941ce74b-035a-4041-8390-2abdeba28a16" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.31.27.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.31.27.png"/></a></figure></li></ul><ul id="0d240ddb-50b0-478d-9738-e7ddd800a9ee" class="bulleted-list"><li style="list-style-type:disc">전체 구조</li></ul><figure id="ccfb5c8b-c54b-48c1-a5fd-adcf02a7b2c4" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.32.28.png"><img style="width:683.99853515625px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.32.28.png"/></a></figure><ul id="eb6eac33-d3e5-4582-9125-923237475bf2" class="bulleted-list"><li style="list-style-type:disc">이슈와 해결 방과<figure id="378f6bd0-51ff-47d0-a381-e205e71cde91" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.37.10.png"><img style="width:680.007080078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.37.10.png"/></a></figure><ul id="f3ca7795-be43-4687-ac00-f075b46cf179" class="bulleted-list"><li style="list-style-type:circle">과도한 파티션 수<figure id="cd1b80c9-ac82-4c64-972a-8034733ca8c7" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.38.48.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.38.48.png"/></a></figure></li></ul><ul id="345d42f0-8b7b-4717-8c33-04b2bc516a04" class="bulleted-list"><li style="list-style-type:circle">토픽의 단위<figure id="4e3b879b-d354-45be-aedc-8c4f080cb4ac" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.40.26.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.40.26.png"/></a></figure></li></ul><ul id="b1f229d2-fa16-4331-8db1-ba9d7932cb35" class="bulleted-list"><li style="list-style-type:circle">리밸런싱과 LAG<figure id="c11a3a6b-b42c-4d7d-882f-e7be8a6f5611" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.41.30.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.41.30.png"/></a></figure><figure id="a5a612bb-0df3-4ccd-8ed6-79aa3a9696e2" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.41.55.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.41.55.png"/></a></figure><figure id="0132dca9-572e-407d-8ece-fc443930fd89" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.42.13.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.42.13.png"/></a></figure><figure id="aa8d8810-844b-44db-9f48-346812c3cc6f" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.42.57.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.42.57.png"/></a></figure><figure id="a9d2b1f6-f8a2-49f8-95c0-52d85f6cfc04" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.43.22.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.43.22.png"/></a></figure><figure id="a0ebe598-54c9-4596-8203-1b74421bd297" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.44.55.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.44.55.png"/></a></figure><figure id="fa7674cc-b6da-4683-8d87-dac9b13c6f63" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.46.02.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.46.02.png"/></a></figure><figure id="264817e4-f91f-43e5-b072-64ce026512cc" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.46.35.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.46.35.png"/></a></figure><figure id="c227c873-5ef3-42b2-9f4e-8d338da40d15" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.47.10.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.47.10.png"/></a></figure></li></ul><figure id="bbb573e1-7e5e-47e6-997b-cb4928453180"><a href="https://www.youtube.com/watch?v=YACC1t_oSlA&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=11" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Kafka Streams를 활용한 이벤트 스트림 처리 삽질기 #우아콘2023 #우아한형제들</div><div class="bookmark-description">[WOOWACON2023 세션 다시보기]

👉 세션 설명

배달 도메인에서 배달/라이더 이벤트를 다루면서 경험한 스트림 처리 과정에 대해 이야기합니다.
스트림 처리를 위한 구조 설계부터, Kafka Streams를 실제 적용하기까지의 전반적인 과정을 소개합니다.
특히 운영 과정에서 마주한 이슈들과 그에 따른 전략 및 해결 과정 등을 중점적으로 공유합니다.
배치 처리의 한계로 스트림 처리 도입을 고려하고 계신 애플리케이션 개발자에게 이번 세션을 바칩니다.ㅤ
ㅤ
👉 발표자 소개

딜리버리서비스팀 서오상

동료들과 개발 문화를 가꾸고, 문제를 정의하고 해결하는 과정을 즐깁니다.
소프트스킬도 유연한 개발자이고 싶습니다.
먼 훗날 어딘가 베이커리 카페를 열고 디지털 노마드처럼 코딩하는 게 꿈입니다.

딜리버리서비스팀 이신은

방탈출을 좋아하고, 언젠가 회사 탈출을 꿈꾸는 개발자입니다.
의견 충돌과 협상, 극적 타결까지 이르는 과정에서 희열을 느끼는 평화주의자입니다.

👍 추천 대상

스트림 처리 도입을 고민 중인 비즈니스 애플리케이션 개발자

🙋🏻‍♀️ 세션에 대해 궁금한 점이 있다면 dev_relations@woowahan.com 으로 문의주시기 바랍니다.</div></div><div class="bookmark-href"><img src="https://www.youtube.com/s/desktop/5766dddc/img/favicon_144x144.png" class="icon bookmark-icon"/>https://www.youtube.com/watch?v=YACC1t_oSlA&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=11</div></div><img src="https://i.ytimg.com/vi/YACC1t_oSlA/maxresdefault.jpg" class="bookmark-image"/></a></figure></li></ul></details></li></ul><ul id="c386f84e-67c7-46bf-9b9a-30bbd7e4bfa0" class="toggle"><li><details open=""><summary>배민 - B마트 전시 도메인 CQRS 적용하기</summary><ul id="1e23a4cc-090a-80fd-86d3-fbc17b1af5fb" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.youtube.com/watch?v=fg5xbs59Lro&amp;list=PLgXGHBqgT2Ttcttvjy5_4GacLPcs6iM-s&amp;index=19">https://www.youtube.com/watch?v=fg5xbs59Lro&amp;list=PLgXGHBqgT2Ttcttvjy5_4GacLPcs6iM-s&amp;index=19</a></li></ul><ul id="1c43a4cc-090a-8040-a5ce-c05c44e60fdc" class="bulleted-list"><li style="list-style-type:disc">데이터 도메인은 정규화 되어 있으나, 전시 도메인은 비정규화 <figure id="1c43a4cc-090a-80c4-9d64-ebeb141ad775" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.02.42.png"><img style="width:957.96875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.02.42.png"/></a></figure><figure id="1c43a4cc-090a-80e0-9185-f0e3b90f82b0" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.07.30.png"><img style="width:929.96875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.07.30.png"/></a></figure><figure id="1c43a4cc-090a-807f-b00d-ce877344f20d" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.08.25.png"><img style="width:929.984375px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.08.25.png"/></a></figure><figure id="1c43a4cc-090a-800c-8e9a-d430eb3e60b8" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.09.49.png"><img style="width:929.984375px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-03-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.09.49.png"/></a></figure></li></ul><ul id="da3c2c76-bde6-4943-9c40-6a1d8cd94f1c" class="bulleted-list"><li style="list-style-type:disc">조회 성능을 높이고 싶을 때, 비지니스 요구사항이 복잡해질 때</li></ul><ul id="22b98b9d-7b82-4ec7-80a4-81f87578e4c8" class="bulleted-list"><li style="list-style-type:disc">이벤트 발생 시 이벤트를 개별적으로 처리하는 건 비효율적임 (중복 메시지 해소, 단건 이벤트 처리 등)<ul id="3b1e2c8d-3fdf-4acb-8a6e-1144215da772" class="bulleted-list"><li style="list-style-type:circle">수신된 이벤트 처리 시 이벤트 로깅 및 redis를 이용하여 버퍼에 저장</li></ul><ul id="327841e2-bba4-4c15-9435-1ed50a3f5f68" class="bulleted-list"><li style="list-style-type:circle">스프링 스케줄러를 통해 10초에 한번씩 버퍼에 있는 모든 요청을 가져와서 <span style="border-bottom:0.05em solid">조회 모델을 벌크로 생성/저장</span></li></ul><ul id="cf762754-fa09-4640-ba52-52412f89d97e" class="bulleted-list"><li style="list-style-type:circle">또한 <span style="border-bottom:0.05em solid">데이터 정합성을 보장하기 위해 매시간 마다 full 배치 실행해서 모든 조회 모델을 생성/저장</span></li></ul><figure id="1945ca0c-5f65-4eeb-998a-92f0003b2f6b" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.40.22.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.40.22.png"/></a></figure><figure id="00c4792d-1c28-4b7b-8813-763f378b1074" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.25.53.png"><img style="width:690.4260864257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.25.53.png"/></a></figure><figure id="6a0c67ad-b09f-4804-aba6-5abe9e95a915" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.44.59.png"><img style="width:652.0596313476562px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.44.59.png"/></a></figure><figure id="e18755c8-d43a-44c7-8c6a-de39a7b253b6" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.29.45.png"><img style="width:690.4260864257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.29.45.png"/></a></figure><figure id="7c05008b-6e91-47e1-87f3-9f70212ee7cc" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.35.56.png"><img style="width:690.4260864257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.35.56.png"/></a></figure><figure id="f5161853-b9bd-418e-8810-2bfe77f40236" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.45.22.png"><img style="width:652.0596313476562px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.45.22.png"/></a></figure><figure id="1690ecc0-5f23-460b-a629-6ab6c8577734" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.48.12.png"><img style="width:652.0596313476562px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.48.12.png"/></a></figure><figure id="ec5b9a4c-be31-42ef-a489-3daa9f3cf9b5" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.48.36.png"><img style="width:652.0596313476562px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-25_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.48.36.png"/></a></figure><figure id="04e8d605-73bd-4332-8417-855ef1a17a13"><a href="https://www.youtube.com/watch?v=fg5xbs59Lro&amp;list=PLgXGHBqgT2Ttcttvjy5_4GacLPcs6iM-s&amp;index=18" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">B마트 전시 도메인 CQRS 적용하기 #우아콘2021 #둘째날_새로운여정</div><div class="bookmark-description">CQRS 패턴에 대해 알아보고 B마트 전시 도메인에 CQRS 패턴을 적용해 나간 과정을 공유합니다.

[발표자 소개] 우태균, B마트서비스팀
서비스 이용자와 맞닿아 있는 앱 개발을 시작으로 좋은 서비스를 만들기 위한 도구로써 여러 개발 분야에 관심을 가져왔습니다. 최근에는 데이터를 기반으로한 서비스 발전과 안정적인 운영을 위해 노력하고 있습니다.</div></div><div class="bookmark-href"><img src="https://www.youtube.com/s/desktop/5766dddc/img/favicon_144x144.png" class="icon bookmark-icon"/>https://www.youtube.com/watch?v=fg5xbs59Lro&amp;list=PLgXGHBqgT2Ttcttvjy5_4GacLPcs6iM-s&amp;index=18</div></div><img src="https://i.ytimg.com/vi/fg5xbs59Lro/maxresdefault.jpg" class="bookmark-image"/></a></figure></li></ul></details></li></ul><ul id="c086bbb3-abe6-4837-b0f4-194a65e65dfc" class="toggle"><li><details open=""><summary>배민 - 선착순 이벤트 서버 생존기! 47만 RPM에서 살아남기</summary><figure id="b9747082-d5ab-40bd-a6af-af781fe93318" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.40.57.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.40.57.png"/></a></figure><figure id="13a12078-c736-4c4e-b373-43b6c5389d3c" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.49.47.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.49.47.png"/></a></figure><figure id="84916d87-6f5c-4acd-b6e3-6ce2837e4d97" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.39.38.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.39.38.png"/></a></figure><figure id="cc4415bb-e384-4e49-b107-aa99ed6c3848" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.39.56.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.39.56.png"/></a></figure><figure id="520161e5-05dc-49c5-a19e-c2fd32ac127e" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.38.59.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.38.59.png"/></a></figure><figure id="161a3c6d-2111-401b-96d8-f6e467631326" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.42.39.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.42.39.png"/></a></figure><figure id="b11f64fc-7a35-4960-a6fc-c08244490950" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.44.57.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.44.57.png"/></a></figure><figure id="283ffedb-4f6e-4f31-9c20-7fa3c82aa7a9" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.43.29.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.43.29.png"/></a></figure><p id="ca24e1c5-249d-435e-a69f-e24c27586827" class="">
</p><figure id="5513d78f-4fa8-48f8-9876-fcf8d4bde863" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.43.57.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.43.57.png"/></a></figure><figure id="6a1113b6-53bd-4f0a-9192-5925bd61f28f" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.46.58.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.46.58.png"/></a></figure><figure id="99edefe3-2a5c-4498-b8b2-0aaf50d964be" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.47.33.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.47.33.png"/></a></figure><p id="fea04614-d7da-4928-9d37-233b081d8f19" class="">
</p><figure id="9a330eef-18fe-4a61-8475-289b0b45b8c8" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.48.53.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-12_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.48.53.png"/></a></figure><figure id="ffbb552f-9c32-4d85-aee2-dfa141b046e3"><a href="https://www.youtube.com/watch?v=7_VdIFH6M6Q" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">신뢰성 있는 카프카 애플리케이션을 만드는 3가지 방법 (최원영 Cory)</div><div class="bookmark-description">[2023.09.14. 제3회 Kakao Tech Meet 발표]
이벤트 드리븐 아키텍처와 스트림 데이터 파이프라인을 만들때 고민해야 하는 부분을 다룹니다. 프로듀서/컨슈머와 같은 카프카 애플리케이션의 전달 신뢰도를 높이기 위해서 적용할 수 있는 기술들에 대해 설명하고 내부적으로 적용했던 경험을 공유합니다.

발표자: 최원영(Cory)
안녕하세요! 광고추천팀 cory입니다. 저서로는 『아파치 카프카 애플리케이션 프로그래밍 with 자바』가 있고, 최근에는 『실시간 데이터 파이프라인 아키텍처』를 번역하였습니다. 
개발 기술 및 문화 공유에 도움이 되고자 데브원영 블로그와 유튜브를 운영하고 있습니다.
🔥 데브원영 블로그: https://blog.voidmainvoid.net/ 
🔥 데브원영 유튜브: https://www.youtube.com/@DevWonYoung 

💬 발표자 인터뷰와 비하인드 보러가기: https://tech.kakao.com/2023/09/22/techmeet-kafka/ 
✨ 카카오테크 톡채널: http://pf.kakao.com/_qmkxcs 
✨ 카카오테크 페이스북: https://www.facebook.com/kakaotech 

카카오테크, 미래의 문턱을 낮추는 기술
https://tech.kakao.com/

#kafka #ExactlyOnceSemantics #transaction #kakaotechmeet #kakaotech #카카오테크밋</div></div><div class="bookmark-href"><img src="https://www.youtube.com/s/desktop/bf8c00d7/img/favicon_144x144.png" class="icon bookmark-icon"/>https://www.youtube.com/watch?v=7_VdIFH6M6Q</div></div><img src="https://i.ytimg.com/vi/7_VdIFH6M6Q/sddefault.jpg" class="bookmark-image"/></a></figure></details></li></ul><p id="527e4ec5-d0f3-4106-b377-8a629d8e9bec" class="">
</p><p id="84bd208a-830c-4266-b421-a901d0ab76fe" class=""><strong>대규모 트래픽을 위한 예약/예매 서비스</strong></p><ul id="59a104b2-f8f1-4272-aa64-2740746e4bae" class="toggle"><li><details open=""><summary><mark class="highlight-blue_background">대규모 트래픽을 고려한 시스템 구조 </mark></summary><figure id="8b4e11b2-bfaa-4ab3-8d9e-855500f459f8" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image.png"><img style="width:624px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image.png"/></a></figure><figure id="c01abb7d-dcfd-431b-94b3-df8c669642c5" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%201.png"><img style="width:720px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%201.png"/></a></figure><figure id="544e8e72-5ee7-4cd0-ab0d-07c1233a8403" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%208.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%208.png"/></a></figure><p id="2f944e8b-ef09-4111-9583-976b61f44775" class="">
</p><ul id="4491af35-bcae-454a-b015-4db53e491103" class="bulleted-list"><li style="list-style-type:disc">스케일-아웃(scale-out)<ul id="48d94164-33f6-4363-9164-fb23303b9a55" class="bulleted-list"><li style="list-style-type:circle">병렬로 서버를 늘려 API요청을 분산처리하는 방법</li></ul><ul id="c3bba307-7869-4654-8a96-c00b4fbd8d4d" class="bulleted-list"><li style="list-style-type:circle">EC2앞에 로드밸런서(Load Balancer)를 추가하여 스케일 아웃을 적용</li></ul></li></ul><ul id="2b007518-907f-4776-94db-fd96c8be49a2" class="bulleted-list"><li style="list-style-type:disc">DB <ul id="d147ed37-6454-4be7-b57e-a258d61fe686" class="bulleted-list"><li style="list-style-type:circle">같은 데이터베이스를 1개의 Master DB와 여러 개의 Slave DB로 나눌 수 있다. </li></ul><ul id="1c43a4cc-090a-80b5-9766-ff7848d8e0da" class="bulleted-list"><li style="list-style-type:circle">Slave DB는 Read만 가능하며 Write 쿼리는 모두 Master DB에서 처리</li></ul></li></ul><ul id="12a2c3de-11e2-40b0-8917-6200064821a2" class="bulleted-list"><li style="list-style-type:disc">캐시 정책 적용<ul id="b4b3bf7d-9837-4d1a-8c7c-34f8c5e32269" class="bulleted-list"><li style="list-style-type:circle">데이터베이스를 좀 더 효율적으로 사용하기 위해서는 데이터베이스 앞에 캐시(Cache)를 두는 것을 고려할 수 있다. </li></ul><ul id="1c43a4cc-090a-80c2-80cc-d8a539485286" class="bulleted-list"><li style="list-style-type:circle">데이터베이스는 기본적으로 Disk기반이라 읽고 쓰는 연산이 메모리에 비해 느리다. </li></ul><ul id="1c43a4cc-090a-8011-8113-f4e882d28aeb" class="bulleted-list"><li style="list-style-type:circle">데이터베이스 앞에 메모리 기반 캐시를 두게 되면 시스템 성능을 향상할 수 있다. AWS에서는 ElasticCache라는 서비스로 캐시서비스를 제공하고 있다.</li></ul></li></ul><ul id="fe523afe-e28b-4d51-9eec-e6866a143cea" class="bulleted-list"><li style="list-style-type:disc">CDN<ul id="ca846e4f-d391-44de-9779-f10b26fc5944" class="bulleted-list"><li style="list-style-type:circle">정적인 데이터를 캐싱하기 위해서는 CDN서비스를 사용할 수 있다. </li></ul></li></ul><ul id="90913204-42df-4328-a0de-d8f9c0cd6deb" class="bulleted-list"><li style="list-style-type:disc">데이터베이스 샤딩<ul id="9e04586a-350b-4072-84d9-3e402e33cf6d" class="bulleted-list"><li style="list-style-type:circle"><span style="border-bottom:0.05em solid">Read Replica와 Cache를 이용해 데이터베이스의 부하를 줄임</span></li></ul><ul id="1c43a4cc-090a-8093-a332-d79d6994cc76" class="bulleted-list"><li style="list-style-type:circle"><span style="border-bottom:0.05em solid">쓰기 작업에 대해서는 DB 부하를 분산하기 위해 데이터베이스 샤딩</span>을 하게 되는데, 데이터를 특정 키를 기준으로 나누어 저장하는 것이다. </li></ul><ul id="1c43a4cc-090a-80d1-98f5-c24864c773db" class="bulleted-list"><li style="list-style-type:circle">이전 회사에서는 회원의 계좌정보를 홀짝으로 구분해, 홀수 계좌번호는 데이터베이스 1번, 짝수 계좌번호는 데이터베이스 2번을 사용했다.</li></ul></li></ul><ul id="2c4ca9f4-0015-4c75-b555-fe0975aced41" class="bulleted-list"><li style="list-style-type:disc">데이터센터 다중화<ul id="afd3b91a-509f-4344-a21e-c5262835b9e5" class="bulleted-list"><li style="list-style-type:circle">이제 물리적인 관점으로 다가가보자. 서버들이 모여있는 데이터센터에 불이 나면 어떻게 될까? 아마 모든 서버들이 작동을 중단하게 되고, 서비스가 중단될 것이다. 이를 위해 우리 서버들을 2개 이상의 데이터 센터에 분배할 필요가 있다. </li></ul><ul id="1c43a4cc-090a-80cc-8ff4-eff724e52227" class="bulleted-list"><li style="list-style-type:circle">다행히도, AWS를 사용하면 AvailableZone을 이용해 물리적 이중화를 구현할 수 있다. AWS에서 제공하는 각각의 서비스에 옵션으로 AZ(AvailbleZone)을 선택하면 되는데, 요즘에는 AZ를 2개 이상 선택해야 하는 게 디폴트라 아마 대부분 2개 이상으로 설정되어 있을 것이다. AWS 서울리전에는 a~d까지 총 4개의 AvailableZone을 운영하고 있기 때문에 원하는 AZ를 선택하면 된다.</li></ul></li></ul><ul id="ca863626-f9f1-402c-a56c-4ffc6e8bac7b" class="bulleted-list"><li style="list-style-type:disc">메시지 큐 활용<ul id="2d43efe0-eec9-471b-b29c-3e409ded9ee8" class="bulleted-list"><li style="list-style-type:circle">서비스가 커지고 복잡해지면서 서버 간 의존성이 높아지고, 작업을 처리하는 시간이 많아지는 이슈가 생길 수 있다. </li></ul><ul id="1c43a4cc-090a-804e-b119-fb266c9d5705" class="bulleted-list"><li style="list-style-type:circle">이때 적용할 수 있는 솔루션으로는 메시지 큐가 있다. 메시지큐를 사용하면 서비스, 서버 간 관계가 느슨해지면서 확장에 용이한 서비스 구조가 된다.</li></ul></li></ul><ul id="98defc0f-9c80-48da-ad0c-c377c6499b8b" class="bulleted-list"><li style="list-style-type:disc">모니터링<ul id="903ca6da-d3ed-4fc7-9e2a-f70c2bd68311" class="bulleted-list"><li style="list-style-type:circle">구조가 복잡해지고 커질수록 모니터링 기능이 필수가 된다. 어떤 서버에 어떤 문제가 발생하는지 실시간으로 확인하는 것은 중요하다. </li></ul><ul id="1c43a4cc-090a-80b3-81fd-effa395daac4" class="bulleted-list"><li style="list-style-type:circle">AWS에서는 기본적으로 CloudWatch를 통해 각 서버들의 상태를 파악할 수 있게 되어있다. </li></ul><ul id="1c43a4cc-090a-8080-9899-d49a6f93ec98" class="bulleted-list"><li style="list-style-type:circle">어플리케이션 서버 레벨에서의 상태를 확인하기 위해 별도의 3rd party 모니터링 툴을 도입할 수 있다. </li></ul><ul id="1c43a4cc-090a-80f8-b6da-fc82b4082e63" class="bulleted-list"><li style="list-style-type:circle">메시지큐를 이용해 각 서버에서 발생하는 로그를 수집해 grafana나 datadog 같은 모니터링 툴로 전송하여 대시보드 형태로 볼 수 있다. </li></ul><p id="74da5834-1bf0-4dc2-badd-1b9ac97e5930" class="">
</p></li></ul></details></li></ul><ul id="220e6fa4-10ee-4fe3-905a-fe93128c9b8d" class="toggle"><li><details open=""><summary>대규모 트랜잭션을 빠르고 안정적으로 처리하는 티켓 예매 사이트</summary><p id="62eda7c9-ef44-4312-8128-49aebc6d3d47" class=""><strong>프로젝트 챌린지 포인트</strong></p><ul id="82ab4cbf-183d-4fed-aac8-ef381acc6ae0" class="toggle"><li><details open=""><summary>📈 사용자의 원활하고 끊김 없는 서비스 제공 위한 높은 TPS와 빠른 응답속도</summary><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="7950645e-668f-454a-99f9-33c679cada5b" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">저희 프로젝트의 주요 목표는 사용자가 항상 원활하고 끊김 없는 서비스를 이용할 수 있도록 하는 것입니다. 이를 위해, 대규모 트랜잭션 상황에서도 안정적이면서도 높은 TPS와 빠른 응답속도를 제공하기 위해 다양한 기술적 요소를 적절하게 활용하였습니다.

우선, 분산 처리 아키텍처와 In-memory caching, Database Tuning 등의 기술을 조합하여 안정적이면서도 높은 TPS와 빠른 응답속도를 실현하였습니다. 
특히, Redis Cache를 활용하여 In-memory Data Store를 구축하여 응답속도를 크게 향상했습니다.

또한, 부하 분산을 위한 Load Balancing과 자원 확장 및 축소를 자동으로 처리하는 Auto Scaling을 도입하여, 서버 부하를 적절하게 분산하고 트래픽 변화에 따라 적절한 자원을 할당함으로써, 트래픽 급증 시에도 끊김 없는 서비스를 제공할 수 있도록 구성하였습니다. 

마지막으로, HikariCP와 MySQL을 Tuning 하여 Database 연결을 최적화하고, 서버 분산을 통해 병목 현상을 예방하여 안정적인 서비스를 구현하였습니다. 

이러한 다양한 기술적 요소들을 적절하게 조합하여, 저희 서비스는 높은 성능과 안정성을 동시에 유지할 수 있게 되었습니다. 이를 통해 사용자들은 언제나 원활하고 끊김 없는 서비스를 경험할 수 있게 되었습니다.
</code></pre></details></li></ul><ul id="b8152047-fb5a-4b1e-b6ee-4c023d8bf59e" class="toggle"><li><details open=""><summary>🕸 데이터의 정확성과 일관성을 보장해, 데이터 무결성 확보</summary><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="d8c7cb54-8599-4c9d-8ba8-855586b87b03" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">저희는 Redis를 도입하여 높은 TPS와 빠른 응답 속도를 확보하였으나, 중복 데이터로 인한 데이터의 일관성과 정확성 문제가 생겼습니다. 이에 대응하여 데이터 무결성을 확보하기 위해 아래와 같은 캐시 전략을 수립하였습니다.

먼저 쓰기 전략으로 Write Back 방식을 도입하여, 티켓의 남은 좌석 수 데이터 수정 시 캐시에만 변경사항이 기록되고, 주기적으로 또는 특정 조건이 충족될 때 Database에 동기화합니다. 이를 통해 빠른 응답 시간과 Database의 부하를 줄일 수 있습니다. 

특히, Redis의 Single Thread 특성과 원자적 연산을 사용해 락을 사용하지 않고도 동시성 제어를 하여 데이터 무결성을 확보할 수 있었습니다.

읽기 전략은 Look Aside 방식을 도입하여 클라이언트가 특정 데이터를 읽을 때마다 캐시를 먼저 확인하고, Cache miss의 경우 Database에서 Data를 가져와 캐시에 저장한 후 클라이언트에 반환합니다. 이 방식을 통해 Database와 캐시 간의 일관성을 유지할 수 있습니다.

종합적으로 Redis를 통해 대규모 트랜잭션 상황에서의 동시성 제어를 하면서, 위의 캐시 전략으로 데이터의 정확성과 일관성을 보장해 데이터 무결성을 확보할 수 있었습니다.</code></pre></details></li></ul><ul id="efba5544-1a93-4b81-a9c4-e07694527026" class="toggle"><li><details open=""><summary>📊 APM을 활용해서 시스템의 성능과 안정성을 지속적으로 관리</summary><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="76005dfd-197d-47d5-ad88-80eb915a6f6e" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">대규모 트랜잭션 상황에서 동시성 제어를 수행하며, 프로젝트의 챌린지 포인트 중 하나로 APM을 활용한 모니터링을 도입하였습니다. 
이를 통해 시스템의 성능과 안정성을 지속적으로 관리하고 개선할 수 있었습니다. 

저희 팀은 Grafana, Cloud Watch 및 Pinpoint와 같은 다양한 모니터링 도구를 사용하여 시스템의 전반적인 성능을 실시간으로 확인하였습니다.
 
특히, Grafana와 Cloud Watch를 통해 EC2, Elastic Cache, ALB, RDS, Auto Scaling 등의 상태를 실시간으로 모니터링할 수 있었습니다. 

또한, Pinpoint를 사용하여 병목 현상이 나타나는 지점을 확인하고 개선할 수 있었습니다. 이를 통해 서비스의 안정성과 성능을 지속적으로 유지하고 개선할 수 있었으며, 사용자들에게 최상의 서비스 경험을 제공할 수 있게 되었습니다. 

종합적으로, 이러한 모니터링 도구들의 활용을 통해 시스템 내 문제가 발생했을 때 빠르게 진단하고 수정 및 개선 작업을 수행할 수 있었습니다. 결과적으로 프로젝트는 안정성과 높은 성능을 보장하는 성공적인 구현이 이루어졌습니다.  </code></pre></details></li></ul><ul id="d9d290a1-4721-4cac-b04a-70c8dbc99f44" class="toggle"><li><details open=""><summary>📉 비용을 최소화하면서도 높은 가용성과 성능을 유지하는 가성비 최적화 전략</summary><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e0bb017b-8fbb-4b98-a12a-b2fd790f9389" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">저희는 최소 비용으로도 높은 가용성과 성능을 유지하는 것을 목표로 하며, 이를 위해 다양한 기술적인 방법과 전략적인 설계를 채택하였습니다. 

EC2는 직전 버전보다 20% 저렴한 Graviton2 arm64 아키텍쳐 기반에, 무료로도 사용 가능한 t4g.small 서버를 사용했습니다. 서버 확장이 필요할 경우 비용이 더 발생하는 Scale Up 방식보다 Load Balancing을 이용해 Scale Out 방식의 수평적 확장으로 비용을 최소화 하였습니다.

공연 예매 사이트의 특성상 예매 오픈 시간대에 트래픽이 집중되는 현상이 발생합니다. 그래서 Auto Scaling을 설정해 오픈 시간 직전과 트랜잭션이 몰리는 상황에서만 서버 인스턴스 확장을 하고, 서버 부하가 없는 대부분의 시간에는 서버 인스턴스가 최소로 유지됩니다. 서버 수를 동적으로 조절하여 자원 사용량을 최적화하고 비용 절감 효과를 극대화할 수 있었습니다.

이를 통해 높은 가용성과 성능을 유지하면서도 비용을 최소화하는 것뿐만 아니라, 가성비 측면에서도 최적의 결과를 얻을 수 있도록 했습니다.</code></pre></details></li></ul><ul id="f63065a5-ca2e-4ba7-9cd5-027ccf1bb08f" class="toggle"><li><details open=""><summary><strong>Architecture 구성도</strong></summary><figure id="4390c959-9148-4ce6-bff6-f0793d76923b" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%209.png"><img style="width:707.9900512695312px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%209.png"/></a></figure></details></li></ul><ul id="594e7b2e-038a-4f1f-ba94-ec9203b7b35c" class="toggle"><li><details open=""><summary>기술적 의사결정</summary><table id="c2ea80dd-9580-4d43-bb9d-90945d602222" class="simple-table"><tbody><tr id="666adc44-5c59-4f14-803f-98200e8a974b"><td id="ue=:" class=""><strong>요구 사항</strong></td><td id="Wd{&gt;" class=""><strong>선택한 기술</strong></td><td id="D`@o" class="" style="width:553.9999847412109px"><strong>기술선택 이유</strong></td></tr><tr id="de0eb839-998c-4dcf-8ec0-4045affe12c5"><td id="ue=:" class=""><strong>DB 부하 개선<br/>응답속도 개선<br/>처리량 개선<br/>동시성 문제 개선<br/></strong></td><td id="Wd{&gt;" class="">Redis</td><td id="D`@o" class="" style="width:553.9999847412109px">Redis Cache 사용<br/>- Redis는 인메모리 데이터 저장소로서, 디스크 기반의 데이터 접근보다 훨씬 빠른 속도를 제공합니다. 이를 통해 전체 성능 향상을 기대할 수 있습니다.<br/>- Redis의 단일 스레드 구조는 모든 명령을 순차적으로 처리하며, 단일 연산에 대해서는 원자성이 보장됩니다. 이로 인해 데이터 일관성 및 무결성을 유지하는 데 도움이 되며, 시스템 안정성을 향상할 수 있습니다.<br/>- 동일한 데이터가 데이터베이스를 통해 반복적으로 조회되는 경우 응답 속도와 자원 사용에 손실이 발생합니다. Redis 캐시를 사용하여 데이터베이스 부하를 줄이고, 애플리케이션의 응답 시간을 개선했습니다.<br/></td></tr><tr id="c4d71c30-9053-46bb-b536-229b2cf91f77"><td id="ue=:" class=""><strong>검색</strong></td><td id="Wd{&gt;" class="">QueryDSL</td><td id="D`@o" class="" style="width:553.9999847412109px">- QueryDSL은 검색 조건의 유연성과 다양한 단어 처리를 간편하게 제공하여 대소문자 구분 없이 특정 단어를 포함하는 이벤트를 효과적으로 찾을 수 있습니다.<br/>- QueryDSL의 동적 쿼리 작성 기능과 높은 코드 가독성 덕분에 복잡한 검색 요구 사항도 쉽게 처리할 수 있습니다. 또한, 타입 안전성을 지원하는 QueryDSL은 안정적인 쿼리 작성을 보장하며, 이를 통해 유지보수 과정에서도 큰 이점을 가져올 것으로 기대되었습니다.<br/>이러한 장점들 덕분에 QueryDSL은 데이터베이스 작업에 효율적이고 신뢰할 수 있는 도구로 선택되었습니다.<br/></td></tr><tr id="1f64cf8a-408c-4dde-ac59-7cc947831f74"><td id="ue=:" class=""><strong>트래픽 분산</strong></td><td id="Wd{&gt;" class="">AWS ALB</td><td id="D`@o" class="" style="width:553.9999847412109px">- 저렴한 EC2 단일 인스턴스로 프로젝트 목표인 1000 TPS를 초과하는 것은 한계가 있다고 판단했습니다. 따라서 동일한 스펙의 추가 서버를 배치하여 부하를 분산하는 Scale-out 전략을 사용해, 비용 효율적으로 성능을 향상했습니다.<br/>- ALB(Application Load Balancer)는 OSI 모델의 레이어 7(Application layer)에서 동작하며, HTTP/HTTPS 프로토콜 기반으로 작동합니다. 웹 애플리케이션 및 RESTful API에서 더욱 유연하고 다양한 기능을 제공하기 때문에, ALB의 사용이 적절하다고 판단했습니다.<br/></td></tr><tr id="d2eaec5c-44f5-44e1-aefe-59cf8771fd71"><td id="ue=:" class=""><strong>수요에 따른 <br/>EC2 인스턴스<br/>개수 조절<br/></strong></td><td id="Wd{&gt;" class="">AWS Auto Scaling</td><td id="D`@o" class="" style="width:553.9999847412109px">- 공연 예매 사이트의 특성상 특정 시간대에 트래픽이 집중되는 현상이 발생합니다. 이러한 상황에서 서버 수를 동적으로 조절하여 자원 사용량을 최적화하고 비용 절감 효과를 극대화할 수 있습니다.</td></tr><tr id="3daf549b-66c0-4235-8d82-93c64fdddc72"><td id="ue=:" class=""><strong>CI/CD</strong></td><td id="Wd{&gt;" class="">GitHub Actions</td><td id="D`@o" class="" style="width:553.9999847412109px">- GitHub Actions는 GitHub 플랫폼에 통합되어 있어서, 별도의 CI/CD 도구를 설정할 필요 없이 프로젝트에 손쉽게 적용할 수 있습니다. 또한, 워크플로우를 코드 저장소 내에서 정의하고 관리함으로써 사용자 경험의 편의성이 크게 향상됩니다.</td></tr><tr id="94f6fd83-460b-4fef-bf84-d589ddd827a2"><td id="ue=:" class=""><strong>배포 환경 일관성</strong></td><td id="Wd{&gt;" class="">Docker</td><td id="D`@o" class="" style="width:553.9999847412109px">- AWS Auto Scaling과 Load Balancer 기술을 사용함으로써, 지속적인 EC2 인스턴스 교체가 발생합니다. 이에 따라 배포 환경 간의 차이가 생겨 심각한 서비스 장애를 초래할 수 있습니다.<br/>이 문제를 해결하기 위해 Docker를 도입하여 애플리케이션과 모든 의존성을 컨테이너로 패키징 했습니다. 이를 통해 개발, 테스트, 운영 환경이 일관된 상태를 유지하게 되어 안정성을 높였습니다. 또한, GitHub Actions를 활용한 CI/CD 구현으로 애플리케이션 배포 및 확장 과정이 빠르고 효율적으로 진행되었습니다.<br/></td></tr><tr id="96200b0e-3150-4931-85d4-4c5bf0068201"><td id="ue=:" class=""><strong>모니터링</strong></td><td id="Wd{&gt;" class="">Grafana, Pinpoint</td><td id="D`@o" class="" style="width:553.9999847412109px">Grafana<br/>- Grafana를 사용하면, AWS CloudWatch와의 통합을 통해 AWS 로드 밸런서 그룹과 관련된 다양한 성능 지표를 한 곳에서 확인하고 관리할 수 있습니다. 직관적이고 사용자 친화적인 대시보드를 제공하며, 시각적으로 풍부한 대시보드, 맞춤형 시각화, 알림 기능 등을 활용해 서버 성능을 효과적으로 관리하고 문제에 신속하게 대응할 수 있는 도구로 선택되었습니다.<br/><br/>Pinpoint<br/>- Pinpoint를 도입한 이유는 애플리케이션 성능 모니터링, 분산 추적, 코드 레벨의 세부 정보 등의 기능을 활용하여 애플리케이션 성능 이슈를 빠르게 파악하고 효과적으로 대응할 수 있도록 지원하기 때문입니다.<br/></td></tr><tr id="632897c5-a976-493a-9db5-4bb1ea69cda7"><td id="ue=:" class=""><strong>Test</strong></td><td id="Wd{&gt;" class="">jmeter</td><td id="D`@o" class="" style="width:553.9999847412109px">분산 테스트 기능을 활용하여 여러 대의 서버를 사용해 대량의 가상 사용자를 동시에 생성하고 테스트할 수 있어, 실제 사용자 트래픽을 가장 정확하게 모방할 수 있습니다. 또한 다양한 조건과 로직을 적용하여 맞춤형 테스트 시나리오를 작성할 수 있습니다.</td></tr></tbody></table></details></li></ul><ul id="8125d057-04e8-4818-bfd8-0e04021270a5" class="toggle"><li><details open=""><summary>ERD</summary><figure id="aea5d569-6312-4f19-9ae5-04308752bf9c" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2010.png"><img style="width:858.4374389648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2010.png"/></a></figure></details></li></ul><ul id="86f3690f-3f28-4192-8077-f1e009d1aa3c" class="toggle"><li><details open=""><summary>API 명세서</summary><div id="600a9359-9f5c-4fbc-ae8e-eabea5a936fd" class="collection-content"><h4 class="collection-title">NETicket API 명세서 (1)</h4><table class="collection-content"><thead><tr><th><span class="icon property-icon"><img src="https://www.notion.so/icons/notification_gray.svg" style="width:14px;height:14px;display:block"/></span>기능</th><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(71, 70, 68, 0.6);flex-shrink:0" class="typesSelect"><path d="M8 15.126C11.8623 15.126 15.0615 11.9336 15.0615 8.06445C15.0615 4.20215 11.8623 1.00293 7.99316 1.00293C4.13086 1.00293 0.938477 4.20215 0.938477 8.06445C0.938477 11.9336 4.1377 15.126 8 15.126ZM8 13.7383C4.85547 13.7383 2.33301 11.209 2.33301 8.06445C2.33301 4.91992 4.84863 2.39746 7.99316 2.39746C11.1377 2.39746 13.6738 4.91992 13.6738 8.06445C13.6738 11.209 11.1445 13.7383 8 13.7383ZM7.62402 10.6348C7.79492 10.915 8.20508 10.9287 8.37598 10.6348L10.666 6.73145C10.8574 6.41016 10.7002 6.04102 10.3652 6.04102H5.62793C5.29297 6.04102 5.14941 6.43066 5.32031 6.73145L7.62402 10.6348Z"></path></svg></span>HTTP 메서드</th><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(71, 70, 68, 0.6);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>API URL</th><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(71, 70, 68, 0.6);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>Request Header</th><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(71, 70, 68, 0.6);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>Request</th><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(71, 70, 68, 0.6);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>Response</th><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(71, 70, 68, 0.6);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>Response Header</th><th><span class="icon property-icon"><svg aria-hidden="true" role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(71, 70, 68, 0.6);flex-shrink:0" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>비고</th></tr></thead><tbody><tr id="77fec0bf-e58b-4541-8a1a-8cb851441888"><td class="cell-title"><a href="https://www.notion.so/77fec0bfe58b45418a1a8cb851441888?pvs=21">회원가입 페이지 이동</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/neticket/signup</td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"><code>ModelAndView(&quot;signup&quot;)</code></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="36e950bf-7aa0-4a97-8719-bfbfa5de5fab"><td class="cell-title"><a href="https://www.notion.so/36e950bf7aa04a978719bfbfa5de5fab?pvs=21">로그인페이지 이동</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/neticket/login</td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"><code>ModelAndView(&quot;login&quot;)</code></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="17adf624-7eab-42ab-a08a-062ce92c2d13"><td class="cell-title"><a href="https://www.notion.so/17adf6247eab42aba08a062ce92c2d13?pvs=21">메인페이지 이동</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/neticket</td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"><code>ModelAndView(&quot;index&quot;)</code></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="d5d0f3e7-69b3-41eb-9f2d-872ead7aeb9d"><td class="cell-title"><a href="https://www.notion.so/d5d0f3e769b341eb9f2d872ead7aeb9d?pvs=21">상세페이지 이동</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/neticket/events/{eventId}</td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"><code>ModelAndView(&quot;detail&quot;)</code></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="ba8137a2-12ea-4896-8497-181d193c34fe"><td class="cell-title"><a href="https://www.notion.so/ba8137a212ea48968497181d193c34fe?pvs=21">예매중 페이지 이동</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/neticket/reservations/in-progress/{ticketInfoId}</td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"><code>ModelAndView(&quot;reservation&quot;)</code></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="ef244e52-fe32-4529-af33-e5daedfbcac0"><td class="cell-title"><a href="https://www.notion.so/ef244e52fe324529af33e5daedfbcac0?pvs=21">예매 완료 페이지 이동</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/neticket/reservations/completed/{resvId}</td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"><code>ModelAndView(&quot;completed&quot;)</code></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="4f308149-0b33-40df-af5c-29d3f460917a"><td class="cell-title"><a href="https://www.notion.so/4f3081490b3340dfaf5c29d3f460917a?pvs=21">공연 추가 페이지 이동</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/neticket/admin/event</td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"><code>ModelAndView(&quot;addevent&quot;)</code></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="dfd9c449-9c82-487d-912c-4acf461d6568"><td class="cell-title"><a href="https://www.notion.so/dfd9c4499c82487d912c4acf461d6568?pvs=21">마이 페이지 이동</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/neticket/user/{nickname}</td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"><code>ModelAndView(&quot;mypage&quot;)</code></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="f45fd0b1-5d18-480a-a9c1-bc778642fd35"><td class="cell-title"><a href="https://www.notion.so/f45fd0b15d18480aa9c1bc778642fd35?pvs=21">검색 페이지 이동</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/neticket/search</td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"><code>ModelAndView(&quot;search&quot;)</code></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="4dc2e054-ac35-4ad6-ae54-7b4a7ce7a0b6"><td class="cell-title"><a href="https://www.notion.so/4dc2e054ac354ad6ae547b4a7ce7a0b6?pvs=21">Untitled</a></td><td class="cell-`]To"></td><td class="cell-S{t_"></td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">PageController</mark></td></tr><tr id="0f98e233-bc54-4f3b-8002-8daaa3cb618f"><td class="cell-title"><a href="https://www.notion.so/0f98e233bc544f3b80028daaa3cb618f?pvs=21">회원가입</a></td><td class="cell-`]To"><span class="selected-value select-value-color-yellow">POST</span></td><td class="cell-S{t_">/api/neticket/signup</td><td class="cell-DCh;"></td><td class="cell-X[lr">body json<br/>{<br/>&quot;email&quot;: &quot;abc@abc.com&quot;,<br/>&quot;password&quot;: &quot;password11@&quot;,<br/>&quot;nickname&quot;: &quot;닉네임&quot;<br/>}<br/></td><td class="cell-=upv">{<br/>    &quot;msg&quot;: &quot;회원가입 완료&quot;,<br/>    &quot;statusCode&quot;: 201<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">UserController</mark></td></tr><tr id="c8aff2e3-28ea-48c3-b4e6-ef223388d4a5"><td class="cell-title"><a href="https://www.notion.so/c8aff2e328ea48c3b4e6ef223388d4a5?pvs=21">로그인</a></td><td class="cell-`]To"><span class="selected-value select-value-color-yellow">POST</span></td><td class="cell-S{t_">/api/neticket/login</td><td class="cell-DCh;"></td><td class="cell-X[lr">body json<br/>{<br/>    &quot;email&quot;: &quot;abc@abc.com&quot;,<br/>    &quot;password&quot;: &quot;password11@&quot;<br/>}<br/></td><td class="cell-=upv">{<br/>    &quot;msg&quot;: &quot;로그인 완료&quot;,<br/>    &quot;statusCode&quot;: 200<br/>}<br/><br/></td><td class="cell-TVpt">Authorization: Bearer eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJiaW4xMjM0IiwiZXhwIjoxNjY5ODcwNDUyLCJpYXQiOjE2Njk4NjY4NTJ9.mm8wgaV8M70hidhPX4Ut6UONZGaxjA1KnOJT1mO59Xc</td><td class="cell-QL|I"><mark class="highlight-blue">UserController<br/><br/></mark></td></tr><tr id="c815c860-32c9-44e7-a2d7-c22c45c7fe09"><td class="cell-title"><a href="https://www.notion.so/c815c86032c944e7a2d7c22c45c7fe09?pvs=21">마이페이지</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/api/neticket/user</td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr"></td><td class="cell-=upv">{<br/>&quot;image&quot;: &quot;randomUUID_xx콘서트.jpg&quot;,<br/>”resvId”: 12345,<br/>”title”: “공연제목”,<br/>”place”: “공연장소”,<br/>”date”: “공연날짜”,<br/>”totalPrice”: “총 가격(매수*1장당가격)”,<br/>”count”: “매수”<br/>},<br/>….<br/>{<br/>&quot;image&quot;: &quot;randomUUID_xx콘서트.jpg&quot;,<br/>”resvId”: 12346,<br/>”title”: “공연제목”,<br/>”place”: “공연장소”,<br/>”date”: “공연날짜”,<br/>”totalPrice”: “총 가격(매수*1장당가격)”,<br/>”count”: “매수”<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">UserController</mark></td></tr><tr id="73d8e888-0d5f-4aaf-97e2-9918b862d49c"><td class="cell-title"><a href="https://www.notion.so/73d8e8880d5f4aaf97e29918b862d49c?pvs=21">Untitled</a></td><td class="cell-`]To"></td><td class="cell-S{t_"></td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"></td><td class="cell-TVpt"></td><td class="cell-QL|I"></td></tr><tr id="fa09c215-4e1a-4c6d-8b4f-cca36a17aae4"><td class="cell-title"><a href="https://www.notion.so/Redis-fa09c2154e1a4c6d8b4fcca36a17aae4?pvs=21">Redis 좌석 수 저장</a></td><td class="cell-`]To"><span class="selected-value select-value-color-yellow">POST</span></td><td class="cell-S{t_">/api/neticket/cache/left-seats/{ticketInfoId}<br/><br/>(@Pathvariable)<br/></td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr"></td><td class="cell-=upv">{<br/>    &quot;msg&quot;: &quot;redis에 성공적으로 저장되었습니다.&quot;,<br/>    &quot;statusCode&quot;: 201<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">AdminController</mark></td></tr><tr id="75656365-4bf4-4722-aa93-dab46e302daf"><td class="cell-title"><a href="https://www.notion.so/Redis-756563654bf44722aa93dab46e302daf?pvs=21">Redis 좌석 수 삭제</a></td><td class="cell-`]To"><span class="selected-value select-value-color-red">DELETE</span></td><td class="cell-S{t_">/api/neticket/cache/left-seats/{ticketInfoId}<br/><br/>(@Pathvariable)<br/></td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr"></td><td class="cell-=upv">{<br/>    &quot;msg&quot;: &quot;redis에 성공적으로 삭제되었습니다.&quot;,<br/>    &quot;statusCode&quot;: 200<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">AdminController</mark></td></tr><tr id="7aaaabab-178e-4b5e-8810-3edc60cb6bc9"><td class="cell-title"><a href="https://www.notion.so/Redis-7aaaabab178e4b5e88103edc60cb6bc9?pvs=21">Redis 좌석 수 리스트 조회</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/api/neticket/cache/left-seats</td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr"></td><td class="cell-=upv">[<br/>&quot;ls47&quot;,<br/>&quot;ls25&quot;,<br/>…..<br/>&quot;ls18&quot;,<br/>&quot;ls10&quot;<br/>]<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">AdminController</mark></td></tr><tr id="bf83200d-2f36-47b0-ac03-31fc90601d43"><td class="cell-title"><a href="https://www.notion.so/Redis-bf83200d2f3647b0ac0331fc90601d43?pvs=21">Redis 좌석 수 갱신</a></td><td class="cell-`]To"><span class="selected-value select-value-color-purple">Patch</span></td><td class="cell-S{t_">/api/neticket/cache/left-seats/{ticketInfoId}<br/><br/>(@Pathvariable)<br/></td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr"></td><td class="cell-=upv">{<br/>    &quot;msg&quot;: &quot;redis와 DB의 남은 좌석수를 올바르게 맞췄습니다.&quot;,<br/>    &quot;statusCode&quot;: 200<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">AdminController</mark></td></tr><tr id="44d412e7-f567-4282-a976-b51f202456f5"><td class="cell-title"><a href="https://www.notion.so/DB-Redis-44d412e7f5674282a976b51f202456f5?pvs=21">DB, Redis 공연 정보 리셋</a></td><td class="cell-`]To"><span class="selected-value select-value-color-purple">Patch</span></td><td class="cell-S{t_">/api/neticket/cache</td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr"></td><td class="cell-=upv">{<br/>    &quot;msg&quot;: &quot;공연 상태를 성공적으로 조정했습니다.&quot;,<br/>    &quot;statusCode&quot;: 200<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">AdminController</mark></td></tr><tr id="f1aa5305-2f43-42d7-af00-0aeb6c522cdf"><td class="cell-title"><a href="https://www.notion.so/f1aa53052f4342d7af000aeb6c522cdf?pvs=21">Untitled</a></td><td class="cell-`]To"></td><td class="cell-S{t_"></td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"></td><td class="cell-TVpt"></td><td class="cell-QL|I"></td></tr><tr id="153a56c3-87e8-49d9-8087-f25d3bc00613"><td class="cell-title"><a href="https://www.notion.so/153a56c387e849d98087f25d3bc00613?pvs=21">메인페이지 조회</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/api/neticket/events/?page=1<br/><br/>(@RequestParam)<br/></td><td class="cell-DCh;"></td><td class="cell-X[lr">param(쿼리스트링)<br/>{<br/>”page” : int 현재페이지<br/>}<br/></td><td class="cell-=upv">공연카드 페이지 반환<br/>{<br/>&quot;content&quot;: [<br/>{<br/>&quot;id&quot;: 4,<br/>&quot;title&quot;: &quot;어느유명한가수콘서트4&quot;,<br/>&quot;date&quot;: &quot;2023-04-09&quot;,<br/>&quot;place&quot;: &quot;잠실어디가경기장&quot;,<br/>&quot;image&quot;: &quot;imageurl&quot;,<br/>”available&quot;: true<br/>},<br/>…<br/>{<br/>&quot;id&quot;: 5,<br/>&quot;title&quot;: &quot;어느유명한가수콘서트5&quot;,<br/>&quot;date&quot;: &quot;2023-04-11&quot;,<br/>&quot;place&quot;: &quot;잠실어디가경기장&quot;,<br/>&quot;image&quot;: &quot;imageurl&quot;,<br/>”available&quot;: true<br/>}<br/>],<br/>&quot;pageable&quot;: {<br/>&quot;sort&quot;: {<br/>&quot;empty&quot;: true,<br/>&quot;sorted&quot;: false,<br/>&quot;unsorted&quot;: true<br/>},<br/>&quot;offset&quot;: 0,<br/>&quot;pageSize&quot;: 8,<br/>&quot;pageNumber&quot;: 0,<br/>&quot;unpaged&quot;: false,<br/>&quot;paged&quot;: true<br/>},<br/>&quot;last&quot;: true,<br/>&quot;totalElements&quot;: 5,<br/>&quot;totalPages&quot;: 1,<br/>&quot;size&quot;: 8,<br/>&quot;number&quot;: 0,<br/>&quot;sort&quot;: {<br/>&quot;empty&quot;: true,<br/>&quot;sorted&quot;: false,<br/>&quot;unsorted&quot;: true<br/>},<br/>&quot;first&quot;: true,<br/>&quot;numberOfElements&quot;: 5,<br/>&quot;empty&quot;: false<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">EventController</mark><br/><br/></td></tr><tr id="f0de8d04-594c-4189-8a06-a26d99ad9024"><td class="cell-title"><a href="https://www.notion.so/f0de8d04594c41898a06a26d99ad9024?pvs=21">상세 페이지 조회</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/api/neticket/events/{eventId}<br/><br/>(@Pathvariable)<br/></td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv">{<br/>&quot;image&quot;: &quot;randomUUID_xx콘서트.jpg&quot;,<br/>”eventId”: 12345,<br/>”title”: “공연제목”,<br/>”place”: “공연장소”,<br/>”price”: “ 가격(1장당가격)”,<br/>”date”: “공연날짜”,<br/>”ticketInfoDto”: <br/>[<br/>”ticketInfoid”: 1,<br/>”openDate”: “티켓오픈시간,<br/>”leftSeate”: “남은 좌석 수”<br/>]<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">EventController<br/><br/><br/></mark></td></tr><tr id="cf0ee964-be76-41e9-87ad-1f5e9353d9df"><td class="cell-title"><a href="https://www.notion.so/cf0ee964be7641e987ad1f5e9353d9df?pvs=21">공연 추가</a></td><td class="cell-`]To"><span class="selected-value select-value-color-yellow">POST</span></td><td class="cell-S{t_">/api/neticket/events<br/><br/>메인페이지에 관리자만<br/>공연추가 버튼 활성화<br/></td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr">body<br/>{<br/>image: 이미지.jpg,<br/>dto: {<br/>&quot;title&quot;: &quot;공연명&quot;,<br/>&quot;place&quot;: &quot;공연장소&quot;,<br/>&quot;price&quot;: 120000,<br/>&quot;date&quot;: &quot;공연날짜&quot;,<br/>&quot;openDate&quot;: &quot;티켓오픈시간&quot;,<br/>&quot;totalSeat&quot;: 10000<br/>}<br/>}<br/><br/></td><td class="cell-=upv">{<br/>    &quot;msg&quot;: &quot;공연이 추가되었습니다.&quot;,<br/>    &quot;statusCode&quot;: 201<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">EventController</mark></td></tr><tr id="584e5d79-2b82-4e9e-b646-791b05d450a9"><td class="cell-title"><a href="https://www.notion.so/584e5d792b824e9eb646791b05d450a9?pvs=21">검색기능</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/api/neticket/events/search?keyword=검색어&amp;page=1<br/><br/><br/>(@RequestParam)<br/>저가순 검색 정렬 예시<br/></td><td class="cell-DCh;"></td><td class="cell-X[lr">param(쿼리스트링)<br/>{<br/>”keyword” : 검색어,<br/>”page” : int 현재페이지<br/>}<br/></td><td class="cell-=upv">검색결과 공연 카드로 반환<br/>{<br/>&quot;content&quot;: [<br/>{<br/>&quot;id&quot;: 1,<br/>&quot;title&quot;: &quot;어느유명한가수콘서트1&quot;,<br/>&quot;date&quot;: &quot;2023-08-01&quot;,<br/>&quot;place&quot;: &quot;잠실어디가경기장&quot;,<br/>&quot;image&quot;: &quot;imageurl&quot;,<br/>”available&quot;: true<br/>},<br/>…<br/>{<br/>&quot;id&quot;: 2,<br/>&quot;title&quot;: &quot;어느유명한가수콘서트2&quot;,<br/>&quot;date&quot;: &quot;2023-07-07&quot;,<br/>&quot;place&quot;: &quot;잠실어디가경기장&quot;,<br/>&quot;image&quot;: &quot;imageurl&quot;,<br/>”available&quot;: true<br/>}<br/>],<br/>&quot;pageable&quot;: {<br/>&quot;sort&quot;: {<br/>&quot;empty&quot;: false,<br/>&quot;sorted&quot;: true,<br/>&quot;unsorted&quot;: false<br/>},<br/>&quot;offset&quot;: 0,<br/>&quot;pageSize&quot;: 8,<br/>&quot;pageNumber&quot;: 0,<br/>&quot;unpaged&quot;: false,<br/>&quot;paged&quot;: true<br/>},<br/>&quot;last&quot;: true,<br/>&quot;totalPages&quot;: 1,<br/>&quot;totalElements&quot;: 5,<br/>&quot;size&quot;: 8,<br/>&quot;number&quot;: 0,<br/>&quot;sort&quot;: {<br/>&quot;empty&quot;: false,<br/>&quot;sorted&quot;: true,<br/>&quot;unsorted&quot;: false<br/>},<br/>&quot;first&quot;: true,<br/>&quot;numberOfElements&quot;: 5,<br/>&quot;empty&quot;: false<br/>}<br/><br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">EventController</mark><br/><br/><br/><br/></td></tr><tr id="d1c683fe-0e8f-4b43-b286-fb79c9db52b6"><td class="cell-title"><a href="https://www.notion.so/d1c683fe0e8f4b43b286fb79c9db52b6?pvs=21">Untitled</a></td><td class="cell-`]To"></td><td class="cell-S{t_"></td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv"></td><td class="cell-TVpt"></td><td class="cell-QL|I"></td></tr><tr id="bbf3e814-7308-4b97-8f4f-c0dbbed4effc"><td class="cell-title"><a href="https://www.notion.so/bbf3e81473084b978f4fc0dbbed4effc?pvs=21">예매중 확인하기</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/api/neticket/ticket-info/{ticketInfoId}<br/><br/>(@Pathvariable)<br/></td><td class="cell-DCh;"></td><td class="cell-X[lr"></td><td class="cell-=upv">{<br/>&quot;image&quot;: &quot;randomUUID_xx콘서트.jpg&quot;,<br/>”eventId”: 12345,<br/>”title”: “공연제목”,<br/>”place”: “공연장소”,<br/>”price”: “ 가격(1장당가격)”,<br/>”date”: “공연날짜”,<br/>”ticketInfoDto”: <br/>[<br/>”ticketInfoid”: 1,<br/>”openDate”: “티켓오픈시간,<br/>”leftSeate”: “남은 좌석 수”<br/>]<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">ReservationController</mark></td></tr><tr id="9bf5b462-e91a-4f3d-9e41-2da259682c3a"><td class="cell-title"><a href="https://www.notion.so/9bf5b462e91a4f3d9e412da259682c3a?pvs=21">예매하기</a></td><td class="cell-`]To"><span class="selected-value select-value-color-yellow">POST</span></td><td class="cell-S{t_">/api/neticket/reservations</td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr">body<br/>{<br/>”ticketInfoId”: 1,<br/>”count”: 3<br/>}<br/><br/></td><td class="cell-=upv">(예매성공)<br/>{<br/>예매 번호 <br/>}<br/><br/>(예매실패)<br/>{<br/>    &quot;msg&quot;: &quot;예매실패&quot;,<br/>    &quot;statusCode&quot;: 예외처리코드<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">ReservationController</mark></td></tr><tr id="98247e6e-efdc-4370-bb9d-3e7caa1ec092"><td class="cell-title"><a href="https://www.notion.so/98247e6eefdc4370bb9d3e7caa1ec092?pvs=21">예매완료</a></td><td class="cell-`]To"><span class="selected-value select-value-color-green">GET</span></td><td class="cell-S{t_">/api/neticket/reservations/{reservationId}<br/><br/>(@Pathvariable)<br/></td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr"></td><td class="cell-=upv">{<br/>&quot;image&quot;: &quot;randomUUID_xx콘서트.jpg&quot;,<br/>”resvId”: 12345,<br/>”title”: “공연제목”,<br/>”place”: “공연장소”,<br/>”date”: “공연날짜”,<br/>”totalPrice”: “총 가격(매수*1장당가격)”,<br/>”count”: “매수”<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">ReservationController</mark></td></tr><tr id="205d67f4-d8d9-4abb-b559-589b08e3ca9b"><td class="cell-title"><a href="https://www.notion.so/205d67f4d8d94abbb559589b08e3ca9b?pvs=21">예매 취소</a></td><td class="cell-`]To"><span class="selected-value select-value-color-red">DELETE</span></td><td class="cell-S{t_">/api/neticket/reservations/{resvId}<br/><br/>(@Pathvariable)<br/></td><td class="cell-DCh;">header<br/>Authorization: 토큰정보<br/></td><td class="cell-X[lr"></td><td class="cell-=upv">(예매취소성공)<br/>{<br/>    &quot;msg&quot;: &quot;예매 기록이 성공적으로 삭제되었습니다.&quot;,<br/>    &quot;statusCode&quot;: 200<br/>}<br/><br/>(예매취소실패)<br/>{<br/>    &quot;msg&quot;: &quot;예매실패&quot;,<br/>    &quot;statusCode&quot;: 예외처리코드<br/>}<br/></td><td class="cell-TVpt"></td><td class="cell-QL|I"><mark class="highlight-blue">ReservationController</mark></td></tr></tbody></table><br/><br/></div><p id="4674726f-85ea-448f-b1ef-26807acd8d83" class="">
</p></details></li></ul><figure id="45d6ced1-a056-488d-ab8e-c1b87937bad2" class="link-to-page"><a href="https://www.notion.so/45d6ced1a056488dab8ec1b87937bad2?pvs=21">발표</a></figure><h3 id="0c193786-0e4d-4a00-9408-ededfe9c1593" class="">예매 서비스 로직에서 데이터 무결성을 지키며 응답속도와 TPS 개선 🌟</h3><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1ebeb3ce-9f67-488f-85eb-47beb0a8540f"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">챌린지 포인트로 설정한 목표를 달성하기 위해<br/>예매 서비스 로직에서 ‘남은 좌석 수’의 데이터 무결성을 지켜야 하고,<br/>많은 트랜잭션을 처리하여 클라이언트에게 빠른 응답 속도로 예매 결과를 돌려줘야 합니다.<br/></div></figure><figure id="ec4e10e0-ae92-41ad-a0f8-659191f36d82" class="link-to-page"><a href="https://www.notion.so/1-1-ec4e10e0ae9241ada0f8659191f36d82?pvs=21"><span class="icon">☠️</span>1. 트랜잭션 충돌 문제를 비관적 락으로 해결 (1)</a></figure><figure id="0a3f2984-241a-48b6-a691-be96a6ccd887" class="link-to-page"><a href="https://www.notion.so/2-Redis-Cache-1-0a3f2984241a48b6a691be96a6ccd887?pvs=21"><span class="icon">⛹🏼</span>2. 비관적 락 적용 시 속도 문제를 Redis Cache로 해결 (1)</a></figure><figure id="d55072ad-4d04-4158-9f76-cc446ee14d02" class="link-to-page"><a href="https://www.notion.so/3-Scale-Out-1-d55072ad4d0441589f76cc446ee14d02?pvs=21"><span class="icon">🚄</span>3. 더 높은 목표치를 Scale Out으로 해결 (1)</a></figure><figure id="32c30a7a-aa15-4bef-a6ee-ede0215b369a" class="link-to-page"><a href="https://www.notion.so/4-AutoScaling-1-32c30a7aaa154befa6eeede0215b369a?pvs=21"><span class="icon">💸</span>4. 서버 확장으로 인한 비용 문제를 AutoScaling으로 해결 (1)</a></figure><figure id="b8900e36-71cc-40f5-bf7c-d7f2ad4bfd48" class="link-to-page"><a href="https://www.notion.so/5-APM-Hikari-MySQL-1-b8900e3671cc40f5bf7cd7f2ad4bfd48?pvs=21"><span class="icon">🖥️</span>5. APM으로 찾은 병목현상을 Hikari, MySQL 튜닝으로 해결 (1)</a></figure><figure id="8c80d7ce-ecb5-47b7-9579-b6b62f4ac3fa"><div class="source">https://github.com/hanghae99-Challenge-2-teams/NETicket</div></figure></details></li></ul><ul id="1ed3a4cc-090a-8043-b79d-ec00c41b5209" class="toggle"><li><details open=""><summary><span style="border-bottom:0.05em solid">100만 이상 동시 접속 요청 시 안정적으로 티켓을 예매할 수 있는 시스템을 설계</span></summary><h2 id="1ed3a4cc-090a-8097-8db6-f6187fd12bba" class="">🎯 <strong>목표</strong></h2><blockquote id="1ed3a4cc-090a-808b-86cf-eb6dc8184822" class="">100만 명 이상 동시 접속 요청이 들어와도, 빠르고 안정적으로 티켓을 예매할 수 있는 시스템을 설계합니다.</blockquote><p id="1ed3a4cc-090a-8056-b1d5-e3d8b54daca5" class="">이런 시스템은 흔히 <strong>&quot;티켓팅 시스템&quot;</strong>, 또는 &quot;Flash Sale Architecture&quot;라고 불리며,</p><p id="1ed3a4cc-090a-8036-947b-c3d4ff90a94e" class=""><strong>초단기 폭주 트래픽, 재고 한정성, 무결성 보장</strong>이 핵심 과제입니다.</p><hr id="1ed3a4cc-090a-8028-85bc-fb505d66bc63"/><h2 id="1ed3a4cc-090a-8080-bb07-df2e5d7c62f1" class="">✅ 시스템 설계 핵심 포인트</h2><table id="1ed3a4cc-090a-80a8-b294-c7e061892365" class="simple-table"><tbody><tr id="1ed3a4cc-090a-801f-a275-e1149b1509a3"><td id="Ldsz" class="">핵심 요소</td><td id="cYgp" class="" style="width:324.9921875px">설명</td></tr><tr id="1ed3a4cc-090a-808b-a9be-d29a7be6d016"><td id="Ldsz" class="">🌐 <strong>트래픽 제어</strong></td><td id="cYgp" class="" style="width:324.9921875px">대기열, 캐시, 레이트 리밋</td></tr><tr id="1ed3a4cc-090a-8097-9742-f539bc4309e8"><td id="Ldsz" class="">⚙️ <strong>고속 처리 구조</strong></td><td id="cYgp" class="" style="width:324.9921875px">In-memory Queue, 분산 처리</td></tr><tr id="1ed3a4cc-090a-8040-a6ba-ec57072863c4"><td id="Ldsz" class="">🔐 <strong>재고 무결성 보장</strong></td><td id="cYgp" class="" style="width:324.9921875px">오버셀링 방지, 원자성 보장</td></tr><tr id="1ed3a4cc-090a-8099-b730-de538fa8837a"><td id="Ldsz" class="">📊 <strong>관측 가능성/모니터링</strong></td><td id="cYgp" class="" style="width:324.9921875px">실시간 로드/에러 추적</td></tr></tbody></table><hr id="1ed3a4cc-090a-80db-b481-c3459bbf0386"/><h2 id="1ed3a4cc-090a-80e5-9f14-e0c1425c8ab1" class="">🧱 전체 시스템 구성도 (설계 레이어)</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1ed3a4cc-090a-80cb-af0c-e16b0fa50902" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">[1] 클라이언트 (웹/모바일)
        ↓
[2] Load Balancer (L7 - CloudFront, ALB)
        ↓
[3] API Gateway or Web App (Node.js, Spring 등)
        ↓
[4] Rate Limiter + 대기열 서버 (Redis, Nginx Lua)
        ↓
[5] 예매 요청 캐싱 + 비동기 처리 큐 (Kafka, Redis Stream)
        ↓
[6] 재고 처리 서버 (Go, Java 등 고성능 프로세서)
        ↓
[7] 데이터베이스 (MySQL with row-lock, Redis stock cache)</code></pre><hr id="1ed3a4cc-090a-8015-b5d0-d20bf8979453"/><h2 id="1ed3a4cc-090a-802b-83f6-fc4135c3453a" class="">✅ 계층별 주요 설계 요소</h2><h3 id="1ed3a4cc-090a-8032-9b4a-e8cc58c4dc10" class="">1. 🌐 클라이언트 + CDN</h3><ul id="1ed3a4cc-090a-80fa-bf7b-dcc2ca858079" class="bulleted-list"><li style="list-style-type:disc">정적 자산은 <strong>CloudFront/S3</strong> 등으로 미리 분산 캐싱</li></ul><ul id="1ed3a4cc-090a-8088-800f-c0901ea11b3f" class="bulleted-list"><li style="list-style-type:disc">클라이언트에서 <strong>티켓팅 시작 시간 이전 대기 화면</strong> 표시</li></ul><hr id="1ed3a4cc-090a-80a9-b68e-c7cabb9eb258"/><h3 id="1ed3a4cc-090a-80ae-969a-cbe275a15895" class="">2. ⚖️ Load Balancer + WAF</h3><ul id="1ed3a4cc-090a-80be-a1ed-f26a700b36cc" class="bulleted-list"><li style="list-style-type:disc"><strong>초기 폭주 트래픽 방어</strong><ul id="1ed3a4cc-090a-80b7-95c9-f940ad93ca6b" class="bulleted-list"><li style="list-style-type:circle">CDN + ALB + Auto Scaling 조합</li></ul><ul id="1ed3a4cc-090a-8008-9632-c47b1b67fcfa" class="bulleted-list"><li style="list-style-type:circle"><strong>봇 차단, IP 제한, 시간 기반 허용</strong></li></ul></li></ul><hr id="1ed3a4cc-090a-8017-9b11-f680073551d2"/><h3 id="1ed3a4cc-090a-8023-b5da-fa31f3218632" class="">3. ⏳ Rate Limiter / 대기열</h3><ul id="1ed3a4cc-090a-802f-bb4f-efe283ff0a81" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis Token Bucket 또는 Nginx Lua 모듈</strong> 활용</li></ul><ul id="1ed3a4cc-090a-80fb-912f-c80078db5fa2" class="bulleted-list"><li style="list-style-type:disc">초당 처리 가능한 요청만 API 통과 허용</li></ul><ul id="1ed3a4cc-090a-80e2-bed1-d4790c9df096" class="bulleted-list"><li style="list-style-type:disc">초과 요청은 <strong>대기열로 분산 또는 429 응답</strong></li></ul><hr id="1ed3a4cc-090a-80aa-8ac9-cb7ef77e29a0"/><h3 id="1ed3a4cc-090a-803a-9bfc-d38fcfcc0191" class="">4. ⚙️ 예매 요청 큐 처리</h3><ul id="1ed3a4cc-090a-8037-a549-eb40a6c21c8a" class="bulleted-list"><li style="list-style-type:disc">통과된 요청은 <strong>Kafka / Redis Stream / SQS</strong> 등에 저장</li></ul><ul id="1ed3a4cc-090a-80f9-acb7-ccda8465e9a5" class="bulleted-list"><li style="list-style-type:disc">실제 예매는 <strong>비동기적으로 큐에서 소비</strong></li></ul><p id="1ed3a4cc-090a-80be-8539-ccd4d01acff8" class="">➡ 시스템 부하를 <strong>비동기 구조</strong>로 분산</p><hr id="1ed3a4cc-090a-802a-bac6-e339d3d32a84"/><h3 id="1ed3a4cc-090a-8078-93c4-dab67ad3bb36" class="">5. 🧠 재고 처리 서버 (핵심 로직)</h3><ul id="1ed3a4cc-090a-8063-8c4e-cc84552e3189" class="bulleted-list"><li style="list-style-type:disc">재고 수량은 <strong>Redis</strong>로 선 캐싱 (e.g., <code>ticket:concert123:stock</code>)</li></ul><ul id="1ed3a4cc-090a-8045-a843-e44d667192bf" class="bulleted-list"><li style="list-style-type:disc">Redis 내에서 <strong>atomic 명령 (</strong><code><strong>DECR</strong></code><strong>)</strong> 으로 재고 감소</li></ul><ul id="1ed3a4cc-090a-8020-a2d3-c274c61aee0b" class="bulleted-list"><li style="list-style-type:disc"><strong>MySQL</strong>에는 최종 확정 트랜잭션만 기록 (이중 저장소)</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1ed3a4cc-090a-801d-a6ab-fbac46be554b" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">if redis.decr(&quot;ticket:concert123:stock&quot;) &gt;= 0:
    enqueue_to_db_writer_queue(order)
else:
    return &quot;Sold Out&quot;</code></pre><hr id="1ed3a4cc-090a-8076-90b8-c2a3b72ab31a"/><h3 id="1ed3a4cc-090a-80bf-b153-df910e2f9214" class="">6. 💾 데이터베이스</h3><ul id="1ed3a4cc-090a-80c3-ad51-c5c427ded995" class="bulleted-list"><li style="list-style-type:disc">예매 성공 기록, 유저 정보, 결제 상태 저장</li></ul><ul id="1ed3a4cc-090a-80a9-a6f5-fb9a15c112a9" class="bulleted-list"><li style="list-style-type:disc"><strong>MySQL/InnoDB</strong> + 트랜잭션 / Row Lock 사용</li></ul><ul id="1ed3a4cc-090a-8094-8923-dc0f701c9509" class="bulleted-list"><li style="list-style-type:disc">재고 처리 서버에서 <strong>최종 정합성 검증</strong> 후 DB 쓰기</li></ul><hr id="1ed3a4cc-090a-8042-aba6-c7d949ce0ce5"/><h3 id="1ed3a4cc-090a-8068-98a2-c120065f3800" class="">7. 📡 관측성과 복구 설계</h3><ul id="1ed3a4cc-090a-800d-851a-e698f7863510" class="bulleted-list"><li style="list-style-type:disc"><strong>Prometheus + Grafana</strong>로 TPS, 오류율, 재고 소진 추적</li></ul><ul id="1ed3a4cc-090a-8037-b018-f111a9358fab" class="bulleted-list"><li style="list-style-type:disc">Kafka/Redis Queue의 <strong>DLQ(Dead Letter Queue)</strong> 설정</li></ul><ul id="1ed3a4cc-090a-802b-89c0-e9762ad8ef16" class="bulleted-list"><li style="list-style-type:disc">예매 실패 시 <strong>자동 환불/취소 큐</strong> 운영</li></ul><hr id="1ed3a4cc-090a-8047-972c-de69db65e185"/><h2 id="1ed3a4cc-090a-807a-9c89-f1e80730d62d" class="">✅ 보완 기술</h2><table id="1ed3a4cc-090a-80b0-a85e-e8953c18cb4c" class="simple-table"><tbody><tr id="1ed3a4cc-090a-800e-a377-dbf9687572a6"><td id="EUTC" class="" style="width:155px">목적</td><td id="@=bO" class="" style="width:536px">기술</td></tr><tr id="1ed3a4cc-090a-805b-a43b-dbcc32905dcc"><td id="EUTC" class="" style="width:155px">오버셀링 방지</td><td id="@=bO" class="" style="width:536px">Redis Atomic, Lua Script</td></tr><tr id="1ed3a4cc-090a-807d-9189-cf8361a61551"><td id="EUTC" class="" style="width:155px">트래픽 완화</td><td id="@=bO" class="" style="width:536px">CDN, Rate Limit, 대기열</td></tr><tr id="1ed3a4cc-090a-8076-a81f-f3d805a6192c"><td id="EUTC" class="" style="width:155px">안정성 &amp; 복원성</td><td id="@=bO" class="" style="width:536px">Queue + Retry + DLQ</td></tr><tr id="1ed3a4cc-090a-807b-88c7-f9a6d0fa095b"><td id="EUTC" class="" style="width:155px">부정 요청 차단</td><td id="@=bO" class="" style="width:536px">CAPTCHA, 로그인 기반 제한</td></tr><tr id="1ed3a4cc-090a-8013-8157-ce6617d73810"><td id="EUTC" class="" style="width:155px">실시간 알림</td><td id="@=bO" class="" style="width:536px">WebSocket / SSE (예매 성공 시 알림)</td></tr></tbody></table><hr id="1ed3a4cc-090a-800f-9699-e5941ab17230"/><h2 id="1ed3a4cc-090a-80b4-89d1-cfedfac9fce7" class="">🧠 결론</h2><blockquote id="1ed3a4cc-090a-8012-b5ff-cab937934b8c" class="">수백만 동시 요청이 몰리는 티켓 예매 시스템은<p id="1ed3a4cc-090a-806a-a928-d32a05122449" class="">단순 API 구조로는 대응이 불가능하며,</p><p id="1ed3a4cc-090a-8013-90cf-d3d31cbfd886" class=""><strong>트래픽 제어 + 큐 기반 비동기 처리 + 인메모리 재고 관리</strong>가 필수입니다.</p></blockquote><p id="1ed3a4cc-090a-80cc-97a9-e1331f93c8e6" class=""><strong>Kafka, Redis, RateLimiter, CDN, AutoScaling</strong> 등을 조합하여</p><p id="1ed3a4cc-090a-80c1-b22f-f6d36a6d4c28" class=""><strong>고성능 + 고가용성 + 무결성 보장 아키텍처</strong>로 설계해야 합니다.</p><p id="1ed3a4cc-090a-8002-ab0e-c7c57c264c32" class="">
</p></details></li></ul><ul id="a7fdc46b-1b6b-4e14-bb02-8d25d1535b72" class="toggle"><li><details open=""><summary>Redis를 사용한 예매 시스템 구현 기술</summary><p id="ae27b68b-8bcb-48a9-8a12-b800fe371f32" class="">Redis를 사용하여 티켓 예매 시스템을 구현하려면 다음과 같은 세부 기술과 방법을 고려할 수 있습니다. 이 설명은 Redis의 다양한 기능을 활용하여 대기열 관리, 티켓 상태 관리, 사용자 세션 관리 등을 처리하는 방법을 다룹니다.</p><h2 id="88b2b1c8-aa32-4690-a059-e152876037a1" class="">1. 시스템 구성 요소</h2><h3 id="8835c746-d722-42f0-a921-1fac3a0b08a5" class="">Redis의 역할</h3><ul id="62f7fead-f17c-4eb8-88a6-09acc6a8e26b" class="bulleted-list"><li style="list-style-type:disc"><strong>대기열 관리 (Queue Management)</strong>: 사용자 대기열을 관리하고 예매 페이지로 이동하는 사용자를 제어합니다.</li></ul><ul id="9a0062f5-a8d9-4842-bfa5-c4961bc56843" class="bulleted-list"><li style="list-style-type:disc"><strong>티켓 관리 (Ticket Management)</strong>: 티켓의 좌석 상태, 등급, 가격 등을 관리합니다.</li></ul><ul id="02817e0f-a7fc-48b9-b212-54bc14bd90d2" class="bulleted-list"><li style="list-style-type:disc"><strong>세션 관리 (Session Management)</strong>: 사용자의 세션 정보를 저장하고 관리합니다.</li></ul><ul id="423cb723-a97b-4892-a845-f852e78b7f93" class="bulleted-list"><li style="list-style-type:disc"><strong>캐시 시스템 (Cache System)</strong>: 티켓 정보, 대기열 상태 등의 자주 사용되는 데이터를 캐싱하여 시스템 부하를 줄입니다.</li></ul><h3 id="9aaf96e9-1fdd-494e-85c6-0644bc1eecf6" class="">Redis 데이터 구조 활용</h3><ul id="654b2130-2019-4742-ab38-4aefe56b615c" class="bulleted-list"><li style="list-style-type:disc"><strong>리스트(List)</strong>: 대기열 관리를 위해 사용됩니다. 예를 들어, 각 대기열에 사용자를 추가하고 제거할 때 사용할 수 있습니다.</li></ul><ul id="53aafc57-b717-4d1e-b3f9-d4112886f513" class="bulleted-list"><li style="list-style-type:disc"><strong>해시(Hash)</strong>: 각 티켓의 세부 정보를 저장하고 관리하는 데 사용됩니다. 예를 들어, 좌석 번호를 키로 사용하고, 해당 좌석의 상태, 가격, 등급 등을 필드로 저장합니다.</li></ul><ul id="8da91183-458d-4c62-ac5c-2007791f0c05" class="bulleted-list"><li style="list-style-type:disc"><strong>셋(Set) 및 정렬된 셋(Sorted Set)</strong>: 예매 우선순위 관리, 티켓 예약 상태 관리 등에 사용됩니다. 예를 들어, 사용자의 대기 시간을 기준으로 정렬된 셋을 사용하여 예매 페이지로 이동할 사용자를 결정할 수 있습니다.</li></ul><ul id="89a4942f-81ed-4356-b812-5dcd4b35138c" class="bulleted-list"><li style="list-style-type:disc"><strong>Pub/Sub (Publish/Subscribe)</strong>: 실시간 알림 및 이벤트 처리를 위해 사용됩니다. 예를 들어, 티켓 예약 상태가 변경될 때 관련 사용자에게 알림을 보낼 수 있습니다.</li></ul><ul id="9873291d-ab98-4f9c-b7e7-40a561afc9e2" class="bulleted-list"><li style="list-style-type:disc"><strong>트랜잭션(Transaction)</strong>: MULTI/EXEC를 사용하여 여러 연산을 원자적으로 처리할 수 있습니다.</li></ul><h2 id="04c2e7bc-0a8f-4360-92ea-e0f0c5e90c08" class="">2. 세부 구현 방법</h2><h3 id="29c0ee3b-96cf-41d9-8477-4f2faa9c180e" class="">예매 전 준비 단계</h3><ol type="1" id="5087bcd4-16c6-4dd3-a3b7-5f4ed1b36a2f" class="numbered-list" start="1"><li><strong>티켓팅 정보 등록</strong>:<ul id="7ae83ce9-0081-4729-abc0-949ea8c90ba2" class="bulleted-list"><li style="list-style-type:disc">Redis 해시(Hash)를 사용하여 각 티켓의 세부 정보를 저장합니다.</li></ul><ul id="00506003-2866-4f04-8882-1e845a70c49f" class="bulleted-list"><li style="list-style-type:disc">예를 들어, <code>ticket:{event_id}:{seat_number}</code> 형식의 키를 사용하여 티켓 정보를 저장합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="2a528d54-4a29-4346-b462-6974050bb6d2" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HSET ticket:event123:A1 &quot;grade&quot; &quot;VIP&quot; &quot;price&quot; 100 &quot;status&quot; &quot;available&quot;

</code></pre></li></ol><ol type="1" id="b153f830-f0a8-431b-96c8-687859909748" class="numbered-list" start="2"><li><strong>좌석 상태 관리</strong>:<ul id="0fae6ec5-ffea-4185-acc7-c266c6469c2b" class="bulleted-list"><li style="list-style-type:disc">모든 좌석의 상태를 해시(Hash)에 저장하고, 대기열 페이지에서 실시간으로 조회할 수 있도록 설정합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="ab704765-5e3f-4352-82e6-fa488334af1c" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HSET ticket_status:event123 &quot;A1&quot; &quot;available&quot; &quot;A2&quot; &quot;reserved&quot;

</code></pre></li></ol><h3 id="4fc9b720-3d39-42be-b5a1-a0a72796133b" class="">예매 대기열 관리</h3><ol type="1" id="ccc0ca9e-4270-4397-a106-1a7418930947" class="numbered-list" start="1"><li><strong>대기열 페이지 관리</strong>:<ul id="387b8a71-4903-4332-9428-26b372a469e0" class="bulleted-list"><li style="list-style-type:disc">Redis 리스트(List)를 사용하여 대기열을 관리합니다. 사용자가 대기열 페이지에 접속하면, 리스트에 사용자 정보를 추가합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="ceb39766-3ec2-4e40-838b-f4fc82769631" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
LPUSH queue:event123 user1

</code></pre></li></ol><ol type="1" id="be84a2e8-2446-4249-9bb6-b288b6e12e78" class="numbered-list" start="2"><li><strong>선착순 n명 관리</strong>:<ul id="b019273f-9b8d-498f-9c87-70351304e2ca" class="bulleted-list"><li style="list-style-type:disc">Redis 리스트에서 왼쪽에서부터 n명의 사용자를 추출하여 예매 페이지로 이동시킵니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="7db05e41-84c9-43c7-952b-8d19157eb801" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
LTRIM queue:event123 0 99  # n명을 100명으로 설정

</code></pre></li></ol><ol type="1" id="0af2e7d4-1107-4c69-bea4-f342838ad4d0" class="numbered-list" start="3"><li><strong>예매 페이지 이동</strong>:<ul id="b5cf7581-44fe-472e-b32b-348b62d2233f" class="bulleted-list"><li style="list-style-type:disc">대기열에서 추출된 사용자를 세션 관리 해시(Hash)에 저장하여, 이 사용자들이 예매 페이지에 접근할 수 있도록 허용합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="a56fa927-9db4-4a60-928a-f8eb45b71631" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HSET session:event123:user1 &quot;status&quot; &quot;in_booking&quot;

</code></pre></li></ol><h3 id="34ccb525-5023-484c-905a-fc588e7c252d" class="">좌석 예매 및 관리</h3><ol type="1" id="43d1f678-1278-4668-8c7f-76b3618d0d47" class="numbered-list" start="1"><li><strong>좌석 선택</strong>:<ul id="1cd047b3-0232-43b3-8375-b69662bda48e" class="bulleted-list"><li style="list-style-type:disc">사용자가 좌석을 선택하면, 해당 좌석의 상태를 “reserved”로 변경하고 예약 시간을 기록합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="642d6a57-b533-4d07-bbc3-e288cba7100b" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HSET ticket:event123:A1 &quot;status&quot; &quot;reserved&quot; &quot;reserved_by&quot; &quot;user1&quot; &quot;reserved_at&quot; &quot;timestamp&quot;

</code></pre></li></ol><ol type="1" id="7edab259-2ab8-45ac-854f-6794b7f7387d" class="numbered-list" start="2"><li><strong>시간 제한 처리</strong>:<ul id="2b57793a-1cb5-444d-a9f1-04fe0270426a" class="bulleted-list"><li style="list-style-type:disc">예약한 좌석에 대해 일정 시간(예: 20분)이 경과하면 자동으로 상태를 “available”로 변경합니다. 이 작업은 백그라운드에서 실행되는 스크립트를 통해 주기적으로 체크합니다.</li></ul></li></ol><ol type="1" id="cf51d2b1-3240-4a4b-be53-54c8d0a62939" class="numbered-list" start="3"><li><strong>예약 상태 확인</strong>:<ul id="e10e26e5-0bd0-43a7-ae1f-757a2ebaed32" class="bulleted-list"><li style="list-style-type:disc">좌석 상태를 해시(Hash)에서 조회하여, 다른 사용자가 해당 좌석을 선택할 수 없도록 합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="6313696f-a757-4e1b-858a-560222197da0" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HGET ticket:event123:A1 &quot;status&quot;

</code></pre></li></ol><h3 id="707b6b63-e780-471a-9999-cbfd8a57fef6" class="">결제 처리</h3><ol type="1" id="bd5d086c-abe2-4843-9da1-a792c0b4c37b" class="numbered-list" start="1"><li><strong>결제 진행</strong>:<ul id="0ce5bd1b-7f2b-426c-8051-958f31ad900e" class="bulleted-list"><li style="list-style-type:disc">사용자가 결제 페이지에 접속하면, 결제 상태를 “pending”으로 변경하고 결제가 완료되면 “completed”로 변경합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8aa53c8c-9075-4b5a-80aa-d04c4cda863b" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HSET session:event123:user1 &quot;payment_status&quot; &quot;pending&quot;

</code></pre></li></ol><ol type="1" id="dce7d040-9839-4fb4-9141-ea912435228a" class="numbered-list" start="2"><li><strong>결제 실패 처리</strong>:<ul id="9ddb5810-2a91-4c31-ac51-3379c3e1bcd6" class="bulleted-list"><li style="list-style-type:disc">결제가 실패하거나 제한 시간이 경과하면, 예약된 좌석의 상태를 “available”로 변경하고 사용자 세션을 종료합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="87f1a02f-9b94-4a1e-b08e-370ff3b081e8" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HSET ticket:event123:A1 &quot;status&quot; &quot;available&quot;
HDEL session:event123:user1

</code></pre></li></ol><ol type="1" id="1da99a0b-6f62-44e1-a322-35b9d4a07ebd" class="numbered-list" start="3"><li><strong>결제 성공 처리</strong>:<ul id="99058fe0-4b91-451e-a036-f9373d782cfc" class="bulleted-list"><li style="list-style-type:disc">결제가 성공적으로 완료되면, 티켓 상태를 “sold”로 변경하고 사용자 예매 기록을 저장합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8a88539f-ae1b-4300-84f3-439ff1149557" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HSET ticket:event123:A1 &quot;status&quot; &quot;sold&quot;
HSET user_tickets:user1 &quot;event123:A1&quot; &quot;VIP&quot;

</code></pre></li></ol><h3 id="58d75f4f-a6fa-4482-aa33-50494fd731b3" class="">남은 티켓 및 대기열 관리</h3><ol type="1" id="865373c7-365c-46e9-bdeb-5ec7b39b9495" class="numbered-list" start="1"><li><strong>남은 티켓 확인</strong>:<ul id="80496020-0651-4ae7-af27-883b8f092b48" class="bulleted-list"><li style="list-style-type:disc">모든 예매가 완료되면, 해시(Hash)에서 남은 티켓 수를 확인합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="5dffb583-cd75-45dd-a632-066b57c3a445" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HLEN ticket_status:event123

</code></pre></li></ol><ol type="1" id="54b96e86-f5dd-4cd8-b24d-39c6ca1723b1" class="numbered-list" start="2"><li><strong>대기열 사용자 이동</strong>:<ul id="5c0475af-1307-4cec-ae7f-8ee74a8631ff" class="bulleted-list"><li style="list-style-type:disc">남은 티켓이 있을 경우, 대기열에서 다음 n명의 사용자를 예매 페이지로 이동시킵니다. 남은 티켓이 없을 경우, 대기열의 모든 사용자의 세션을 종료합니다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="5424fd87-9ee9-4d9d-965f-440fa6664cfa" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
LPOP queue:event123
HDEL session:event123:user2

</code></pre></li></ol><h2 id="24e9e86d-ebb6-45a7-8d27-f07eca14384d" class="">3. Redis 스크립트 및 트랜잭션 활용</h2><h3 id="013194e3-035b-474a-a86b-503fb4edc541" class="">Lua 스크립트</h3><ul id="e0dbcbeb-a08a-42ee-ade7-7a2ca6500683" class="bulleted-list"><li style="list-style-type:disc">Redis Lua 스크립트를 사용하여 복잡한 로직을 서버 측에서 처리할 수 있습니다. 예를 들어, 여러 좌석을 한 번에 예약하거나, 사용자 대기열을 관리하는 등의 작업을 Lua 스크립트로 구현할 수 있습니다.</li></ul><ul id="c2258206-ac6a-49dc-a50f-e8710ded6c81" class="bulleted-list"><li style="list-style-type:disc">예시:<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="ddda230e-4c47-4249-9141-f17422b7b4ee" class="code"><code class="language-Lua" style="white-space:pre-wrap;word-break:break-all">lua코드 복사
-- 좌석 예약 Lua 스크립트
local seat_status = redis.call(&#x27;HGET&#x27;, KEYS[1], ARGV[1])
if seat_status == &#x27;available&#x27; then
    redis.call(&#x27;HSET&#x27;, KEYS[1], ARGV[1], &#x27;reserved&#x27;)
    return 1
else
    return 0
end

</code></pre></li></ul><h3 id="8f534864-249b-44ff-a410-a740261ac6dc" class="">Redis 트랜잭션</h3><ul id="b31d1ada-9f44-4d7e-a68c-05deb356608e" class="bulleted-list"><li style="list-style-type:disc">Redis의 트랜잭션 기능(MULTI/EXEC)을 사용하여 여러 명령을 원자적으로 실행할 수 있습니다.</li></ul><ul id="5445b858-b0ab-4f27-96a7-2abadaa5f878" class="bulleted-list"><li style="list-style-type:disc">예시:<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="f50ebfdf-1fde-4a08-96d9-51c9a28388b2" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
MULTI
HSET ticket:event123:A1 &quot;status&quot; &quot;reserved&quot;
HSET session:event123:user1 &quot;status&quot; &quot;in_booking&quot;
EXEC

</code></pre></li></ul><h2 id="484d0f7b-34f1-4d41-ab8f-ce591fe65b2b" class="">4. 최적화 및 스케일링</h2><h3 id="0982a1fc-9fb3-4801-add4-0efd872c0b9e" class="">캐시 최적화</h3><ul id="f09fba45-3803-4973-a123-bf36a613f667" class="bulleted-list"><li style="list-style-type:disc">Redis를 사용하여 티켓 정보, 대기열 상태 등의 자주 조회되는 데이터를 캐싱합니다. 이를 통해 데이터베이스의 부하를 줄이고 시스템의 응답 속도를 높일 수 있습니다.</li></ul><h3 id="b4673d5d-af93-4f90-8eff-b094e98f4608" class="">수평적 스케일링</h3><ul id="0788fdad-3c44-4f35-993e-384ba419fd24" class="bulleted-list"><li style="list-style-type:disc">Redis 클러스터링을 통해 수평적 스케일링을 구현합니다. 여러 개의 Redis 노드를 사용하여 데이터와 트래픽을 분산 처리할 수 있습니다.</li></ul><ul id="88fada61-f772-4849-a7ac-5d898df07cd1" class="bulleted-list"><li style="list-style-type:disc">Redis 클러스터링을 통해 높은 가용성과 확장성을 확보할 수 있습니다.</li></ul><h3 id="73d6127f-4175-4ab6-bac6-741812cd8a1e" class="">데이터 일관성 유지</h3><ul id="03c7932d-60aa-4e6b-9a46-235da1ca5a0a" class="bulleted-list"><li style="list-style-type:disc">Redis는 기본적으로 Eventually Consistent한 모델을 사용하므로, 데이터 일관성을 유지하기 위해 추가적인 고려가 필요합니다. 트랜잭션, Lua 스크립트 등을 사용하여 데이터의 일관성을 확보할 수 있습니다.</li></ul><h2 id="c1a9266f-db18-4e21-b76b-e4fe5a42f569" class="">5. 결론</h2><p id="c930d46f-a935-4a6a-9d53-b7ecb2d97564" class="">Redis를 사용하여 티켓 예매 시스템을 구현할 경우, 높은 성능과 확장성을 제공할 수 있습니다. 그러나 Redis는 기본적으로 In-memory 데이터베이스이므로 데이터 영속성에 대한 추가적인 고려가 필요합니다. 이를 보완하기 위해 RDB 스냅샷이나 AOF(Append Only File) 모드를 사용하여 데이터의 영속성을 확보할 수 있습니다. Redis의 다양한 데이터 구조와 기능을 활용하여 대기열 관리, 티켓 관리, 세션 관리 등을 효과적으로 처리할 수 있으며, Lua 스크립트와 트랜잭션을 통해 복잡한 로직을 간편하게 구현할 수 있습니다.</p></details></li></ul><ul id="98265512-3042-4630-9b1a-a5e5c4b89b47" class="toggle"><li><details open=""><summary>Redis 활용 사례</summary><p id="6e80eded-caa5-4114-8d86-cc98c6251074" class=""><a href="https://devs0n.tistory.com/92">https://devs0n.tistory.com/92</a></p><p id="bde8d7cf-2a08-4996-954d-e17091ef707c" class="">Redis를 사용하여 효과적으로 시스템을 구축하고 운영하는 다양한 사례가 있습니다. Redis는 In-memory 데이터베이스의 특성을 활용하여 고속의 데이터 처리, 복잡한 자료 구조의 지원, 분산 처리 등의 기능을 제공하며, 이를 통해 다양한 애플리케이션의 성능과 확장성을 높일 수 있습니다. 다음은 Redis를 효과적으로 활용한 구체적인 사례들입니다.</p><h2 id="5f6b4021-045c-467d-b8d2-77a8b76d2e09" class="">1. <strong>인스턴트 메신저 및 채팅 애플리케이션</strong></h2><h3 id="94747488-b836-4927-a785-ef1b5843b209" class="">사례: WhatsApp 및 기타 실시간 채팅 애플리케이션</h3><h3 id="1cda3bc4-b56e-4951-991f-1bfc9719118e" class="">기술적 구현 및 활용</h3><ul id="9b758ad1-391b-4454-9170-247221fd98fc" class="bulleted-list"><li style="list-style-type:disc"><strong>메시지 큐 관리</strong><ul id="17d757c4-b6b8-4583-8cab-585a09c97fbd" class="bulleted-list"><li style="list-style-type:circle">Redis의 리스트(List) 자료 구조를 사용하여 메시지 큐를 관리합니다. 각 채팅방 또는 사용자별로 메시지 큐를 생성하여 새 메시지를 리스트의 끝에 추가하고, 읽은 메시지는 리스트에서 제거합니다.</li></ul><ul id="b9585b56-28cf-4ccc-b890-3244c6dbb8a3" class="bulleted-list"><li style="list-style-type:circle">예시: 사용자 <code>user1</code>와 <code>user2</code> 간의 대화 큐<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e1e0f073-b250-4082-8654-bb34d3063003" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
RPUSH chat:user1:user2 &quot;Hello, how are you?&quot;
LPOP chat:user1:user2</code></pre></li></ul></li></ul><ul id="03691309-7922-4e9b-b597-4cc7dc89ce1d" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 알림 전송</strong><ul id="3d7018e2-7973-4156-876f-08df57264dc9" class="bulleted-list"><li style="list-style-type:circle">Redis의 Pub/Sub (Publish/Subscribe) 기능을 사용하여 실시간으로 사용자에게 알림을 전송합니다. 새로운 메시지가 도착하면 해당 채팅방 또는 사용자 채널에 메시지를 게시(publish)하고, 구독(subscribe)된 클라이언트에게 즉시 알림을 전송합니다.</li></ul><ul id="5597c7d6-a664-406f-b2fc-6f5fbe76f810" class="bulleted-list"><li style="list-style-type:circle">예시: 새로운 메시지를 사용자 <code>user2</code>에게 알림<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="11a79dcc-7d1b-426f-9dcc-190611bcde69" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">PUBLISH user2:notifications &quot;You have a new message from user1&quot;</code></pre></li></ul></li></ul><ul id="933959fb-688a-4db1-81a1-8f8dee1876d3" class="bulleted-list"><li style="list-style-type:disc"><strong>사용자 상태 관리</strong><ul id="5a928ffa-5971-462e-80d3-07296aa84082" class="bulleted-list"><li style="list-style-type:circle">Redis의 해시(Hash) 자료 구조를 사용하여 사용자의 상태(온라인, 오프라인, 자리 비움 등)를 관리합니다. 클라이언트가 로그인하거나 로그아웃할 때 사용자 상태를 업데이트합니다.</li></ul><ul id="2a878776-5245-4854-9cd2-122d629c7737" class="bulleted-list"><li style="list-style-type:circle">예시: 사용자 <code>user1</code>의 상태 업데이트<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="9ec92fe6-258a-4a78-b557-2f72495a4873" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
HSET user_status:user1 &quot;status&quot; &quot;online&quot; &quot;last_active&quot; &quot;timestamp&quot;</code></pre></li></ul></li></ul><h3 id="f54e01ab-25fe-4942-96f5-d19c1dd62f86" class="">효과</h3><ul id="32a50fc5-bdd4-4646-bcd1-49a3ec1862a0" class="bulleted-list"><li style="list-style-type:disc"><strong>높은 응답 속도</strong>: 메시지 처리와 알림 전송이 Redis의 고속 데이터 처리 기능을 통해 빠르게 이루어집니다.</li></ul><ul id="5c3a51f0-24f7-41db-b73b-fe24570342d8" class="bulleted-list"><li style="list-style-type:disc"><strong>확장성</strong>: Redis 클러스터링을 통해 대규모 사용자 기반을 효과적으로 지원할 수 있습니다.</li></ul><ul id="cb975b6c-b62b-47cd-805d-a3da165059e9" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 일관성</strong>: Redis 트랜잭션 및 Lua 스크립트를 통해 메시지 전송과 상태 업데이트의 원자성을 확보합니다.</li></ul><h2 id="aa407ef8-f305-4894-80fa-6736cfa85bbe" class="">2. <strong>실시간 분석 및 모니터링 시스템</strong></h2><h3 id="4518cfac-fa97-4b93-b9c7-69706b505e00" class="">사례: Netflix 및 미디어 스트리밍 서비스</h3><h3 id="7416055c-57fe-430a-9bb1-5efc28bbd994" class="">기술적 구현 및 활용</h3><ul id="6b4474e0-ba95-47e1-8b59-33eb2a6894b5" class="bulleted-list"><li style="list-style-type:disc"><strong>시청 기록 저장 및 분석</strong><ul id="9e28ff08-5379-4d70-aac5-5bd1e8862f1a" class="bulleted-list"><li style="list-style-type:circle">Redis의 해시(Hash)와 정렬된 셋(Sorted Set)을 사용하여 사용자의 시청 기록과 콘텐츠의 인기도를 저장하고 분석합니다.</li></ul><ul id="bc6120be-a6ed-4f5a-9dd1-ea24efcf75de" class="bulleted-list"><li style="list-style-type:circle">예시: 사용자 <code>user1</code>의 시청 기록 저장<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="144bb0f0-40fe-4d47-912d-e1a7931f999d" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">HSET user_views:user1 &quot;movie123&quot; &quot;timestamp&quot;
ZINCRBY movie_popularity 1 &quot;movie123&quot;

</code></pre></li></ul></li></ul><ul id="416d38fe-d431-4bd4-afdb-150112269fd3" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 대시보드</strong><ul id="aefee09b-534e-44b2-97c6-d7e6f05e2d17" class="bulleted-list"><li style="list-style-type:circle">Redis의 Pub/Sub 기능을 사용하여 실시간 대시보드를 구현합니다. 시청 기록이나 이벤트가 발생하면 Redis 채널에 메시지를 게시하고, 대시보드 클라이언트가 이를 수신하여 화면을 업데이트합니다.</li></ul><ul id="8cbf9c95-2aae-46d3-ad34-d5be4807c734" class="bulleted-list"><li style="list-style-type:circle">예시: 새로운 시청 이벤트 알림<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e2e4da05-9f47-4426-88ac-5625ea17ba4f" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">PUBLISH dashboard:updates &quot;user1 started watching movie123&quot;

</code></pre></li></ul></li></ul><ul id="c086e45a-a9b1-494b-84cb-013a4a15be68" class="bulleted-list"><li style="list-style-type:disc"><strong>장애 감지 및 경보 시스템</strong><ul id="8367b953-8647-4ba0-89de-12bbd538f96d" class="bulleted-list"><li style="list-style-type:circle">Redis의 리스트(List)와 Lua 스크립트를 사용하여 장애 감지 및 경보 시스템을 구현합니다. 시스템의 상태를 모니터링하고, 이상 징후가 발견되면 경보를 발령합니다.</li></ul><ul id="01fafc03-0677-4408-b1e7-bab9e3f77835" class="bulleted-list"><li style="list-style-type:circle">예시: 시스템 부하 감지 및 경보<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="35cd816d-6543-42e1-87c1-428d8c3d503e" class="code"><code class="language-Lua" style="white-space:pre-wrap;word-break:break-all">local load = redis.call(&#x27;GET&#x27;, &#x27;system:load&#x27;)
if tonumber(load) &gt; threshold then
    redis.call(&#x27;PUBLISH&#x27;, &#x27;alerts&#x27;, &#x27;High system load detected&#x27;)
end

</code></pre></li></ul></li></ul><h3 id="02863a9d-81b1-4205-a0d1-95a400799a3a" class="">효과</h3><ul id="ffdcf930-6eb8-45e4-b808-21a648fd9dd5" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 데이터 처리</strong>: 시청 기록 및 시스템 상태를 실시간으로 분석하여 사용자 경험을 향상시킵니다.</li></ul><ul id="e1276390-930e-40d4-b9ac-295a5bd4e67f" class="bulleted-list"><li style="list-style-type:disc"><strong>고가용성</strong>: Redis 클러스터링과 복제를 통해 시스템의 고가용성과 안정성을 확보합니다.</li></ul><ul id="2719bfeb-1466-4ee1-8586-ea11a41f94da" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 통합</strong>: Redis의 다양한 자료 구조를 사용하여 여러 소스의 데이터를 통합하고 처리합니다.</li></ul><h2 id="1b7e4862-2667-49f9-a052-fa0378a25d2e" class="">3. <strong>티켓 예매 시스템</strong></h2><h3 id="768c46be-0251-45eb-98bd-055442a4a4d7" class="">사례: 대형 공연 및 스포츠 이벤트 티켓팅 시스템</h3><h3 id="f13defc4-f3f6-4c01-abc5-a59a4696c222" class="">기술적 구현 및 활용</h3><ul id="c78d36d5-ccff-4243-b618-a2b2ea486cb5" class="bulleted-list"><li style="list-style-type:disc"><strong>대기열 관리</strong><ul id="5d70f3f3-10ca-4f5d-be7c-427879264feb" class="bulleted-list"><li style="list-style-type:circle">Redis의 리스트(List) 자료 구조를 사용하여 사용자 대기열을 관리합니다. 사용자들이 예매 페이지에 진입할 때마다 대기열에 추가되고, 순서에 따라 예매 페이지로 이동합니다.</li></ul><ul id="519fc9ac-e117-431e-b330-0a7368e747ce" class="bulleted-list"><li style="list-style-type:circle">예시: 사용자 <code>user1</code> 대기열 추가<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="cdae5390-25ff-4796-b6d4-ef397efd8c95" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">LPUSH ticket_queue:event123 user1

</code></pre></li></ul></li></ul><ul id="2af5f5d1-215c-4c2a-a545-138bbf29628d" class="bulleted-list"><li style="list-style-type:disc"><strong>좌석 예약 및 결제 처리</strong><ul id="203f0e2f-eb00-4d42-a3e4-47d1c8989916" class="bulleted-list"><li style="list-style-type:circle">Redis의 해시(Hash)와 트랜잭션 기능을 사용하여 좌석 예약 및 결제 처리를 관리합니다. 좌석 상태를 “예약됨”으로 변경하고, 사용자가 결제를 완료하면 상태를 “판매됨”으로 변경합니다.</li></ul><ul id="d4848bc3-19e9-44d8-b7fe-b02d61b59789" class="bulleted-list"><li style="list-style-type:circle">예시: 좌석 <code>A1</code> 예약 및 결제 처리<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="c6121bf1-2249-41bd-9b30-6654670c05f2" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">MULTI
HSET ticket:event123:A1 &quot;status&quot; &quot;reserved&quot; &quot;reserved_by&quot; &quot;user1&quot;
EXEC</code></pre></li></ul></li></ul><ul id="29a5b3f1-4ba1-459f-bd21-5dda03854e84" class="bulleted-list"><li style="list-style-type:disc"><strong>시간 제한 및 자동 해제</strong><ul id="1b52ef3a-0f94-4212-9280-16309eac9b9a" class="bulleted-list"><li style="list-style-type:circle">Lua 스크립트와 백그라운드 작업을 사용하여 좌석 예약 시간 제한을 관리합니다. 사용자가 일정 시간 내에 결제를 완료하지 않으면, 좌석 예약을 자동으로 해제합니다.</li></ul><ul id="926649d7-6609-443c-8b65-a3938bdd7f21" class="bulleted-list"><li style="list-style-type:circle">예시: 좌석 <code>A1</code> 예약 시간 제한 체크 및 해제<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="565d84c7-7175-4808-9db4-9f1e01c9da69" class="code"><code class="language-Lua" style="white-space:pre-wrap;word-break:break-all">local reserved_time = redis.call(&#x27;HGET&#x27;, &#x27;ticket:event123:A1&#x27;, &#x27;reserved_at&#x27;)
if (current_time - tonumber(reserved_time)) &gt; 1200 then  -- 20 minutes
    redis.call(&#x27;HSET&#x27;, &#x27;ticket:event123:A1&#x27;, &#x27;status&#x27;, &#x27;available&#x27;)
end</code></pre></li></ul></li></ul><h3 id="2d4abf09-a2ce-4878-9027-bc51bfb899fe" class="">효과</h3><ul id="ef1c3a72-0362-4aff-bc13-8bde24145592" class="bulleted-list"><li style="list-style-type:disc"><strong>높은 처리량 및 응답 속도</strong>: Redis의 빠른 처리 속도로 대규모 티켓 예매 이벤트에서도 안정적으로 운영할 수 있습니다.</li></ul><ul id="aacfb738-6de7-459d-bc7d-7e029e32414a" class="bulleted-list"><li style="list-style-type:disc"><strong>정합성 보장</strong>: 트랜잭션과 Lua 스크립트를 통해 데이터 정합성과 무결성을 유지합니다.</li></ul><ul id="e632ae56-89ba-4054-b695-c37daa496f9a" class="bulleted-list"><li style="list-style-type:disc"><strong>유연한 대기열 및 사용자 관리</strong>: 다양한 자료 구조를 사용하여 사용자 대기열과 좌석 상태를 유연하게 관리합니다.</li></ul><h2 id="147d60c5-fc4f-40d6-abc7-fd5554b3e508" class="">4. <strong>게임 리더보드 시스템</strong></h2><h3 id="59f1c296-f68c-4bf1-bbca-fc70a4a94b45" class="">사례: 온라인 게임 플랫폼</h3><h3 id="b4aaade2-c641-4083-869e-44b9d8690e68" class="">기술적 구현 및 활용</h3><ul id="f99b2701-99b1-49c8-9881-9d6b99c86eb5" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 리더보드 업데이트</strong><ul id="ad4b9edb-3bc4-47e9-a418-43aa0b795eca" class="bulleted-list"><li style="list-style-type:circle">Redis의 정렬된 셋(Sorted Set)을 사용하여 플레이어의 점수를 관리하고, 실시간으로 리더보드를 업데이트합니다.</li></ul><ul id="443ea46b-29b1-41b6-adaf-f1c0eb3312ab" class="bulleted-list"><li style="list-style-type:circle">예시: 플레이어 <code>player1</code>의 점수 업데이트<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="d6b45e06-ea4b-4d7e-aaf6-fbfaa2c4a8b0" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">ZADD game_leaderboard 1500 player1</code></pre></li></ul></li></ul><ul id="bef469a9-f2f8-4c75-a018-9b12fb61b8fb" class="bulleted-list"><li style="list-style-type:disc"><strong>플레이어 순위 조회</strong><ul id="75fd3c89-d116-4e3c-b9be-ce055d7ef05f" class="bulleted-list"><li style="list-style-type:circle">Redis의 정렬된 셋(Sorted Set)을 사용하여 특정 플레이어의 순위를 조회하거나, 상위 N명의 플레이어 목록을 가져옵니다.</li></ul><ul id="48b6bc0f-e0bb-4b58-8fe1-3092843c391c" class="bulleted-list"><li style="list-style-type:circle">예시: 상위 10명 플레이어 조회<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="78b8dfd5-d519-45d0-8eb1-c4111938b3e6" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">ZREVRANGE game_leaderboard 0 9 WITHSCORES</code></pre></li></ul></li></ul><ul id="0b5d17be-923f-4bc4-9cce-f26b83146832" class="bulleted-list"><li style="list-style-type:disc"><strong>리더보드의 구간별 데이터 관리</strong><ul id="40c2b111-61c2-4fb1-aa50-b1066c0fcd98" class="bulleted-list"><li style="list-style-type:circle">Redis의 정렬된 셋(Sorted Set)과 Lua 스크립트를 사용하여 리더보드를 특정 구간별로 관리합니다. 예를 들어, 게임 시즌별 또는 지역별로 리더보드를 분리하여 관리합니다.</li></ul><ul id="484b2e0f-dedd-434d-aa1d-959594bdb9c1" class="bulleted-list"><li style="list-style-type:circle">예시: 특정 지역의 리더보드 조회<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="999e8c05-6641-4571-832f-322bc75bd852" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">ZRANGEBYSCORE game_leaderboard:region1 1000 2000</code></pre></li></ul></li></ul><h3 id="1e7b531e-5996-4614-b8cf-b91956246061" class="">효과</h3><ul id="09814061-c36d-400b-875f-91499a580b89" class="bulleted-list"><li style="list-style-type:disc"><strong>빠른 업데이트 및 조회</strong>: Redis의 정렬된 셋을 사용하여 실시간으로 리더보드를 업데이트하고 조회합니다.</li></ul><ul id="e82c5af9-3b0a-4bb7-8a9c-f21abbf816ca" class="bulleted-list"><li style="list-style-type:disc"><strong>확장성 및 유연성</strong>: 게임의 규모와 복잡도에 따라 리더보드를 확장하고, 다양한 조건으로 데이터를 관리할 수 있습니다.</li></ul><ul id="92f50bb7-491c-4446-a0c8-9a49fc60336e" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 정확성 및 일관성</strong>: Redis의 원자적 연산을 통해 리더보드 데이터의 정확성과 일관성을 유지합니다.</li></ul><h2 id="08e5b6a4-a1b7-48eb-9247-35f3d6ce7c48" class="">5. <strong>광고 실시간 입찰 시스템 (Real-Time Bidding, RTB)</strong></h2><h3 id="698a2ffd-8610-4917-ad64-ef65697fcf0a" class="">사례: 온라인 광고 플랫폼</h3><h3 id="80063704-7817-49c8-a2a2-94352378265d" class="">기술적 구현 및 활용</h3><ul id="733e9e9f-e942-4d2a-97a7-b730c734f942" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 입찰 요청 관리</strong><ul id="30bb4127-fcc2-41c2-a720-d19804c5a38c" class="bulleted-list"><li style="list-style-type:circle">Redis의 리스트(List)와 Lua 스크립트를 사용하여 실시간 입찰 요청을 관리합니다. 입찰 요청이 들어오면 리스트에 추가하고, Lua 스크립트를 통해 최적의 광고를 선택합니다.</li></ul><ul id="3f5cb7a5-794f-4e96-9f37-b242b721ee7f" class="bulleted-list"><li style="list-style-type:circle">예시: 입찰 요청 처리 및 최적 광고 선택<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="557d93ed-6f6b-4baf-b288-121d37f25d53" class="code"><code class="language-Lua" style="white-space:pre-wrap;word-break:break-all">local bid_request = redis.call(&#x27;LPOP&#x27;, KEYS[1])
-- 광고 선택 로직
redis.call(&#x27;PUBLISH&#x27;, &#x27;bid_responses&#x27;, selected_ad)</code></pre></li></ul></li></ul><ul id="99ec1596-4721-4440-8f78-7e4378121970" class="bulleted-list"><li style="list-style-type:disc"><strong>광고 데이터 캐싱</strong><ul id="23bb59bc-ebd3-439a-9695-c9a4a7db0c7d" class="bulleted-list"><li style="list-style-type:circle">Redis의 해시(Hash)와 셋(Set)을 사용하여 광고 데이터를 캐싱합니다. 광고주, 캠페인, 광고 세부 정보 등을 캐싱하여 빠르게 접근할 수 있습니다.</li></ul><ul id="e3c5d784-bb67-4cb3-af6b-4ac456c75855" class="bulleted-list"><li style="list-style-type:circle">예시: 광고 데이터 캐싱<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="6e2a4378-d41e-499c-88ac-947e37aaf744" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">HSET ad_data:campaign123 &quot;advertiser&quot; &quot;advertiser1&quot; &quot;budget&quot; 5000</code></pre></li></ul></li></ul><ul id="449992f9-f9a4-48ed-8d05-a739dbf81c85" class="bulleted-list"><li style="list-style-type:disc"><strong>효율적인 트래픽 관리</strong><ul id="6a8ee8c0-59e8-40b8-b602-e3387e6981ac" class="bulleted-list"><li style="list-style-type:circle">Redis의 Pub/Sub 기능을 사용하여 광고 요청과 응답을 처리하고, 효율적인 트래픽 관리를 위해 메시지 브로커로 사용합니다.</li></ul><ul id="51c5a7f7-7a25-4ce1-8915-2a12e1493319" class="bulleted-list"><li style="list-style-type:circle">예시: 광고 요청 및 응답 처리<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="a1eff921-6223-412d-a9ca-170ad4802124" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">PUBLISH ad_requests &quot;new_bid_request&quot;</code></pre></li></ul></li></ul><h3 id="1bf9e049-6c75-4b9e-a73d-26459757cb9b" class="">효과</h3><ul id="da21f3a5-c083-44a0-96ad-60a42668ba6b" class="bulleted-list"><li style="list-style-type:disc"><strong>고성능 및 저지연</strong>: Redis의 빠른 데이터 처리 속도로 실시간 입찰 시스템의 성능을 극대화합니다.</li></ul><ul id="2823ee67-b720-45b5-b7e4-fe68e14cc5aa" class="bulleted-list"><li style="list-style-type:disc"><strong>광고주 및 캠페인 관리의 유연성</strong>: 다양한 자료 구조를 사용하여 광고주, 캠페인, 광고 세부 정보 등을 유연하게 관리합니다.</li></ul><ul id="2c0efa93-05f6-401f-86bd-44b9978ea01e" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 데이터 처리 및 응답</strong>: Pub/Sub 기능을 통해 실시간으로 광고 요청 및 응답을 처리하여 사용자 경험을 향상시킵니다.</li></ul><h2 id="130afcb1-3493-483e-9933-07bc14789c80" class="">결론</h2><p id="310e1341-0f05-4b3c-8534-ac07af8a3aea" class="">Redis를 활용한 다양한 시스템 구축 사례는 고속 데이터 처리, 복잡한 자료 구조 지원, 분산 처리 등 Redis의 강점을 효과적으로 활용하여 구현됩니다. 이러한 사례들은 Redis를 통해 다양한 비즈니스 요구사항을 만족시키고, 시스템의 성능과 확장성을 향상시키는 데 큰 도움이 됩니다. Redis의 다양한 기능과 자료 구조를 활용하여 효과적으로 시스템을 구축하고 운영할 수 있습니다</p><p id="1ed3a4cc-090a-8079-a036-e14baa79e949" class="">
</p></details></li></ul><ul id="4680715d-713b-422d-979c-c5d3caa9d479" class="toggle"><li><details open=""><summary><span style="border-bottom:0.05em solid">Redis 캐시, 세션 활용</span></summary><p id="10d324da-7a1e-48cc-a331-0c318c07c160" class="">Redis를 캐시와 세션 용도로 사용하는 방법은 웹 애플리케이션의 성능과 확장성을 개선하는 데 중요한 역할을 합니다. Redis는 In-memory 데이터베이스로서 빠른 데이터 접근 속도를 제공하며, 다양한 데이터 구조를 지원해 데이터 관리에 유연성을 제공합니다. 다음은 Redis를 캐시 및 세션 용도로 사용하는 방법에 대한 상세한 설명입니다.</p><h2 id="a5f8ac52-2562-44c3-8682-7fdcfcb572ca" class="">Redis를 캐시 용도로 사용하는 방법</h2><h3 id="f77229ab-567d-4603-be63-e1f59fe89aec" class="">1. <strong>일반적인 캐시 사용 패턴</strong></h3><h3 id="184bc83b-fb7b-4b71-8594-3cadf96420b1" class="">a. <strong>Read-Through Cache</strong></h3><ul id="d264a513-dc2f-47b1-8319-d9d116b54e1b" class="bulleted-list"><li style="list-style-type:disc"><strong>동작 원리</strong>: 애플리케이션이 Redis 캐시를 조회하고, 데이터가 없을 경우 백엔드 데이터베이스에서 가져와 Redis에 저장한 후 응답합니다.</li></ul><ul id="11dc73fc-c11c-463b-be75-7399cc8a7073" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 데이터가 항상 최신 상태로 유지되며, 백엔드 DB의 부담이 줄어듭니다.</li></ul><ul id="763443b5-886d-4c18-b9ca-9e7c752fac0a" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 예시</strong>:<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="0a6ea2ea-d0c6-4e7e-9656-b551be5f459d" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">def get_data(key):
    data = redis.get(key)
    if data is None:
        data = database.query(key)
        redis.set(key, data)
    return data</code></pre></li></ul><h3 id="2d3c91a0-eb4a-4424-a03a-fa5a0b7a55cf" class="">b. <strong>Write-Through Cache</strong></h3><ul id="423642e9-40f9-4721-b930-b489ef66d3a1" class="bulleted-list"><li style="list-style-type:disc"><strong>동작 원리</strong>: 데이터가 변경될 때마다 Redis 캐시와 백엔드 데이터베이스에 동시에 저장됩니다.</li></ul><ul id="adb0367e-594d-4cfb-97b6-568283468821" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 캐시와 백엔드 데이터베이스의 데이터 일관성을 보장합니다.</li></ul><ul id="07cb5df8-5a2d-4579-9b24-92375ba99241" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 예시</strong>:<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="67daa2f3-dc85-4f71-bec4-3077dab8c183" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">def update_data(key, value):
    database.update(key, value)
    redis.set(key, value)</code></pre></li></ul><h3 id="fa847cc2-27e2-4a52-89cb-59fa89716bc5" class="">c. <strong>Cache-Aside (Lazy Loading)</strong></h3><ul id="a25e4728-3955-4533-b3b8-c54b22fbd871" class="bulleted-list"><li style="list-style-type:disc"><strong>동작 원리</strong>: 애플리케이션이 캐시를 조회하고 데이터가 없으면 백엔드 데이터베이스에서 가져온 후 캐시에 저장합니다.</li></ul><ul id="fd4963a5-9bef-4af4-b942-e6e785928425" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 필요한 데이터만 캐시에 저장하므로 메모리 사용을 최적화할 수 있습니다.</li></ul><ul id="c8bfc12b-4173-4a76-bd1f-8c0183c67398" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 예시</strong>:<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="2cd76d87-b32e-44c1-a4a8-0439a2a50f54" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">def get_data(key):
    data = redis.get(key)
    if data is None:
        data = database.query(key)
        redis.set(key, data)
    return data</code></pre></li></ul><h3 id="a5ec9742-d227-45a2-8fe5-478c19810166" class="">d. <strong>Write-Behind Cache</strong></h3><ul id="fca13db9-b231-44c9-b973-155f86f05a5d" class="bulleted-list"><li style="list-style-type:disc"><strong>동작 원리</strong>: 데이터가 캐시에 쓰여질 때마다 비동기적으로 백엔드 데이터베이스에 저장됩니다.</li></ul><ul id="e9251312-c3ea-4d14-89bf-46a8677caa02" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 백엔드 DB에 대한 쓰기 작업을 비동기로 처리하여 애플리케이션의 쓰기 속도를 높일 수 있습니다.</li></ul><ul id="acdf6927-dcd7-4b68-bd95-160572a2d001" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 예시</strong>:<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="3a01e0fb-fec2-41f9-8d99-3d70dffde036" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">def update_data(key, value):
    redis.set(key, value)
    # 비동기적으로 데이터베이스 업데이트
    async_update_db(key, value)</code></pre></li></ul><h3 id="82d65040-294a-483b-8cc6-107b565d92a2" class="">2. <strong>Redis 캐시 설정</strong></h3><ul id="6e207980-da0c-46a7-bfce-dee611bed22c" class="bulleted-list"><li style="list-style-type:disc"><strong>TTL(Time-to-Live)</strong>: 각 캐시 항목에 만료 시간을 설정하여 캐시 데이터가 일정 시간이 지나면 자동으로 삭제되도록 합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="742425f0-ee2d-4f47-a1f4-195e05ea1e76" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">SET key value EX 60  # 60초 동안 유효한 캐시 데이터</code></pre></li></ul><ul id="3ac5c3b5-7420-4334-b0de-e977c0ef3e78" class="bulleted-list"><li style="list-style-type:disc"><strong>LRU(Least Recently Used) 정책</strong>: Redis의 메모리가 부족할 경우 오래 사용하지 않은 데이터를 자동으로 삭제하는 정책을 사용할 수 있습니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="9b87a70f-a6ce-4eba-843a-e540c0fd3d25" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">CONFIG SET maxmemory-policy allkeys-lru</code></pre></li></ul><h3 id="1f85ba0e-a7a3-4efb-a0bc-42f02a7a86a8" class="">3. <strong>캐시 데이터 관리</strong></h3><ul id="38c1f26c-a306-4cb7-96e3-6998e24a617d" class="bulleted-list"><li style="list-style-type:disc"><strong>일괄 삭제</strong>: 특정 조건에 맞는 캐시 데이터들을 일괄적으로 삭제합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="cec4ef56-4662-4f50-b6e4-31af2b313678" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">DEL key1 key2 key3</code></pre></li></ul><ul id="b4cb1e00-3ccb-449d-b6fe-f57e19ee5d62" class="bulleted-list"><li style="list-style-type:disc"><strong>부분적 삭제</strong>: 특정 패턴에 맞는 키들을 찾아서 삭제합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="ffc16d55-7216-4ff2-9dde-9c8828779705" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">for key in redis.scan_iter(&quot;user:*&quot;):
    redis.delete(key)</code></pre></li></ul><h3 id="2ecfecbc-a3c9-49e0-a144-9834d1e019fa" class="">4. <strong>캐시 적용 사례</strong></h3><ul id="80e3ea3f-d272-4e3b-b636-7c5e0f08f201" class="bulleted-list"><li style="list-style-type:disc"><strong>웹 페이지 콘텐츠 캐싱</strong>: 정적 콘텐츠나 자주 변경되지 않는 데이터를 Redis에 캐싱하여 웹 서버의 응답 속도를 높입니다.</li></ul><ul id="73cbd260-dcf7-4201-bf72-04145dcbdca6" class="bulleted-list"><li style="list-style-type:disc"><strong>API 응답 캐싱</strong>: 외부 API 호출 결과를 Redis에 캐싱하여 반복적인 호출을 줄이고, 응답 시간을 단축합니다.</li></ul><ul id="72f0b1aa-4bf0-4631-8a7d-b128328b4c57" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터베이스 쿼리 결과 캐싱</strong>: 복잡한 쿼리의 결과를 Redis에 캐싱하여 데이터베이스 부하를 감소시킵니다.</li></ul><h2 id="ffce218b-291f-4127-9788-5ac49d990dcd" class="">Redis를 세션 관리 용도로 사용하는 방법</h2><h3 id="8aa21103-7ba8-40b8-a2b9-6db3084a0bb3" class="">1. <strong>Redis를 세션 스토리지로 사용하기</strong></h3><ul id="ddb9f66e-fcfc-43b9-9701-5b97f628b711" class="bulleted-list"><li style="list-style-type:disc"><strong>세션 데이터 저장</strong>: Redis를 사용하여 각 사용자의 세션 데이터를 저장하고 관리합니다. 세션 데이터는 일반적으로 키-값 형태로 저장됩니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="fd557f78-3723-4140-9a28-28e009e336f8" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">SET session:user123 {&quot;username&quot;: &quot;john&quot;, &quot;role&quot;: &quot;admin&quot;} EX 3600  # 1시간 유효</code></pre></li></ul><ul id="f95e80fa-2eb5-4527-87ee-a6009c835d77" class="bulleted-list"><li style="list-style-type:disc"><strong>세션 데이터 조회</strong>: 사용자가 웹 사이트를 방문할 때마다 해당 세션 데이터를 Redis에서 조회합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="2b251542-9072-41ed-8c71-55eea7c5ad85" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">session_data = redis.get(f&quot;session:{user_id}&quot;)
if session_data:
    # 세션 데이터 처리
else:
    # 세션 없음 처리</code></pre></li></ul><ul id="908ed3c1-05cf-4ea1-8d48-2a4110437b56" class="bulleted-list"><li style="list-style-type:disc"><strong>세션 데이터 갱신</strong>: 사용자의 활동에 따라 세션 데이터를 업데이트하고, 만료 시간을 연장합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="3be0f64a-205e-41d9-abc1-5411d6ec09ce" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">redis.set(f&quot;session:{user_id}&quot;, updated_session_data, ex=3600)</code></pre></li></ul><h3 id="431fa4ad-7bfc-4d92-b51d-3c85001582e2" class="">2. <strong>세션 관리의 특징과 장점</strong></h3><ul id="5789598b-781b-41ea-be24-6bc51ad4fa94" class="bulleted-list"><li style="list-style-type:disc"><strong>고가용성</strong>: Redis의 클러스터링 및 복제 기능을 통해 세션 데이터의 고가용성을 보장할 수 있습니다.</li></ul><ul id="06cdb16b-138e-4b24-b207-99c9314f41bc" class="bulleted-list"><li style="list-style-type:disc"><strong>확장성</strong>: Redis는 분산 환경에서 세션 데이터를 효율적으로 관리할 수 있어, 대규모 사용자 기반을 가진 애플리케이션에 적합합니다.</li></ul><ul id="45ce9b2d-5ed8-43b3-a4bf-03e34cf5edf1" class="bulleted-list"><li style="list-style-type:disc"><strong>빠른 접근 속도</strong>: In-memory 데이터베이스인 Redis는 세션 데이터에 빠르게 접근할 수 있어 사용자 경험을 향상시킵니다.</li></ul><h3 id="e4b8b591-55f7-4004-98f3-86dfae015ae0" class="">3. <strong>Redis 세션 관리 설정</strong></h3><ul id="8fc95755-e82f-4698-9fbd-c524045d3132" class="bulleted-list"><li style="list-style-type:disc"><strong>TTL 설정</strong>: 각 세션에 만료 시간을 설정하여 일정 시간이 지나면 세션이 자동으로 만료되도록 합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="5f7da5be-3541-45c6-acd5-15b1ae74ab11" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">SET session:user123 {&quot;username&quot;: &quot;john&quot;, &quot;role&quot;: &quot;admin&quot;} EX 3600</code></pre></li></ul><ul id="e4f5aaab-6638-42bd-9569-41a974775019" class="bulleted-list"><li style="list-style-type:disc"><strong>세션 데이터 보호</strong>: 세션 데이터를 저장할 때 데이터 무결성을 보장하기 위해 해시(Hash) 또는 해시셋(Hashset)으로 저장할 수 있습니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="2598300e-bfcf-4497-908f-ed3d79d5c207" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">HSET session:user123 username &quot;john&quot; role &quot;admin&quot;</code></pre></li></ul><h3 id="af139a4e-74ac-4a94-8b9e-6eb45e5c5eb6" class="">4. <strong>세션 관리 적용 사례</strong></h3><ul id="d0c17a18-42da-483d-8579-0df0bab7f7f1" class="bulleted-list"><li style="list-style-type:disc"><strong>전자 상거래 사이트</strong>: 쇼핑 카트, 사용자 인증 정보, 주문 이력 등을 Redis 세션에 저장하여 빠르게 접근하고 관리합니다.</li></ul><ul id="abfc9d98-5e06-43b1-b640-5f86bedf8c66" class="bulleted-list"><li style="list-style-type:disc"><strong>소셜 미디어 플랫폼</strong>: 사용자 상태, 친구 목록, 알림 설정 등을 세션 데이터로 관리하여 사용자 경험을 개선합니다.</li></ul><ul id="bd130290-8baf-4423-807f-e344ff9b41c0" class="bulleted-list"><li style="list-style-type:disc"><strong>온라인 게임</strong>: 플레이어의 게임 상태, 설정, 인벤토리 등을 Redis 세션으로 관리하여 실시간 게임 플레이를 지원합니다.</li></ul><h2 id="9b5c5f19-2f3d-492e-affa-99e025946361" class="">결론</h2><p id="a1ce3e6a-cee5-454a-83d4-2f2e1c34e111" class="">Redis를 캐시 및 세션 용도로 활용하는 것은 웹 애플리케이션의 성능과 확장성을 높이는 데 매우 효과적입니다. </p><p id="1ed3a4cc-090a-8019-bb7c-c37f1839dcf9" class="">Redis의 다양한 자료 구조와 고속 데이터 처리 능력을 통해 데이터의 일관성과 안정성을 유지하면서도 빠른 응답 속도를 제공합니다. </p><p id="1ed3a4cc-090a-804f-9226-edb3f5068e5d" class="">이를 통해 대규모 애플리케이션에서도 원활한 사용자 경험을 제공할 수 있습니다.</p><p id="1ed3a4cc-090a-80da-ab3d-f290fda96bb4" class="">
</p></details></li></ul><ul id="43871202-b1d9-44e9-892b-b687e0412206" class="toggle"><li><details open=""><summary>G마켓 대기 유지 시스템</summary><figure id="3174658a-9176-402f-b2ff-6903fd08dc43" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%202.png"><img style="width:886.3848876953125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%202.png"/></a></figure><ul id="e32f3351-b42d-462e-af9f-90a65c5b0444" class="bulleted-list"><li style="list-style-type:disc">Front-end webpage<ul id="6a9763a9-6472-4638-b6bc-e1d3a47f6155" class="bulleted-list"><li style="list-style-type:circle">사용자의 웹브라우저에 대기 중 상태의 웹페이지를 서비스합니다.</li></ul></li></ul><ul id="73a75f63-bb2c-4fc5-a2f1-cf96614ed20c" class="bulleted-list"><li style="list-style-type:disc">Web API Service<ul id="bf663a27-4176-4932-af60-3ab9b4f228f0" class="bulleted-list"><li style="list-style-type:circle">대기열의 주요 기능들 [대기열 등록, 조회 등]을 제공하는 API 서비스입니다.</li></ul></li></ul><ul id="04666c09-1d06-4ac1-a699-0ebb045847c8" class="bulleted-list"><li style="list-style-type:disc">Job Service<ul id="a33c76fb-6d8f-4652-b3f4-6c4e1ac9937e" class="bulleted-list"><li style="list-style-type:circle">주기적으로 Redis Queue에 쌓인 사용자들을 이동시키고, 모니터링을 위한 정보를 기록합니다.</li></ul></li></ul><ul id="5dce3fb7-8b38-49a1-9c36-309925748c1d" class="bulleted-list"><li style="list-style-type:disc">Admin Tool<ul id="3c5ac220-85af-4b18-b7a8-e2069e55d0ec" class="bulleted-list"><li style="list-style-type:circle">대기열의 등록, 수정 등을 통해 실시간으로 유입량을 조절할 수 있는 관리 도구입니다.</li></ul></li></ul><figure id="f2a0559a-6954-4f6c-b81e-fe85ccaa72da"><a href="https://dev.gmarket.com/46" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">지마켓 대기열 시스템 파헤치기</div><div class="bookmark-description">지마켓 대기열 시스템 파헤치기 안녕하세요 VIP &amp; Vertical 팀 김윤제입니다. VIP 파트에서 상품 상세 페이지 및 리뷰 업무를 맡고 있습니다. 이번 블로깅에서는 Auction, Gmarket에서 사용하고 있는 대기열 시스템인 Redcarpet에 대해 소개하려 합니다. Redcarpet Redcarpet은 Auction, Gmarket의 대기열 시스템으로 일시적으로 많은 트래픽이 발생하는 서비스에 과도한 트래픽의 유입을 방지해 주고 시스템을 보호합니다. 대기열 시스템 Redcarpet의 이름은 대형 홀 등의 줄을 서서 기다리는 곳에 깔린 레드카펫에서 유래되었습니다. Redcarpet의 도입이유 Big Smile Day, Big Sale 등의 이벤트 또는 인기 있는 상품에 대해 트래픽이 몰리는 순간..</div></div><div class="bookmark-href"><img src="https://dev.gmarket.com/favicon.ico" class="icon bookmark-icon"/>https://dev.gmarket.com/46</div></div><img src="https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbsJ7le%2FbtrNpsCzkna%2FV53GKnMSOQqr2KYD4njuS1%2Fimg.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="a920e531-0e24-45ae-b736-7dd10f205d23" class="toggle"><li><details open=""><summary>온라인 예매 시스템 구성 요소 </summary><h3 id="e310abff-ded4-4f94-9ec9-b51a29d2b60e" class="">1. <strong>클라우드 기반 인프라</strong></h3><ul id="7583be09-c55b-4df6-935f-e8285d22b3fb" class="bulleted-list"><li style="list-style-type:disc"><strong>클라우드 서비스 사용:</strong> AWS, Google Cloud, Azure와 같은 클라우드 제공자를 사용하여 자동 확장, 로드 밸런싱, 고가용성, 데이터 복제 및 백업을 제공.</li></ul><ul id="aa995a90-b231-445b-8fb2-b78e4ad70606" class="bulleted-list"><li style="list-style-type:disc"><strong>오토스케일링(Auto-scaling):</strong> 사용량에 따라 인스턴스 수를 자동으로 조절하여 트래픽 급증에 대응.</li></ul><h3 id="e9094a34-9b4f-4f71-86e5-4f13f07c5710" class="">2. <strong>마이크로서비스 아키텍처</strong></h3><ul id="05010036-d702-451e-b371-a32d7c1ff443" class="bulleted-list"><li style="list-style-type:disc"><strong>서비스 분리:</strong> 사용자 인증, 예매 관리, 결제 처리, 알림 서비스 등으로 기능을 분리하여 각각 독립적으로 배포 및 확장 가능.</li></ul><ul id="b40efa94-087a-4c8c-8b68-ff91ded05d56" class="bulleted-list"><li style="list-style-type:disc"><strong>API Gateway:</strong> 클라이언트와 내부 서비스 간의 중계 역할을 수행하며, 인증, 라우팅, 로깅, 모니터링 기능을 제공.</li></ul><h3 id="d2babf02-6d82-43cd-b4c6-44db26203712" class="">3. <strong>데이터베이스</strong></h3><ul id="dda1156c-234e-48be-b894-f0cba0cb1407" class="bulleted-list"><li style="list-style-type:disc"><strong>분산 데이터베이스:</strong> Cassandra, MongoDB, DynamoDB 등 NoSQL 데이터베이스를 사용하여 확장성 있는 데이터 저장소 구축.</li></ul><ul id="f6d75a8c-8a97-4517-afc6-5266080d743d" class="bulleted-list"><li style="list-style-type:disc"><strong>RDBMS:</strong> 트랜잭션과 데이터 일관성이 중요한 경우 PostgreSQL, MySQL과 같은 관계형 데이터베이스 사용. 특히 티켓 재고 관리 등의 경우에 유용.</li></ul><ul id="a1e56e90-af41-4c1d-a438-b10972617c30" class="bulleted-list"><li style="list-style-type:disc"><strong>캐싱:</strong> Redis, Memcached 등을 사용하여 빈번히 조회되는 데이터를 캐싱하여 성능 향상.</li></ul><h3 id="ee6e0f5b-cbf9-465e-9caa-12e10bef771d" class="">4. <strong>로드 밸런싱과 CDN</strong></h3><ul id="330b7b72-7029-48ae-92c0-81c18b71f2df" class="bulleted-list"><li style="list-style-type:disc"><strong>로드 밸런서:</strong> 트래픽을 여러 서버로 분산시켜 서버의 과부하를 방지하고 안정성을 높임.</li></ul><ul id="5a09ec46-db74-40bc-8778-0f5878fc34fa" class="bulleted-list"><li style="list-style-type:disc"><strong>CDN(Content Delivery Network):</strong> 전 세계적으로 분산된 엣지 서버를 통해 정적 콘텐츠(이미지, CSS, JS 등)를 제공하여 응답 시간을 줄임.</li></ul><h3 id="942a6a79-bc95-46c5-8281-4ee2950f8dce" class="">5. <strong>메시징 시스템</strong></h3><ul id="28979ae2-be30-4a0a-9b79-29ef0373ab92" class="bulleted-list"><li style="list-style-type:disc"><strong>메시지 큐:</strong> RabbitMQ, Kafka 등을 사용하여 비동기 작업 처리, 트랜잭션 메시지 처리, 알림 서비스 등에서 활용.</li></ul><h3 id="cd1d2f5c-65f8-45b3-8b70-eb83a4e4d699" class="">6. <strong>모니터링 및 로깅</strong></h3><ul id="55c87068-bf0b-48d5-890a-5782bab65356" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링:</strong> Prometheus, Grafana 등을 사용하여 시스템 성능, 애플리케이션 상태를 모니터링.</li></ul><ul id="c9439c53-6ba7-49f2-a593-4fdbfd5c1ef0" class="bulleted-list"><li style="list-style-type:disc"><strong>로깅:</strong> ELK Stack (Elasticsearch, Logstash, Kibana) 또는 Splunk를 사용하여 로그 데이터를 분석하고 시각화.</li></ul><h3 id="ee6cf8ef-6663-4019-9ced-2898ebf0fc2c" class="">7. <strong>보안</strong></h3><ul id="be88756b-4483-4de0-9c32-4f86ae53a251" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 암호화:</strong> TLS/SSL을 사용하여 데이터 전송 시 보안을 강화.</li></ul><ul id="e5cf5570-dcb9-4f88-82a2-207d192fa654" class="bulleted-list"><li style="list-style-type:disc"><strong>인증 및 권한 관리:</strong> OAuth, OpenID Connect와 같은 표준 프로토콜을 사용하여 안전한 사용자 인증 및 권한 관리.</li></ul><ul id="c4032ff4-a5e8-406f-99c7-d76d231e9166" class="bulleted-list"><li style="list-style-type:disc"><strong>웹 애플리케이션 방화벽(WAF):</strong> OWASP Top 10과 같은 일반적인 보안 취약점으로부터 보호.</li></ul><h3 id="72fac908-99f9-4066-846b-fdd338651634" class="">8. <strong>테스트 및 배포</strong></h3><ul id="3f5489fc-8ed9-4617-8363-e87eb468f83c" class="bulleted-list"><li style="list-style-type:disc"><strong>CI/CD 파이프라인:</strong> GitLab CI, Jenkins, CircleCI 등을 사용하여 자동화된 빌드, 테스트, 배포 환경 구축.</li></ul><ul id="073422b8-16da-4162-a7f9-a121852f8316" class="bulleted-list"><li style="list-style-type:disc"><strong>블루/그린 배포 및 카나리 배포:</strong> 배포 중단 없이 새로운 기능을 출시하고 안정성을 유지.</li></ul><p id="e0f0190a-d09f-4769-933e-e4a5809dfe35" class="">이러한 아키텍처를 구현하면 높은 트래픽을 안정적으로 처리할 수 있고, 필요에 따라 쉽게 확장할 수 있습니다. 물론, 실제로 구현할 때는 비즈니스 요구사항과 기술적 제한사항을 고려하여 구체적인 선택을 해야 합니다.</p></details></li></ul><ul id="7476a48a-c053-4bc8-bda9-a0cdaf8c4d59" class="toggle"><li><details open=""><summary>100만 동시 접속을 견뎌내는 티켓 예매 서비스</summary><h1 id="e70ffaa7-e968-48cb-8b08-e6ef948d2b89" class="">서비스 개요</h1><ol type="1" id="e87c114a-30b1-4204-bd8c-ae67913dd9ea" class="numbered-list" start="1"><li><strong>서비스의 목적</strong>이 무엇인가요?<p id="a17b2ba4-b593-4abf-8370-e0e4cb15477c" class="">2023년 내한했던 브루노 마스의 티켓 예매 사이트 동접자가 100만을 넘었던 것을 모티브로 삼아 이와 같은 티켓 예매 시스템을 설계, 구현해보고자 했습니다.</p></li></ol><ol type="1" id="9ead67a9-9b6e-4ce3-b23e-e14cf9e91038" class="numbered-list" start="2"><li>누가 이 <strong>서비스의 대상</strong>인가요?<ul id="9cf6a43c-f591-4df3-b153-eb753124f07e" class="bulleted-list"><li style="list-style-type:disc">티켓을 구매하고자 하는 티켓 예매 사이트에 가입한 유저들 (사이트 가입 유저 200만 추정)</li></ul><ul id="59bbdd76-5ffe-407e-bbde-49705f5e28e4" class="bulleted-list"><li style="list-style-type:disc">2023.06 브루노 마스 티켓팅을 기준으로, 100만의 유저가 동시간 대에 티켓 구매 요청을 할 것으로 예상합니다.</li></ul></li></ol><ol type="1" id="78083eae-0c17-40cd-9cd0-77aee8e623bd" class="numbered-list" start="3"><li>서비스를 위해 충족해야 하는 <strong>요구사항</strong>은 무엇인가요?<ul id="27f2d94a-2cf6-4b13-ae13-2d399d2243c2" class="bulleted-list"><li style="list-style-type:disc"><strong>동접자 100만의 트래픽</strong>을 처리할 수 있어야 합니다.</li></ul><ul id="d098523e-b4c6-4389-876e-a4e167facbd0" class="bulleted-list"><li style="list-style-type:disc"><strong>접속한 순서</strong>대로 티켓을 예매할 수 있어야 합니다.</li></ul><ul id="2d5ef789-8506-4fd9-8c1a-2f1c60ab52a9" class="bulleted-list"><li style="list-style-type:disc"><strong>티켓은 좌석 마다 하나 씩</strong> 발급 되어야 합니다.</li></ul><ul id="6e475711-1457-4c84-b609-2b5686a39cee" class="bulleted-list"><li style="list-style-type:disc"><strong>1명의 유저당 최대 3개의 티켓을 구매할</strong> 수 있습니다.</li></ul><ul id="d0be8610-1189-4bf4-be6d-dfdb3024f4de" class="bulleted-list"><li style="list-style-type:disc">예매 완료 시 유저는 <strong>자신이 예매한 티켓 정보를 조회</strong>할 수 있습니다.</li></ul></li></ol><h1 id="02be1ecf-d794-4e52-85da-2e8c0f0833c5" class="">티켓 예매 프로세스</h1><p id="fe272cb1-c118-40b1-a4bf-37e305b9b76d" class="">티켓 예매는 어떻게 진행되어야 할까요?</p><p id="4de6d718-92a3-4a53-9c1e-2176252540cd" class="">사용되는 기술 및 상세 구현을 시작하기 전, 간략하게 예매 흐름을 작성 해보았습니다. 실제 구현될 내용과는 다를 수 있습니다.</p><p id="d8d7ffa2-0f78-49fc-9e4d-19d7d18fb43f" class=""><strong>예매 전</strong></p><ol type="1" id="d18faa3f-f419-465f-8740-545892b4f933" class="numbered-list" start="1"><li>아래의 <strong>티켓팅 정보</strong>를 등록합니다. <em>(실제 DB 테이블 내용과는 다를 수 있습니다.)</em><ul id="3f02de36-e0b8-4d33-ab3c-598e8d7c1201" class="bulleted-list"><li style="list-style-type:disc">티켓팅할 행사 이름</li></ul><ul id="5f28d62e-7655-4ca3-99e5-d590884accc0" class="bulleted-list"><li style="list-style-type:disc">티켓팅 시작 시간</li></ul><ul id="0d404dbb-b06d-406c-95b5-a449d0c303d6" class="bulleted-list"><li style="list-style-type:disc">행사 시 사용될 티켓 좌석<ul id="2b6be736-8afb-4b9c-9cb7-d9c1e1fc9eb3" class="bulleted-list"><li style="list-style-type:circle">티켓 좌석 번호</li></ul><ul id="a6bf85c5-68b2-48b4-8d55-2b32033fb419" class="bulleted-list"><li style="list-style-type:circle">티켓 좌석 등급</li></ul><ul id="e0c1f26d-a37b-4291-9a6e-e619f5c1a9a4" class="bulleted-list"><li style="list-style-type:circle">티켓 좌석 금액</li></ul></li></ul></li></ol><p id="fc049be4-91f6-42ed-9fa9-76f855af1272" class=""><strong>예매 시</strong></p><ol type="1" id="5b7d2696-aff3-4ad7-b80d-5bd3884a2db1" class="numbered-list" start="1"><li>사용자가 <strong>예매 준비 페이지에 접속</strong>합니다. 예매를 하기 위해서 유저는 로그인 된 상태이어야 하며, 지정된 시간부터 예매가 가능합니다.</li></ol><ol type="1" id="94e26e31-fe91-4745-abf5-7271582526e9" class="numbered-list" start="2"><li>예매 가능 시간 이후부터 <strong>“예매하기”</strong> 버튼을 통해 예매 대기열 페이지로 접속이 가능합니다.<p id="8dc721c0-6ae1-4234-bf1a-5daecf47157e" class="">ex. 예매 가능 시간이 오전 10시부터 시작일 경우, 10시 0분 0초부터 예매 대기열 페이지 접속이가 가능합니다.</p></li></ol><ol type="1" id="e6f3a36c-b277-46e6-b7d7-30b6aa62b9a7" class="numbered-list" start="3"><li>접속한 인원들은 우선 <strong>대기열 페이지로 이동</strong>합니다.<ul id="efeef5ff-a96d-4f8e-9eef-1fa97d739005" class="bulleted-list"><li style="list-style-type:disc">생각할 점<ul id="1879cd42-b3c3-49b6-8d6d-c0646e5602a5" class="bulleted-list"><li style="list-style-type:circle">대기 페이지에 있는 인원들은 어떻게 관리할 것인가?</li></ul></li></ul></li></ol><ol type="1" id="3d434d14-fb6f-4b32-a430-95549d136749" class="numbered-list" start="4"><li>대기열 페이지에서 <strong>선착순 n명의 인원만 예매 페이지로 이동하여 좌석 예매를 시작</strong>하도록 합니다.<ul id="96953afb-1738-41c7-975a-4f467fed6a50" class="bulleted-list"><li style="list-style-type:disc">생각할 점<ol type="1" id="18f1e324-9bfc-44b7-94b8-40517cc87bab" class="numbered-list" start="1"><li>선착순 n명을 어떻게 측정할 것인가? 정합성을 보장할 방법이 있는가?</li></ol><ol type="1" id="640ef56d-b5cc-430c-a2c6-522556857c90" class="numbered-list" start="2"><li>n명의 기준은 어떻게 정할 것인가?</li></ol></li></ul></li></ol><ol type="1" id="81eae58f-9045-4e19-a404-ec7577636325" class="numbered-list" start="5"><li>예매 페이지에 접속한 유저는 <strong>좌석을 선택</strong>합니다.<ul id="6d8e21c5-18e5-488a-99a6-0902adc24fa6" class="bulleted-list"><li style="list-style-type:disc">이 때, 최대 3자리를 선택할 수 있고, 각 좌석의 등급, 가격은 다를 수 있습니다.</li></ul><ul id="f4e9924f-6201-445a-94ce-7baaf0b50382" class="bulleted-list"><li style="list-style-type:disc">생각할 점<ul id="e54fc9a1-7bc4-4162-8763-32d6c55d81b4" class="bulleted-list"><li style="list-style-type:circle"><em>좌석 선택에 시간 제한을 두어야 하는가?</em><ul id="d8600873-ee12-407f-b5fa-fe7be400896e" class="bulleted-list"><li style="list-style-type:square">YES 현재 대기 열이 있기 때문에, 좌석 선택은 20분 안에 완료되어야 한다. 그렇지 않으면 접속을 강제 종료시킨다.</li></ul></li></ul></li></ul></li></ol><ol type="1" id="fa215784-b1f4-46c5-975b-71eeb85d2b3c" class="numbered-list" start="6"><li>좌석을 선택한 유저는 <strong>결제 페이지</strong>로 넘어갑니다.<ul id="61f23ed3-b253-4bd6-9fcc-b6c9f94e1a9b" class="bulleted-list"><li style="list-style-type:disc">결제 페이지에서 다시 자리 선택 화면으로 이동할 수 없습니다.</li></ul><ul id="63a09c87-d16c-430b-b49a-9197f6085f65" class="bulleted-list"><li style="list-style-type:disc">좌석 선택 후 7분 이내에 결제가 이루어지지 않으면 선점한 자리가 해제되고, 접속이 강제 종료됩니다.</li></ul></li></ol><ol type="1" id="25ac288f-7e37-4948-b2df-5b7b8b9a459f" class="numbered-list" start="7"><li>결제까지 완료되었을 경우, 티켓 예매 접속이 종료됩니다.</li></ol><ol type="1" id="22480885-635c-4357-b690-aed567043da8" class="numbered-list" start="8"><li>N명 만큼 예매 페이지 접속이 종료되면, 그리고 남은 티켓이 존재한다면 대기 페이지에 있는 유저를 최대 N명만큼 선착순 예매 페이지로 이동시킵니다.<ul id="2aa283ed-5b23-4467-96d6-c4f04a004dfb" class="bulleted-list"><li style="list-style-type:disc">만약 남은 예매 티켓이 존재하지 않는다면, 대기자들의 접속을 종료시킵니다.</li></ul></li></ol><h1 id="3802bcd8-cdcc-4f82-b6de-7bb19f99087a" class="">기능 정의 및 기능 별 서버 분리</h1><h2 id="db1233b6-6707-4766-a7c5-2e2376c76601" class="">전체 시스템 추상화</h2><ul id="6f93bde3-6f44-476c-b389-74f9ba8962ba" class="bulleted-list"><li style="list-style-type:disc">구체적으로 어떤 기술을 사용할지는 정하지 않은 상태에서, 전체적인 데이터의 흐름을 바탕으로 시스템을 추상화해보았습니다.<ul id="ba2560bb-3e37-46d7-9c92-3e093d6225f0" class="bulleted-list"><li style="list-style-type:circle">전체 시스템 구성도<figure id="e75ab9ab-8b7d-404d-aa1c-3d5b9a658eba" class="image"><a href="https://velog.velcdn.com/images/tilsong/post/f6773204-5446-4977-b78f-2e20da311431/image.png"><img src="https://velog.velcdn.com/images/tilsong/post/f6773204-5446-4977-b78f-2e20da311431/image.png"/></a></figure></li></ul></li></ul><ul id="308ae8f9-e831-40b2-bcaa-0ad1ecd02cdf" class="bulleted-list"><li style="list-style-type:disc">프로젝트에서 주로 다룰 부분은 아래의 3 서버 애플리케이션입니다.<ol type="1" id="983efe04-e282-4000-901d-f36598e43075" class="numbered-list" start="1"><li>User, Ticket Info를 관리하는 <strong>User and Ticket Info Management Server</strong></li></ol><ol type="1" id="0dbc0a9f-5137-4f17-ac1e-20d2fef34024" class="numbered-list" start="2"><li>티켓 예매를 기다리는 유저들을 순차적으로 관리하는 <strong>Queue Management Server</strong></li></ol><ol type="1" id="4e6e68fc-a87e-49dc-abd0-7dac5e853d8b" class="numbered-list" start="3"><li>좌석 예매 기능을 제공하는 <strong>Ticketing Server</strong></li></ol></li></ul><h2 id="cec157b8-cd3e-4cfd-922c-ccec517d137a" class="">서버별 주요 기능 및 구조도</h2><p id="a84c50c4-a056-468f-9503-6fb923bfa532" class=""><em>주요 기능 위주로 나눈 각 서버의 구체적인 기능, 그리고 간단한 시스템 구조를 작성해보았습니다.</em></p><h3 id="991ab871-f525-40d9-989b-dc60b8be8972" class=""><strong>User And Ticket Info Server</strong></h3><ul id="552b149f-ee79-4445-8279-d9d2d1e0f7ac" class="bulleted-list"><li style="list-style-type:disc">유저의 회원 가입 및 로그인, 로그아웃, 그리고 티켓팅 정보를 관리하는 서버</li></ul><ul id="7714e67e-78b8-45a3-80d6-e5d38107019b" class="bulleted-list"><li style="list-style-type:disc">기능<ul id="3fc79cf6-d133-434d-96d0-c8986c9cac55" class="bulleted-list"><li style="list-style-type:circle">유저 회원 가입 기능</li></ul><ul id="18d257f9-fd22-476c-bbce-301468f4ec42" class="bulleted-list"><li style="list-style-type:circle">유저 로그인 기능</li></ul><ul id="e198febf-5b9b-4c25-9091-790d9512c7d3" class="bulleted-list"><li style="list-style-type:circle">유저 로그아웃 기능</li></ul><ul id="7c4a0daf-463d-44ff-a3bd-92cef404e771" class="bulleted-list"><li style="list-style-type:circle">티켓팅 정보 등록</li></ul></li></ul><h3 id="cce47720-09d1-4668-a3f2-c35f891144d1" class=""><strong>Queue Management Server</strong></h3><ul id="5929acfb-639d-4b45-aa12-27c25f8c8a23" class="bulleted-list"><li style="list-style-type:disc">티켓팅 대기열을 관리하는 서버<figure id="790205a8-f0d8-40b4-a774-12cfe4c8c8e9" class="image"><a href="https://velog.velcdn.com/images/tilsong/post/fcf7c587-6236-4320-b40e-d8985c95a68a/image.png"><img src="https://velog.velcdn.com/images/tilsong/post/fcf7c587-6236-4320-b40e-d8985c95a68a/image.png"/></a></figure></li></ul><ul id="aa6d817e-2bc3-418a-8d11-60549aba0904" class="bulleted-list"><li style="list-style-type:disc">기능<ul id="293e2fe6-13db-4dd8-ae12-59d886915134" class="bulleted-list"><li style="list-style-type:circle">유저 선착순 등록 기능<ul id="c7ae4d0a-7a17-4aaa-83c3-b2fdcc0a3e8a" class="bulleted-list"><li style="list-style-type:square">접속한 유저들을 선착순으로 등록하여 관리합니다.</li></ul></li></ul><ul id="d4e162cc-381d-4ecb-a62a-ea724f0bcc1e" class="bulleted-list"><li style="list-style-type:circle">유저 연결 기능<ul id="40e16025-d704-4834-8410-6bd30e7c76bc" class="bulleted-list"><li style="list-style-type:square">웹소켓을 통해 유저들과의 연결을 유지합니다.</li></ul><ul id="0f975e6f-facf-475c-a23f-fccaeef5d7b0" class="bulleted-list"><li style="list-style-type:square">웹소켓을 통해 실시간으로 유저들에게 필요한 메시지를 전달합니다.</li></ul></li></ul><ul id="9d672d01-f873-4bdb-8b4b-8aadcac68e7d" class="bulleted-list"><li style="list-style-type:circle">티켓팅 서버 리다이렉트 기능<ul id="371d868c-ab83-4253-8462-709e20ef25e8" class="bulleted-list"><li style="list-style-type:square">스케줄러를 통해 주기적으로 티켓팅 서버로 이동할 수 있는 유저의 수를 파악합니다.</li></ul><ul id="5212aa6a-4908-44bd-b716-f6db83ccce70" class="bulleted-list"><li style="list-style-type:square">이동할 수 있는 유저의 수만큼 티켓팅 서버 액세스 토큰을 등록합니다.</li></ul><ul id="9ea392d3-8062-4def-907d-8e09fc17416d" class="bulleted-list"><li style="list-style-type:square">이후 웹소켓을 통해 티켓팅 서버로 리다이렉트할 수 있도록 하는 메시지를 클라이언트에 전달합니다.</li></ul></li></ul></li></ul><h3 id="79e93368-874a-4599-8964-397d8294dc49" class=""><strong>Ticketing Server</strong></h3><ul id="d63e6633-ad00-46a5-ac89-89878b1a1263" class="bulleted-list"><li style="list-style-type:disc">티켓팅 기능을 제공하는 서버<figure id="d963bb67-94ac-4bf5-b67a-b44e96bece0c" class="image"><a href="https://velog.velcdn.com/images/tilsong/post/3d986daa-7e5b-4298-bddb-4dc8038f1a2c/image.png"><img src="https://velog.velcdn.com/images/tilsong/post/3d986daa-7e5b-4298-bddb-4dc8038f1a2c/image.png"/></a></figure></li></ul><ul id="512c3313-ba54-4d4b-adae-1661b9bfbec1" class="bulleted-list"><li style="list-style-type:disc">기능<ul id="135e0669-d626-4453-8f12-191eb632ea38" class="bulleted-list"><li style="list-style-type:circle">토큰 기반 접속 기능<ul id="9e41652f-afc5-45de-9758-343fdde6d9b1" class="bulleted-list"><li style="list-style-type:square">접속 토큰이 있는 유저만 접근을 허용합니다.</li></ul></li></ul><ul id="62c43f2d-06cb-485f-a979-b0ad11845b6b" class="bulleted-list"><li style="list-style-type:circle">유저 연결 기능<ul id="a5604486-7366-409f-b492-c7b2a2ec780a" class="bulleted-list"><li style="list-style-type:square">접속 시 웹 소켓을 연결하고, 토큰에 대한 만료 시간을 10분 뒤로 설정합니다.<ul id="ec741a0a-fbd2-41b7-9eef-8938bcae4843" class="bulleted-list"><li style="list-style-type:disc">생각할 점<ul id="030d0c2a-4aa6-49d7-8a65-e889378de3cd" class="bulleted-list"><li style="list-style-type:circle">웹소켓에 대한 시간 처리는 어떻게 할 것인가? 가령, 10초가 지나갔을 경우 해당 시간을 클라이언트에 어떻게 전달할 것인가?</li></ul><ul id="5a9f8c0e-28c0-42a9-b097-b0b1a988a826" class="bulleted-list"><li style="list-style-type:circle">서버가 다운되었을 때, 어떻게 복구할 수 있는가?</li></ul></li></ul></li></ul></li></ul><ul id="59b8ddc3-2f49-4f3f-bcef-a48bd010d1f5" class="bulleted-list"><li style="list-style-type:circle">좌석 선택 기능<ul id="b311c491-e8cb-4100-ac02-c29c07acffb5" class="bulleted-list"><li style="list-style-type:square">좌석 선택 시, 현재 전체 좌석 상태와 함께 좌석 선택 성공 여부를 반환합니다.<ul id="b8ece0f7-b0d4-4ae9-9708-8b26bc2fc064" class="bulleted-list"><li style="list-style-type:disc">선택이 된 좌석이면, 실패 응답을 전달합니다.</li></ul><ul id="f607a07d-b344-40ee-97da-d78ca1c6f9a3" class="bulleted-list"><li style="list-style-type:disc">아직 선택되지 않은 좌석이면, 좌석을 선점 처리합니다.</li></ul><ul id="ce094ce4-0e6e-4001-8b35-3e35234fd9af" class="bulleted-list"><li style="list-style-type:disc">전달되는 좌석 상태는 선점된 좌석 목록입니다.</li></ul></li></ul><ul id="648f882e-146a-4883-8760-cc8782674719" class="bulleted-list"><li style="list-style-type:square">좌석 선택이 완료되면, 결제 페이지로 넘어갑니다.</li></ul><ul id="687a1ff6-fb84-4291-b544-7f80a42e8d49" class="bulleted-list"><li style="list-style-type:square">10분 내로 좌석 선택을 완료하지 못하면, 선택한 좌석을 모두 비선점 상태로 바꾸고 접속을 종료시킵니다.</li></ul></li></ul><ul id="d498b66d-f801-4fa7-80dd-e86de125676d" class="bulleted-list"><li style="list-style-type:circle">결제 기능<ul id="f9a75ab8-5c51-4d3b-af4e-d63a2579134c" class="bulleted-list"><li style="list-style-type:square">결제 페이지 접속 시 결제에 대한 만료 시간을 7분 뒤로 설정합니다.</li></ul><ul id="3f2d32f0-c3b6-4675-8958-1325da50ab67" class="bulleted-list"><li style="list-style-type:square">7분 내 결제를 완료하지 못하면, 선택한 좌석을 모두 비선점 상태로 바꾸고, 접속을 종료시킵니다.</li></ul><ul id="0d427422-084e-411d-8dd5-50c9e19f8ed1" class="bulleted-list"><li style="list-style-type:square">결제 완료 시 티켓을 생성하고, 토큰을 제거하고 접속을 종료합니다.</li></ul></li></ul></li></ul><p id="da8956ac-ca90-419b-8e95-eecd9323b24b" class="">
</p></details></li></ul><ul id="e9e9c7cf-84cb-4d5b-932d-6f6683b4dc19" class="toggle"><li><details open=""><summary>티켓 예매 시스템</summary><p id="1a854f0e-3c0a-45da-bccf-b1c87f8f3a41" class="">100만 명의 동시 접속자를 처리할 수 있는 티켓 예매 시스템을 설계하려면, 높은 확장성과 안정성을 가진 마이크로서비스 아키텍처(MSA)를 구성해야 합니다. 이 구조는 웹 서버, API 게이트웨이, 로드 밸런서(LB), 데이터베이스(DB), Kafka, Redis 등을 포함합니다. 이를 바탕으로 시스템을 설계해 보겠습니다.</p><h3 id="a8452db1-457e-4bb2-9590-09e0167826c7" class="">1. 시스템 구성 요소</h3><ol type="1" id="58b56695-f1b5-4f05-b036-08bdc1cb80d3" class="numbered-list" start="1"><li><strong>웹 서버(Web Server)</strong>:<ul id="547320a2-f3f2-44f5-8d1e-8ad6ae5abc16" class="bulleted-list"><li style="list-style-type:disc">역할: 클라이언트의 HTTP 요청을 수신하고, 필요한 경우 API 게이트웨이를 통해 백엔드 마이크로서비스로 요청을 전달합니다.</li></ul><ul id="f5cc68f3-291a-4bdf-82d7-03677ff7af56" class="bulleted-list"><li style="list-style-type:disc">추천 기술: Nginx, Apache</li></ul><ul id="4bb10057-745a-41c4-9890-ebc90256ad37" class="bulleted-list"><li style="list-style-type:disc">특징: SSL/TLS를 통해 보안을 강화하며, CDN(Content Delivery Network)과 연동해 정적 컨텐츠를 효율적으로 제공할 수 있습니다.</li></ul></li></ol><ol type="1" id="ba067f84-e338-4c89-9a3e-e33131ae4939" class="numbered-list" start="2"><li><strong>API 게이트웨이(API Gateway)</strong>:<ul id="6c9b1830-0ba7-49d7-9d49-10a6819e35c6" class="bulleted-list"><li style="list-style-type:disc">역할: 클라이언트 요청을 각 마이크로서비스로 라우팅하고, 인증, 인가, 로깅, API 버저닝 등을 처리합니다.</li></ul><ul id="2c9153f9-13f5-4a3f-87e6-5cca840f2cd4" class="bulleted-list"><li style="list-style-type:disc">추천 기술: Kong, AWS API Gateway, Apigee</li></ul><ul id="9550e34f-3d64-4e0c-a921-a73f698699d2" class="bulleted-list"><li style="list-style-type:disc">특징: 모든 요청이 통합 포인트를 통과하도록 함으로써 보안과 관리 용이성을 높입니다.</li></ul></li></ol><ol type="1" id="9611d59f-2d91-4477-93bb-37b649b84a44" class="numbered-list" start="3"><li><strong>로드 밸런서(Load Balancer)</strong>:<ul id="d489844e-ff56-4ecb-ae26-ec793aafac11" class="bulleted-list"><li style="list-style-type:disc">역할: 웹 서버, API 게이트웨이 및 마이크로서비스 인스턴스 사이의 부하를 균등하게 분산하여 고가용성을 확보합니다.</li></ul><ul id="9e14f129-61d2-4e01-a7d7-62e1263abdfe" class="bulleted-list"><li style="list-style-type:disc">추천 기술: HAProxy, AWS ELB, Nginx</li></ul><ul id="ccb5b803-bed2-4134-a9cc-f6fde9e67170" class="bulleted-list"><li style="list-style-type:disc">특징: L4(Layer 4)와 L7(Layer 7) 로드 밸런싱을 모두 지원하여 트래픽을 효율적으로 관리할 수 있습니다.</li></ul></li></ol><ol type="1" id="c69bf59d-be3c-4fec-8b35-817e9263059c" class="numbered-list" start="4"><li><strong>데이터베이스(Database)</strong>:<ul id="c5105ea2-3aa8-43be-a8e0-d7ffb472197b" class="bulleted-list"><li style="list-style-type:disc">역할: 티켓, 사용자, 이벤트 등의 데이터를 영구적으로 저장하고 관리합니다.</li></ul><ul id="d10357a5-bf35-441f-b78b-31a9998db29d" class="bulleted-list"><li style="list-style-type:disc">추천 기술:<ul id="c869af7b-4cb4-44dd-ae33-2e4fb6283e30" class="bulleted-list"><li style="list-style-type:circle">관계형 DB: PostgreSQL, MySQL</li></ul><ul id="d9935583-9b63-4745-8112-57b7a6ac4ac7" class="bulleted-list"><li style="list-style-type:circle">NoSQL DB: MongoDB, Cassandra</li></ul></li></ul><ul id="66cdbfa9-d905-4fca-bf28-8f0b2598dd4a" class="bulleted-list"><li style="list-style-type:disc">특징: ACID 트랜잭션 지원을 통해 일관성과 무결성을 유지하며, 샤딩과 레플리케이션을 통해 확장성을 보장합니다.</li></ul></li></ol><ol type="1" id="269de162-d1c2-469b-aae9-3bf31e46007e" class="numbered-list" start="5"><li><strong>Kafka</strong>:<ul id="80dec3b0-a0b0-4acc-98e8-5e48fd8102be" class="bulleted-list"><li style="list-style-type:disc">역할: 이벤트 스트리밍을 처리하여 시스템 내부의 비동기 통신을 지원합니다. 예를 들어, 티켓 예매 시도 시 실시간 알림을 보내거나 로그를 처리하는 데 사용됩니다.</li></ul><ul id="29d76091-84ab-4cbd-b011-09b3119532ce" class="bulleted-list"><li style="list-style-type:disc">특징: 대용량의 데이터를 빠르게 처리하고, 시스템의 다른 부분과 느슨하게 결합될 수 있도록 설계되었습니다.</li></ul></li></ol><ol type="1" id="d7a2a167-bef5-4791-aa2e-29be7578b701" class="numbered-list" start="6"><li><strong>Redis</strong>:<ul id="73fb7953-549d-4822-afbc-ae675ffd5ef0" class="bulleted-list"><li style="list-style-type:disc">역할: 캐싱, 세션 관리, 레이트 리미팅 등에 사용됩니다.</li></ul><ul id="51fc1e13-79d7-44f5-8e50-c0f132ed17a0" class="bulleted-list"><li style="list-style-type:disc">특징: 인메모리 데이터 저장소로써 빠른 읽기/쓰기 성능을 제공합니다. 또한 데이터 구조를 다양하게 지원하여 사용 사례에 맞게 유연하게 활용할 수 있습니다.</li></ul></li></ol><h3 id="6314426a-b420-4dd2-8fed-bc9096fc074b" class="">2. 마이크로서비스 구성</h3><p id="eb488885-63cb-4a40-82dc-5b3663a2cee4" class="">마이크로서비스는 각각 특정 비즈니스 기능을 수행하도록 설계됩니다. 다음은 주요 마이크로서비스의 예시입니다.</p><ol type="1" id="5ef6a9b9-c4e5-41cd-a4ae-c4f2271a62fa" class="numbered-list" start="1"><li><strong>Authentication Service</strong>:<ul id="6f675b56-f217-4879-80da-51e54b94ffc9" class="bulleted-list"><li style="list-style-type:disc">기능: 사용자 인증 및 권한 부여를 처리합니다.</li></ul><ul id="976a4fec-c8df-416f-9353-56adc6158aa7" class="bulleted-list"><li style="list-style-type:disc">기술: JWT(JSON Web Token)를 이용한 인증, OAuth2 지원</li></ul></li></ol><ol type="1" id="93e29998-90cb-4721-bf95-b8dcc4a42795" class="numbered-list" start="2"><li><strong>User Management Service</strong>:<ul id="02542378-cfea-45e6-9cef-3776125d3ccb" class="bulleted-list"><li style="list-style-type:disc">기능: 사용자 프로필 관리, 사용자 정보 업데이트 등을 처리합니다.</li></ul></li></ol><ol type="1" id="0e82591f-1190-4c03-87f3-8284f038a6ed" class="numbered-list" start="3"><li><strong>Ticketing Service</strong>:<ul id="01ff6654-e887-4074-b511-868ecb10a6af" class="bulleted-list"><li style="list-style-type:disc">기능: 티켓 조회, 예약, 구매 등을 처리합니다.</li></ul><ul id="c1212934-3f93-4009-a8ad-0d3ec955b691" class="bulleted-list"><li style="list-style-type:disc">트랜잭션 관리 및 롤백 메커니즘을 통해 데이터 일관성을 유지합니다.</li></ul></li></ol><ol type="1" id="5ca075fe-c1f7-4361-9b28-5414c907c05a" class="numbered-list" start="4"><li><strong>Event Management Service</strong>:<ul id="48014a1c-0ae2-4b2c-9086-c42316ca9b96" class="bulleted-list"><li style="list-style-type:disc">기능: 이벤트 생성, 수정, 삭제 및 조회를 처리합니다.</li></ul></li></ol><ol type="1" id="edf6d51c-e0d8-4084-8f00-895751c39cf1" class="numbered-list" start="5"><li><strong>Notification Service</strong>:<ul id="2ed8c965-fe0a-496f-8df0-dd26a3870c89" class="bulleted-list"><li style="list-style-type:disc">기능: 티켓 구매, 예약 완료 등의 이벤트에 대한 알림을 처리합니다.</li></ul><ul id="9c5708f6-e0b4-41f3-a7bb-e7ab88d994dc" class="bulleted-list"><li style="list-style-type:disc">Kafka를 통해 이벤트를 수신하고, 이메일, SMS, 푸시 알림 등 다양한 채널로 알림을 전송합니다.</li></ul></li></ol><ol type="1" id="8d3ae698-2e52-4f41-ad59-3c17725c3f50" class="numbered-list" start="6"><li><strong>Analytics Service</strong>:<ul id="7cf588bd-6881-45c7-9267-3f64dd7656a0" class="bulleted-list"><li style="list-style-type:disc">기능: 실시간으로 사용자 활동, 티켓 구매 패턴 등을 분석하여 인사이트를 제공합니다.</li></ul><ul id="e52f419c-affb-482c-991c-ec2fe41beab7" class="bulleted-list"><li style="list-style-type:disc">Kafka를 통해 이벤트 데이터를 수신하고, 대시보드를 통해 시각화합니다.</li></ul></li></ol><h3 id="262c4292-9ade-4582-ac88-d9db0e7f2a80" class="">3. MSA 아키텍처의 전체 흐름</h3><ol type="1" id="384e63b1-1b64-4a01-a33b-b7d089ec560b" class="numbered-list" start="1"><li><strong>클라이언트 요청</strong>: 사용자는 웹 또는 모바일 앱을 통해 티켓 예매 시스템에 접근합니다.</li></ol><ol type="1" id="54bd3dea-fc70-4b3f-8f4a-8d5f19e75f9d" class="numbered-list" start="2"><li><strong>로드 밸런싱 및 웹 서버</strong>: 로드 밸런서는 클라이언트 요청을 여러 웹 서버 인스턴스로 분산합니다. 웹 서버는 정적 콘텐츠를 제공하고, 필요한 경우 API 게이트웨이로 요청을 전달합니다.</li></ol><ol type="1" id="2d92e251-60a2-46e0-bc7c-9ed49bcb2ecc" class="numbered-list" start="3"><li><strong>API 게이트웨이</strong>: 클라이언트 요청을 수신하여 인증, 인가 등을 처리한 후 해당하는 마이크로서비스로 요청을 라우팅합니다.</li></ol><ol type="1" id="e1207ceb-8319-4513-a196-bcf36072b46a" class="numbered-list" start="4"><li><strong>마이크로서비스 통신</strong>:<ul id="8f8ca6b4-c120-4cd4-bd71-fc47baadb07f" class="bulleted-list"><li style="list-style-type:disc">API 게이트웨이는 클라이언트의 요청을 Ticketing Service 등 해당 마이크로서비스로 전달합니다.</li></ul><ul id="06cdad98-24a2-4c5a-8340-3343fd6e55b2" class="bulleted-list"><li style="list-style-type:disc">마이크로서비스는 데이터베이스와 통신하여 필요한 데이터를 조회하거나 업데이트합니다.</li></ul><ul id="d2550397-227f-4ab7-b4ea-9b5c5fa59917" class="bulleted-list"><li style="list-style-type:disc">Kafka를 통해 비동기 통신을 수행하여 다른 마이크로서비스에 이벤트를 전달하거나 알림을 전송합니다.</li></ul><ul id="b8d4d81f-5e9b-46e6-a0f0-5df643a2b0a9" class="bulleted-list"><li style="list-style-type:disc">Redis를 활용하여 캐싱 및 세션 관리 등의 기능을 수행하여 응답 속도를 향상시킵니다.</li></ul></li></ol><ol type="1" id="e670ab94-2ebf-4bc9-9713-63eb5c3f8edf" class="numbered-list" start="5"><li><strong>응답 처리</strong>: 각 마이크로서비스는 처리 결과를 API 게이트웨이로 반환하며, 게이트웨이는 이를 웹 서버를 통해 클라이언트에 응답합니다.</li></ol><h3 id="37b49717-3e38-4ccd-a707-242c7f45eaf3" class="">4. 고려사항</h3><ol type="1" id="e9ae1907-faee-4e8a-9f30-04e2a0a2e73c" class="numbered-list" start="1"><li><strong>확장성(Scalability)</strong>:<ul id="aacfa6ab-863b-4c0e-afb4-237dd2e81ac9" class="bulleted-list"><li style="list-style-type:disc">마이크로서비스를 독립적으로 확장할 수 있도록 설계하여 부하를 분산하고, 특정 서비스에 대한 수요가 증가할 경우 해당 서비스만을 확장할 수 있습니다.</li></ul></li></ol><ol type="1" id="e7c29ba4-7a8b-476d-991b-0b5afb0e28bf" class="numbered-list" start="2"><li><strong>고가용성(High Availability)</strong>:<ul id="7b951f43-bed7-46c9-850e-281aa42ae501" class="bulleted-list"><li style="list-style-type:disc">로드 밸런싱과 자동 복구 메커니즘을 통해 시스템의 가용성을 높입니다.</li></ul><ul id="3caf25d2-54fd-4b30-b9a2-1ef9778a2327" class="bulleted-list"><li style="list-style-type:disc">마이크로서비스 및 데이터베이스의 이중화를 통해 장애 발생 시에도 서비스 지속성을 보장합니다.</li></ul></li></ol><ol type="1" id="4a9554c5-8800-485c-ae6b-17c912fef501" class="numbered-list" start="3"><li><strong>보안(Security)</strong>:<ul id="2dea6cf5-707d-4ebe-b84e-6789b2e72e10" class="bulleted-list"><li style="list-style-type:disc">SSL/TLS를 통한 데이터 암호화와 API 게이트웨이를 통한 인증 및 인가 메커니즘을 강화합니다.</li></ul><ul id="5576cf22-b743-40ba-ac07-8cf386e317f6" class="bulleted-list"><li style="list-style-type:disc">마이크로서비스 간의 통신에 대한 보안 정책을 적용하여 내부 데이터 유출을 방지합니다.</li></ul></li></ol><ol type="1" id="96271231-d03f-4228-a57a-3c535763e675" class="numbered-list" start="4"><li><strong>데이터 일관성(Data Consistency)</strong>:<ul id="3e4ec439-126c-4cf1-8916-fc5c5c01d858" class="bulleted-list"><li style="list-style-type:disc">트랜잭션 관리와 데이터베이스의 ACID 속성을 활용하여 데이터 일관성을 유지합니다.</li></ul><ul id="920209db-dea1-4c0b-99e4-7b09ee2de38e" class="bulleted-list"><li style="list-style-type:disc">Kafka를 통한 이벤트 기반 아키텍처를 도입하여 최종적 일관성(Eventual Consistency)을 보장합니다.</li></ul></li></ol><p id="4eef0aa9-8f0e-44ef-9c00-83e70f000a55" class="">
</p><h3 id="8d7d709f-2270-47cc-a2ad-bee76c1cc5cc" class="">1. Public Zone과 Private Zone 구성</h3><p id="fe399058-7c9c-44d1-a2ae-1af91de5aac3" class=""><strong>Public Zone:</strong></p><ul id="d5cd5626-be53-40a2-b002-dda43d505a20" class="bulleted-list"><li style="list-style-type:disc">외부 사용자가 접근 가능한 영역으로, 인터넷을 통해 직접 접근할 수 있습니다.</li></ul><ul id="05c9a076-cfdb-4487-98f5-9a0513c089db" class="bulleted-list"><li style="list-style-type:disc">보안상의 이유로 최소한의 컴포넌트만 배치됩니다.</li></ul><p id="e09dea08-ba21-4a25-8962-7c5a00909595" class=""><strong>Private Zone:</strong></p><ul id="5ce39706-38ea-439f-80e2-a014b141ef27" class="bulleted-list"><li style="list-style-type:disc">내부 네트워크에 속하는 영역으로, Public Zone에서 인입된 요청만 처리합니다.</li></ul><ul id="ef1fd69a-1e5d-4aa3-8a3d-e863a973e82d" class="bulleted-list"><li style="list-style-type:disc">보안이 강화된 상태로 운영되며, 데이터와 중요한 비즈니스 로직을 처리합니다.</li></ul><h3 id="896a8a71-63f8-478b-a404-ccb5e55eef9a" class="">2. 컴포넌트 배치</h3><p id="5883d898-ff0e-4ec1-ac50-52e4318e7721" class=""><strong>Public Zone</strong>에 배치되는 컴포넌트:</p><ol type="1" id="b2f78bb7-f881-4544-a51f-5c811b227664" class="numbered-list" start="1"><li><strong>로드 밸런서 (Load Balancer)</strong><ul id="17106073-1607-428d-87f8-74053134b5af" class="bulleted-list"><li style="list-style-type:disc">역할: 외부에서 들어오는 트래픽을 웹 서버로 분산합니다.</li></ul></li></ol><ol type="1" id="2e0b1c90-7047-4d62-91ff-2f2edf687973" class="numbered-list" start="2"><li><strong>웹 서버 (Web Server)</strong><ul id="e89c0097-2222-4777-9a45-8ac1a0d944d9" class="bulleted-list"><li style="list-style-type:disc">역할: 정적 콘텐츠 제공, 클라이언트의 HTTP 요청을 처리하고 API Gateway로 전달합니다.</li></ul></li></ol><p id="8f32bc20-8fd2-48a6-8b3d-cba3c75e8d1f" class=""><strong>Private Zone</strong>에 배치되는 컴포넌트:</p><ol type="1" id="159f339f-3b02-46da-9dde-856999547b1e" class="numbered-list" start="1"><li><strong>API 게이트웨이 (API Gateway)</strong><ul id="d7f7e0d2-c246-4b44-9ee4-d75a28529d98" class="bulleted-list"><li style="list-style-type:disc">역할: 각 마이크로서비스로 클라이언트 요청을 라우팅하고, 인증, 인가를 처리합니다.</li></ul></li></ol><ol type="1" id="1f7cac0d-4da4-48d1-a905-591f66b5f9b0" class="numbered-list" start="2"><li><strong>마이크로서비스 (Microservices)</strong><ul id="c07acd23-1c6e-4dfd-8fda-13b603196075" class="bulleted-list"><li style="list-style-type:disc">역할: 티켓 예매, 사용자 관리, 이벤트 관리 등의 비즈니스 로직을 처리합니다.</li></ul></li></ol><ol type="1" id="44f3840e-dbbc-4056-9bac-e90118a3a4ab" class="numbered-list" start="3"><li><strong>데이터베이스 (Database)</strong><ul id="ac11726c-2e13-4440-ba44-6408b50f9d5d" class="bulleted-list"><li style="list-style-type:disc">역할: 데이터 저장 및 관리</li></ul></li></ol><ol type="1" id="216d463b-aa1d-422c-bf3d-f193126eb474" class="numbered-list" start="4"><li><strong>Kafka</strong><ul id="6aab8f08-2ea0-42d5-877a-4e4c96bbe568" class="bulleted-list"><li style="list-style-type:disc">역할: 비동기 통신 및 이벤트 스트리밍을 처리합니다.</li></ul></li></ol><ol type="1" id="81e702a2-330d-405f-9c15-965f30c60e13" class="numbered-list" start="5"><li><strong>Redis</strong><ul id="40533387-6488-4cea-a5bc-1e548844585d" class="bulleted-list"><li style="list-style-type:disc">역할: 캐시 및 세션 관리, 레이트 리미팅을 처리합니다.</li></ul></li></ol><h3 id="41d13cb1-9cae-42b0-9bb5-9f95b15de6eb" class="">3. 사용자 요청 처리 흐름</h3><p id="24c8b646-8d1c-46e7-a9e0-c55e60d3a476" class="">다음은 사용자 요청이 어떤 컴포넌트를 거쳐 처리되는지에 대한 흐름을 예로 설명합니다.</p><ol type="1" id="6bbcdcb6-8ccc-43f0-b7a0-6377758e5d5a" class="numbered-list" start="1"><li><strong>사용자 요청 (클라이언트 → 로드 밸런서)</strong><ul id="a91c7312-9913-4d8a-8d62-397da1697a2e" class="bulleted-list"><li style="list-style-type:disc">사용자는 웹 또는 모바일 앱을 통해 티켓 예매 시스템에 접속합니다.</li></ul><ul id="a044d787-13a6-496d-8516-132d9106e70d" class="bulleted-list"><li style="list-style-type:disc">사용자의 요청은 먼저 로드 밸런서에 도달합니다.</li></ul></li></ol><ol type="1" id="8ccb71a5-a952-45c8-b9fc-bd289761e436" class="numbered-list" start="2"><li><strong>로드 밸런서 (Load Balancer → 웹 서버)</strong><ul id="9b255448-7fa6-4617-ac16-7f9fae51fd8c" class="bulleted-list"><li style="list-style-type:disc">로드 밸런서는 트래픽을 여러 웹 서버 인스턴스로 분산시킵니다.</li></ul><ul id="d08f9a38-d650-4b54-8c61-7de1de8de0b9" class="bulleted-list"><li style="list-style-type:disc">이는 시스템의 가용성을 높이고 부하를 분산하기 위함입니다.</li></ul></li></ol><ol type="1" id="27594df3-6e85-437c-81b7-8fb00d5911b2" class="numbered-list" start="3"><li><strong>웹 서버 (Web Server → API 게이트웨이)</strong><ul id="def9c407-ef2c-4eeb-a3e2-de17a8b2b2c6" class="bulleted-list"><li style="list-style-type:disc">웹 서버는 클라이언트로부터 받은 HTTP 요청을 처리합니다.</li></ul><ul id="7f62275e-06b8-43d1-8af3-938f33e140f6" class="bulleted-list"><li style="list-style-type:disc">정적 콘텐츠가 아닌 경우, 요청은 API 게이트웨이로 전달됩니다.</li></ul></li></ol><ol type="1" id="ee17fe0b-d47b-4389-8678-7822f9c4cca2" class="numbered-list" start="4"><li><strong>API 게이트웨이 (API Gateway → 마이크로서비스)</strong><ul id="f41bc7f9-8758-4df7-aae1-283e6665a118" class="bulleted-list"><li style="list-style-type:disc">API 게이트웨이는 요청을 받아 인증 및 인가 과정을 수행합니다.</li></ul><ul id="356c747c-7c6e-45cd-8ad6-f335f2ad938d" class="bulleted-list"><li style="list-style-type:disc">이후 요청을 해당 마이크로서비스로 라우팅합니다.</li></ul></li></ol><ol type="1" id="2c5a13f3-cca0-4d09-9c03-10a720430c11" class="numbered-list" start="5"><li><strong>마이크로서비스 (Microservices → 데이터베이스/Kafka/Redis)</strong><ul id="1709dacf-ab27-4b50-b3e4-c1ecd54c7c4a" class="bulleted-list"><li style="list-style-type:disc">예매 서비스 예를 들면, Ticketing Service는 요청을 받아 필요한 비즈니스 로직을 처리합니다.</li></ul><ul id="4f68cb94-acb3-4535-bb66-39a864e04308" class="bulleted-list"><li style="list-style-type:disc">데이터베이스와 통신하여 티켓 정보를 조회하거나 업데이트합니다.</li></ul><ul id="292477d8-ed3e-4d80-aa22-79349764bd15" class="bulleted-list"><li style="list-style-type:disc">Redis를 통해 세션이나 캐시된 데이터를 활용할 수 있습니다.</li></ul><ul id="e555fd96-c7b1-4123-b363-dd160d550f97" class="bulleted-list"><li style="list-style-type:disc">Kafka를 통해 다른 서비스에 이벤트를 발행하거나 실시간 알림을 전송합니다.</li></ul></li></ol><ol type="1" id="7a57076f-a332-49b5-a253-78abe5f335e8" class="numbered-list" start="6"><li><strong>응답 (마이크로서비스 → API 게이트웨이 → 웹 서버 → 클라이언트)</strong><ul id="3166847b-4e5b-4939-8ade-f6516d3b63ff" class="bulleted-list"><li style="list-style-type:disc">마이크로서비스는 처리 결과를 API 게이트웨이로 반환합니다.</li></ul><ul id="400a13b5-46c4-4c62-bd0f-ee38d77ee0e5" class="bulleted-list"><li style="list-style-type:disc">API 게이트웨이는 이를 웹 서버로 전달하고, 웹 서버는 최종적으로 클라이언트에 응답을 보냅니다.</li></ul></li></ol><h3 id="790b714f-6b42-4562-9a07-ef30041750ae" class="">4. 컴포넌트 간 연결 구성</h3><p id="4b6db127-c421-4d45-9e17-01c3f6ed485c" class=""><strong>Public Zone</strong>에서 <strong>Private Zone</strong>으로의 연결은 최소한의 경로로 제한되어 보안성을 높입니다.</p><ol type="1" id="8616c161-f83f-43d1-8f2d-9968e36019b2" class="numbered-list" start="1"><li><strong>Public Zone의 로드 밸런서</strong>는 <strong>Private Zone의 웹 서버</strong>로만 연결됩니다.</li></ol><ol type="1" id="1be66766-8712-49ad-ad97-1594edb38aaa" class="numbered-list" start="2"><li><strong>웹 서버</strong>는 <strong>API 게이트웨이</strong>로만 연결되며, 이는 클라이언트 요청이 마이크로서비스와 직접 상호작용하지 않도록 설계되어 있습니다.</li></ol><ol type="1" id="b1d7700c-0472-40a4-b9b0-73bfcc36a530" class="numbered-list" start="3"><li><strong>API 게이트웨이</strong>는 내부의 <strong>마이크로서비스</strong>로만 연결됩니다.</li></ol><ol type="1" id="edf3fd49-7893-4da6-b2b0-474d846ac5ae" class="numbered-list" start="4"><li><strong>마이크로서비스</strong>는 필요한 경우 <strong>데이터베이스</strong>, <strong>Redis</strong>, <strong>Kafka</strong>와 통신합니다.</li></ol><p id="b6b63a6e-9f7e-4925-8244-bc92a78a6e68" class="">이러한 구조는 다음과 같은 장점을 제공합니다:</p><ul id="dd285cd8-fc8d-4b77-9e21-7f00db40f441" class="bulleted-list"><li style="list-style-type:disc"><strong>보안 강화</strong>: Public Zone에 노출되는 컴포넌트를 최소화하여 외부로부터의 공격을 줄입니다.</li></ul><ul id="546ecfe4-fe5f-49bb-b6cf-691c4d54c240" class="bulleted-list"><li style="list-style-type:disc"><strong>확장성 및 관리 용이성</strong>: 각각의 컴포넌트를 독립적으로 관리하고 확장할 수 있어 시스템 전체의 성능을 최적화할 수 있습니다.</li></ul><ul id="40517b0c-901f-4ddd-a252-f67962020090" class="bulleted-list"><li style="list-style-type:disc"><strong>유연한 트래픽 관리</strong>: 로드 밸런서와 API 게이트웨이를 통해 트래픽을 효율적으로 분산하고 관리할 수 있습니다.</li></ul><h3 id="c0abf699-6a17-4415-8063-74726f9a064c" class="">5. 아키텍처 다이어그램</h3><p id="cc2af7d9-7b0f-4a8e-9d3b-69cc6123751c" class="">위 그림은 전체 시스템 아키텍처를 시각화한 것입니다. Public Zone과 Private Zone의 구성 요소 및 연결을 한눈에 파악할 수 있습니다.</p><h3 id="567a72d2-a965-44d0-9e5c-f64e646b3d38" class="">6. 추가 고려사항</h3><ol type="1" id="2e5d674f-3d5c-4176-8767-01cd15f67553" class="numbered-list" start="1"><li><strong>네트워크 보안</strong>:<ul id="9386c1c4-256b-4afe-9da7-c304dbdb9a63" class="bulleted-list"><li style="list-style-type:disc">Public Zone과 Private Zone 사이의 네트워크 트래픽을 방화벽으로 보호합니다.</li></ul><ul id="6d8ca0aa-5d3e-42a8-add5-7046e448fe6c" class="bulleted-list"><li style="list-style-type:disc">모든 API 요청 및 응답을 SSL/TLS로 암호화하여 보안을 강화합니다.</li></ul></li></ol><ol type="1" id="eaa303f8-9bd7-4371-93a3-efd88adb1a57" class="numbered-list" start="2"><li><strong>성능 최적화</strong>:<ul id="efc10656-8e54-4447-a6b1-cdbaea88b767" class="bulleted-list"><li style="list-style-type:disc">Redis를 적극 활용하여 캐싱을 통해 데이터베이스 부하를 줄입니다.</li></ul><ul id="b03d8dfa-89af-4404-858a-2ef170751b61" class="bulleted-list"><li style="list-style-type:disc">Kafka를 사용하여 이벤트 기반 아키텍처를 구현하고, 실시간 데이터 처리를 최적화합니다.</li></ul></li></ol><ol type="1" id="625e4015-bda6-4614-ab43-299fe738ae0c" class="numbered-list" start="3"><li><strong>로그 및 모니터링</strong>:<ul id="7d46bebe-b0e0-4913-883a-d65c8ca9e8c1" class="bulleted-list"><li style="list-style-type:disc">각 컴포넌트의 상태 및 성능을 모니터링하여 문제 발생 시 빠르게 대응할 수 있습니다.</li></ul><ul id="29243060-998b-4a5f-89a9-7d13ee210fd1" class="bulleted-list"><li style="list-style-type:disc">중앙 집중식 로깅 시스템을 통해 로그를 수집하고 분석합니다.</li></ul></li></ol><p id="cea48aac-e846-4c22-aa49-696e16963647" class="">이와 같은 구성은 티켓 예매 시스템의 성능, 보안, 확장성 및 가용성을 모두 고려한 최적의 아키텍처를 제공합니다.</p><p id="5b73180e-c404-491f-94a2-c3f2d4823c8d" class="">
</p><h3 id="b754a4d3-53fe-41be-962d-891f403ece7e" class="">1. 요구사항 정리</h3><ol type="1" id="8c49e2f2-2c97-4b43-b032-62f2320e4d60" class="numbered-list" start="1"><li><strong>동시 접속자 100만 명</strong>: 많은 접속자를 효율적으로 처리할 수 있는 아키텍처가 필요합니다.</li></ol><ol type="1" id="c13d576f-e2a0-416e-8828-306468dbf3f9" class="numbered-list" start="2"><li><strong>100명 단위로 승인</strong>: 매 시간마다 100명씩 티켓 예매를 승인해야 합니다.</li></ol><ol type="1" id="94dd306a-28db-4e33-888f-83448f7a630a" class="numbered-list" start="3"><li><strong>대기 상태 제공</strong>: 대기 상태인 사용자에게 예매 가능한 시간을 제공해야 합니다.</li></ol><ol type="1" id="15ccdc63-fd91-4a5c-a2d0-c3063ecbccc2" class="numbered-list" start="4"><li><strong>최대 1만 명까지 예매 가능</strong>: 예매가 가능한 최대 사용자 수를 1만 명으로 제한합니다.</li></ol><h3 id="8b74b2b9-a973-4e81-b1fa-1b2a88ec3f5a" class="">2. 시스템 설계</h3><h3 id="514aa547-8566-4c6c-8ebc-70daefe86a81" class="">2.1 대기열 관리 (Queue Management)</h3><p id="80337363-827e-4999-a550-d47ca74d0c3e" class=""><strong>Redis</strong>를 이용한 대기열 관리가 가장 적합합니다. Redis는 메모리 기반의 데이터 저장소로 빠른 속도로 데이터를 처리할 수 있습니다.</p><ol type="1" id="437aa9c6-44f0-427d-8d5e-53ab9d96dd04" class="numbered-list" start="1"><li><strong>대기열 큐 생성</strong>: Redis의 리스트(List) 구조를 사용하여 대기열을 생성합니다.<ul id="e4807a7b-5577-446c-95e8-25e463b5fc63" class="bulleted-list"><li style="list-style-type:disc">사용자들이 예매 요청을 보내면 해당 요청을 Redis 큐에 삽입합니다.</li></ul></li></ol><ol type="1" id="b7d645f3-48cd-4d15-a1db-483f146930d0" class="numbered-list" start="2"><li><strong>예매 승인</strong>: 큐에서 100명씩 Pop(꺼내기)하여 예매를 승인합니다.<ul id="bf90a61e-3d25-46f3-897f-bb588c9a0b69" class="bulleted-list"><li style="list-style-type:disc">특정 시간 간격(예: 매 5초마다)으로 100명씩 큐에서 꺼내어 예매를 처리합니다.</li></ul></li></ol><ol type="1" id="11667040-c627-453e-9e38-78615f258f7e" class="numbered-list" start="3"><li><strong>대기 상태 제공</strong>: 대기열에서 사용자의 위치를 조회하여 예상 대기 시간을 제공합니다.<ul id="9f7ffeff-9de0-4d7f-bfd1-8f15f1a593ca" class="bulleted-list"><li style="list-style-type:disc">큐에서 사용자의 위치를 기반으로 대기 시간을 계산합니다.</li></ul></li></ol><h3 id="354403ed-b186-419b-99a1-41ace12a0fc5" class="">2.2 세션 및 예매 관리</h3><p id="679d38d2-e0a1-46b9-93aa-44c487a39b97" class=""><strong>Redis</strong>의 Sorted Set 구조를 이용하여 세션과 예매를 관리합니다.</p><ol type="1" id="6078ac28-065d-4228-839d-5c1e0b6455bf" class="numbered-list" start="1"><li><strong>세션 관리</strong>: 각 사용자의 세션을 Redis에 저장하고 TTL(Time To Live)을 설정하여 일정 시간이 지나면 자동으로 만료되도록 합니다.</li></ol><ol type="1" id="e6a8a225-db8e-464e-8fc0-0864f93220ad" class="numbered-list" start="2"><li><strong>예매 가능한 사용자 관리</strong>: Redis의 Sorted Set을 이용하여 예매 가능한 사용자를 관리합니다.<ul id="e85b864e-f841-4dd6-b837-43a665ed7474" class="bulleted-list"><li style="list-style-type:disc">사용자가 승인되면 Sorted Set에 추가하고, 예매가 완료되면 제거합니다.</li></ul></li></ol><h3 id="54f4dcac-7704-4ddf-9ca8-e655ad220261" class="">2.3 티켓 수량 관리</h3><p id="12eec553-b674-4835-9668-b50ccba8c2c9" class="">티켓 수량은 데이터베이스와 Redis를 함께 사용하여 관리합니다.</p><ol type="1" id="d141e23a-fdd3-4794-a87f-c3a0b8eb24a2" class="numbered-list" start="1"><li><strong>티켓 수량 확인</strong>: 티켓 예매 시 Redis에서 티켓 수량을 확인하고, 수량이 남아있는 경우에만 예매를 진행합니다.</li></ol><ol type="1" id="e4cabdd8-4f86-4de5-ae1f-c1d4e558fefa" class="numbered-list" start="2"><li><strong>티켓 수량 감소</strong>: 예매가 완료되면 Redis에서 티켓 수량을 감소시키고, 정기적으로 데이터베이스에 반영합니다.</li></ol><h3 id="bd1310c7-4a64-43f2-8221-b62135c3f4b9" class="">3. 구현 예시</h3><h3 id="55122b5e-e992-407a-93df-a212d9e773fe" class="">3.1 Redis 대기열 관리</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8ccae570-63e3-4e1c-9d01-431a6da1f0c5" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">python코드 복사
import redis
import time

# Redis 클라이언트 연결
r = redis.Redis(host=&#x27;localhost&#x27;, port=6379, db=0)

# 사용자 예매 요청
def request_ticket(user_id):
    r.rpush(&#x27;ticket_queue&#x27;, user_id)

# 예매 승인 프로세스
def approve_tickets():
    while True:
        # 100명씩 큐에서 꺼내기
        approved_users = r.lrange(&#x27;ticket_queue&#x27;, 0, 99)
        if not approved_users:
            break

        # 예매 승인 처리
        for user_id in approved_users:
            # 예매 승인 로직
            print(f&quot;User {user_id} approved for ticket booking.&quot;)
            # 승인된 사용자는 큐에서 제거
            r.lrem(&#x27;ticket_queue&#x27;, 1, user_id)

        # 5초 대기
        time.sleep(5)

# 대기 상태 조회
def get_wait_time(user_id):
    position = r.lpos(&#x27;ticket_queue&#x27;, user_id)
    if position is not None:
        # 대기 시간을 100명 단위로 계산 (예: 5초 간격)
        wait_time = (position // 100) * 5
        return wait_time
    else:
        return -1

</code></pre><h3 id="31d8f440-e485-4ad5-98ea-c831a9365742" class="">3.2 티켓 수량 관리</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="10ddefe1-eabd-4033-bcc0-4adfb2720dd5" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">python코드 복사
# Redis에서 티켓 수량 확인
def get_ticket_count():
    return int(r.get(&#x27;ticket_count&#x27;) or 0)

# 티켓 수량 감소
def decrement_ticket_count():
    r.decr(&#x27;ticket_count&#x27;)

# 예매 프로세스
def book_ticket(user_id):
    # 티켓 수량 확인
    if get_ticket_count() &gt; 0:
        # 티켓 예매 승인
        decrement_ticket_count()
        print(f&quot;User {user_id} successfully booked a ticket.&quot;)
    else:
        print(f&quot;User {user_id} could not book a ticket - sold out.&quot;)

</code></pre><h3 id="806604c5-649b-4b2b-9ef5-408981755dca" class="">4. 사용자 요청 처리 흐름</h3><ol type="1" id="c6b6519b-641d-4683-a8b6-361f4d333aa7" class="numbered-list" start="1"><li><strong>사용자 예매 요청</strong>: 사용자가 웹 또는 모바일 앱을 통해 티켓 예매를 요청합니다.</li></ol><ol type="1" id="ae7e64fb-6e74-4ae4-a3de-b1807719349a" class="numbered-list" start="2"><li><strong>대기열 큐에 추가</strong>: API Gateway는 사용자의 예매 요청을 Redis 대기열 큐에 추가합니다.</li></ol><ol type="1" id="8a5a3079-4f3f-4f0d-a93a-84ecc170161d" class="numbered-list" start="3"><li><strong>예매 승인 프로세스 실행</strong>: 백엔드에서 일정 간격으로 Redis 큐에서 100명씩 꺼내어 예매를 승인합니다.</li></ol><ol type="1" id="0cc27b37-1fc6-4eb3-9231-363ad57de15f" class="numbered-list" start="4"><li><strong>대기 상태 제공</strong>: 대기 중인 사용자는 API를 통해 자신의 대기열 위치와 예상 대기 시간을 조회할 수 있습니다.</li></ol><ol type="1" id="8fb2601c-3612-49dd-93f0-29deba76cbd7" class="numbered-list" start="5"><li><strong>티켓 예매</strong>: 승인된 사용자는 티켓을 예매하고, 예매가 완료되면 Redis에서 티켓 수량을 감소시킵니다.</li></ol><ol type="1" id="51e14e7d-ef04-4e9d-94e1-f895d89c05c4" class="numbered-list" start="6"><li><strong>예매 가능한 사용자 제한</strong>: 최대 1만 명까지 예매 가능하도록 Redis의 Sorted Set을 통해 관리합니다.</li></ol><h3 id="9fbedca0-4eef-45d1-bbd2-6c6e921d9d4f" class="">5. 장점 및 고려사항</h3><ol type="1" id="5cdc44f0-563f-4f18-8b64-4642ff110d94" class="numbered-list" start="1"><li><strong>성능 및 확장성</strong>: Redis를 활용하여 빠른 속도로 대기열과 세션을 관리할 수 있습니다.</li></ol><ol type="1" id="1b06836d-bf90-4bb7-a128-e017a30cbb96" class="numbered-list" start="2"><li><strong>보안 및 안정성</strong>: Public Zone과 Private Zone으로 구분하여 보안을 강화하고, 승인된 사용자만 예매하도록 설계하여 안정성을 높였습니다.</li></ol><ol type="1" id="b6bc1609-59bc-4cb9-8ff9-8096d9fc177e" class="numbered-list" start="3"><li><strong>유연한 확장</strong>: 시스템의 각 컴포넌트는 독립적으로 확장할 수 있어, 예매 요청이 증가해도 효율적으로 처리할 수 있습니다.</li></ol><ol type="1" id="facdc011-1bdd-43c7-8011-3c3266470e26" class="numbered-list" start="4"><li><strong>실시간 대기 시간 제공</strong>: 사용자는 자신의 대기 상태를 실시간으로 확인할 수 있어, 예매 과정에서의 불편함을 최소화할 수 있습니다.</li></ol><p id="f8dbe4aa-4694-44e7-b142-b019131030c8" class="">이와 같은 시스템 설계를 통해 동시 100만 명의 사용자 중 특정 시간에 100명씩 예매를 승인하고, 최대 1만 명까지만 예매를 허용하는 효율적인 티켓 예매 시스템을 구현할 수 있습니다.</p><p id="8e03dd6c-9f73-4b21-917d-9ec0a15958d7" class="">4o</p></details></li></ul><ul id="6ed6dd66-0e83-4e46-ba63-29e109b5bc38" class="toggle"><li><details open=""><summary>Redis 대기열 설계</summary><h1 id="76dd2f12-7b4a-4c62-9cde-95af9f806853" class=""><strong>[대기열이란?]</strong></h1><p id="245ee789-57e9-4d0d-b433-daa20c3e097c" class="">대기열은 서버에 대용량 트래픽이 몰릴 때를 대비해서 서버의 부하를 일정 수준으로 유지하기 위해 만듭니다.</p><figure id="3eac6a4d-c57d-48f1-b6f4-8c1443b7395c" class="image"><a href="https://blog.kakaocdn.net/dn/cKlk5v/btsIcD176dn/JW1uyfTpFC1WtU1cIwWcy1/img.png"><img style="width:642px" src="https://blog.kakaocdn.net/dn/cKlk5v/btsIcD176dn/JW1uyfTpFC1WtU1cIwWcy1/img.png"/></a></figure><p id="4891f311-d3d5-4722-bf55-8576001f9b2f" class="">1000명이 동시에 좌석 예약을 하기 위해 요청을 보냈을 때, 선착순 50명만 예약이 가능하도록 하고 나머지 사용자는 대기열에 들어가게 됩니다. 이렇게 되면 서버의 부하를 줄여서 트래픽을 제어할 수 있다는 장점이 있습니다. 대기열에 있는 사용자의 요청은 일정 시간이 지나면 예약이 가능한 상태로 변경되어 고객들은 콘서트 예매를 할 수 있습니다.</p><p id="034f93a5-efa6-4517-8fdd-054ae1add057" class="">이렇게 하여 단시간에 서버에 발생하는 부하를 줄여서 안정적으로 서버를 유지할 수 있습니다.</p><h1 id="6d7962ac-aff9-4949-b7f8-32bef9ebfead" class=""><strong>[대기열 구현 방법]</strong></h1><p id="73516425-de6a-44d7-8137-97f5d249566f" class="">제가 생각한 대기열 구현 방법은 2가지가 있습니다.</p><h1 id="cd9032aa-48b4-4c9a-87c1-0d7dc65c2fc0" class=""><strong>1. 은행 창구방식 + DB를 활용한 대기열 구현</strong></h1><p id="c428879e-499f-4610-b481-d63421317bbf" class="">은행창구방식이란?</p><p id="23b02317-b7b5-494b-9909-2e313f0dc40c" class="">은행 창구에서 은행원이 고객을 1명씩 응대하듯이, 고객 1명의 업무가 종료되면 다음 고객이 기회를 갖게 되는 방식입니다.</p><p id="129715d6-767a-4c3e-9d9d-2883ea9befad" class=""><strong>장점</strong></p><p id="18989da2-cb21-45d5-bb27-d7b9d8d55423" class="">딱 정해진 사용자수만 예약이 가능한 상태입니다. 그래서 서버의 부하를 일정 수준 이상을 넘지 않는다는 장점이 있습니다.</p><p id="30b5c1db-0ad0-4bcf-ad4d-46c2ded1c4d3" class=""><strong>단점</strong></p><p id="12a2acae-4ab4-41e8-ae29-7e66c0bbd97d" class="">대기열에 있는 사용자는 기약없이 기다려야 합니다. 예약이 완료될 때마다 대기열에 있는 사용자들이 1명씩 예약 가능한 상태로 변경이 됩니다. 그렇다보니 대기 중인 사용자는 <span style="border-bottom:0.05em solid">언제까지 대기해야 하는지 모릅니다</span>. 그래서 대기열에서 <strong>이탈하는 고객이 발생</strong>할 가능성이 높습니다.</p><figure id="d7c5eaef-b1ca-4940-bba9-638248e85086" class="image"><a href="https://blog.kakaocdn.net/dn/m9acF/btsIblg5gZc/Uxh7KIavzwSLDljUNzYWV0/img.png"><img style="width:700px" src="https://blog.kakaocdn.net/dn/m9acF/btsIblg5gZc/Uxh7KIavzwSLDljUNzYWV0/img.png"/></a></figure><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8f58d397-69e4-4bd4-970a-6385ae87caf2" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Transactional
  public TokenResponse insertQueue(TokenRequest request) {

    Token tokenEntity = null;

    // 0. 사용자 생성
    User user = userManagerImpl.createUser();

    // 1. 토큰 발행
    String token = tokenGenerator.generateToken(user.getUserId());

    // 2. 대기 순번조회
    long waitNo = tokenReader.selectNextWaitNo();
    //if(waitNo == 0) waitNo++;

    // 3. 대기 상태조회
    ProgressStatus status = tokenReader.getCurrentQueueStatus();

    // 4. Token 엔티티 생성(현재 상태에 따라서 토큰 만료시각을 다르게 설정)
    if(status == ProgressStatus.ONGOING) { // 토큰 만료시간은 10분 후
      tokenEntity = Token.builder()
          .user(user)
          .token(token)
          .waitNo(waitNo)
          .progressStatus(status)
          .createdAt(LocalDateTime.now())
          .expiredAt(LocalDateTime.now().plusMinutes(10)) //토큰이 10분간 유효함.
          .build();
    } else if(status == ProgressStatus.WAIT) { // 대기상태이기 때문에 토큰의 만료시간을 설정하지 않음.
      tokenEntity = Token.builder()
          .user(user)
          .token(token)
          .waitNo(waitNo)
          .progressStatus(status)
          .createdAt(LocalDateTime.now()) // 대기상태이기 때문에 토큰의 만료시간을 설정하지 않음.
          .build();
    }


    // 4. 발급한 토큰 테이블에 저장
    Token savedTokenEntity = tokenWriter.insertTokenTable(tokenEntity);
    user.setToken(token);

    return TokenResponse.from(savedTokenEntity);
  }</code></pre><p id="31774fce-a174-48d2-a02d-0d7eb4e24300" class="">위와 같이 DB를 활용해서 대기열을 구현했습니다. 사용자 생성 -&gt; 토큰 발급 -&gt; 대기순번 조회 -&gt; 토큰 상태 결정(대기 or 예약가능) -&gt; 토큰 테이블에 저장. 이 순서로 프로세스를 타고 대기열에 진입합니다.</p><p id="275eb06a-5ac6-4747-b34e-2c4dcf39b7d9" class="">DB를 활용한 대기열에서 중요한 점은 바로 &quot;일정 시간별로 사용자(토큰)의 상태를 변환&quot; 시켜주는 것입니다. 예약이 완료된 고객이 있다면 대기열에서 1명의 고객을 예약 가능한 상태로 변경해줘야 합니다. 그 역할을 Spring Scheduler를 사용하여 구현했습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="c602ace3-fe7b-47ea-8686-2743e6dcd7ad" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">package com.tdd.concert.domain.token.component;

import java.time.LocalDateTime;
import java.util.List;

import com.tdd.concert.domain.token.model.Token;
import com.tdd.concert.domain.token.repository.TokenCoreRepository;
import com.tdd.concert.domain.token.status.ProgressStatus;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

@Component
@Slf4j
@RequiredArgsConstructor
public class TokenScheduler {

    private final TokenCoreRepository tokenCoreRepository;

    @Scheduled(cron = &quot;0 * * * * *&quot;)
    @Transactional
    public void updateToken() {

        long ongoingCount = tokenCoreRepository.getProgressStatusCount(ProgressStatus.ONGOING);
        long waitCount = tokenCoreRepository.getProgressStatusCount(ProgressStatus.WAIT);

        if(ongoingCount &lt; 50) {
            int availableCount = (int) (50 - ongoingCount);

            for(int i = 0; i&lt;Math.min(availableCount, waitCount); i++) {
                long nextWaitNo = tokenCoreRepository.getNextPriorityWaitNo(ProgressStatus.WAIT); // 가장 우선인 다음 대기순번 고객

                Token token = tokenCoreRepository.findByWaitNo(nextWaitNo);

                if(token != null) {
                    // 토큰의 속성을 변경하고 저장하는 부분
                    token.setExpiredAtAndStatus(LocalDateTime.now().plusMinutes(10)
                                                , ProgressStatus.ONGOING);
                }

            }
        }
    }


    @Scheduled(cron = &quot;0 * * * * *&quot;)
    @Transactional
    public void dropToken() {
        List&lt;Token&gt; tokenList = tokenCoreRepository.findExpiredTokenList(ProgressStatus.ONGOING);

        for(Token token : tokenList) {
            if(token.getExpiredAt().isBefore(LocalDateTime.now())) {
                token.dropToken();
            }
        }
    }

}</code></pre><p id="4b69d09b-f734-424a-bb9a-381dd414e834" class="">각 토큰에는 ProcessStatus(예약진행상태)로 &quot;대기&quot;, &quot;예약진행중&quot;, &quot;예약완료&quot;가 있습니다. 스케쥴러는 현재 추가로 들여보낼 수 있는</p><p id="0ce58f2a-1ef5-4709-91d3-cce36ecd36d2" class="">사용자의 수를 계산하고 대기열에서 그 수만큼 사용자의 상태를 대기 --&gt; 예약진행중으로 변경합니다.</p><p id="ee906a9a-b0e3-4282-bf05-a3037067e1fe" class="">스케쥴러는 1분마다 돌게 설정을 하였습니다.</p><h1 id="1779b056-19b3-4986-a365-2cf35a8058b6" class=""><strong>스케쥴러로 일정주기별로 대기열을 관리하게 된 이유??</strong></h1><p id="8e004d3b-27b1-4dc7-a031-037fe080d3bb" class="">이 부분이 고민이 되는 지점이었습니다. 1분 주기로 스케쥴러가 돌기 때문에 이미 자리가 났음에도 불구하고 대기중인 사용자는 스케쥴러가 실행되는 <span style="border-bottom:0.05em solid">다음 주기까지 대기</span>해야 하기 때문입니다. 그럼에도 불구하고 스케쥴러로 구현한 이유는 아래와 같습니다.</p><p id="bf5087ed-b71a-49a2-9855-206a4cca2e3a" class="">1) 스케쥴러는 토큰의 상태값을 <span style="border-bottom:0.05em solid">&quot;대기&quot; --&gt; &quot;예약진행중&quot; 상태로 변경</span>하는 역할</p><p id="e6970c7c-78ed-4301-a25e-1049a40550ac" class="">2) 스케쥴러는 예약 중인 사용자 중에 <span style="border-bottom:0.05em solid">10분이 지난 토큰은 강제로 만료</span>시키는 역할도 한다.</p><p id="6514602e-2e5f-49b9-8f79-a02379ea8fcf" class="">이렇게 2가지 역할을 하다보니 <span style="border-bottom:0.05em solid">대량의 사용자들의 상태를 한번에 변경</span>하고, <span style="border-bottom:0.05em solid">구현 난이도가 상대적으로 쉬운</span> 스케쥴러를 채택했습니다.</p><h1 id="e95831ce-61a4-4cc9-9c0b-1e0f9e250fc0" class=""><strong>그럼 더 좋은 방법은 없을까?</strong></h1><p id="fd7d10d5-3235-4af1-a27b-247647653ffd" class="">이벤트 리스너 or 메시징 방식을 사용하여 토큰의 상태값을 변경하는 방법도 효과적이라고 생각합니다.</p><p id="adf0f8e1-4d61-4431-bcd0-8c057010b75b" class="">그 이유는 예약이 완료되었을 때 빈 자리가 생기면 그 즉시 이벤트 리스너가 토큰의 상태값을 &quot;대기&quot; --&gt; &quot;예약중&quot;으로 변경할 수 있기 때문입니다. 실시간으로 상태값이 변경 가능하여 사용자들은 대기시간이 감소합니다.</p><h1 id="f903142e-20ab-4e6b-80ff-757903496deb" class=""><strong>2. 놀이동산방식 + Redis Sorted set을 활용한 대기열 구현</strong></h1><p id="bf8da1eb-f06f-4cfd-890f-aa7c4f868f32" class="">놀이동산 방식이란?</p><p id="d9294106-c2e3-4939-9afe-664c06248ce6" class="">일정 주기마다 N명씩 놀이동산에 입장하는 방식처럼 일정 주기가 되면 대기열에 대기 중인 사용자들을 N명씩 들여보내는 방식</p><p id="22c14d59-2f2e-4ef6-badb-df783b8a0515" class=""><strong>장점</strong></p><p id="9fab9fbc-f629-419c-babe-cc60f34cbc3b" class="">사용자들이 일정 시간만 대기하면 된다.</p><p id="5515a1ac-a675-47ae-bc9e-58746e887924" class="">예를 들면 10초마다 250명씩 예약가능하도록 상태변경 한다면, 1200번째 사용자는 약 50초 후에 예약이 가능하다</p><p id="7a4060f2-9a19-4397-b1ff-12a17c29f0ea" class=""><strong>단점</strong></p><p id="0589fd35-a10a-4206-a31b-b3707b0d7c0d" class="">예약이 완료되어 나가는 사용자보다, 예약하기 위해 진입하는 사용자가 더 많은 경우 <span style="border-bottom:0.05em solid">서버에 부하</span>가 생기게 된다.</p><h1 id="cfcf60dc-ec9f-44ae-ad74-a8cec0c8fb0e" class=""><strong>Redis를 사용한 이유?</strong></h1><p id="f57e9860-362b-443c-8904-cac1f8336570" class=""><strong>1) DB의 부하를 줄여준다</strong></p><p id="e63c30fb-d494-42b1-a0d8-8854c666961a" class="">DB는 비용이 비싼 자원입니다. 그리고 상대적으로 속도도 느립니다. 반면에 Redis는 인메모리 방식의 저장소이기 때문에 속도가 매우 빨라서 대용량 트래픽을 감당하기 용이합니다</p><p id="72315b76-9f11-4631-a48d-9906a5f2ab88" class=""><strong>2) 대기열을 진입 순서대로 관리 가능</strong></p><p id="91ecd131-a8a4-4101-ae94-22ae53783745" class="">Redis의 Sorted Set을 사용하면 Score를 사용해서 사용자들이 진입한 시각으로 <span style="border-bottom:0.05em solid">우선순위를 결정</span>할 수 있습니다.</p><p id="caab078a-ae40-4b88-a375-e0239f5c10e8" class="">따라서 대기 중인 사용자를 예약가능한 상태로 변경하기도 용이합니다.</p><p id="c09b858b-4035-4423-afcc-141335215ffd" class=""><strong>3) 콘서트별로 각각 다른 대기열을 만들어낼 수 있다</strong></p><p id="dd6a8f64-8692-4199-a6a4-8d1bb8e08e62" class="">Sorted Set에서 대기열의 key를 &quot;waiting:concert:1&quot;, &quot;waiting:concert:2&quot; ....  이렇게 콘서트ID별로 생성하여</p><p id="e68cac19-632e-47bb-97ff-aad9641258ef" class="">대기열을 관리할 수 있습니다. 그러면<span style="border-bottom:0.05em solid"> 인기 많은 콘서트와 인기가 없는 콘서트 예매가 동시에 열려도 서로의 영향을 받지 않고</span></p><p id="efb84eb0-4607-4c90-a474-a7919dcb8d77" class="">대기열을 관리할 수가 있습니다.</p><p id="c5a04961-4a7c-4dda-8064-c8d80acc1e41" class=""><a href="https://github.com/wwwkang8/hhplus/blob/main/week3/src/main/java/com/tdd/concert/domain/token_redis/infra/RedisTokenCoreRepositoryImpl.java">https://github.com/wwwkang8/hhplus/blob/main/week3/src/main/java/com/tdd/concert/domain/token_redis/infra/RedisTokenCoreRepositoryImpl.java</a></p><p id="460f9868-0a6b-4296-a86f-b01596a73a0b" class=""><a href="https://github.com/wwwkang8/hhplus/blob/main/week3/src/main/java/com/tdd/concert/domain/token_redis/infra/RedisTokenCoreRepositoryImpl.java"><br/>hhplus/week3/src/main/java/com/tdd/concert/domain/token_redis/infra/RedisTokenCoreRepositoryImpl.java at main · wwwkang8/hhplus<br/>항해플러스 백엔드 주차별 과제 모음. Contribute to wwwkang8/hhplus development by creating an account on GitHub.<br/>github.com<br/></a></p><p id="b161fe0f-3979-4d4a-8188-fcbb850362f7" class="">위의 링크는 Redis 대기열, 예약가능열에 토큰을 insert 하는 로직이 있습니다.</p><p id="3ba388b6-5cf8-47f2-94e6-9b0ac6c05544" class="">Redis도 마찬가지로 토큰을 관리해주는 스케쥴러가 필요합니다.</p><ul id="902cb5aa-f4fb-4f53-b789-d9905891c2bf" class="bulleted-list"><li style="list-style-type:disc">토큰 상태변경 : 10초마다 750명을 대기열--&gt;활성화열(예약가능한열)로 이동시켜줍니다.&lt;-- 스케쥴러가 필요</li></ul><ul id="042efa85-4b4b-4280-8519-483b486e4a32" class="bulleted-list"><li style="list-style-type:disc">토큰 만료 : Redis의 sorted Set에 추가할 때 ttl을 설정(expire 되는 시각)하여 시간이 지나면 자동으로 삭제됨.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="78186c46-6aaf-4d44-8c1d-411267bdfbe6" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Component
@RequiredArgsConstructor
@Slf4j
public class RedisTokenScheduler {

  private final RedisTokenCoreRepositoryImpl redisTokenCoreRepositoryImpl;
  private final ConcertCoreRepositoryImpl concertCoreRepository;
  private final RedisTemplate&lt;String, String&gt; redisTemplate;
  private ZSetOperations&lt;String ,String&gt; zSetOperations;

  private final long POP_CNT = 750;

  @PostConstruct
  public void init() {
    this.zSetOperations = redisTemplate.opsForZSet();
  }

  /** 여유 자리가 생기면 WaitingQueue에서 끄집어 내서 WorkingQueue에 넣어주는 것 */
  @Scheduled(cron = &quot;*/10 * * * * *&quot;)
  @Transactional
  public void updateWaitingQueue() {

    List&lt;Long&gt; concertIdList = concertCoreRepository.concertList();

    for(Long concertId : concertIdList) {

     List&lt;String&gt; tokenList = redisTokenCoreRepositoryImpl.popTokensFromWaitingQueue(concertId, POP_CNT);
     redisTokenCoreRepositoryImpl.addTokenListWorkingQueue(concertId, tokenList);

     for(String token_n : tokenList) {
       redisTokenCoreRepositoryImpl.addWorkingQueue(concertId, token_n);
       log.info(&quot;[RedisTokenScheduler] 콘서트ID : &quot;+concertId + &quot;, 토큰 : &quot; + token_n + &quot; WorkingQueue 진입 완료&quot;);
     }
    }
  }


}</code></pre><h1 id="37add7ce-c367-463b-8f40-8bd7a591ef36" class=""><strong>10초마다 750명을 대기열-&gt;활성화열로 이동시켜주는 근거?</strong></h1><ul id="408a1651-d958-4ca0-a162-8664fc9afb0c" class="bulleted-list"><li style="list-style-type:disc">1명의 유저가 예약조회부터 결제까지 걸리는 시간 : 평균 1분</li></ul><ul id="ccc6d2e0-a81b-45e2-bcfc-37c869802892" class="bulleted-list"><li style="list-style-type:disc">DB에 동시에 접근할 수 있는 트래픽의 최대치 : 1초에 약 1,000TPS ⇒ 1분에 60,000TPS</li></ul><ul id="94d4ea9a-f772-49cb-badb-310b1d932aa9" class="bulleted-list"><li style="list-style-type:disc">1분간 유저가 호출하는 API 횟수 :</li></ul><p id="fe509561-cebc-4ebb-9b33-f7fb675de116" class="">4(예약가능날짜조회, 좌석조회, 좌석예약, 결제처리) * 2(동시성 이슈에 의해 예약실패하여 API 재처리) = 8</p><ul id="5361ccac-f70c-4646-bbc7-1250cf62520b" class="bulleted-list"><li style="list-style-type:disc">1분당 처리할 수 있는 동시접속자 수 = 7,500명</li></ul><p id="4439df33-1bc8-4ba9-a82d-0850a4942749" class="">⇒ 최종 결론 : 10초마다 750명을 예약가능한 상태로 전환.</p><h1 id="142946f6-87ff-4b07-b490-81794d79c607" class=""><strong>놀이동산방식 + Redis 대기열로 구현했을 때의 한계점?</strong></h1><p id="bdaebf68-b580-41e7-b6de-8a0624b76377" class=""><span style="border-bottom:0.05em solid">예약가능한 사용자가 계속해서 증가하게 될 때 서버의 부하가 커질 것이다.</span></p><p id="1f7b10e1-00c5-492a-9647-8db91bfe896e" class="">이런 경우에 어떻게 문제를 해결할 것인가?</p><p id="5fe8fca3-8bbb-437f-9d93-41efb0744b6c" class="">이 부분은 추가로 고민을 해서 개선해봐야겠습니다</p></details></li></ul><ul id="b70f4ba7-282f-4449-9c28-18cb87f900fc" class="toggle"><li><details open=""><summary>Toss - 서버 증설 없이 처리하는 대규모 트래픽</summary><p id="ee04ca17-ec80-4cf8-a12e-69531ae20137" class="">안녕하세요. 저는 토스의 광고 제품과 플랫폼을 개발하는 서버 개발자 함종현입니다. 저는 토스에서 라이브 쇼핑 보기 서비스를 담당하고 있어요.</p><h1 id="944d3bcd-d8e2-4468-ae79-ca8887e61b23" class=""><strong>라이브 쇼핑 보기 서비스란</strong></h1><p id="ec6cc53c-4d7c-4487-beb6-7c985d58813f" class="">라이브 쇼핑 보기는 토스의 “혜택” 탭에 있는 서비스예요. 라이브 쇼핑 보기를 통해서 유저는 상품을 구매하면 포인트를 적립 받을 수 있고, 광고주는 빠르게 상품 물량을 소진시킬 수 있어요.</p><p id="0364c9ed-4616-4aa2-b5f6-9a2a62bac3b9" class="">라이브 쇼핑 보기 서비스를 론칭하는 날, 예상했던 것보다 굉장히 많은 유저가 들어왔어요. 그 후에도 매일 신규 유저가 늘었고, 서비스의 성장이 눈에 띄게 보였죠. 그러면서 자연스럽게 라이브 방송하는 광고주도 많아졌습니다.</p><figure id="ff493d1d-9dfe-45ad-b150-3c29c0701040" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/f8ec76cc-e204-40ac-ad6d-043510de4ace/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/f8ec76cc-e204-40ac-ad6d-043510de4ace/Untitled.png"/></a></figure><h1 id="060e9ca2-f5fa-4e7a-8e7e-2dc7c2262f62" class=""><strong>급격하게 성장하는 서비스가 겪는 문제</strong></h1><p id="ab32f87c-d177-4d66-b891-4df745b22249" class="">이렇게 라이브 쇼핑 보기 서비스는 피크 시간대 동시 접속자 수는 분당 수십만 명, 포인트 지급 요청 API 요청은 초당 수십만 건이 오는 서비스로 성장했는데요. 급격히 늘어난 트래픽은 성장하는 서비스 서버에 치명적일 수 있어요. 서버가 트래픽을 유연하게 처리하지 못하면 유저에게 안 좋은 경험을 제공하고, 최악의 상황에서는 이탈할 수도 있기 때문이에요.</p><p id="fd43f8aa-7371-48ca-9fd7-4132bd978f30" class="">트래픽이 급격히 늘어나면 쓰레드가 밀리는 것부터 시작해서 데이터베이스와 캐시 시스템, 다른 서버와 같이 사용하는 서버 애플리케이션, 게이트웨이 등에서 장애가 발생할 수 있는데요. Redis와 같은 캐시 서비스의 메모리 사용량이나 CPU 사용량이 늘어나면 캐시가 누락되어 데이터베이스에 큰 부하를 줄 수 있어요. 데이터베이스 장애는 데이터를 오염하거나 다른 서비스의 영향을 줄 수 있고요.</p><p id="5a5784e4-1b6a-412f-be7d-8e2fdead6735" class="">간단히 서버 증설로 증가한 트래픽을 모두 처리할 수 있다면 가장 좋겠지만 고민해야 하는 점이 몇 가지 더 있습니다. 증설 비용 규모, 그리고 특정 시점에만 트래픽이 몰리면 그 외 시간에는 자원이 낭비될 수 있다는 점이 크고요. 서버 증설 만으로 해결할 수 없는 다른 문제가 생길 수도 있어요.</p><p id="6a4ccea6-96a4-4a07-b616-84de6db2a697" class="">늘어나는 트래픽을 잘 처리하기 위해 서버 개발자는 어떤 고민을 해야 할까요?</p><figure id="d3e2daf2-840a-4b90-92d8-ce14b6bc3b07" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/bdaab275-5be7-4dfd-a736-f584023347b9/contents-inner-1_(2).jpg"><img src="https://static.toss.im/ipd-tcs/toss_core/live/bdaab275-5be7-4dfd-a736-f584023347b9/contents-inner-1_(2).jpg"/></a></figure><p id="e651bc97-4837-4124-8318-44910cd65bc9" class="">pod 100대가 요청을 처리하고 있는 그래프</p><h1 id="120c198f-1843-473b-9ec6-5c7701a16001" class=""><strong>라이브 쇼핑 서버가 만났던 문제</strong></h1><p id="c3df4fb1-ddc4-41ed-8fd5-18e5603cdf4b" class="">먼저 라이브 쇼핑 서버가 겪었던 몇 가지 문제를 소개하고 해결책을 살펴볼게요.</p><h1 id="64606a5f-8ed2-43c6-825a-0fa0d440f99b" class=""><strong>1. Redis 과부하 문제</strong></h1><p id="8287d8c1-f8a6-482f-8977-d1bd88de13cc" class="">매일 정각에 수십만 명의 유저에게 방송 리스트, 포인트 적립 내역 등을 Redis에 저장하고 읽었는데요. 유저가 늘면서 커맨드와 캐싱하는 데이터 양이 급격히 늘어났어요. CPU가 커맨드를 너무 느리게 처리하거나 데이터가 너무 많으면 Redis에 과부하가 생길 수 있는데요. Redis의 과부하는 데이터베이스의 부하로 이어질 수 있기 때문에 심각한 문제입니다.</p><p id="5c68171c-b21f-4e9d-b13e-6e0b71edddf7" class="">Redis 과부하를 방지하려면 Redis가 캐싱하는 데이터와 읽고 쓰는 시점을 체크해야 하는데요. 먼저 Redis가 캐싱하는 데이터를 두 가지로 분류할 수 있어요. 모든 유저에게 동일하게 보이는 Universal Data와 유저 별로 다르게 사용되는 User-Specific Data입니다. 토스 라이브 쇼핑 서비스에서 전자는 모든 유저가 볼 수 있는 방송 리스트, 방송 상세 정보 등을 캐싱하고 후자는 방송 시청 여부 등을 캐싱합니다.</p><p id="2e2b949c-67bc-4af4-a434-341bf4736fe5" class=""><strong>Universal Data 문제 &amp; 해결책</strong></p><p id="f9dd390c-d934-46ba-aa92-6b6045565fda" class="">Universal Data는 트래픽이 늘어날수록 한 개의 키에서 GET 커맨드가 굉장히 많이 발생하는데요. Redis에 많은 읽기 요청을 보내면 Redis의 CPU가 부하를 겪어요. 이로 인해 Redis의 커맨드 요청이 증가하고 Network IO도 증가합니다. 커맨드가 밀려 Redis에서 지연이 발생할 수 있고, 이는 Redis를 사용하는 모든 곳에서 지연이 발생합니다.</p><p id="4f54541f-344d-43f2-b057-6215d0fefdf5" class="">이러한 문제는<span style="border-bottom:0.05em solid"> 웹 서버에서 Local Cache를 사용해서 Universal Data를 서버 내에서 전부 캐싱하는 방법으로 Redis의 사용량을 줄일 수 있습니다</span>. 또한 Universal Data의 빠른 캐시 초기화가 중요하다면, Redis의 Pub/Sub 기능을 사용해 Local Cache 초기화에 대한 비동기 메시지를 받아 로컬 캐시를 초기화할 수 있어요.</p><p id="c2b8cacc-f156-44f3-8114-84cdf0280ff2" class=""><strong>User-Specific Data 문제 &amp; 해결책</strong></p><p id="1178e547-e146-4d1b-97d4-500fd806cc5a" class="">User-Specific Data는 유저가 늘어날수록 캐싱해야 하는 데이터가 많아지고, 데이터의 크기가 커질수록 Redis 메모리 사용량이 늘어난다는 문제가 생길 수 있습니다. 유저가 늘어나면 메모리 사용량이 늘어나는 건 당연하지만, 데이터 하나의 크기가 작아진다면 메모리 사용량도 효과적으로 줄어듭니다.</p><p id="612a3879-d71f-472a-9a4e-ff53debeaffb" class="">즉, <span style="border-bottom:0.05em solid">Redis에 DTO와 같은 데이터를 저장할 때 다양한 압축 방법을 활용해서 데이터 크기를 최소화</span>해야 합니다. 단, 너무 작은 크기의 데이터를 압축하면 오히려 데이터가 커질 수 있으니 주의해야 해요.</p><p id="5ee9d8c0-0694-40e4-af08-2d2c115b69c9" class=""><span style="border-bottom:0.05em solid">Redis 과부하로 데이터 처리를 못하게 된다면 Fallback 로직도 고려</span>해야 합니다. 만약 거대한 트래픽이 그대로 데이터베이스에 가게 된다면, 데이터베이스 서버에서 큰 장애가 발생할 수 있기 때문이죠.</p><figure id="7a290fa1-57b7-45ed-94f2-24c259a9ef73" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/56997015-c822-4ec4-82e6-ad241aafc5e1/contents-inner-2.jpg"><img src="https://static.toss.im/ipd-tcs/toss_core/live/56997015-c822-4ec4-82e6-ad241aafc5e1/contents-inner-2.jpg"/></a></figure><figure id="9bfd3673-a4e1-4a06-9d9c-d0352649a3ee" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/e8b56232-8da8-4f00-b36f-d28e067a9184/contents-inner-3.jpg"><img src="https://static.toss.im/ipd-tcs/toss_core/live/e8b56232-8da8-4f00-b36f-d28e067a9184/contents-inner-3.jpg"/></a></figure><p id="888a1674-6148-4f39-baf4-30e977647354" class="">트래픽이 1주일 사이에 많이 늘었지만, Redis 커맨드가 밀리지 않음</p><h1 id="c927cde3-f0ee-490c-a41c-f8e916f9727c" class=""><strong>2. 선착순 포인트 지급과 데이터베이스 과부하 문제</strong></h1><p id="0bfe21be-53f1-4b10-aa8f-eba084f710f4" class="">서비스는 계속 성장하면서 유저 인입도 늘고 광고주들도 더 많은 라이브 쇼핑 광고를 집행했어요. 방송이 많아질수록 더 많은 포인트를 받을 수 있어서 방송이 많은 시간에는 유저가 더 많이 들어오고, 포인트 지급 요청도 더욱 많아졌습니다.</p><p id="ed0cbd0b-67d8-49b8-9e41-7743b55fdabd" class="">포인트 지급 요청 기능을 개발할 때는 아래 네 가지 요소를 반드시 고려해야 했습니다.</p><ul id="5ba12afd-ce36-48ed-9b82-98cb607b8d44" class="bulleted-list"><li style="list-style-type:disc">한 유저에게 포인트가 중복 지급돼서는 안됩니다.</li></ul><ul id="532ce460-c83a-4d22-aa65-bd9ec1d3d3fd" class="bulleted-list"><li style="list-style-type:disc">유저가 포인트가 지급되었다는 걸 즉시 인지할 수 있어야 합니다.</li></ul><ul id="96087f47-9e51-4c1f-85ea-6a1652ef897e" class="bulleted-list"><li style="list-style-type:disc">포인트가 지급되었다는 걸 토스의 포인트 지급 내역 원장에 기록할 수 있어야 합니다.</li></ul><ul id="23a8cb23-07e3-4699-ae24-3cfcb90c8e98" class="bulleted-list"><li style="list-style-type:disc">선착순에 들지 못하면 포인트 지급을 하면 안 됩니다.</li></ul><p id="517a256b-843d-4ed7-9f4e-52735668705d" class="">첫 번째 문제인 포인트 중복 지급은 간단하게 생각하면 아래와 같은 로직을 적용하여 해결할 수 있습니다.</p><ol type="1" id="6dda57f1-679e-4bf9-b5a5-f41943cfcc77" class="numbered-list" start="1"><li>포인트 지급 API 요청이 오면 유저에게 포인트가 지급된 후 특정 저장소에 지급되었다는 내역을 생성합니다.</li></ol><ol type="1" id="42945e6c-57df-430d-bbe2-a25dff68c7d0" class="numbered-list" start="2"><li>포인트 지급 API 요청이 오면 특정 저장소에 지급되었다는 내역이 있는지 확인하고, 이미 지급된 경우 지급되지 않도록 분기를 구현합니다.</li></ol><p id="8d2b0d9f-0c7b-4f17-9d46-a3bc3d7f6fe2" class="">간단해보이는 로직이지만 고려할 부분이 꽤 많습니다.</p><p id="c41b9047-ba3b-4ad5-8258-c3c472360d0a" class="">먼저 API 요청이 연속으로 2개가 들어오는 현상을 막기 위해 RedLock을 통해 API 요청에 대한 Distributed Lock을 걸어 주어야 합니다. 그 이유는 API 요청이 연속으로 2개가 오게 되면, 포인트가 지급되었다는 내역을 저장소에 넣기 전에 각 서버에서 2개의 포인트 지급 요청이 처리되기 때문이에요.</p><p id="f866b845-c774-4bf1-82dc-adbb43a7091e" class="">다음으로 두 번째 문제의 해결 방법인데요. 포인트가 지급 되었다는 걸 즉시 인지하고, 중복 지급 여부에 대해 체크할 수 있도록 Redis와 같은 캐시 시스템에 포인트 적립 내역을 하나의 키에 Append하고, 데이터베이스에 적립 내역을 저장해야 합니다. 데이터베이스에 적립 내역을 바로 넣지 못하는 이유는, 순간적으로 트래픽이 올라갈 때 데이터베이스에서 버틸 수 있는 Insert QPS가 넘어 데이터베이스 과부하로 이어질 수 있어요.</p><p id="0c204936-336d-48af-b947-d5bbcfd96631" class="">따라서 데이터베이스에 Insert할 때에는 Kafka를 통해 비동기로 Insert하고, Consumer에서 Throttling을 걸어 최대 QPS에 도달하지 않도록 조절해야 합니다. 지급 내역을 Insert할 때 포인트 지급 내역이 원장에 쌓이기에 이 부분도 해결돼요.</p><figure id="c2a0aff5-48d6-4164-a454-4516efe9f816" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/d999ec2e-4282-4175-80e1-59030ebb156d/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/d999ec2e-4282-4175-80e1-59030ebb156d/Untitled.png"/></a></figure><figure id="ad3debe8-9c36-4a28-ab38-fbb4a4d5c97a" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/d4e7d501-871a-44db-a046-1bd6640e5df1/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2024-05-10_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_6.09.08.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/d4e7d501-871a-44db-a046-1bd6640e5df1/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2024-05-10_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_6.09.08.png"/></a></figure><p id="d45ef066-cd3b-421b-a948-61e5662724ac" class="">Insert QPS(노란색)가 Throttling을 적용하고 줄어든 모습</p><p id="814736b1-0f79-4bd8-a7a1-ef149d75b5cf" class="">마지막으로 선착순 포인트 지급 문제는 Redis에서 지원하는 Increment 커맨드를 통해 리워드 지급 인원을 더하여 지정된 Cap에 도달하였는지 체크하는 방법으로 해결할 수 있습니다. 도달하지 못하였다면 리워드를 지급하고 Increment를 하는 반면, 도달한 경우 리워드를 지급하지 않도록 구현해야 합니다.</p><figure id="530fe033-41ce-460c-a005-5edf0b08e190" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/baf3aa16-d6cc-4a68-b9e3-588b3bc031da/contents-inner-8.jpg"><img src="https://static.toss.im/ipd-tcs/toss_core/live/baf3aa16-d6cc-4a68-b9e3-588b3bc031da/contents-inner-8.jpg"/></a></figure><p id="01150d45-db2f-4b05-9c83-d22bc80e56a8" class="">Redis는 Single-Thread로 동작하기에 Increment의 경우 Thread-Safe한 동작인데요. 단시간에 너무 많은 Increment 커맨드를 요청하면 Redis의 Thread가 밀려 CPU가 상승해요. 이 부분의 경우 Local Cache에서 Counting한 후 특정 시점에 ScheduleJob으로 Redis에 Flush하는 방법으로 성능 이슈를 개선할 수 있어요. 하지만 이 방법은 Hard하게 Capping하는 방식은 아니어서 서비스에서 추구하는 선착순의 개념과 일치한지 확인해야 합니다.</p><figure id="16969336-d1a8-4c76-8686-6c30098c3625" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/01c4f7d3-efd8-4d59-977f-0fca2f064d9c/contents-inner-7.jpg"><img src="https://static.toss.im/ipd-tcs/toss_core/live/01c4f7d3-efd8-4d59-977f-0fca2f064d9c/contents-inner-7.jpg"/></a></figure><h1 id="8aaf61b7-18d7-4667-b894-66c5f4df03c0" class=""><strong>3. API 중복 요청 및 Gateway 과부하 문제</strong></h1><figure id="ea7423a6-07a3-4c11-9815-600fd266174b" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/78664fd7-0b9f-4574-986d-05b517909657/image_(13).png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/78664fd7-0b9f-4574-986d-05b517909657/image_(13).png"/></a></figure><p id="91e14d2b-2551-46cb-b902-783b2a775a5e" class="">피크 타임에 라이브 쇼핑 보기 서비스에 트래픽이 너무 많이 올라와서 트래픽을 최소화할 수 있는 방법을 찾던 도중, <strong>중복 요청을 제거하는 것과 API 요청을 1개로 합치는 방법을 적용해 봤어요</strong>.</p><p id="2f924402-0981-4764-b0d8-581ee12f6b7d" class="">API 중복 요청은 서비스가 성장할수록 큰 독이 됩니다. 피크 트래픽이 커지면 커질수록 중복 요청에서 발생하는 부하는 더더욱 커지게 돼요. 유저 1명에게서 중복 요청이 N개 만큼 오게 되면, 서비스가 성장할수록 의미 없는 중복 요청의 수가 매우 늘어나게 되는데요. 중복 요청은 결국 게이트웨이, 웹서버, Redis, 데이터베이스를 포함해서 한 개의 API 요청을 처리하는 모든 컴포넌트에 부하가 생깁니다.</p><p id="93689837-3a05-4a4f-bc5a-8284e6bd5f1a" class="">특히 중복 요청은 토스 서버로 오는 모든 요청 값과 응답 값을 암호화하는 Gateway에 부하를 발생시키고, 이는 전체 토스 서비스에 영향을 미칠 수 있어요. API 중복 요청은 분석하기가 까다롭고, 해결하기 위해서는 클라이언트 개발자와 지속적으로 소통하면서 서비스와 유저 경험에 영향이 없도록 해야 합니다.</p><p id="0bf62839-c709-4c89-aae0-4315dfbda08e" class="">먼저 중복 요청을 분석하기 위해 라이브 쇼핑 보기 트래픽 중에 API 요청이 가장 많은 유저 ID 기준으로 API 요청 기록을 확인했어요. 그리고 단 시간에 중복으로 요청되는 API가 어떤 상황에서 재현되는지 체크했습니다. <strong>재현된 중복 요청은 클라이언트 개발자와 커뮤니케이션하여 제거하고, 중복 요청을 제거한 후에 서비스에 문제가 없는지, 실제로 API 요청이 눈에 띄게 줄었는지 모니터링했어요.</strong></p><figure id="04a5584b-c4ba-413a-9fa2-2b2c73d788a9" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/a4d6a5d9-d072-4abd-b3c3-9a9241fb2440/contents-inner-5_(1).jpg"><img src="https://static.toss.im/ipd-tcs/toss_core/live/a4d6a5d9-d072-4abd-b3c3-9a9241fb2440/contents-inner-5_(1).jpg"/></a></figure><p id="5ff8f690-540a-422d-b8c4-f7b09c802792" class="">중복 요청을 제거한 후 깔끔해진 로그</p><p id="aab21753-520a-4740-affd-996425284e68" class="">그리고 API를 합쳐서 응답을 보낼 수 있는 상황이라면, 적극적으로 합쳐야 합니다.</p><p id="6a88c198-f05f-43ee-b18c-deb61e65efe1" class="">라이브 쇼핑 보기 서비스에 접속하면 방송 리스트 API, 포인트 지급 예정 API, 공지사항 API 총 3개의 API를 동시에 요청하도록 구현되어 있었는데요. 3개의 API를 동시에 요청하면 피크 트래픽의 규모가 더 커지고, API 요청/응답에서 발생하는 오버헤드가 더 커져요. 또한 Gateway 부하도 늘어납니다.</p><p id="cd15888c-6a00-495c-a64e-32d73f74f42e" class=""><strong>해당 API는 한 개의 API 로 묶을 수 있을 수 있어, </strong><code><strong>/view</strong></code><strong>라는 API로 묶었고, 결과적으로 피크 트래픽의 규모를 50%나 줄일 수 있었어요.</strong></p><p id="d94a1421-0d7e-40f6-a1a3-f34cc3d500f4" class="">하지만 묶기 어려운 API도 있죠. 응답 시간이 긴 API 의 경우 1개의 API로 합치게 되면 API 응답이 길어지게 되어 문제가 발생할 수 있습니다. 상황에 따라 합칠 수 있는 API는 합치고, 분리해야 하는 API는 분리해서 사용해야 합니다.</p><figure id="43e87232-419a-402f-97bf-5bae47bee1bd" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/38bd2ab0-f88f-4927-8dee-ee4557a196a7/contents-inner-6_(2).jpg"><img src="https://static.toss.im/ipd-tcs/toss_core/live/38bd2ab0-f88f-4927-8dee-ee4557a196a7/contents-inner-6_(2).jpg"/></a></figure><p id="86aaeb9d-c12e-4169-bea9-729666024d94" class="">중복 요청을 제거하고, API를 합친 후 Gateway 로 오는 요청량이 감소한 모습</p><h1 id="02032e4a-ebd5-42b8-9341-b1d3fb3baa08" class=""><strong>성능 개선의 이터레이션</strong></h1><p id="9ab794c1-0e6b-4f46-a16f-e15e5c45bce0" class="">빠르게 성장하는 서비스라면 앞서 이야기 한 문제 외에도 많은 문제가 생길 수 있는데요. 성능 개선의 이터레이션을 지속적으로 반복하면 문제를 초기에 발견하고 해결해서 서비스 운영에 장애를 막을 수 있습니다.</p><ul id="a42e06e1-23df-4598-b69d-a86f34450061" class="bulleted-list"><li style="list-style-type:disc">서버 모니터링</li></ul><ul id="5892a9d0-afac-497f-82fc-944f53181777" class="bulleted-list"><li style="list-style-type:disc">문제점 파악</li></ul><ul id="2c3841f0-c208-4955-9385-9056df901640" class="bulleted-list"><li style="list-style-type:disc">해결책 제안 및 적용</li></ul><ul id="e68e7c8b-700b-4c58-905b-8e5891f879d1" class="bulleted-list"><li style="list-style-type:disc">카나리 배포 후 서버 모니터링</li></ul><p id="5ee9ab8d-2357-4bba-a1d4-1e98b4110ebe" class="">위 네 가지를 이터레이션한다면, 서버를 증설하기 전에 다시 한번 증설 여부에 대해 고민할 수 있고, 서버를 증설한 후에 개선이 된다면 많은 리소스가 절약될 수 있어요.</p><p id="75c7077f-a624-4260-8e25-7d31d1bf48a7" class="">그 외에도 프로파일러를 통해 성능 모니터링을 지속적으로 하고, 메모리나 연산이 많은 부분을 최적화하면서 서버 리소스를 최적화할 수 있어야 돼요. 또한 중복으로 실행되는 로직이 있는지도 지속적으로 체크하여 불필요한 로직을 모두 없애야 합니다. 그리고 최적화한 버전을 Canary로 배포하면서 장애가 발생하는지, 이전 버전과 비교하여 성능 개선이 유의미한지 모니터링을 해야 합니다.</p><h1 id="965c3622-742b-41cf-a81b-b52ab4bf389b" class=""><strong>맺음말: 모니터링 구축을 기본으로</strong></h1><p id="162fbef9-bd05-4390-bd41-7edfc1eb6262" class="">성능 개선의 이터레이션을 진행할 때에도 시작과 끝은 모니터링입니다. <strong>제품이 성장할 때 서버 개발자는 모니터링 환경을 먼저 구축해야 합니다</strong>. 서버를 포함해서 서버에 연결된 각 컴포넌트(Redis, DB, Kafka 등)와 서비스 지표(PV, UV, 리텐션 등)를 실시간으로 모니터링할 수 있고, 문제가 발생할 수 있는 특정 수준까지 온 경우 Alert 을 줄 수 있도록 말이죠.</p><p id="fc2a3627-85e1-4f15-a8b3-6a5946ef591f" class="">서비스를 사용하는 유저가 장애로 인해 서비스를 사용하지 못하거나 유저 경험이 좋지 않다면, 유저 리텐션이나 신규 유입 지표에서 안 좋은 영향을 미치고, 서비스의 성장을 막을 수 있어요. 또, 서비스가 성장하면서 발생하는 장애를 모니터 할 때 Metric은 원인과 결과를 예상하고 해결책을 제시할 수 있는 매우 중요한 지표입니다.</p><p id="df593535-0b00-49d7-97cc-3989fdf6b140" class="">성능 개선의 이터레이션을 반복하여 급격하게 성장하는 서비스에서도 장애와 성능 이슈를 유연하게 대처할 수 있길 바랍니다.</p><figure id="0344a55d-b181-4dc4-9295-ed815613fc95"><a href="https://toss.tech/article/monitoring-traffic" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">서버 증설 없이 처리하는 대규모 트래픽</div><div class="bookmark-description">늘어나는 트래픽을 잘 처리하기 위해 서버 개발자는 어떤 고민을 해야 할까요? “라이브 쇼핑 보기” 서비스에 대규모 트래픽이 들어오면서 겪은 문제와 해결책을 공유드려요.</div></div><div class="bookmark-href"><img src="https://static.toss.im/tds/favicon/favicon-196x196.png" class="icon bookmark-icon"/>https://toss.tech/article/monitoring-traffic</div></div><img src="https://static.toss.im/assets/payments/contents/liveshopping-thumb.jpg" class="bookmark-image"/></a></figure></details></li></ul><ul id="1c97356d-d636-4952-bfaa-3d54650798d2" class="toggle"><li><details open=""><summary>Redis 과부하 문제 해결 방안 </summary><p id="ac1a999f-ed59-47ea-840d-85e7f305d77b" class="">Redis의 과부하는 심각한 문제이며, 이를 해결하기 위한 다양한 최적화 방법이 있습니다. 여기서는 Redis의 성능을 향상시키고 부하를 줄이기 위한 구체적인 해결책을 살펴보겠습니다.</p><h2 id="1351f623-3313-4aa6-873b-dc0eb6068757" class="">1. <strong>데이터 구조 최적화</strong></h2><h3 id="9030b588-e95e-40d6-9042-5e3b46194904" class="">a. <strong>효율적인 데이터 구조 사용</strong></h3><ul id="88f01f01-ea89-4054-aa9c-961b18bf5140" class="bulleted-list"><li style="list-style-type:disc"><strong>적합한 데이터 구조 선택</strong>: Redis에서 데이터 저장 시, 사용 목적에 맞는 효율적인 데이터 구조를 선택하는 것이 중요합니다. 예를 들어, 리스트(List)와 해시(Hash)의 사용 시점, 데이터 구조의 크기 등을 고려해야 합니다.<ul id="8907d71d-bd23-4521-bdd0-5c5d64f7dc54" class="bulleted-list"><li style="list-style-type:circle"><strong>작은 값의 경우</strong>: 단일 값 또는 작은 데이터는 <code>String</code> 타입을 사용합니다.</li></ul><ul id="753046be-3c6c-4bd8-8a30-8a003c1d156c" class="bulleted-list"><li style="list-style-type:circle"><strong>복잡한 구조</strong>: 여러 필드를 가지는 경우, <code>Hash</code>를 사용하여 필드를 효율적으로 관리합니다.</li></ul></li></ul><h3 id="26e1010c-1654-4ad5-b31e-a3e44aaf27c3" class="">b. <strong>데이터 압축 및 최적화</strong></h3><ul id="309cd790-adbb-4f0b-84a5-e007e28d47a6" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 압축 사용</strong>: Redis에서 <code>zlib</code>, <code>lz4</code>와 같은 데이터 압축 라이브러리를 사용하여 데이터를 압축하면 저장 공간을 절약할 수 있습니다. 다만, 압축과 해제를 위한 CPU 부하를 고려해야 합니다.</li></ul><ul id="c5843574-07ac-476d-8155-e6dcafb074b6" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 정규화</strong>: 중복 데이터 저장을 피하고, 필요한 정보만 저장하여 데이터 크기를 최소화합니다.</li></ul><h2 id="c2dd021f-1ebb-4802-a7bf-aa316e0c7d6e" class="">2. <strong>캐시 관리 및 TTL 설정</strong></h2><h3 id="a26ee650-0207-4233-ae20-06bbac738306" class="">a. <strong>TTL(Time-to-Live) 설정</strong></h3><ul id="cbdd4ec5-4edd-4edd-b886-2cf51477ceab" class="bulleted-list"><li style="list-style-type:disc"><strong>적절한 TTL 설정</strong>: 모든 캐시 항목에 만료 시간을 설정하여 불필요한 데이터가 오래 유지되는 것을 방지하고 메모리 사용을 최적화합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="51191082-adad-43ee-bbf6-e4a7e1ede5c3" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">SET user:123:points 100 EX 3600  # 1시간 동안 유효</code></pre></li></ul><h3 id="9bfc9928-f8cc-46e7-aeea-b92d3d4537d1" class="">b. <strong>LRU(Least Recently Used) 정책 사용</strong></h3><ul id="51c1a2f7-d6bc-4567-8603-7d2e9939acb2" class="bulleted-list"><li style="list-style-type:disc"><strong>메모리 관리 정책 설정</strong>: Redis의 <code>maxmemory-policy</code> 설정을 사용하여 오래된 데이터가 자동으로 제거되도록 합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1bdbc04f-d2e1-4e50-9396-fffe6b307ea0" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">CONFIG SET maxmemory-policy allkeys-lru</code></pre></li></ul><h3 id="f42b2916-d234-4f57-bb10-d5ab839a6a52" class="">c. <strong>핫 데이터와 콜드 데이터 분리</strong></h3><ul id="8bd9b961-5a7a-4288-aff5-5cd0f2e456c1" class="bulleted-list"><li style="list-style-type:disc"><strong>핫 데이터 우선 캐싱</strong>: 자주 액세스되는 데이터(핫 데이터)와 그렇지 않은 데이터(콜드 데이터)를 구분하여, 핫 데이터를 우선적으로 캐싱하고, 콜드 데이터는 필요 시에만 로드합니다.</li></ul><h2 id="90e4c0b6-29ae-40f8-a02b-ac37779f8a21" class="">3. <strong>Redis 클러스터링 및 샤딩</strong></h2><h3 id="fb163186-c534-49b3-98ee-721567986f83" class="">a. <strong>Redis 클러스터 사용</strong></h3><ul id="8bd8fb1a-bdbe-4c67-b4f0-5ed785daed97" class="bulleted-list"><li style="list-style-type:disc"><strong>분산 처리</strong>: Redis 클러스터링을 사용하여 데이터와 요청을 여러 Redis 노드로 분산 처리하여 부하를 줄입니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="9b3e1ff3-3300-4222-bb73-ef00e2b03f94" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 --cluster-replicas 1</code></pre></li></ul><h3 id="bd8bc613-6b88-404e-8786-17b6ecec7daf" class="">b. <strong>샤딩(Sharding) 적용</strong></h3><ul id="89ce96db-85a2-4fa8-a75b-951cb2a4582d" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 분할</strong>: 사용자 ID 또는 키의 해시를 기반으로 데이터를 여러 Redis 인스턴스로 분산 저장합니다. 이를 통해 각 인스턴스의 부하를 줄이고, 전체 성능을 향상시킵니다.</li></ul><h2 id="091c6731-220d-4e73-8788-147ffdc2ed0d" class="">4. <strong>Redis 설정 최적화</strong></h2><h3 id="7d1787e7-7ce7-42cb-a3fd-243eb660c3fd" class="">a. <strong>I/O 및 네트워크 최적화</strong></h3><ul id="8c04c6e1-cab9-4641-a960-25f7ade4cd97" class="bulleted-list"><li style="list-style-type:disc"><strong>바이너리 프로토콜 사용</strong>: Redis 통신에 <code>RESP3</code>와 같은 바이너리 프로토콜을 사용하여 네트워크 오버헤드를 줄입니다.</li></ul><ul id="145741ee-865a-469d-81ee-2a9caaf4e71f" class="bulleted-list"><li style="list-style-type:disc"><strong>패킷 크기 최적화</strong>: Redis 설정에서 <code>tcp-backlog</code>, <code>client-output-buffer-limit</code> 등의 파라미터를 조정하여 네트워크 병목 현상을 최소화합니다.</li></ul><h3 id="3ee3a845-91f3-448c-89b6-0408035642a5" class="">b. <strong>AOF(Append-Only File) 및 RDB 설정 최적화</strong></h3><ul id="54a279c7-6164-4051-a0c7-fd11602be825" class="bulleted-list"><li style="list-style-type:disc"><strong>AOF 파일 크기 최적화</strong>: <code>AOF</code> 리라이트를 정기적으로 수행하여 <code>AOF</code> 파일의 크기를 줄이고, 디스크 I/O를 최적화합니다.</li></ul><ul id="aed9050e-2021-4b8c-8b13-bed49348507f" class="bulleted-list"><li style="list-style-type:disc"><strong>RDB 스냅샷 빈도 조절</strong>: RDB 스냅샷을 너무 자주 수행하면 디스크 I/O 부하가 증가할 수 있으므로, 적절한 빈도로 설정합니다.</li></ul><h2 id="877cd1fa-d1ca-4920-aeda-8123965de5d6" class="">5. <strong>Redis의 비동기 작업 활용</strong></h2><h3 id="3527c3ea-183e-4c2f-b7ba-42d023efde1b" class="">a. <strong>비동기적으로 데이터를 처리</strong></h3><ul id="2c9b074c-eaf3-4bf4-896c-70700c1ad4f3" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis의 Lua 스크립트 활용</strong>: Redis 내부에서 데이터 처리 로직을 Lua 스크립트로 작성하여, 여러 커맨드를 하나의 원자적 작업으로 처리할 수 있습니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="25602ea0-c4f8-461a-85ad-8142e3b4b019" class="code"><code class="language-Lua" style="white-space:pre-wrap;word-break:break-all">local points = redis.call(&#x27;GET&#x27;, KEYS[1])
if points then
    redis.call(&#x27;SET&#x27;, KEYS[1], points + ARGV[1])
else
    redis.call(&#x27;SET&#x27;, KEYS[1], ARGV[1])
end</code></pre></li></ul><h3 id="d574cb57-676a-4ff5-8912-c2af5c42b0ca" class="">b. <strong>백그라운드 작업 처리</strong></h3><ul id="85e41b04-4ae5-4921-b29e-d28b9ba18c95" class="bulleted-list"><li style="list-style-type:disc"><strong>비동기 작업 처리 시스템</strong>: Redis의 Pub/Sub 기능을 사용하여 데이터 업데이트를 비동기적으로 처리하는 시스템을 구축합니다. 이렇게 하면 메인 스레드의 부하를 줄일 수 있습니다.</li></ul><h2 id="6b31cbc2-76a9-45c9-afcf-e4a35e20f014" class="">6. <strong>모니터링 및 경고 시스템 구축</strong></h2><h3 id="9d91fb52-ffb2-47f8-a294-c1f9a99c6984" class="">a. <strong>Redis 성능 모니터링</strong></h3><ul id="6ec61245-4bda-419e-82b9-b5f567f957d9" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis 모니터링 툴 사용</strong>: <code>RedisInsight</code>, <code>Grafana</code>, <code>Prometheus</code>와 같은 모니터링 도구를 사용하여 Redis의 성능 지표를 실시간으로 모니터링하고, 문제 발생 시 신속히 대응할 수 있도록 합니다.</li></ul><h3 id="6517b147-1053-4eeb-9d27-9916b277ee1f" class="">b. <strong>자동 경고 시스템 구축</strong></h3><ul id="508b16b1-4b59-4501-88ee-fa13265e64d8" class="bulleted-list"><li style="list-style-type:disc"><strong>경고 임계값 설정</strong>: Redis의 메모리 사용량, CPU 부하, 요청 처리 속도 등에 대한 임계값을 설정하고, 이를 초과할 경우 자동으로 경고를 발송하는 시스템을 구축합니다.</li></ul><h2 id="2b26fdcf-7ad6-4439-8d60-28d6059c717f" class="">7. <strong>하드웨어 및 인프라 확장</strong></h2><h3 id="4a83d559-8bb5-44f8-b13d-948bd7818fef" class="">a. <strong>서버 및 네트워크 업그레이드</strong></h3><ul id="71027f66-22db-46fc-bcc9-a38777821101" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis 서버 스펙 업그레이드</strong>: Redis 서버의 CPU, 메모리, 네트워크 대역폭을 업그레이드하여 성능을 향상시킵니다.</li></ul><h3 id="dab1e0c5-6358-4c72-ba7b-af96a56aa1a9" class="">b. <strong>인프라 확장 및 분산 처리</strong></h3><ul id="64543d18-08f7-4428-9580-011fc9fb2293" class="bulleted-list"><li style="list-style-type:disc"><strong>서버 인스턴스 추가</strong>: Redis 인스턴스를 추가하고, 로드 밸런서를 통해 트래픽을 분산 처리합니다.</li></ul><h2 id="33221e08-d120-411c-93fb-767bce2d48d0" class="">결론</h2><p id="9236d9be-66f7-4ee3-8812-80cf8342646d" class="">Redis의 부하 문제는 데이터 구조 최적화, 캐시 관리, 클러스터링, 비동기 작업 처리, 모니터링 시스템 구축 등 다양한 방법을 통해 해결할 수 있습니다. 이러한 방법들을 적절하게 적용하여 Redis의 성능과 안정성을 개선하고, 애플리케이션의 요구사항에 맞게 Redis를 최적화할 수 있습니다.</p><p id="1ed3a4cc-090a-8068-8b8f-ff515de08352" class="">
</p></details></li></ul><ul id="65f050dc-20ca-4709-aee3-ddb9e7b94a83" class="toggle"><li><details open=""><summary>레디스를 이용한 기프티콘 선착순 이벤트 구현</summary><h2 id="9452e704-e28a-47df-8f94-8140eb8a62af" class="">1. 왜 레디스로 구현해야하나?</h2><h3 id="991a0d67-8837-4ab2-acf7-59b528161d54" class="">💡 선착순 이벤트에서 레디스가 사용되는 이유?</h3><ul id="bd324f1a-7156-4734-8ff5-bd98f66a0e41" class="bulleted-list"><li style="list-style-type:disc">보통 선착순 이벤트는 특정 시간에 트래픽이 몰리기 때문에 서버가 다운되거나 원활하지 못한 이벤트를 참여해보신 적이 한 번씩 경험해보셨을 겁니다.</li></ul><ul id="85429fa2-405c-4e60-bba4-1972609f42c5" class="bulleted-list"><li style="list-style-type:disc">이번 포스팅에선, 레디스에서 제공하는 자료구조 중 하나인 <strong>Sorted Set</strong>을 활용하여 <code>모든 요청이 DB에 바로 부하가 가지 않고 차례대로 일정 범위만큼씩 처리</code>하는 구성을 해보려고합니다.</li></ul><ul id="b2cb5c28-1f85-4dc9-8394-0fa3178a57c5" class="bulleted-list"><li style="list-style-type:disc">선착순 이벤트 시 대기하고 있는 인원에 대해 대기열 순번을 표출하기 용이합니다.</li></ul><h2 id="a7f83302-0c59-46a7-8551-2c0f8a4f2d28" class="">2. 레디스 Sorted Set</h2><h3 id="cac1a3d2-4f31-4624-a66b-aba013b40fd8" class="">❓ Sorted Set이란?</h3><figure id="c1f9c72b-bfa8-4364-b0f5-10c25f5a340e" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/2e3811e7-7e8c-4df9-aa15-961d8a03bd46/image.png"><img style="width:528px" src="https://velog.velcdn.com/images/hgs-study/post/2e3811e7-7e8c-4df9-aa15-961d8a03bd46/image.png"/></a></figure><ul id="7cc8cfd2-9f5c-4972-a987-1b3f56d92b61" class="bulleted-list"><li style="list-style-type:disc">Sorted Sets은 <strong>key 하나에 여러개의 score와 value</strong>로 구성하는 자료구조입니다.</li></ul><ul id="fca0d9c3-305b-4032-8a3f-06ede236cde5" class="bulleted-list"><li style="list-style-type:disc">Value는 score로 sort되며 중복되지 않습니다.</li></ul><ul id="e525142d-b7f2-4c0f-b454-7bb86388795b" class="bulleted-list"><li style="list-style-type:disc">Score가 같으면 value로 sort됩니다.</li></ul><ul id="492284ef-9300-44e6-a2f5-ae1c32358719" class="bulleted-list"><li style="list-style-type:disc">Sorted Sets에서는 집합이라는 의미에서 value를 member라 부릅니다.</li></ul><ul id="367b947a-2e92-4916-b355-de3fe1cf9ea3" class="bulleted-list"><li style="list-style-type:disc">Sorted Sets은 주로 sort가 필요한 곳에 사용됩니다.</li></ul><blockquote id="dbd9564f-c5e5-4c08-8b02-b70c4221a755" class="">간단히 정리하자면, 한 Key에 여러 value와 score를 가지고 있으며 중복되지 않는 value로 score순으로 데이터를 정렬합니다.</blockquote><h2 id="8adedccd-dde3-4f1b-84b5-94d685d1fb4c" class="">3. 기프티콘 선착순 이벤트 구조</h2><h3 id="6654c250-dcca-4ab5-a211-966aa93f56ff" class="">📌 Sorted Set을 활용한 선착순 이벤트</h3><figure id="350dd919-9226-44f0-ada3-5cdcaae772a8" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/9add5f28-20d4-4d36-b72e-2413bf323955/image.png"><img style="width:624px" src="https://velog.velcdn.com/images/hgs-study/post/9add5f28-20d4-4d36-b72e-2413bf323955/image.png"/></a></figure><ul id="9160d95e-c03a-4c7d-8eac-f3c18cafdcb2" class="bulleted-list"><li style="list-style-type:disc">Sorted Set Key에는 <strong>GIFTICON_EVENT</strong> 를 설정합니다.</li></ul><ul id="7dda013b-fab4-40c5-af55-285829d12047" class="bulleted-list"><li style="list-style-type:disc">Value에는 <strong>사용자명(Pir, David, Foo, John)</strong>을 설정합니다. 해당 예제는 사용자명으로 했지만 사용자명이 중복일 경우, 사용자에 대한 <code>고유한 값</code>으로 세팅하면 됩니다.</li></ul><ul id="016ac791-bc1a-4027-9160-f1ae0d73e168" class="bulleted-list"><li style="list-style-type:disc">Score에는 <code>참여한 사람들을 순서대로 정렬</code>하기 위해, 이벤트를 참여한 시간을 <strong>유닉스타임(m/s)</strong> 값으로 넣어줍니다.</li></ul><h2 id="fd23d79c-1ab2-4ac0-a57c-fc541787a0bb" class="">4. 어플리케이션 구성</h2><h3 id="41889f88-c31e-465b-a399-7c93bf7d752e" class="">📌 기프티콘 30개 선착순 이벤트 시 100명이 요청했을 경우</h3><figure id="8a890bf3-4055-4b40-a506-d37f11664bf2" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/ec1bf878-c934-499a-8f3f-ab7a8f93bfa1/image.png"><img src="https://velog.velcdn.com/images/hgs-study/post/ec1bf878-c934-499a-8f3f-ab7a8f93bfa1/image.png"/></a></figure><p id="2bd86ed2-9647-42d3-9de0-982737afcf22" class=""><strong>(1)</strong> 100명의 유저가 기프티콘 발급 요청을 합니다.</p><p id="5378b184-10f4-419c-be8f-7e54487df413" class=""><strong>(2)</strong> 100명의 유저는 대기열에 쌓이게 됩니다.</p><p id="1a434e83-b33d-487d-8c40-7d9ec63544c5" class=""><strong>(3)</strong> 1초마다 동기화 돼어 기프티콘 발급 성공, 실패 로직을 수행합니다.</p><p id="114e5176-4579-4587-9ce3-8311b90f9539" class=""><strong>(4)</strong> 성공시, 이벤트가 종료되지 않았으면 <strong>100명의 유저중 먼저 들어온 순서대로 </strong><code><strong>10명씩 기프티콘 발급</strong></code>합니다.</p><p id="95f55909-aa9f-4466-b00e-e0c7df587df8" class=""><strong>(5)</strong> 실패시, 다음 대기열로 돌아가면서 <code><strong>남은 대기열 순번을 표출</strong></code>합니다.</p><p id="702a1a41-f9c1-4183-972d-c9f898442587" class=""><strong>(6)</strong> 해당 과정을 반복하면서 이벤트는 종료(30개 발급완료)합니다</p><blockquote id="e70bbfe1-3812-475f-a40f-73819de154e0" class="">10개씩 발급하는 이유는 DB 부하를 줄이기 위해입니다. 해당 예시는 10개이지만 실제 서비스에선 10000개의 요청 중 1000개의 기프티콘을 발급할 경우 1초마다 50개씩 순차적으로 발급해서 DB부하를 줄일 수 있을 것 같습니다.</blockquote><figure id="d8b1f089-83c2-46fe-b634-9d228af737b2"><a href="https://velog.io/@hgs-study/redis-sorted-set" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">레디스를 이용한 기프티콘 선착순 이벤트 구현</div><div class="bookmark-description">이번 포스팅은 레디스에서 제공해주는 자료구조 중 하나인 Sorted Set을 간단하게 설명하고, Sorted Set을 이용해서 치킨 기프티콘 선착순 이벤트를 구현해봅니다.  1. 왜 레디스으로 구현해야하나? 💡 선착순 이벤트에서 레디스가 사용되는 이유? 보통 선착순</div></div><div class="bookmark-href"><img src="https://static.velog.io/favicons/apple-icon-152x152.png" class="icon bookmark-icon"/>https://velog.io/@hgs-study/redis-sorted-set</div></div><img src="https://velog.velcdn.com/images/hgs-study/post/b1ed6bd1-7ddf-4500-a0fc-f9f376b4d31b/image.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="42f81b26-a135-4742-913e-bd583ff72b42" class="toggle"><li><details open=""><summary>선착순 티켓 예매의 동시성 문제: 잠금으로 안전하게 처리하기</summary><p id="9373f597-9aa3-42b5-ae64-5c83c7b481d5" class="">대학 축제 티케팅 서비스 <a href="https://github.com/woowacourse-teams/2023-festa-go">페스타고</a>를 개발하면서 아래와 같은 고민을 하게 되었다.</p><p id="698494b6-4628-4b34-8fb0-7453c6e75459" class="">티켓 오픈 시간에 많은 사용자가 동시에 티켓 예매를 요청하면 어떠한 문제가 발생할까? 그리고 그 문제를 어떻게 해결할 수 있을까?</p><p id="80b0e3c4-9752-40fd-adf3-08776b4d0a04" class="">여기서 가장 중요한 것은 요청 순서에 따라 티켓을 발급하되, 준비된 수량만큼만 발급하는 것이다.</p><p id="8dbb5084-7b40-4ceb-a554-44f26bd8e545" class="">이번 글에서는 위와 같이 ‘동시성’에 대한 고민을 한 경험을 공유하고자 한다.</p><p id="e4af3bae-3ed1-4a5c-9ac6-74e36105b94c" class="">참고로, 이번 글에서는 개념에 대한 깊은 설명은 따로 하지 않는다. 모르는 개념이 있다면 아래 참고자료에서 개념을 익히도록 하자.</p><h1 id="9886074c-48e5-43f0-9d2e-4299b5002a13" class=""><strong>예제 코드</strong></h1><p id="17f29c94-6412-46f3-a12c-0ac3c1fdc4d3" class="">아래는 티켓 예매 상황을 간략하게 구현한 예제 코드이다. (실제로는 더 복잡한 요구사항이 존재하나, 이를 단순화하여 작성하였다.)</p><p id="ef727638-e50c-40dd-bfb4-219af1fd72fe" class="">아래 예제 코드는 MySQL 8.0 innoDB 스토리지 엔진 기반으로 동작한다.</p><p id="76a98512-5779-4ace-b562-53bda7567fd1" class="">먼저 사용자가 “티켓 예매” 요청 시 호출되는 TicketingService의 ticketing 메서드이다.</p><p id="35245c9e-13c3-4201-804c-ab122b08c8a4" class=""><code>@Transactional<br/>public void ticketing(long ticketId) {<br/>    Ticket ticket = ticketRepository.findById(ticketId)<br/>        .orElseThrow(() -&gt; new IllegalArgumentException(&quot;Ticket Not Found.&quot;));<br/>    ticket.increaseReservedAmount();<br/>    int ticketNumber = ticket.getReservedAmount();<br/>    reservationRepository.save(new Reservation(ticket, ticketNumber));<br/>}<br/></code></p><p id="05c74bb3-bc6b-4864-b206-e27f7e3139c5" class="">아래는 Ticket 도메인 코드 중 일부이다. increaseReservedAmount 메서드 호출 시 예매 수량과 총수량을 비교해 예매 가능 여부를 판단하고, 불가능할 시 예외가 발생한다.</p><p id="9380c12a-2f91-4201-823a-8cbc3a788824" class=""><code>@Entity<br/>@Getter<br/>@NoArgsConstructor(access = AccessLevel.PROTECTED)<br/>public class Ticket {<br/><br/>    @Id<br/>    @GeneratedValue(strategy = GenerationType.IDENTITY)<br/>    private Long id;<br/><br/>    private int totalAmount;<br/><br/>    private int reservedAmount = 0;<br/><br/>		/***/<br/><br/>    public void increaseReservedAmount() {<br/>        if (reservedAmount &gt;= totalAmount) {<br/>            throw new IllegalArgumentException(&quot;Sold out.&quot;);<br/>        }<br/>        reservedAmount++;<br/>    }<br/>}<br/></code></p><h1 id="999f12a9-196a-4fc6-a03c-8bb76d81e823" class=""><strong>순차적 예매</strong></h1><p id="23977206-e383-4524-a6c6-0d73115f56c9" class="">모든 사용자가 순차적으로 요청한다고 가정하자.</p><p id="46aafbcc-16fe-45a7-81cb-76c876693dce" class="">해당 테스트에서는 10장의 티켓을 30명의 사용자가 예매하는 상황을 가정했다.</p><p id="db3b2b00-47d9-4686-8c6c-5886c42505e2" class=""><code>@Test<br/>void 티켓_순차적_예매_테스트() {<br/>    // given<br/>    int memberCount = 30;<br/>    int ticketAmount = 10;<br/>    Ticket ticket = ticketRepository.save(new Ticket(ticketAmount));<br/><br/>    AtomicInteger successCount = new AtomicInteger();<br/>    AtomicInteger failCount = new AtomicInteger();<br/><br/>    // when<br/>    for (int i = 0; i &lt; memberCount; i++) {<br/>        try {<br/>            ticketingService.ticketing(ticket.getId());<br/>            successCount.incrementAndGet();<br/>        } catch (Exception e) {<br/>            failCount.incrementAndGet();<br/>        }<br/>    }<br/><br/>    System.out.println(&quot;successCount = &quot; + successCount);<br/>    System.out.println(&quot;failCount = &quot; + failCount);<br/><br/>    // then<br/>    long reservationCount = reservationRepository.count();<br/>    assertThat(reservationCount)<br/>        .isEqualTo(Math.min(memberCount, ticketAmount));<br/>}<br/></code></p><h1 id="440514dd-1f21-41bd-9938-842587918069" class=""><strong>실행 결과</strong></h1><figure id="bafea49e-d3ef-4eef-a222-5ded2d2e90c5" class="image"><a href="https://tecoble.techcourse.co.kr/static/cddcd5e72fd1754fc8f512263ba13f61/ce235/2023-08-16-ash-0.png"><img style="width:334px" src="https://tecoble.techcourse.co.kr/static/cddcd5e72fd1754fc8f512263ba13f61/ce235/2023-08-16-ash-0.png"/></a></figure><p id="7f20ffe8-68b5-44cb-82a5-dd6a72ae9b32" class="">해당 테스트는 당연하게도 성공했다. 예상한 수량인 10장만 정확하게 예매되었다.</p><p id="8bdca120-5487-4d35-9390-737a8acba74e" class="">티켓 예매 내역을 기록하는 Reservation 테이블을 조회해보니, 1~10번 티켓이 각각 한 장씩 예매된 것을 확인할 수 있었다.</p><figure id="f50309e3-44ae-4063-b678-5f08d7f0c022" class="image"><a href="https://tecoble.techcourse.co.kr/static/4b5dab5c9305ad0001a24f1ffd807e7d/8d021/2023-08-16-ash-1.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/4b5dab5c9305ad0001a24f1ffd807e7d/8d021/2023-08-16-ash-1.png"/></a></figure><p id="e7ac2dd6-05d1-4844-b743-57b1df152484" class="">아주 성공적이다.</p><p id="d49678c4-37ec-4275-b259-72eadf4eb620" class="">하지만, 티케팅 상황에서는 다수의 사용자가 순차적으로 요청하기보다, 동시에 요청을 하는 상황이 더 일반적이다.</p><h1 id="bb2f3bcd-998a-4895-910d-6d562b426993" class=""><strong>동시 예매</strong></h1><p id="328594f9-646c-4aae-bf54-dadfcfe3d3bf" class="">동시에 여러 요청이 발생한 상황을 테스트한 코드는 아래와 같다.</p><p id="cfdf231d-3081-47fa-baa5-5ead76d8bb07" class="">순차 요청 테스트와 같이 10장의 티켓을 30명의 사용자가 예매하는 상황을 가정했다.</p><p id="18c2b252-53b4-484b-ad01-a1ec18d14686" class=""><code>@Test<br/>void 티켓_동시_예매_테스트() throws InterruptedException {<br/>    // given<br/>    int memberCount = 30;<br/>    int ticketAmount = 10;<br/>    Ticket ticket = ticketRepository.save(new Ticket(ticketAmount));<br/><br/>    ExecutorService executorService = Executors.newFixedThreadPool(30);<br/>    CountDownLatch latch = new CountDownLatch(memberCount);<br/><br/>    AtomicInteger successCount = new AtomicInteger();<br/>    AtomicInteger failCount = new AtomicInteger();<br/><br/>    // when<br/>    for (int i = 0; i &lt; memberCount; i++) {<br/>        executorService.submit(() -&gt; {<br/>            try {<br/>                ticketingService.ticketing(ticket.getId());<br/>                successCount.incrementAndGet();<br/>            } catch (Exception e) {<br/>                System.out.println(e.getMessage());<br/>                failCount.incrementAndGet();<br/>            } finally {<br/>                latch.countDown();<br/>            }<br/>        });<br/>    }<br/><br/>    latch.await();<br/><br/>    System.out.println(&quot;successCount = &quot; + successCount);<br/>    System.out.println(&quot;failCount = &quot; + failCount);<br/><br/>    // then<br/>    long reservationCount = reservationRepository.count();<br/>    assertThat(reservationCount)<br/>        .isEqualTo(Math.min(memberCount, ticketAmount));<br/>}<br/></code></p><h1 id="d8e70a8f-0417-4cba-a18f-28c84fa107b5" class=""><strong>실행 결과</strong></h1><p id="f6b6fd3b-13f5-431c-9687-a0576b64d33b" class="">정확히 10장의 티켓이 예매되는 것을 기대했으나, 테스트 결과는 그렇지 않았다.</p><figure id="e0c137d0-441c-4d34-813e-1b1d28f68656" class="image"><a href="https://tecoble.techcourse.co.kr/static/d566bdefcf309d24f07f8306f72e6d3c/9e38b/2023-08-16-ash-2.png"><img style="width:308px" src="https://tecoble.techcourse.co.kr/static/d566bdefcf309d24f07f8306f72e6d3c/9e38b/2023-08-16-ash-2.png"/></a></figure><p id="97893a8b-159b-46ab-b375-d9bfd6c80566" class="">10장보다 적은 6장만 예매되었음을 확인할 수 있었다.</p><p id="79ab87b8-4848-44e9-825c-061190c54879" class="">티켓의 수량보다 많은 요청이 있었는데, 왜 더 적게 예매되었을까?</p><p id="0bb58f9c-df6a-48f5-a25d-1f6c4f15c845" class="">출력문을 보니 아래와 같이 <code>Deadlock found when trying to get lock; try restarting transaction</code>이라는 문구와 함께 SQL Error가 발생했음을 확인할 수 있었다.</p><figure id="225aa1d3-334c-4000-be0b-ac4578097486" class="image"><a href="https://tecoble.techcourse.co.kr/static/cc8410f88d230a4487d366c5b8f39c71/5dd2a/2023-08-16-ash-3.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/cc8410f88d230a4487d366c5b8f39c71/5dd2a/2023-08-16-ash-3.png"/></a></figure><p id="58730a1f-a579-4883-a383-cfcbf9111901" class="">lock을 얻어오는 과정에서 Deadlock 즉, 교착 상태가 발생했다. lock을 얻어오는 행위를 따로 하지 않았는데 왜 교착 상태가 발생했을까?</p><h3 id="3c408e4f-6d47-4a16-8a90-f04de9d462a4" class=""><strong>교착 상태가 발생한 이유</strong></h3><p id="a9c47c09-76ee-4228-9155-0b21790a3216" class="">티켓 예매 내역을 의미하는 Reservation 엔티티를 보자.</p><p id="9d0c3cef-2d5a-4d7a-81c6-662c75b14e6c" class=""><code>@Entity<br/>@Getter<br/>@NoArgsConstructor(access = AccessLevel.PROTECTED)<br/>public class Reservation {<br/><br/>    @Id<br/>    @GeneratedValue(strategy = GenerationType.IDENTITY)<br/>    private Long id;<br/><br/>    @ManyToOne(fetch = FetchType.LAZY)<br/>    private Ticket ticket;<br/><br/>    private int ticketNumber;<br/>}<br/></code></p><figure id="8ed762e8-e268-4f2e-8e04-b8450d856c7c" class="image"><a href="https://tecoble.techcourse.co.kr/static/01aa95d4ffa12adcada14dede843701a/1f9f1/2023-08-16-ash-4.png"><img style="width:412px" src="https://tecoble.techcourse.co.kr/static/01aa95d4ffa12adcada14dede843701a/1f9f1/2023-08-16-ash-4.png"/></a></figure><p id="d355b285-0ca6-4c39-9655-dc8d88a49465" class="">Reservation 엔티티에 Ticket 엔티티와의 연관관계를 설정해 줌으로써, DB의 reservation 테이블에 외래 키 칼럼 ticketId가 추가되었다.</p><p id="b4bc3bbe-d56a-4a14-9ee6-db986846c9b6" class=""><a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html">MySQL 공식문서</a>에 아래와 같은 내용이 있다.</p><blockquote id="d67faf59-8bbb-4d64-a8eb-ad25f61155b6" class="">If a FOREIGN KEY constraint is defined on a table, any insert, update, or delete that requires the constraint condition to be checked sets shared record-level locks on the records that it looks at to check the constraint. InnoDB also sets these locks in the case where the constraint fails.</blockquote><p id="2ffb359d-9cb0-4fd8-bad0-d758301ad13f" class="">즉, 외래 키 제약 조건이 있는 테이블에서 레코드를 삽입, 갱신, 삭제할 때 해당 제약 조건을 위반하는지 확인하기 위해 관련된 레코드들에 공유 잠금(S lock)을 설정한다는 뜻이다.</p><p id="67ceb243-8419-4cc3-bb4a-1f82c04f8fa7" class="">공유 잠금이란 다른 트랜잭션의 데이터 변경을 막고 데이터 일관성을 유지하는 잠금 유형이다. 여러 트랜잭션이 동시에 공유 잠금을 얻을 수 있다. 그러나 공유 잠금을 설정한 트랜잭션이 있을 때, 다른 트랜잭션은 해당 데이터에 대해 배타적 잠금(X lock)을 얻지 못한다.</p><p id="a3128180-d56f-45a0-87d4-accf54861a78" class="">배타적 잠금은 한 번에 하나의 트랜잭션만이 특정 데이터에 대한 쓰기 작업을 수행할 수 있도록 하는 잠금 유형이다. 다른 트랜잭션들은 쓰기 작업이 끝날 때까지 대기해야 하며, 이를 통해 데이터 충돌 문제를 방지한다.</p><p id="2e19534d-95a1-48db-aa78-9b80aa98f69c" class="">실제로 innodb의 로그를 확인해보니, 여러 트랜잭션에서 데이터에 잠금을 거는 과정에서 교착 상태가 발생했음을 알 수 있었다. 아래는 로그 내용을 간략화한 것이다.</p><p id="3dcaa306-9d79-46e9-aa19-b30d6d84f81b" class=""><code>LATEST DETECTED DEADLOCK<br/>------------------------<br/>Transaction 1 (ID 20238):<br/>- Holding S Lock on data ID 1 in table `ticket`, Waiting for X Lock<br/>Transaction 2 (ID 20240):<br/>- Holding S Lock on data ID 1 in table `ticket`, Waiting for X Lock<br/>Transaction 2 Rolled Back<br/></code></p><p id="b8306824-f204-41e9-8bda-d2f44d7dc91b" class="">로그를 토대로 아래와 같이 교착 상태가 걸리는 과정을 알 수 있었다.</p><figure id="933a76af-fe64-4fde-94f3-dfa97a914c64" class="image"><a href="https://tecoble.techcourse.co.kr/static/9f5d4bf32d734851fba53c6ad6a4ab35/2637b/2023-08-16-ash-5.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/9f5d4bf32d734851fba53c6ad6a4ab35/2637b/2023-08-16-ash-5.png"/></a></figure><ol type="1" id="eae1b407-9a28-4e63-9f19-34ac867c5f27" class="numbered-list" start="1"><li>트랜잭션 1이 id=1인 데이터에 공유 잠금을 얻었다.</li></ol><ol type="1" id="8e9742eb-6c0f-4207-bd29-24dfb5d2fe01" class="numbered-list" start="2"><li>트랜잭션 2가 id=1인 데이터에 공유 잠금을 얻었다.</li></ol><ol type="1" id="2a417833-320f-49fd-a0b0-4e01715d4acc" class="numbered-list" start="3"><li>트랜잭션 1이 id=1인 데이터에 배타적 잠금을 얻고싶지만, 트랜잭션 2에서 해당 데이터에 공유 잠금을 걸어두었기 때문에 대기한다.</li></ol><ol type="1" id="7cfd8ae1-49ca-42c4-bc92-357ac3c56dec" class="numbered-list" start="4"><li>트랜잭션 2가 id=1인 데이터에 배타적 잠금을 얻고싶지만, 트랜잭션 1에서 해당 데이터에 공유 잠금을 걸어두었기 때문에 대기한다.</li></ol><ol type="1" id="b4a0906a-a6b8-4e35-8cc3-f24255cf67b2" class="numbered-list" start="5"><li>무한 대기상태에 빠진다. 즉, 교착 상태가 발생한다.</li></ol><h1 id="c02cacec-e3f1-464f-90ff-4fae65543097" class=""><strong>연관관계 제거</strong></h1><p id="468460e9-47aa-43a7-b8de-084e9465299c" class="">실제로 교착 상태의 위험성 때문에 외래 키를 사용할 때는 신중해야 한다.</p><p id="446928df-49a5-45a9-b4e0-68bcf53b3ad8" class="">교착 상태의 문제를 해결하기 위해 Ticket과 Reservation간의 외래 키 관계를 제거했다.</p><p id="1546e403-c7f4-473d-b259-0b080e5e093a" class=""><code>@Entity<br/>@Getter<br/>@NoArgsConstructor(access = AccessLevel.PROTECTED)<br/>public class Reservation {<br/><br/>    @Id<br/>    @GeneratedValue(strategy = GenerationType.IDENTITY)<br/>    private Long id;<br/><br/>    private Long ticketId;<br/><br/>    private int ticketNumber;<br/><br/>    public Reservation(Ticket ticket, int ticketNumber) {<br/>        this.ticketId = ticket.getId();<br/>        this.ticketNumber = ticketNumber;<br/>    }<br/>}<br/></code></p><p id="7541a451-f51d-40f3-8d14-26d8e46aeaae" class="">연관관계 제거 후 다시 동시 예매 테스트를 실행하니, 교착 상태는 발생하지 않았다.</p><p id="7df84a0b-27b1-4163-ae49-cd7d607b0dfa" class="">하지만 총 수량은 10장뿐이지만, 30명의 사용자 모두 예매에 성공하는 결과가 발생했다.</p><figure id="b7e773af-d38b-4a5b-b8bf-a813291ef2d2" class="image"><a href="https://tecoble.techcourse.co.kr/static/8386a9547c96ca05ff2650044c725bb4/9e45f/2023-08-16-ash-6.png"><img style="width:286px" src="https://tecoble.techcourse.co.kr/static/8386a9547c96ca05ff2650044c725bb4/9e45f/2023-08-16-ash-6.png"/></a></figure><p id="a1b693d1-3ef7-4a41-b371-d2fd8698c616" class="">어떻게 티켓의 수량보다 많은 사용자가 티켓을 예매할 수 있었을까?</p><p id="cc03657d-9593-40e3-903f-b57136f52649" class="">DB의 reservation 테이블을 확인하니 그 이유를 알 수 있었다.</p><figure id="66fafafd-0fee-40c4-946c-e586be4b687d" class="image"><a href="https://tecoble.techcourse.co.kr/static/63e80a317763eb47b903c2a81e6c8571/5f5e5/2023-08-16-ash-7.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/63e80a317763eb47b903c2a81e6c8571/5f5e5/2023-08-16-ash-7.png"/></a></figure><p id="81078b74-65cf-403e-a13d-177b899c9c2d" class="">1~10번 티켓이 각각 한 장씩 예매된게 아니라 1번 티켓 10장, 2번 티켓 9장, 3번 티켓 9장, 4번 티켓 2장이 예매되었다. 즉, 하나의 티켓이 여러 사용자에게 발급되는 문제가 발생했다.</p><p id="eda0ff30-667a-4cc0-9e3a-a469d48fd22c" class="">순차적으로 예매를 요청할 때는 발생하지 않았던 문제였는데, 동시에 예매를 요청하는 상황에서는 왜 이와 같은 문제가 발생했을까?</p><h3 id="5fad63c6-1da9-4d88-b807-20dba7ba4834" class=""><strong>순차적 예매 실행 흐름</strong></h3><figure id="19fd5546-5ef6-4276-872f-4b47fcfafcbe" class="image"><a href="https://tecoble.techcourse.co.kr/static/bd0a1777fe65ab9db8874f20b5ffb230/7e08f/2023-08-16-ash-8.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/bd0a1777fe65ab9db8874f20b5ffb230/7e08f/2023-08-16-ash-8.png"/></a></figure><p id="5a8f14c7-8a50-4cdc-a2d7-0cb10bd3b613" class="">순차적 예매 시 위 그림과 같이 한 스레드의 작업이 끝난 후 다음 스레드에서의 작업이 시작되기 때문에 충돌이 일어나지 않는다.</p><h3 id="c5af120d-2213-46ea-a9b6-b75dda73977d" class=""><strong>동시 예매 실행 흐름</strong></h3><figure id="f6c3061a-9f90-4ec7-b989-04cdac3e453a" class="image"><a href="https://tecoble.techcourse.co.kr/static/61863fc9cd77a53b821987e4f2698cb3/2d324/2023-08-16-ash-9.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/61863fc9cd77a53b821987e4f2698cb3/2d324/2023-08-16-ash-9.png"/></a></figure><p id="194c7c61-259e-4327-a5bc-52efa24870a8" class="">순차적 예매와 달리, 동시 예매 시 위 그림과 같이 한 스레드가 데이터를 읽고 이를 갱신하기 전, 다른 스레드에서 데이터를 읽기 때문에 충돌이 발생한다. 이 이유로 여러 개의 트랜잭션에서 동일한 티켓을 예매할 수 있었다.</p><p id="ef85c5b6-0a6b-4427-82cb-f1bb93356dd1" class="">이제부터 위 문제 상황에 대한 해결책을 알아보자.</p><h1 id="68ca72c6-f38f-4a47-acda-4117d5412a7f" class=""><strong>해결책</strong></h1><h3 id="fb76c528-fb6c-4336-ba09-7a1fa0b4d9a3" class=""><strong>synchronized</strong></h3><p id="a8c49fb5-a232-43ef-a4fe-99c526799fb1" class="">java에서 한 자원에 synchronized 키워드를 붙이면, 멀티 스레드 환경에서 단일 스레드만이 해당 자원에 접근가능하도록 보장한다.</p><p id="a5de9d76-2c30-4d8a-a9e8-d9de2708418e" class="">그렇다면 ticketing 메서드에 synchronized 키워드를 붙임으로써, 동시에 들어오는 요청들을 순차적으로 처리할 수 있지 않을까?</p><p id="c113e696-3d56-4b02-b823-c22cfa69fd54" class="">한 번 실험해보자.</p><p id="2ce461d2-6821-4653-8a9b-da1f5d0a38af" class="">아래와 같이 ticketing 메서드에 synchronized 키워드를 붙여주고, 동시 예매 테스트를 실행하였다.</p><p id="656dac96-aab0-4296-a37f-dbf7f46adc63" class=""><code>@Transactional<br/>public synchronized void ticketing(long ticketId) {<br/>    Ticket ticket = ticketRepository.findById(ticketId)<br/>        .orElseThrow(() -&gt; new IllegalArgumentException(&quot;Ticket Not Found.&quot;));<br/>    ticket.increaseReservedAmount();<br/>    int ticketNumber = ticket.getReservedAmount();<br/>    reservationRepository.save(new Reservation(ticket, ticketNumber));<br/>}<br/></code></p><figure id="7b2fb83b-6e25-4eb7-80a2-2e26b5cfb365" class="image"><a href="https://tecoble.techcourse.co.kr/static/3f77a06fb1689024e2334be7b010f384/f00bc/2023-08-16-ash-10.png"><img style="width:312px" src="https://tecoble.techcourse.co.kr/static/3f77a06fb1689024e2334be7b010f384/f00bc/2023-08-16-ash-10.png"/></a></figure><p id="4f9c6570-d76c-47d7-a8a9-9a2753d07725" class="">여전히 결과는 옳지 않았다. 요청이 순차적으로 진행되지 않고, 병렬적으로 진행되었다.</p><p id="ada06132-c849-4953-9589-1048aeb07309" class="">@Transactional 키워드와 synchronized 키워드를 동시에 사용하면 어떤 문제가 발생하는 것일까?</p><p id="9c8cdf68-6db8-46f2-886e-ac5393513f0f" class="">@Transactional이 붙은 메서드가 호출되면, Spring은 프록시 객체를 생성한다.</p><p id="daae6c2e-cbae-4a50-bf5c-83fdfcf4bfa9" class="">해당 프록시 객체는 원본 객체를 감싸며, 메서드 호출 전 후로 transaction begin, commit을 수행한다.</p><figure id="3214801f-e57a-4316-bf1c-966e43f9445e" class="image"><a href="https://tecoble.techcourse.co.kr/static/3a151c092d7ea2c8921ece68c113e71b/26cba/2023-08-16-ash-11.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/3a151c092d7ea2c8921ece68c113e71b/26cba/2023-08-16-ash-11.png"/></a></figure><p id="f317a46a-1d33-4783-a654-e24b93cd6b8e" class="">여기서 프록시 객체에서 수행되는 transaction begin, commit 코드는 synchronized의 영향을 받지 않는다.</p><p id="52fb6e27-33d5-4e32-b15a-2a2a5ddb1f42" class="">즉, 위 그림과 같이 T1 스레드에서 commit 되기 전 T2 스레드는 메서드를 시작할 수 있다.</p><p id="bef775cd-7bda-46ad-a99f-feaa6953a0ef" class="">이와 별개로 synchronized 키워드에는 몇 가지 단점이 존재한다.</p><p id="f15407b2-927c-4a4b-9ccd-edf1079048dc" class="">한 스레드가 메서드 작업을 완료할 때까지 다른 스레드들은 대기해야 한다. 이로 인해 프로그램의 성능이 저하될 수 있다.</p><p id="e1c61763-a8d3-4d4a-b095-f3045191d2e9" class="">또한 이는 하나의 프로세스 안에서만 보장이 되기 때문에, 서버가 여러 대인 분산 환경에서는 데이터의 정합성을 보장할 수 없다.</p><p id="904af20d-28bf-474a-88d5-a4740fcaae62" class="">따라서, synchronized 키워드는 우리 문제 상황의 해결책으로 적절하지 않다.</p><h3 id="b49cbe56-9d96-4086-aa7b-d1d26316ea59" class=""><strong>잠금</strong></h3><p id="753737b1-3514-4d7a-9348-4796c8693012" class=""><strong>잠금(Locking)</strong> 은 데이터가 읽힌 후 사용될 때까지 데이터가 변경되는 것을 방지하기 위한 조치이다.</p><p id="cbaee087-8a9d-4365-913a-be7dbe8d0d33" class="">잠금 전략으로는 여러 트랜잭션 간 충돌이 일어나지 않을 것이라 가정하는 <strong>낙관적 잠금(Optimistic Lock)</strong> , 여러 트랜잭션 간 충돌이 일어날 것이라 가정하는 <strong>비관적 잠금(Pessimistic Lock)</strong> 이 있다.</p><p id="b90c7e65-92f2-4fe0-a5f6-3177301a907c" class="">낙관적 잠금과 비관적 잠금을 통해 문제상황 해결을 시도해 보자.</p><h3 id="e549ace8-a1fc-4d36-a05b-464c07dfc57d" class=""><strong>낙관적 잠금</strong></h3><p id="f803362f-c19a-44a5-acda-5e69c71d70d5" class="">우선 우리의 코드에 낙관적 잠금을 적용해 보자.</p><p id="ec4c25dd-65e1-4067-bbd3-733d145cb6bb" class="">낙관적 잠금은 아래와 같이 @Version 어노테이션을 통해 처리할 수 있다.</p><p id="7ff1b748-b55d-4b01-b4d4-699912933b1b" class=""><code>@Entity<br/>@Getter<br/>@NoArgsConstructor(access = AccessLevel.PROTECTED)<br/>public class Ticket {<br/><br/>    @Id<br/>    @GeneratedValue(strategy = GenerationType.IDENTITY)<br/>    private Long id;<br/><br/>    private int totalAmount;<br/><br/>    private int reservedAmount = 0;<br/><br/>    @Version<br/>    private Integer version;<br/><br/>		/***/<br/>}<br/></code></p><p id="0ab3499b-0435-49b2-80ba-54b48ea64d48" class="">DB의 Ticket 테이블에는 아래와 같이 version 칼럼이 추가되었다.</p><figure id="6d7f72d8-a044-4cf3-bf99-bfa7610ace99" class="image"><a href="https://tecoble.techcourse.co.kr/static/1497ddb93d5df5a437de21bc3260aca7/683d4/2023-08-16-ash-12.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/1497ddb93d5df5a437de21bc3260aca7/683d4/2023-08-16-ash-12.png"/></a></figure><p id="6ff85cce-9d78-4eb2-98a8-c0db8e82e557" class="">이제 동시 예매 테스트를 실행해 보자.</p><figure id="2002b7dd-99ff-4a51-b46d-93836b7bf8e4" class="image"><a href="https://tecoble.techcourse.co.kr/static/18ca5286a1800b6552bf57f371c5f607/bd800/2023-08-16-ash-13.png"><img style="width:290px" src="https://tecoble.techcourse.co.kr/static/18ca5286a1800b6552bf57f371c5f607/bd800/2023-08-16-ash-13.png"/></a></figure><p id="c26f7167-5cb4-4b6d-8c20-6e5c724162cb" class="">결과는 여전히 실패이다. 10장이 아닌 5장만 예매되었다.</p><p id="2cbcd7ec-9174-4d6c-b816-b9d4c4f17bfa" class="">reservation 테이블을 조회하니, 잠금을 걸지 않은 코드와 차이점을 발견할 수 있었다.</p><figure id="ba938a20-726a-4d63-bdbe-a7076c69452e" class="image"><a href="https://tecoble.techcourse.co.kr/static/cd219d4ae481d269d8ea1671131368f5/249e2/2023-08-16-ash-14.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/cd219d4ae481d269d8ea1671131368f5/249e2/2023-08-16-ash-14.png"/></a></figure><p id="430f9bcf-7dfd-47c2-84c4-a346205744a7" class="">한 티켓이 여러 번 발급된 이전과 달리, 1~5번 티켓이 각각 한 장씩만 발급되었다.</p><figure id="474813f0-9009-4705-b162-85e45f4edce1" class="image"><a href="https://tecoble.techcourse.co.kr/static/d8349964ba560546c4370fe7984eb2d9/9e38b/2023-08-16-ash-15.png"><img style="width:308px" src="https://tecoble.techcourse.co.kr/static/d8349964ba560546c4370fe7984eb2d9/9e38b/2023-08-16-ash-15.png"/></a></figure><p id="c6b650bc-4216-49e3-8f8d-0bee42ea950a" class="">사용자 수를 100명으로 늘리고 다시 테스트를 실행하니 10장이 다 발급되었다.</p><p id="113c8c29-bd56-4a81-ab47-dafc867586dc" class="">위와 같은 상황이 발생한 이유에 대해 알아보자.</p><p id="e93a55b4-aa3b-43d1-956c-1b0ba4df1bbc" class="">낙관적 잠금을 사용하면 아래와 같이 버전 정보가 update문의 조건으로 포함된다.</p><figure id="7a9d9128-21d9-4937-9efd-cc739f41e20e" class="image"><a href="https://tecoble.techcourse.co.kr/static/f4483cb15aa12d529de117839109ce5d/29984/2023-08-16-ash-16.png"><img style="width:382px" src="https://tecoble.techcourse.co.kr/static/f4483cb15aa12d529de117839109ce5d/29984/2023-08-16-ash-16.png"/></a></figure><p id="f53fecd9-7d00-4141-a363-0e90f2c8e708" class="">일부 요청에서 데이터를 읽어왔을 때의 버전 정보와 현재 DB의 버전 정보가 일치하지 않아 요청에 실패한 것이다.</p><figure id="26c96f64-cbe4-40f6-abd5-61454348bc56" class="image"><a href="https://tecoble.techcourse.co.kr/static/610cd73b5014848934fa470368cb463b/3553b/2023-08-16-ash-17.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/610cd73b5014848934fa470368cb463b/3553b/2023-08-16-ash-17.png"/></a></figure><p id="6c05cb15-e9c4-4172-80ad-00107e72cb40" class="">위 그림과 같이 트랜잭션 1과 트랜잭션 3은 버전 충돌이 없어 티켓 예매에 성공하였지만, 트랜잭션 2는 트랜잭션 1에서 업데이트한 버전과 충돌이 생겨 update문이 성공적으로 수행되지 못하였다.</p><p id="19247e67-ac19-41de-936e-b639b30ba9e0" class="">낙관적 잠금은 버전 불일치 시 처리를 어플리케이션 레벨에서 담당하게 된다. 이는 티켓 예매 요청이 버전 충돌로 인해 실패할 경우, 직접 예외를 처리하여 재시도하는 로직을 구현해야 함을 뜻한다.</p><p id="58854c7e-a1b0-4244-971b-d8f66aa8dd82" class="">이러한 재시도 로직을 AOP를 통해 구현해보자.</p><p id="8f44891e-bc8f-4380-b53a-0982fa967b4c" class="">먼저 @Retry 어노테이션을 정의한다.</p><p id="ef6d2972-dbce-433c-9f4c-4cb40393bd4d" class=""><code>@Retention(RetentionPolicy.RUNTIME)<br/>@Target(ElementType.METHOD)<br/>public @interface Retry { }<br/></code></p><p id="41e9cb19-bbbf-40a7-b896-8baca689d84a" class="">다음은 낙관적 잠금 재시도 로직을 구현한 Aspect이다. 최대 1000번까지 0.1초 간격으로 재시도하도록 했다.</p><p id="23ef28fa-ce6b-452e-9583-47fecdd5f93e" class=""><code>@Order(Ordered.LOWEST_PRECEDENCE - 1)<br/>@Aspect<br/>@Component<br/>public class OptimisticLockRetryAspect {<br/><br/>    private static final int MAX_RETRIES = 1000;<br/>    private static final int RETRY_DELAY_MS = 100;<br/><br/>    @Pointcut(&quot;@annotation(Retry)&quot;)<br/>    public void retry() {<br/>    }<br/><br/>    @Around(&quot;retry()&quot;)<br/>    public Object retryOptimisticLock(ProceedingJoinPoint joinPoint) throws Throwable {<br/>        Exception exceptionHolder = null;<br/>        for (int attempt = 0; attempt &lt; MAX_RETRIES; attempt++) {<br/>            try {<br/>                return joinPoint.proceed();<br/>            } catch (OptimisticLockException | ObjectOptimisticLockingFailureException | StaleObjectStateException e) {<br/>                exceptionHolder = e;<br/>                Thread.sleep(RETRY_DELAY_MS);<br/>            }<br/>        }<br/>        throw exceptionHolder;<br/>    }<br/>}<br/></code></p><p id="e61bed1b-a7ca-433c-bd7f-292f828a6bce" class="">다음과 같이 ticketing 메서드에 @Retry 어노테이션을 적용하면 낙관적 잠금에서 버전이 맞지 않을 때 재시도한다.</p><p id="16c28ef1-6ae2-46c3-8606-6e566642f6f4" class=""><code>@Retry<br/>@Transactional<br/>public void ticketing(long ticketId, long memberId) {<br/>    Ticket ticket = ticketRepository.findByIdForUpdate(ticketId)<br/>        .orElseThrow(() -&gt; new IllegalArgumentException(&quot;Ticket Not Found.&quot;));<br/>    ticket.increaseReservedAmount();<br/>    int sequence = ticket.getReservedAmount();<br/>    reservationRepository.save(new Reservation(ticket, sequence, memberId));<br/>}<br/></code></p><figure id="171b8405-2565-4704-afc0-a75a117a6b13" class="image"><a href="https://tecoble.techcourse.co.kr/static/ce10ab1adffb731a10bd79002b5477f7/c4cd0/2023-08-16-ash-18.png"><img style="width:328px" src="https://tecoble.techcourse.co.kr/static/ce10ab1adffb731a10bd79002b5477f7/c4cd0/2023-08-16-ash-18.png"/></a></figure><p id="31590b2c-155b-4493-9589-e054bf463b14" class="">테스트 실행 결과 성공적으로 10장의 티켓이 예매되었지만, 이때 주의할 점이 있다.</p><p id="30352f81-566e-4ca9-9cb1-00e85d79cb9a" class="">그것은 요청이 들어온 순서대로 처리되는 것이 아니라, 재시도의 타이밍에 따라 결정된다는 점이다.</p><p id="66f2f54d-e1c7-407b-9c83-0ddaf759d941" class="">이는 요청의 순서에 따라 티켓 번호를 할당해야하는 상황에서는 적절하지 않다.</p><h3 id="211ecbaa-b0f5-4163-89fc-9a2964ab3d66" class=""><strong>비관적 잠금</strong></h3><p id="6223a017-2d4b-46c0-a6d3-7bbf8e3bcb24" class="">그러면 이제 비관적 잠금을 통해 해결해 보자.</p><p id="5c58f7dc-c8c0-4494-8667-fad357d73934" class="">아래와 같은 방법으로 비관적 잠금을 적용해 보았다. 우리는 Ticket의 reservedAmount를 갱신해줘야 하기 때문에 PESSIMISTIC_WRITE 즉, 배타적 잠금을 걸었다.</p><p id="67aced89-0bc0-4c78-9dd6-923d2d087aba" class=""><code>public interface TicketRepository extends JpaRepository&lt;Ticket, Long&gt; {<br/><br/>    @Lock(LockModeType.PESSIMISTIC_WRITE)<br/>    @Query(&quot;select t from Ticket t where t.id = :id&quot;)<br/>    Optional&lt;Ticket&gt; findByIdForUpdate(@Param(&quot;id&quot;) Long id);<br/>}<br/></code></p><p id="3f7834b3-3cb4-4cb5-9eb7-cd290568c388" class=""><code>@Transactional<br/>public void ticketing(long ticketId) {<br/>    Ticket ticket = ticketRepository.findByIdForUpdate(ticketId)<br/>        .orElseThrow(() -&gt; new IllegalArgumentException(&quot;Ticket Not Found.&quot;));<br/>    ticket.increaseReservedAmount();<br/>    int sequence = ticket.getReservedAmount();<br/>    reservationRepository.save(new Reservation(ticket, sequence));<br/>}<br/></code></p><p id="9f45a031-8634-478b-9217-460d3911737c" class="">테스트 실행 결과 정확히 10장만 발급하는 데 성공했다.</p><figure id="ef57385d-2753-4caf-bdc5-5aee5ed3a8aa" class="image"><a href="https://tecoble.techcourse.co.kr/static/ce10ab1adffb731a10bd79002b5477f7/c4cd0/2023-08-16-ash-18.png"><img style="width:328px" src="https://tecoble.techcourse.co.kr/static/ce10ab1adffb731a10bd79002b5477f7/c4cd0/2023-08-16-ash-18.png"/></a></figure><figure id="eafebbbf-abb4-4bae-a832-3206cdf4c78e" class="image"><a href="https://tecoble.techcourse.co.kr/static/dc635a507f55f85f17cc2d170ca160dc/f3cf6/2023-08-16-ash-19.png"><img style="width:700px" src="https://tecoble.techcourse.co.kr/static/dc635a507f55f85f17cc2d170ca160dc/f3cf6/2023-08-16-ash-19.png"/></a></figure><p id="35a97e37-8924-4725-b717-c30006877a52" class="">또한 출력 쿼리문에서 select for update문을 통해서 DB의 특정 row에 잠금을 거는 것을 확인할 수 있었다.</p><figure id="e4ba5e1e-3036-4b92-ac9c-d7c7f6e13ed7" class="image"><a href="https://tecoble.techcourse.co.kr/static/f9a3c367ab55bed5c7bef89adb942c3a/c52b7/2023-08-16-ash-20.png"><img style="width:470px" src="https://tecoble.techcourse.co.kr/static/f9a3c367ab55bed5c7bef89adb942c3a/c52b7/2023-08-16-ash-20.png"/></a></figure><p id="68be7701-33c9-4305-98b8-697a99fe667f" class="">이렇게 비관적 잠금을 통해 동시 예매에서 발생하는 문제상황을 해결할 수 있었다.</p><p id="11f70338-0744-45bb-8b59-332eb36802be" class="">하지만 모든 상황에서 비관적 잠금이 효율적인 해결책인 건 아니다.</p><p id="f76a5dbe-1bc1-4133-b7bd-eb1b7ab8956f" class="">비관적 잠금은 단일 DB 환경에만 적용 가능하다. 분산 DB 환경에서는 동시성 제어의 효력을 잃는다.</p><p id="b1a1ea67-6330-4234-936a-6a3057400ede" class="">또한, 많은 대기 시간이 발생한다는 단점도 존재한다. 한 트랜잭션이 완료되기 전까지 다른 트랜잭션들은 대기상태에 빠진다. 동시에 많은 요청이 들어왔을 때, 사실상 하나의 요청씩만 작업할 수 있으므로 요청의 수가 많아지면 대기 시간이 길어진다.</p><p id="38907524-7a83-4b27-a4a8-7eaeb9b54035" class="">우리는 단일 DB 환경이고, 몇만 건의 동시 요청이 예상되는 상황은 아니므로 위의 단점들이 치명적이진 않다고 판단했다. 따라서 간단하게 적용할 수 있고 데이터의 정합성을 보장하는 비관적 잠금을 통한 해결책을 채택했다.</p><h1 id="e0eba822-3d5d-4db3-9a88-e9abe47f68f7" class=""><strong>마무리</strong></h1><p id="95682564-829f-4483-a429-5a611f9dcbeb" class="">티켓 예매 예제를 통해 동시 예매 상황에서 발생할 수 있는 문제 상황과 그에 대한 해결책들을 알아봤다.</p><p id="d969c769-a366-4a73-8271-f027a2e2fa92" class="">메세지큐 도입이나 분산 잠금 등의 다른 해결책들도 많이 존재하지만, 우선 가장 간단하게 해결할 수 있는 방법인 비관적 잠금을 통해 해결했다.</p><p id="5c4eeaf7-1af9-4317-8f4c-deeeba839771" class="">서비스가 커지며 분산 DB 환경이 되거나, 현 상황에서 발생할 수 있는 문제가 발견된다면 그때 다른 구조를 도입하도록 하자.</p><figure id="7e88a276-4974-4001-9653-63bb48ad59af"><a href="https://tecoble.techcourse.co.kr/post/2023-08-16-concurrency-managing/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">선착순 티켓 예매의 동시성 문제: 잠금으로 안전하게 처리하기</div><div class="bookmark-description">…</div></div><div class="bookmark-href">https://tecoble.techcourse.co.kr/post/2023-08-16-concurrency-managing/</div></div><img src="https://tecoble.techcourse.co.kr/static/5b2d6e0cda9f8f90b89f0e9ab9af1d38/80fa0/ash-concurrency.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="dee7cf64-8f57-4b28-904b-638b8b7e7176" class="toggle"><li><details open=""><summary>Naver - 일 3,000만 건의 네이버페이 주문 메시지를 처리하는 Kafka 시스템의 무중단 전환 사례</summary><p id="a4877610-13f8-4ae5-ac68-2c3b3115d8ce" class="">대규모 데이터를 안정적이고 빠르게 처리하기 위해 이미 오래 전부터 많은 서비스에서 Kafka를 사용해왔습니다. 한 번 Kafka 메시지 토픽을 구축하고 나면 다양한 컨슈머 서비스를 연계하여 사용하기가 너무나도 쉽지만, 그만큼 변경하기는 시간이 지날수록 점점 더 어려워질 수밖에 없습니다.</p><p id="effc6fe1-2147-4cd6-a97a-c11215ae1581" class="">이 글에서는 메시지를 일 3,000만 건씩 발행하고 있던 네이버페이 주문 메시징 시스템을 재설계하면서 고민했던 지점과 무중단 전환 방법을 공유하고자 합니다.</p><h1 id="9a7bdc78-3f49-47b0-86b6-d7ef5eb9b865" class="">배경 설명</h1><p id="73c9a641-c5b4-49be-9a26-97c83c7a2fbb" class="">가장 먼저 이번 글의 주제인 네이버페이 주문 메시징 시스템을 간략하게 소개하겠다.</p><p id="83eca6a1-b210-4bb4-92c3-52a975f43cd3" class="">주문 메시지는 네이버페이 주문에서 발생하는 모든 주문의 흐름에 대한 이벤트가 발생할 때 주문 관련 정보를 모두 담아 연관 시스템에 전파된다. 예를 들어, 고객이 주문을 위해 결제를 완료했을 때, 판매자가 상품을 발송했을 때, 택배사가 배송을 완료했을 때, 고객이 구매를 확정했을 때 등 주문에 연관된 다양한 액션이 이루어질 때마다 주문 정보를 업데이트하며 전파된다.</p><h3 id="184691b2-6107-4bc0-abf0-d2ab4b2afbd9" class="">트랜잭셔널 아웃박스 패턴</h3><p id="143d18d0-846e-4460-8453-99f6634114de" class="">기존 시스템의 흐름을 간략하게 표현하면 다음과 같다.</p><figure id="b02e057f-ceea-4a7e-9841-5ab105b0a4fa" class="image"><a href="https://d2.naver.com/content/images/2024/02/05-1.png"><img src="https://d2.naver.com/content/images/2024/02/05-1.png"/></a></figure><p id="2bf5038b-b26f-4840-b485-368fc75d8814" class="">위 다이어그램에서는 많이 생략했지만 주문 메시지에 들어가는 데이터는 500개 이상의 필드로 구성된 대용량 메시지로, 만약 API에서 주문 액션이 생길 때마다 해당 데이터를 만든다면 사용자 측면에서 처리 성능이 떨어지고 서버 자원 활용 측면에서 큰 비용이 든다.</p><p id="9b983fc7-de91-40b6-bfe1-c0015b1ff716" class="">이를 해결하고자 네이버페이 주문 메시징 시스템은 DB 트랜잭션이 성공할 때만 메시지 발행을 보장하는 <a href="https://microservices.io/patterns/data/transactional-outbox.html">트랜잭셔널 아웃박스 패턴</a>을 이용해 별도 배치 서비스에 주문 메시지 발행을 위임하는 형태로 구성되어 있었다. 아웃박스 테이블에는 주문 액션이 일어날 때 주문에 대해 키가 될 수 있는 주문 번호, 주문 액션 타입 등의 최소한의 데이터만 DB 트랜잭션에 포함해 저장하고, 주문 메시지 폴링 배치 모듈에서는 응용 단에서 해당 키 데이터를 짧은 주기로 반복해서 읽어가는 <a href="https://microservices.io/patterns/data/polling-publisher.html">폴링 퍼블리셔 패턴</a>을 이용해 데이터를 조합해 주문 메시지를 만들고 메시지를 발행하는 방식이다.</p><h3 id="0f1fe9c8-ee85-40e0-b656-0b380c97df89" class="">아키텍처 재설계</h3><figure id="40dc21bf-b535-49e7-ac27-91ef72b79397" class="image"><a href="https://d2.naver.com/content/images/2024/02/06-1.png"><img src="https://d2.naver.com/content/images/2024/02/06-1.png"/></a></figure><p id="08e0e125-38be-4b53-b3bb-f9b550ea0955" class="">기존 아키텍처가 오랫동안 잘 동작하고 있었지만 네이버페이 주문량이 늘어나면서 몇 가지 문제점이 생겼다.</p><ul id="cb0afdce-ab4b-43c6-8e8c-af688158c5fb" class="bulleted-list"><li style="list-style-type:disc">공용 Kafka를 사용하면서 다른 토픽들과의 Kafka 리소스 경쟁 발생</li></ul><ul id="c44f8a05-2668-4c44-a575-6da6ee4dcfe5" class="bulleted-list"><li style="list-style-type:disc">발행 요청 메시지가 많아지면서 메시지 발행 지연 현상 발생</li></ul><ul id="4d4dadac-ba64-4563-8bb0-6c562994a1ff" class="bulleted-list"><li style="list-style-type:disc">메시지 발행이 지연되면서, 주문 데이터가 메시지 발행 당시 데이터가 아닌 변경된 최신 상태 데이터 제공</li></ul><p id="7b85d138-848c-49d9-871a-f3e8c6ee1778" class="">위 문제점 중에서도 특히 주문 메시지 발행이 지연되면 사용자에게 결제 내역이 노출되지 않아 사용자 불편 사항이 생길 수 있다거나 정산 처리가 지연되어 운영 손실이 생길 수 있는 등의 사용자 불편 사항이 발생할 수 있었기 때문에 전면적으로 아키텍처를 재설계해 위 문제점들을 해결하고자 했다.</p><ul id="ebb9dd29-5c46-4bc6-974d-ce9e9df7eab0" class="bulleted-list"><li style="list-style-type:disc">주문 메시지를 위한 전용 Kafka 클러스터를 사용</li></ul><ul id="99168672-8a77-4bdb-97d2-b84fbf114ff3" class="bulleted-list"><li style="list-style-type:disc">자체 개발한 CDC(Change Data Capture)를 활용해, 트랜잭셔널 아웃박스 패턴의 구현 방식을 <a href="https://microservices.io/patterns/data/transaction-log-tailing.html">트랜잭션 로그 테일링 패턴</a>으로 개편하면서 처리 성능과 안정성 개선</li></ul><h1 id="32f35044-5013-4fa7-b05e-1a179ee50eb8" class="">Kafka 시스템 전환 시 발생할 수 있는 문제</h1><p id="0f9d6159-d224-4a30-89bb-7a5864891da6" class="">위 아키텍처 그림들만 보면 크게 변경된 사항이 없어 보이지만, 실제로는 핵심 모듈인 주문 메시지 발행 모듈과 Kafka 브로커가 완전히 변경되어 고민해야 할 문제가 많았다.</p><h3 id="c5160cea-3261-457f-abcf-404ba3a362b5" class="">신규 메시지 신뢰성 보장</h3><p id="6e87b823-8040-456a-96f8-b165827a061e" class="">주문 메시지를 발행하는 모듈을 새로 만들면서 가장 우려했던 점은 &#x27;메시지 데이터의 신뢰성을 보장할 수 있는가&#x27;였다. 작업 과정에서 단순히 코드를 재배치한 것이 아니라 쿼리를 최적화하고 로직을 재설계하는 등, 완전히 새로운 프로젝트를 만드는 수준으로 대부분의 코드를 변경했기 때문에 개발 환경 검증이나 QA 검증만으로는 신뢰성을 보장하기 어려웠다.</p><p id="e8e0b8aa-223a-40cc-afaf-2e69d3aa5c89" class="">특히 위에서도 언급했던 것처럼, 주문 메시지 자체가 수많은 데이터를 담고 있고 민감한 서비스에서 데이터를 소비하고 있었기 때문에 주문 메시지 데이터에 이상이 생긴다면 큰 운영 손실까지 발생할 수 있는 상황이었다. 그렇기 때문에 가능한 한 완벽하게 검증하여 데이터의 신뢰성을 확보하는 것은 매우 중요했다.</p><p id="e3363185-c911-4ad7-a764-2e806958d480" class="">여기서 우리는 &#x27;신뢰성을 확보함&#x27;의 기준을 기존 메시지와 동일한지 여부로 판단했다. 메시지 생성 과정에서 로직이 변경되면서, 일부 메시지 데이터가 달라지거나, 발행되었어야 하는 메시지가 발행되지 못하거나, 반대로 발행되면 안 되는 메시지가 발행될 수도 있을 것이다. 예상되는 이상 케이스를 정리하면 다음과 같다.</p><ol type="1" id="68208346-dc1b-46d2-98a6-b4fb19fa0713" class="numbered-list" start="1"><li>주문 메시지 스펙이 달라짐</li></ol><ol type="1" id="37b71b69-17dc-47ce-862d-6ceb4bcf6c0f" class="numbered-list" start="2"><li>주문 메시지 발행이 누락됨</li></ol><ol type="1" id="4558d1da-f5ae-4747-aa59-5d3466c0373b" class="numbered-list" start="3"><li>주문 메시지 중복 발행</li></ol><ol type="1" id="bd306554-a8b1-4190-927e-25392444e9eb" class="numbered-list" start="4"><li>의도하지 않은 주문 메시지 발행</li></ol><p id="59896555-ef40-4931-a7ef-8f33c36a8e2d" class="">위 케이스들을 크게 2가지 이슈로 분류하면, 1번 케이스는 약속된 메시지 스펙이 보장되는지 여부, 2, 3, 4번 케이스는 약속된 메시지만 발행되는지 여부라고 볼 수 있다. 신규 시스템에서 이 2가지 이슈를 검증하여 신뢰성을 보장하기 위해, 다음과 같이 운영 환경에서 메시지를 두 벌로 발행하는 검증 시스템을 구축했다.</p><figure id="c5d99de5-3aac-4662-b104-19f78cbbc18a" class="image"><a href="https://d2.naver.com/content/images/2024/02/07-1.png"><img src="https://d2.naver.com/content/images/2024/02/07-1.png"/></a></figure><h3 id="e678f754-7256-4d03-aadb-d471070a9cac" class="">메시지 정합성 검증</h3><figure id="295effd8-5053-43b1-b4b7-b06f51da1e8d" class="image"><a href="https://d2.naver.com/content/images/2024/02/08-1.png"><img src="https://d2.naver.com/content/images/2024/02/08-1.png"/></a></figure><p id="65061eba-8c95-4af7-ab91-6b92eb6463b3" class="">먼저 정합성 검증 로직을 살펴보면 다음과 같다.</p><ol type="1" id="2cbc6a86-e504-4337-804d-3381c603961d" class="numbered-list" start="1"><li>정합성 검증 컨슈머는 기존 주문 메시지를 소비한다.</li></ol><ol type="1" id="52eb20ff-da70-413a-8d40-ea296d5a4e09" class="numbered-list" start="2"><li>주문 Key에 필요한 데이터를 추출한다.</li></ol><ol type="1" id="fc3aadbe-f826-428a-873c-16e7275d1734" class="numbered-list" start="3"><li>신규 모듈에서 주문 메시지를 생성하는 로직을 수행해 검증용 주문 메시지를 생성한다.</li></ol><ol type="1" id="68b281ce-b35a-4722-bfb6-506a7060370e" class="numbered-list" start="4"><li>기존 주문 메시지와 검증용 주문 메시지 데이터를 비교한다.</li></ol><p id="5ed8f1be-e4ab-49a4-b35d-d64e583a4a21" class="">운영 환경에서 기존 주문 메시지를 소비하는 정합성 검증기는 실시간으로 메시지를 비교 검증해 검출된 메시지를 로그로 남긴다. 이를 통해 신규 메시징 시스템에서 약속된 메시지 스펙을 보장할 수 있다.</p><p id="cb9edd57-11d0-4f7d-a272-975c50afae82" class="">위 로직에서 주의할 점은 메시지 생성 시점에 따라 달라지는 메시지 스펙이 있을 수 있으니 해당 데이터 값에 대해서는 검증 민감도를 조절해야 한다는 것이다.</p><h3 id="c323fa09-1f3d-4e56-a07e-0a6d5351a518" class="">메시지 발행 검증</h3><figure id="922f3fae-123e-4926-81a1-22fed0e3cc37" class="image"><a href="https://d2.naver.com/content/images/2024/02/09-1.png"><img src="https://d2.naver.com/content/images/2024/02/09-1.png"/></a></figure><p id="f83a3105-d6e8-40c5-bed0-ec0b52b88de0" class="">발행 검증 로직은 다음과 같다.</p><ol type="1" id="274637c2-7fde-4f26-8db9-b8cd08b01db9" class="numbered-list" start="1"><li>기존 주문 메시지를 소비하여 메시지 Key 데이터를 저장소에 저장한다.</li></ol><ol type="1" id="5104afb7-7e3a-42fa-8dff-039f4070c181" class="numbered-list" start="2"><li>신규 주문 메시지를 소비하여 메시지 Key 데이터를 저장소에 저장한다.</li></ol><ol type="1" id="81faa79b-5bce-4d7e-88ae-f652cf0244a5" class="numbered-list" start="3"><li>발행 검증 배치 모듈에서 저장소 데이터를 조회해 양쪽 데이터가 동일하게 발행되었는지 검증한다.</li></ol><p id="d5f487ca-7756-4f50-a428-151fb46786b1" class="">발행 검증기에서는 상세한 메시지 스펙보다는 발행 여부가 중요한 검증 요건이기 때문에 메시지의 동일성을 보장할 수 있는 Key 데이터만을 별도 저장소에 저장하고 비교 검증한다. 이를 통해 신규 메시징 시스템에서 약속된 메시지 발행을 보장할 수 있다.</p><h3 id="11fc0358-d642-47fc-a9ba-b7a42082f2ca" class="">실제 검증 결과</h3><p id="e1c85bfa-fc16-45a4-915c-2936daf60e26" class="">실제로 이 검증기를 이용한 검증 기간 중 다음과 같은 여러 케이스가 실시간으로 검출되어 수정하면서, 신규 주문 메시지의 신뢰성을 높일 뿐만 아니라 전환 작업에 자신감도 얻을 수 있었다.</p><ul id="6e58ea67-9ce7-49ab-8c5a-70f7aa3adab7" class="bulleted-list"><li style="list-style-type:disc">메시지 생성 누락된 필드</li></ul><ul id="a3744d08-b9da-495d-b266-33bfaa83963f" class="bulleted-list"><li style="list-style-type:disc">기존과 다른 값으로 메시지 생성된 필드</li></ul><ul id="3b49f923-8367-4650-bddf-e8d4e82a7b98" class="bulleted-list"><li style="list-style-type:disc">암호화가 필요한 필드이나 암호화되지 않고 생성된 필드</li></ul><ul id="3edb283c-de82-4218-9c80-25a903db0072" class="bulleted-list"><li style="list-style-type:disc">작업 과정 중 기존 메시징 시스템에 추가된 신규 스펙</li></ul><h1 id="5cf7c9cc-9442-4320-94d2-d32945f8055e" class="">Kafka 시스템 무중단 전환</h1><p id="243ad87f-5c59-4314-bed0-cbd90cc0b818" class="">검증기 수행을 통해 메시지의 신뢰성을 확보했지만 아직 중요한 관문이 하나 더 남아있었다. Kafka 시스템은 실시간으로 대용량 데이터를 처리하기 때문에 안정적인 전환 전략을 강구하는 것이 무엇보다도 중요했다.</p><h3 id="e95581df-33cf-4e3b-a793-2876cf1b0f3c" class="">전환 과정에서 발생할 수 있는 문제</h3><p id="3582e6b2-9d6d-41fb-b750-c81843e38d84" class="">이번 전환 과제에서 단순히 메시지를 발행하는 Producer만 변경된 것이 아니라 Kafka 브로커 자체가 변경되었기 때문에, 일반적인 방식으로 단순히 컨슈머가 Kafka 브로커 주소만 변경한다면 컨슈머 그룹 오프셋이 초기화되어 컨슈머의 메시지 소비가 누락되거나 혹은 메시지가 중복으로 소비되는 이슈가 발생할 수 있다.</p><figure id="2560faa7-7d8a-42cf-8805-8f1bd9a43742" class="image"><a href="https://d2.naver.com/content/images/2024/02/10-1.png"><img src="https://d2.naver.com/content/images/2024/02/10-1.png"/></a></figure><p id="e942b146-25c1-48ed-af91-32cef4bd9e10" class="">처음 생각한 해결책은 컨슈머들에서 중복 소비에 대한 멱등성을 보장하고 있다는 가정 하에 브로커 전환 시 컨슈머의 start-offset을 earliest로 설정하고 중복 메시지를 허용하는 방식으로 전환하는 방법이었다. 이 방법은 컨슈머를 직접 통제할 수 있는 상황이라면 가장 유용하겠지만, 멱등성이 보장되지 않는 컨슈머를 많은 부서에서 오래 전부터 사용하고 있었기 때문에 우리의 상황에서는 부적합한 면이 있었다.</p><p id="c08e3e06-3497-47f3-8b96-e1c42484ac95" class="">더 간단한 해결책으로는 컨슈머들의 전환 기간 동안 메시지 발행을 멈춰두고 한 번에 전환하는 방법이 있다. 다만 이 방법 역시 많은 컨슈머에서 동시에 작업해야 한다는 점에서 우리의 상황에는 부적합하다고 판단했다. 특히 무엇보다도 실시간 처리가 중요한 컨슈머들이 있었기 때문에 중단 시간이 길어지면 큰 문제가 발생할 수 있었다.</p><h3 id="9f6bfa43-bf3e-49d9-98c4-ba4e7b871386" class="">무중단 전환을 위한 방법</h3><p id="f3098fd1-ebc2-4672-95e4-18bf49fc132c" class="">전환 전략을 세우면서 중요하게 생각한 도전 과제는 다음과 같다.</p><ul id="df1e18a3-7b11-40f6-a675-80c48826551e" class="bulleted-list"><li style="list-style-type:disc">전환 과정에서 중단은 순간적이어야 한다.</li></ul><ul id="2433334e-9c15-45c2-9fdb-97b13c8bf940" class="bulleted-list"><li style="list-style-type:disc">전환 과정에서 여러 컨슈머가 개별적으로 브로커를 전환할 수 있어야 한다.</li></ul><figure id="c21f698c-f9da-4769-94a2-2edb50601dad" class="image"><a href="https://d2.naver.com/content/images/2024/02/11-1.png"><img src="https://d2.naver.com/content/images/2024/02/11-1.png"/></a></figure><p id="5ba48ff8-ad4f-41d8-8bf9-c9781d74e861" class="">위 도전 과제를 해결하기 위해 선택한 방식은 복제를 활용한 점진적 전환이었다. 전환 과정을 단계별로 정리하면 다음과 같다.</p><p id="135f6ea8-8910-4ab4-be83-d66ac929119c" class="">1. 신규 Kafka 브로커에 주문 메시지를 발행하던 신규 발행 모듈에서 발행을 중지한다.</p><p id="a0187baf-2a2a-48f1-9f26-22ed687761cc" class="">2. MirrorMaker를 활용해 기존 Kafka 브로커에 발행되던 주문 메시지를 신규 Kafka 브로커로 복제한다.</p><p id="8292da20-5bb5-4e29-9f08-91cc41e0dc1d" class="">3. 컨슈머에서 리스너를 신규 Kafka 브로커로 변경한다.</p><p id="197f692a-b769-44aa-8d43-6534454217c3" class="">여기에서 주의할 점은, 토픽을 복제해도 리스너가 새로운 브로커로 변경되면서 컨슈머 그룹 오프셋이 초기화될 수 있다는 것이다. 따라서 MirrorMaker로 복제할 때 메시지와 함께 컨슈머 그룹 오프셋까지 함께 복제해야 컨슈머가 메시지를 소비한 위치를 기억하고 누락 및 중복 없이 연속해서 메시지를 소비할 수 있다. 이때 주의할 점이 몇 가지 있다.</p><ul id="5d951fc0-d81d-41b4-8165-9578a9ebba9e" class="bulleted-list"><li style="list-style-type:disc">컨슈머가 Kafka 브로커를 변경할 때 컨슈머 그룹 ID는 동일하게 설정해야 오프셋도 잘 승계받아서 소비할 수 있다.</li></ul><ul id="92d3c4a5-e443-4a8e-87ce-642ce61f491e" class="bulleted-list"><li style="list-style-type:disc">실시간 복제가 일어나고 있는 상황이기 때문에 컨슈머가 브로커 전환 시 기존 Kafka 브로커와 신규 Kafka 브로커를 동시에 소비하면 오프셋 설정이 꼬이면서 중복 소비가 발생할 수 있다. 컨슈머가 BlueGreen 배포 방식으로 배포하는 경우 문제가 생길 수 있으니 주의해야 한다.</li></ul><ul id="ed6a27f1-bdd8-419a-ac7d-399e615b3184" class="bulleted-list"><li style="list-style-type:disc">MirrorMaker에서 컨슈머 그룹 오프셋 동기화는 실시간으로 이루어지지 않고 주기적으로 이루어진다. 동기화 시간 확보를 위해 interval 설정값에 따라 컨슈머의 전환 과정에서 중단 시간을 조절하는 것이 안전하다(최소 interval 설정값: 1초).</li></ul><p id="36e8eeaf-9538-4b31-a6ba-8d392008e6fe" class="">우리 시스템 전환 작업에서는 위와 같은 방식으로 총 3주에 걸쳐 약 30여 개의 컨슈머에 대해 순간적인 중단을 제외하고는 무중단으로 Kafka 브로커 전환을 완료할 수 있었다.</p><p id="092f0f55-c9ec-4237-8393-0cb5fb4a7433" class="">위 단계까지 해서 모든 컨슈머가 신규 Kafka 브로커로 이전이 완료되었기 때문에 다음 단계로는 주문 메시지를 신규 발행 모듈에서 발행되는 메시지로 교체하는 일이 남았다.</p><figure id="c3a2afc8-b801-4f0b-bf1e-1a08c87e6ac6" class="image"><a href="https://d2.naver.com/content/images/2024/02/12-1.png"><img src="https://d2.naver.com/content/images/2024/02/12-1.png"/></a></figure><p id="2ec2a3da-3694-4cdc-9063-b71a9c6f3496" class="">그 과정은 다음과 같다.</p><p id="cc4654e4-65ff-4123-a7e0-183ddbc17ee5" class="">4. 제어 가능한 스위치를 주문 API에 추가하여 메시지 발행 위치를 구분할 수 있도록 한다.</p><p id="fcf6da9a-a4b9-4b67-8ed6-97d72276511e" class="">5. 1번에서 중지한 신규 발행 모듈에서 주문 메시지 발행을 재개한다.</p><p id="333419d9-f83d-4e10-8379-e4182c3a2494" class="">6. 4번에서 추가한 발행 제어 스위치를 조작해 신규 발행 모듈에서 주문 메시지를 생성하도록 제어한다.</p><p id="75cb43be-dfd9-4f12-8dcd-e6044b1c8f6e" class="">이때도 발행 제어 스위치에서 모든 메시지에 대해 한 번에 발행 모듈을 전환하지 않고, 주문 고객 ID를 발행 제어 키로 두고 이 키 값에 따라서 특정 비율로 전환하는 방식으로 영향도를 확인하면서 점진적으로 전환했다.</p><p id="28c2a3ce-9da3-4651-b11b-90dd1cca87f8" class="">이때도 주의할 점이 있는데, 양쪽 발행 모듈에서 동일한 Kafka 파티션에 메시지가 생성될 수 있기 때문에 순서를 보장하기 위해서는 파티션 키가 되는 값을 기준으로 발행 제어에 적용해야 한다는 것이다. 만약 발행 제어 스위치 키와 Kafka 파티션 키가 다른 값으로 설정되면 기존 발행 모듈과 신규 발행 모듈 양쪽에서 주문 메시지가 발행되면서, 순서가 보장되어야 하는 메시지들이 MirrorMaker 복제 시간에 따라 순서가 보장되지 않을 수 있다.</p><p id="92676da7-6f51-45be-ac8c-6bc0a1d8c858" class="">여기까지 해서 기존 버전 Kafka 브로커에는 더 이상 주문 메시지가 생성되지 않고 MirrorMaker 복제 프로세스도 종료되었다.</p><figure id="ae07fa88-5734-4a0a-bae4-651ff5eef540" class="image"><a href="https://d2.naver.com/content/images/2024/02/13.png"><img src="https://d2.naver.com/content/images/2024/02/13.png"/></a></figure><p id="b8728af8-89c2-4940-ba95-d45ac594a305" class="">전환이 완료된 모습은 기대했던 대로 &#x27;신규 주문 메시지 발행 컨슈머 모듈&#x27;에서 주문 메시지를 발행하고 &#x27;신규 Kafka 브로커&#x27;를 컨슈머들이 소비하는 그림이 되었다.</p><h1 id="91361246-8de6-483b-82cf-fe4b16e29861" class="">마치며</h1><p id="5e4d84ec-b955-46ac-95e5-002bb435c3ed" class="">지금까지 네이버페이의 주문 메시지 전파 시스템을 개편하는 과제를 진행하면서 사용한 전환 전략을 정리했다.</p><p id="cfa3b450-c05f-43e0-9604-c755b636efa2" class="">오랫동안 사용되어온 Kafka 시스템에 변화를 준다는 것은 높은 위험 영향도를 감수하고 진행해야 하는 작업일 수밖에 없다. 우리도 이번 과제를 진행하면서 문제될 수 있는 영향도를 미리 파악하고 안정적으로 시스템 전환을 마무리 짓는 것을 최우선으로 생각하며 다양한 전략을 시도하고 테스트하며 많은 시행착오를 겪었다. 또한 대규모 시스템일수록 다양한 협업 팀들에 영향을 끼칠 가능성이 높으므로 미리 협업 팀들과도 전환 전략을 공유하며 작업 협조를 구해두는 것이 중요하다. 이 자리를 빌려 전환 작업 중에 적극 협조해 준 협업 팀의 동료 개발자들에게 한 번 더 감사의 말씀을 전한다.</p><figure id="459a6774-0ad5-482c-89eb-74ab50471a36"><a href="https://d2.naver.com/helloworld/9581727" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">일 3,000만 건의 네이버페이 주문 메시지를 처리하는 Kafka 시스템의 무중단 전환 사례</div><div class="bookmark-description">대규모 데이터를 안정적이고 빠르게 처리하기 위해 이미 오래 전부터 많은 서비스에서 Kafka를 사용해왔습니다. 한 번 Kafka 메시지 토픽을 구축하고 나면 다양..</div></div><div class="bookmark-href"><img src="https://d2.naver.com/favicon.ico" class="icon bookmark-icon"/>https://d2.naver.com/helloworld/9581727</div></div><img src="https://d2.naver.com/content/images/2024/03/helloworld_240306-1.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="f0a78c4d-9820-4c2c-a418-c202520273ec" class="toggle"><li><details open=""><summary>Kafka에서 파티션 증가 없이 동시 처리량을 늘리는 방법 - Parallel Consumer</summary><p id="4374d799-88eb-4d62-934d-5c590cb86402" class="">Kafka를 사용하면서 메시지 동시 처리량을 늘릴 수 있는 가장 쉬운 방법 중 하나는 파티션을 증가시키는 것입니다. 다만 파티션 수는 한번 늘어나면 줄일 수 없기에 신중해야 합니다.</p><p id="3308c442-bf56-4794-9a0f-14134572a52d" class="">Log&amp;Metric 조직에서는 Kafka를 활용하여 사내 로그 관리 시스템을 운영하고 있습니다. 방대한 양의 로그를 빠르게 처리하려다 보니 파티션 수가 굉장히 늘어나 있었으며 많은 파티션 수로 인한 사이드 이펙트도 존재했습니다. 파티션을 늘리지 않고도 동시 처리량을 늘리기 위해 고민하던 중 Parallel Consumer라는 라이브러리를 알게 되었으며 이후에 Parallel Consumer를 사용하여 적은 파티션으로 높은 동시 처리량 수준을 만족시킬 수 있었습니다.</p><p id="3e6d06c1-a95b-48f9-9205-ccde04265a91" class="">이 글에서는 Parallel Consumer가 무엇인지, 어떻게 동작하는지 그리고 내부 구조는 어떤지 간략하게 공유해 보겠습니다. Kafka Client나 Producer에 대한 자세한 설명은 <a href="https://d2.naver.com/helloworld/6560422">KafkaProducer Client Internals</a>, <a href="https://d2.naver.com/helloworld/0974525">KafkaConsumer Client Internals</a> 등을 참고 바랍니다.</p><ul id="30a4225d-f246-4e27-8ebe-3b61ced3c39a" class="bulleted-list"><li style="list-style-type:disc"><a href="https://d2.naver.com/helloworld/7181840#%EA%B7%B8%EB%83%A5-%ED%8C%8C%ED%8B%B0%EC%85%98-%EB%8A%98%EB%A6%AC%EB%A9%B4-%EC%95%88-%EB%8F%BC">그냥 파티션 늘리면 안 돼?</a></li></ul><ul id="bd985b7a-97b5-44b1-8955-03e94efceafa" class="bulleted-list"><li style="list-style-type:disc"><a href="https://d2.naver.com/helloworld/7181840#parallel-consumer%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80">Parallel Consumer란 무엇인가</a><ul id="1b0ff67c-a9cc-4ea7-9884-06ad25bd68ac" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#%ED%8C%8C%ED%8B%B0%EC%85%98-%EB%8B%A8%EC%9C%84-vs-%EB%A9%94%EC%8B%9C%EC%A7%80-%EB%8B%A8%EC%9C%84">파티션 단위 vs 메시지 단위</a></li></ul><ul id="7b44943c-e7cc-41fa-aa8c-039987b3bb78" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#%EB%A9%94%EC%8B%9C%EC%A7%80-%EB%8B%A8%EC%9C%84-%EB%B3%91%EB%A0%AC%EC%84%B1%EC%9D%B4-%EC%96%B4%EB%96%BB%EA%B2%8C-%EA%B0%80%EB%8A%A5%ED%95%9C%EA%B0%80">메시지 단위 병렬성이 어떻게 가능한가</a></li></ul></li></ul><ul id="a7615a1f-ef19-4937-8f5d-430a36625335" class="bulleted-list"><li style="list-style-type:disc"><a href="https://d2.naver.com/helloworld/7181840#parallel-consumer%EC%9D%98-%EC%88%9C%EC%84%9C-%EB%B3%B4%EC%9E%A5-%EB%B0%A9%EC%8B%9D">Parallel Consumer의 순서 보장 방식</a><ul id="b6e5443e-1ece-466e-afe0-f6919d3818b3" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#partition">Partition</a></li></ul><ul id="c13d9d5c-c5dc-49e1-8758-487895a1b849" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#key">Key</a></li></ul><ul id="3d12ebe5-9638-4039-8dd3-0587b5644430" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#unordered">Unordered</a></li></ul></li></ul><ul id="fc0efec5-4850-419f-a419-0ef5fb6c0482" class="bulleted-list"><li style="list-style-type:disc"><a href="https://d2.naver.com/helloworld/7181840#parallel-consumer%EC%9D%98-%EB%82%B4%EB%B6%80-%EA%B5%AC%EC%A1%B0">Parallel Consumer의 내부 구조</a><ul id="f6520192-ec8c-483f-ba3a-6b7ebe1b5b0d" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98">아키텍처</a></li></ul><ul id="c2f86fc6-97b4-457d-8725-86ff22133f2f" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#%EC%88%9C%EC%84%9C-%EB%B3%B4%EC%9E%A5-%EB%B0%A9%EC%8B%9D-%EA%B5%AC%ED%98%84">순서 보장 방식 구현</a></li></ul><ul id="178bb3fc-ca1c-4c96-aca4-080cbfcd2ab8" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#batchsize-delta">batchSize, delta</a></li></ul><ul id="b6bc7e03-6fe3-413d-9e62-50e2c37ffc9e" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#%EC%BB%A4%EB%B0%8B">커밋</a></li></ul><ul id="21deccc8-54c1-4492-a8fa-3b8148515426" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#%EC%98%A4%EB%A5%98%EB%A1%9C-%EC%9D%B8%ED%95%9C-%EB%A9%94%EC%8B%9C%EC%A7%80-%EC%A4%91%EB%B3%B5-%EC%B2%98%EB%A6%AC-%EB%B0%A9%EC%A7%80">오류로 인한 메시지 중복 처리 방지</a></li></ul><ul id="5552222b-e52b-4bc2-882b-22517ed2baaf" class="bulleted-list"><li style="list-style-type:circle"><a href="https://d2.naver.com/helloworld/7181840#%EC%9A%B0%EC%95%84%ED%95%9C-%EC%A2%85%EB%A3%8C">우아한 종료</a></li></ul></li></ul><ul id="fa8c177f-2ae3-4edf-ab8d-f67a01524b30" class="bulleted-list"><li style="list-style-type:disc"><a href="https://d2.naver.com/helloworld/7181840#%EC%84%B1%EB%8A%A5-%EB%B9%84%EA%B5%90">성능 비교</a></li></ul><ul id="11c1f27f-271b-4003-baa9-81eb80ec49c1" class="bulleted-list"><li style="list-style-type:disc"><a href="https://d2.naver.com/helloworld/7181840#%EB%A7%88%EC%B9%98%EB%A9%B0">마치며</a></li></ul><h1 id="b9511e29-043a-4575-a8bb-cecc1d56642a" class="">그냥 파티션 늘리면 안 돼?</h1><p id="75f59f7f-0961-42d0-9782-5d9ccd3a6b85" class="">기존 Kafka Consumer의 병렬 처리 단위는 <strong>파티션</strong>이다. 보통 파티션별 단일 컨슈머 스레드가 할당되는 구조이기 때문에 동시 처리량을 늘리기 위해서는 파티션 수 또한 늘려야 한다. 파티션을 늘리면 동시 처리량은 늘겠지만 다음과 같은 단점이 존재한다.</p><h3 id="1721d595-1639-40a3-99dc-739a392430d5" class="">1. 브로커 파일 시스템 리소스 사용량 증가</h3><p id="f0656825-36aa-4832-a597-3afcb03e65fe" class="">Kafka 브로커는 파티션별로 데이터를 저장하는데 이때 단순 데이터 정보(<code>.log</code> 파일)뿐만 아니라 메타 정보(<code>.index</code>, <code>.timeindex</code>, <code>.snapshot</code> 파일)도 함께 저장한다. 따라서 파티션이 많아질수록 많아지는 파일에 대한 파일 오픈 비용, 디스크 사용량 비용 등이 추가로 필요해진다.</p><figure id="f84ff38f-bb3e-4cce-9666-4b4749ae6c0c" class="image"><a href="https://d2.naver.com/content/images/2023/10/kafka-broker-data.png"><img src="https://d2.naver.com/content/images/2023/10/kafka-broker-data.png"/></a></figure><h3 id="28a86384-c37e-4dd7-8853-80a03bedf02d" class="">2. 장애에 더 취약한 구조</h3><p id="0fc98e0a-f9f2-4914-86b9-3087e988ae2e" class="">단일 브로커에 파티션 리더가 더 많이 배치되기 때문에 브로커 노드 장애 혹은 재시작으로 영향받는 범위가 더 넓다.</p><h3 id="9d7b91ea-b384-4b89-8d61-24ea2620d72d" class="">3. 복제 비용 증가</h3><p id="e991d2b8-a27e-44a3-8fd9-f5111291063b" class="">파티션 단위로 설정된 replicas 수만큼 복제가 이루어지기 때문에 복제로 인한 디스크 사용량, latency가 증가한다.</p><p id="d76987f8-84f8-478b-98bf-314635fa986c" class="">파티션 수가 적은 환경에서는 어쩌면 큰 문제가 아닐 수 있지만, 과도하게 늘어나 있는 환경에서는 문제가 될 수 있다.</p><h1 id="6c6f8d54-0c41-47cd-b8e6-718e87298966" class="">Parallel Consumer란 무엇인가</h1><p id="cf604693-47a0-47c8-a825-cb46f73b967b" class=""><a href="https://github.com/confluentinc/parallel-consumer">Parallel Consumer</a>는 Confluent Inc.에서 만든 오픈소스다(Apache 2.0 License). Parallel Consumer의 README를 살펴보면 이 라이브러리의 탄생 의도가 보인다.</p><figure id="7cb8723f-8979-4ac9-b053-2aa7eac733aa" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-motivation.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-motivation.png"/></a></figure><p id="a96700f0-06a7-4cd0-9701-d80f2b72f97c" class="">간단히 말하자면 Parallel Consumer란 단일 파티션에 여러 컨슈머 스레드를 사용하여 <strong>파티션을 늘리지 않고 동시 처리량을 증가시키기 위해</strong> 만들어진 라이브러리이다.</p><h3 id="14899e21-fa2f-412f-99ee-9a012c261ac0" class="">파티션 단위 vs 메시지 단위</h3><p id="4bd6ed64-35fd-4588-86ee-05146c191f12" class="">Parallel Consumer를 사용하면 병렬 처리 단위를 파티션이 아닌 <strong>개별 Kafka 메시지</strong> 또는 유사한 단위로 지정이 가능하다. 이해하기 쉽게 그림으로 비교해보면 다음과 같다. 첫 번째 그림은 일반 Kafka Consumer를 사용한 예시다. 파티션 단위로 병렬성을 달성해서 3개 메시지를 병렬로 처리하는 것을 볼 수 있다. 두 번째 그림은 Parallel Consumer를 사용한 예시다. 파티션이 한 개임에도 불구하고 복수의 스레드를 사용하여 첫 번째 그림과 동일하게 3개 메시지를 동시에 처리하는 것을 볼 수 있다.</p><figure id="096068cc-d16c-4947-82ef-3fd1b7ffa64c" class="image"><a href="https://d2.naver.com/content/images/2023/10/kafka-vanilla-consumer-parallelism.png"><img src="https://d2.naver.com/content/images/2023/10/kafka-vanilla-consumer-parallelism.png"/></a></figure><figure id="13e14bd7-18bb-4fea-bc88-8321117ecafa" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-parallelism-1.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-parallelism-1.png"/></a></figure><p id="f88a8155-001c-4a71-baa4-13ea57a1b062" class="">즉, <strong>파티션 수를 늘리지 않고도 동시 처리량을 늘릴 수 있다는 이점</strong>이 Parallel Consumer와 일반 Kafka Consumer의 차이이다.</p><h3 id="387393d3-1988-416d-9112-f966c5514e9f" class="">메시지 단위 병렬성이 어떻게 가능한가</h3><p id="738e5ba0-e660-41a1-88d7-15b506a52c99" class="">기존 Kafka에서는 파티션별로 마지막으로 처리한 오프셋을 관리하고 있고 브로커의 오프셋 정보는 컨슈머가 메시지를 처리한 후 커밋을 하면서 갱신된다. 일반적으로는 한 번에 한 개의 메시지를 처리하며 auto 커밋 방식을 많이 사용한다.</p><figure id="120f038f-2f53-4b95-9644-bc462634f1a8" class="image"><a href="https://d2.naver.com/content/images/2023/10/kafka-vanilla-consumer.png"><img src="https://d2.naver.com/content/images/2023/10/kafka-vanilla-consumer.png"/></a></figure><p id="86b19d5a-4f5f-4814-9b99-d5c87a9af4f4" class="">한 번에 한 개씩 처리하지 않고 여러 개의 메시지를 처리한 후 마지막 오프셋을 커밋할 수도 있다. 이때 커밋은 수동으로 직접 수행해야 한다.</p><figure id="c648bcfa-d73f-495a-b479-c9ce9cd827d5" class="image"><a href="https://d2.naver.com/content/images/2023/10/kafka-vanilla-batch-consumer.png"><img src="https://d2.naver.com/content/images/2023/10/kafka-vanilla-batch-consumer.png"/></a></figure><p id="35f93d7e-e7f4-4959-9148-c933f5d98e96" class="">여기서 메시지 처리는 실제 Kafka Consumer가 하는 것이 아니기 때문에 사용자가 이를 병렬로 수행하면 성능이 더 올라갈 수 있다. 이 경우도 마찬가지로 처리 후 마지막 오프셋을 커밋한다. 마찬가지로 커밋은 수동으로 수행해야 한다.</p><figure id="dc3ed905-3f6f-45c7-8bff-677b4cc722ec" class="image"><a href="https://d2.naver.com/content/images/2023/10/kafka-vanilla-batch-consumer-multithread.png"><img src="https://d2.naver.com/content/images/2023/10/kafka-vanilla-batch-consumer-multithread.png"/></a></figure><p id="2435b86a-ba2f-4584-a592-2d2393215595" class="">Parallel Consumer는 여기서 더 나아가서 오프셋 갱신을 비동기로 수행한다. 처리 결과를 임시로 저장해두고 주기적으로 오프셋을 커밋한다. 이렇게 하면 오프셋 커밋으로 인한 병목 없이 연이어서 처리할 수 있다. 아래의 그림은 11번 오프셋에 해당하는 메시지 처리 후 11번 오프셋을 저장하고 있다가 메시지 처리와 비동기로 커밋하는 과정을 보여준다. 커밋을 할 때 12, 13, 14번 오프셋에 해당하는 메시지를 동시에 처리하고 있는 것을 볼 수 있다.</p><figure id="c3af6968-7fd1-4fbe-a7ca-5006d76a49fa" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-async.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-async.png"/></a></figure><p id="f0fb3d44-39f1-4291-acfe-33447eb700eb" class="">메시지 처리를 병렬로 수행하면 어떤 오프셋을 처리해야 할지 모호할 수 있다. 예를 들어 한 파티션에서 12~14번 오프셋에 해당하는 3개의 메시지를 가져갔지만 병렬 처리로 인해 13번 오프셋을 처리하기 전에 14번 오프셋을 처리할 수 있다. Parallel Consumer는 누적하여 이전 오프셋들에 대한 처리를 완료한 가장 마지막 오프셋을 커밋한다. 다음 그림은 누적하여 12번 오프셋까지 처리를 완료한 상황을 보여준다. 14번 오프셋을 처리했지만 13번 오프셋을 아직 미처리 했기에 12번 오프셋을 커밋한다.</p><figure id="44cc5e8c-a001-43bb-8d1d-531c7cfdbc27" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-last-processed-omit.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-last-processed-omit.png"/></a></figure><p id="965b2c6d-3c2f-417d-9270-6e01d393b0b1" class="">만약 13번 오프셋도 처리한 상황이라면 누적하여 14번 오프셋까지 처리 완료 했기에 14번 오프셋을 커밋할 것이다.</p><figure id="36d85684-0217-4d8d-8554-27635aa70a8c" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-last-processed-normal.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-last-processed-normal.png"/></a></figure><h1 id="b3d05036-88d3-4931-a677-cc8aa5309ed0" class="">Parallel Consumer의 순서 보장 방식</h1><p id="8f0a9da1-6a55-499e-84fa-e577002e0505" class="">지금까지 Parallel Consumer가 병렬성을 높이는 방법을 알아보았다. 메시지 병렬 처리 및 비동기 오프셋 관리를 통해 성능을 높일 수 있다. 하지만 메시지 간에 순서가 중요한 경우가 있다. 예를 들어 상품 주문에 대한 이벤트를 처리하는 경우 주문 요청 이벤트를 처리하기 전에 취소 요청 이벤트를 처리하면 문제가 될 수 있다. Parallel Consumer는 이를 위해 Partition, Key, Unordered 세 가지의 순서 보장 방식을 제공한다. Partition, Key, Unordered순으로 순서 보장 관련 제약이 느슨해지며 성능이 향상된다.</p><h3 id="f891a60e-ad2d-45a2-841e-91aec2784c5a" class="">Partition</h3><figure id="e0c9ef92-dbbb-43cc-9c1a-b028305014e4" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-partition-ordering.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-partition-ordering.png"/></a></figure><p id="818220c0-d4d5-4483-bcb7-a2938029e55e" class="">Partition 방식은 말 그대로 Kafka 파티션 단위로 순서 보장을 하는 것으로 원래 방식과 큰 차이는 없다. 이 방법은 서버 한 대로 여러 Kafka Consumer를 손쉽게 띄울 수 있어서 보다 적은 리소스로 처리할 수 있다는 점 외에는 큰 장점은 없다.</p><h3 id="77449467-9dff-441e-a9e4-4a2eacd1f515" class="">Key</h3><figure id="882dec15-800d-4480-92a2-0e8a4be51c64" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-key-ordering.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-key-ordering.png"/></a></figure><p id="383ea738-236e-4613-a674-542d38027632" class="">Kafka 메시지에는 어떤 파티션으로 들어가야 한다는 힌트를 제공하는 Key가 있다. Parallel Consumer는 Key 단위의 순서 보장 방식이 있으며 이는 동일 Key 기준으로 메시지를 순차적으로 처리한다. 앞선 Partition 방식에서는 파티션 단위로만 병렬 처리가 가능한 반면에 Key 방식의 경우 동일 파티션 내에도 Key가 다르면 메시지가 병렬로 처리될 수 있다.</p><h3 id="d916039d-30de-41f2-845c-bcc52b41a648" class="">Unordered</h3><figure id="74662223-3959-4357-884d-3a145741b617" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-unordered.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-unordered.png"/></a></figure><p id="d4ca1dc9-7487-4022-897f-d7d052abad5a" class="">마지막으로 Unordered 방식은 순서를 아예 보장하지 않는 방식이며 앞서 들어온 메시지의 완료 결과를 기다리지 않는다. 즉, 메시지 단위로 병렬 처리하는 방식이다. 특별한 제약이 없기 때문에 세 방식 중 성능이 가장 뛰어나다.</p><h1 id="fc3b413b-00ce-42b4-99a9-5075045c4d4a" class="">Parallel Consumer의 내부 구조</h1><p id="ddd0768f-467b-48ad-8e4c-872c884f1ae3" class="">사용하는 라이브러리의 코드를 보며 내부 구현을 살펴보는 것은 해당 라이브러리를 목적에 맞게 더 잘 사용하고 추후 이슈 발생 시 원인 파악 및 대응에 큰 도움을 준다. Log&amp;Metric 조직 내에서는 Parallel Consumer 코드를 면밀히 분석했으며 도중에 일부 버그를 찾아 기여하기도 했다. Parallel Consumer가 병렬성을 어떻게 달성하는지, 순서 보장은 어떻게 하는지 알아보았으니, 이제 내부 동작을 직접 확인해 보자. 관련 내용은 현재 이 글을 작성하는 시점에서 최신 버전인 0.5.2.7을 기반으로 작성했다.</p><h3 id="93f6d552-3b77-4aec-9381-f25071abc1cb" class="">아키텍처</h3><p id="de6f4172-2b0f-46e8-8f67-ba8724964ef6" class="">Parallel Consumer에는 Broker Poller Thread와 Controller Thread라는 2개의 중요한 스레드와 실제 사용자 코드를 처리하는 Worker Thread Pool, 그리고 오프셋 저장소인 Work State Manager가 있다.</p><figure id="4fdff3df-818a-45db-9640-73d17101e9c9" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-model.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-model.png"/></a></figure><p id="59581e94-3d60-4996-8dfc-ca75bd8e885f" class="">Broker Poller Thread는 실제 Kafka Broker와 통신하는 스레드로, 메시지를 가져와서 Mailbox에 저장한다. Controller Thread는 실제 메인 로직으로, Mailbox에서 메시지를 가져와서 Worker Thread에 전달하는 작업 및 메시지 커밋을 담당한다. Worker Thread Pool은 실제 사용자가 등록한 작업을 하는 스레드로, Controller Thread가 전달한 메시지를 처리한다. Work State Manager는 처리한 오프셋 및 순서 보장을 고려하여 다음에 처리될 메시지를 관리한다. 여기서 Mailbox는 Broker Poller Thread가 Controller Thread에게 polling한 Kafka 메시지를 전달하기 위한 매개체이다.</p><p id="2ff66ae3-22be-4fe6-960f-59ceef117876" class="">실제 코드를 간략히 살펴보자. 실제 코드를 살펴볼 때는 사용자가 직접 호출할 수 있는 메서드부터 보는 것이 좋다. 실제 사용자는 <code>ParallelEoSStreamProcessor#poll</code>을 주로 호출한다. 해당 메서드를 들어가 보면 <code>wrappedUserFunc</code>라는 것을 만들어서 <code>AbstractParallelEoSStreamProcessor#supervisorLoop</code>를 호출한다.</p><figure id="98334207-9fe9-4f17-aac3-5134952936dd" class="image"><a href="https://d2.naver.com/content/images/2023/10/ParallelEoSStreamProcessor-poll.png"><img src="https://d2.naver.com/content/images/2023/10/ParallelEoSStreamProcessor-poll.png"/></a></figure><p id="1e322eba-840a-4bf8-8e2f-88261eda9661" class=""><code>AbstractParallelEoSStreamProcessor#supervisorLoop</code>는 Parallel Consumer 내부 구현의 핵심 메서드로, Broker, Control Loop 호출 등 거의 모든 작업을 트리거한다.</p><figure id="060b25f1-059e-4cd7-a9ee-70ffcc264990" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-supervisorloop.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-supervisorloop.png"/></a></figure><p id="ba8c191e-7942-4729-97c3-7a33ede1a2a5" class=""><code>AbstractParallelEoSStreamProcessor#supervisorLoop</code> 위쪽에서 <code>BrokerPollSystem#start</code>를 호출하는 것을 볼 수 있다. 이는 앞서 설명한 Broker Poller Thread에 해당하는 부분으로, 코드를 타고 들어가면 <code>pc-broker-poll</code>이라는 이름으로 스레드를 생성하는 것을 확인할 수 있다. <code>handlePoll</code> 메서드에서 Mailbox에 저장한다.</p><figure id="e3aa0af4-a070-4fa7-b2a3-856f0a5a5c09" class="image"><a href="https://d2.naver.com/content/images/2023/10/BrokerPollSystem-start.png"><img src="https://d2.naver.com/content/images/2023/10/BrokerPollSystem-start.png"/></a></figure><figure id="af63d395-20f0-4dfa-86f2-42bcfaa822f5" class="image"><a href="https://d2.naver.com/content/images/2023/10/BrokerPollSystem-controlloop.png"><img src="https://d2.naver.com/content/images/2023/10/BrokerPollSystem-controlloop.png"/></a></figure><p id="94ca52fb-84f4-49f3-9568-387e4a6bc9b1" class=""><code>AbstractParallelEoSStreamProcessor#supervisorLoop</code> 아래쪽에서는 <code>controlTask</code>라는 함수를 만든 후 <code>ExecutorService</code>에 넘기는 것을 볼 수 있다. 여기가 바로 Controller Thread를 생성하는 부분이다. 앞서 설명했듯이 Controller Thread는 Mailbox에서 메시지를 읽은 후 Worker Thread에 분배한다. 코드를 타고 들어가면 <code>AbstractParallelEoSStreamProcessor#submitWorkToPoolInner</code> 메서드를 호출하여 <code>workerThreadPool</code>에 submit한다.</p><figure id="7c6dd074-6edd-4ed9-9821-225231075db4" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-submitWorkToPoolInner.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-submitWorkToPoolInner.png"/></a></figure><p id="9265dcbd-f3c6-4a07-912a-4376a9a5d284" class="">Worker Thread Pool은 AbstractParallelEoSStreamProcessor의 필드에 있는 것을 확인할 수 있다.</p><figure id="8a539658-0013-4791-96d8-38c46fba1ead" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-workerThreadPool.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-workerThreadPool.png"/></a></figure><p id="b6d1a8c5-8a0d-4080-96f0-39b5e4c94827" class="">여기서 Control Thread가 Mailbox에서 가져오는 부분을 타고 들어가면 <code>AbstractParallelEoSStreamProcessor#processWorkCompleteMailbox</code>에 도달한다. 이 메서드에서 <code>WorkManager#registerWork</code>를 호출하여 Mailbox에서 메시지를 가져와서 <code>WorkManager</code>에 등록한다.</p><figure id="0930e492-1c5f-4daa-9ea1-bd5488f5d385" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-processWorkCompleteMailBox.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-processWorkCompleteMailBox.png"/></a></figure><p id="ef7b8800-8df2-45f0-ae9c-0ce87e85ec2b" class=""><code>WorkManager</code>에 등록한 메시지를 <code>AbstractParallelEoSStreamProcessor#retrieveAndDistributeNewWork</code>에서 <code>WorkManager#getWorkIfAvailable</code>를 호출하여 가져온다. <code>WorkManager</code>는 순서 보장을 고려하여 메시지를 반환한다.</p><figure id="b79e731e-643c-46a4-aa40-75ba6bec77c5" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-retrieveAndDistributeNewWork.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-retrieveAndDistributeNewWork.png"/></a></figure><h3 id="24bcaef3-46f8-4184-9e9a-92df8295477a" class="">순서 보장 방식 구현</h3><p id="f2594e4b-be86-4721-b672-7956ff2a824d" class="">위에서 언급한 순서 보장 방식을(Partition, Key, Unordered) Parallel Consumer는 어떤 식으로 구현하는지 살펴보겠다.</p><figure id="346820b4-e209-4e88-b82e-8cc639db0247" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-shard.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-shard.png"/></a></figure><p id="6357196d-dafb-4c3c-817c-fc8125725148" class="">Parallel Consumer는 Kafka 메시지를 shard 단위로 분배하며, 각 shard별로 작업이 병렬 수행된다.</p><figure id="c6b44c66-7e82-4949-8c77-a74b0cd9e406" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-shard-partition-key.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-shard-partition-key.png"/></a></figure><p id="aaf0127f-19ad-4f8a-b263-6de023f3eae9" class="">Key, Partition별로 shard가 생기고 shard 내에서 작업은 순서대로 처리되기 때문에, 단일 shard 내에서 메시지 처리 순서는 보장된다.</p><figure id="d94bad8e-bf15-4ba9-8c0f-417944c3dcb9" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-shard-unordered.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-shard-unordered.png"/></a></figure><p id="a2ef9f52-3e30-4228-80a6-74b5479cfa9d" class="">재밌는 것은 Unordered일 경우 Partition 개수만큼 shard가 생기지만 Partition shard 내의 메시지가 동시에 소비될 수 있다는 점이다.</p><p id="e7392821-b65b-4f88-8406-732e4779960d" class="">즉, shard 내의 메시지를 1개씩 순서대로 처리하면 Key, Partition 방식의 순서가 보장되고, shard 내의 메시지를 동시에 여러 건을 처리하면 Unordered 방식이 구현된다.</p><figure id="c2d9d580-e6c7-42c2-a74f-2aae1131753f" class="image"><a href="https://d2.naver.com/content/images/2023/10/processing-shard.png"><img src="https://d2.naver.com/content/images/2023/10/processing-shard.png"/></a></figure><p id="84e5c0aa-1df6-438f-8dba-1283bd2074f1" class=""><code>ProcessingShard</code>는 단일 shard를 지칭하는데 entries를 통해 작업 메시지를, key를 통해 shardkey를 관리한다.</p><figure id="6c89d9a0-6c2f-4858-aa0b-088a65898dfc" class="image"><a href="https://d2.naver.com/content/images/2023/10/shard-manager.png"><img src="https://d2.naver.com/content/images/2023/10/shard-manager.png"/></a></figure><p id="5726b843-3040-4f6a-9395-004e97142448" class=""><code>ShardManager</code>는 모든 shard 정보를 관리하며, 각 shard별로 메시지를 가져와 WorkPool에 넘겨준다.</p><figure id="d55b38c6-fafc-47e9-b734-acbe02534450" class="image"><a href="https://d2.naver.com/content/images/2023/10/get-work-from-shard.png"><img src="https://d2.naver.com/content/images/2023/10/get-work-from-shard.png"/></a></figure><p id="7ca91368-8886-45f5-ac49-221f71f2f903" class=""><code>ProcessingShard#getWorkIfAvailable</code>는 shard별로 처리할 task를 가져오는 메서드이다. 이때 <code>ProcessingShard#getWorkIfAvailable</code>를 보면 순서 보장이 필요한 경우(Key, Partition) shard별로 1건의 메시지만 가져오고, 순서 보장이 필요 없는 경우(Unordered) 병렬로 수행할 수 있는 최대의 메시지, 즉 batchSize만큼 가져온다.</p><h3 id="e724d8f3-32b1-4ca8-9654-937b366aed4f" class="">batchSize, delta</h3><p id="b6884fd6-594b-4ec3-9177-65e385ee42c6" class=""><code>batchSize</code>는 단일 Worker Thread에서 한 번에 처리할 Kafka 메시지 개수, 즉 단일 스레드 chunk를 의미한다. <code>delta</code>는 전체 Worker Thread Pool에서 한 번에 처리할 Kafka 메시지 개수를 의미한다. 정리하면, 전체 shard로부터 <code>delta</code>만큼 task를 가져와서 각 Worker Thread에 <code>batchSize</code>만큼 task를 전달한다.</p><p id="cb385f47-72fb-452a-9bf9-bf4af41e22ba" class=""><code>delta</code>를 구하는 기본 공식은 <code>workerThreadPoolSize * 2 * batchSize * batchSize</code>이다. <code>batchSize</code>의 기본 값은 <code>1</code>이므로, 기본 값을 사용한다는 가정 하에 <code>workerThreadPoolSize * 2</code>라고 봐도 무방하다.</p><p id="624427f7-3b45-4632-9ab0-abccca9301fc" class=""><code>batchSize</code>와 <code>delta</code>는 <code>ParallelConsumerOptions</code>으로 쉽게 수정 가능하다.</p><figure id="9e5ea826-2e0e-4f22-aff6-cd065302b372" class="image"><a href="https://d2.naver.com/content/images/2023/10/batch-size-delta.png"><img src="https://d2.naver.com/content/images/2023/10/batch-size-delta.png"/></a></figure><h3 id="309babbd-8b4a-43ef-86e7-14a892d2460e" class="">커밋</h3><p id="8d3785e2-1000-4264-9be4-5ce472001672" class="">다음으로 먼저 커밋을 어디서 하는지 알아보자. 커밋은 Controller Thread에서 수행한다. <code>AbstractParallelEoSStreamProcessor#controlLoop</code> 위쪽을 보면 <code>commitOffsetsThatAreReady</code>라는 메서드를 호출한다.</p><figure id="866ad2d1-d314-4ad1-b666-c064baff8060" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-controlloop-upper.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-controlloop-upper.png"/></a></figure><p id="fa36be3d-cee2-4f61-976b-f63a1a14f48c" class=""><code>AbstractParallelEoSStreamProcessor#commitOffsetsThatAreReady</code> 내부를 보면 commiter에게 <code>OffsetCommitter#retrieveOffsetsAndCommit</code>를 호출한다.</p><figure id="bdb743cc-e4a5-4ef5-b9fd-5658bfb96d4c" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-commitOffsetsThatAreReady.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-commitOffsetsThatAreReady.png"/></a></figure><p id="6e2cf56b-adb1-4c5b-9722-b0f632a3608c" class=""><code>OffsetCommitter</code>는 <code>AbstractParallelEoSStreamProcessor</code>의 필드에 있으며 생성자에서 옵션에 따라 어떤 <code>OffsetCommitter</code>를 쓸지 결정한다. <code>OffsetCommitter</code> 구현체는 앞서 설명한 Work State Manager에서 최신 오프셋을 가져와서 커밋한다.</p><figure id="749aea98-c337-4b4c-bcef-90e99273908f" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-commiter.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-commiter.png"/></a></figure><figure id="74a8dacf-5ec0-460c-bb61-0f87fca9ee13" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-constructor.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-constructor.png"/></a></figure><h3 id="f79dbf80-76cb-488c-8513-045d009f4afd" class="">오류로 인한 메시지 중복 처리 방지</h3><p id="8869c2c8-bfd8-4afc-ae76-0a1237655ee4" class="">예를 들어 한 파티션에서 4, 5, 6, 7번 오프셋을 처리 중 4, 6, 7번 오프셋은 성공했지만 5번 오프셋은 처리하지 못한 경우 <strong>4번 오프셋까지 완료했다고 커밋한다.</strong></p><figure id="124477be-c6b5-4375-b25e-1bbfa187676e" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-commit-server-down-before.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-commit-server-down-before.png"/></a></figure><p id="ed38d372-8340-423f-b88a-61c5e82d223f" class="">이때 장애로 서버가 재시작되면, 마지막으로 커밋한 오프셋을 4번으로 인식하고 5, 6, 7번 오프셋에 해당하는 메시지를 처리하려 할 것이다. 그런데 6, 7번 오프셋에 해당하는 메시지는 이미 처리했으므로 중복하여 재처리할 필요가 없다.</p><figure id="49b0bdc2-537b-487a-a957-457690035faa" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-commit-server-down-after.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-commit-server-down-after.png"/></a></figure><p id="88215173-548d-4b33-9912-7eb1d1ce063b" class="">Parallel Consumer에서는 이런 상황을 방지하기 위해 완료되지 않은 오프셋들을 오프셋 메타데이터에 기록한다. 이를 <code>incompleteOffsets</code>이라고 부른다. 여기서는 5번 오프셋이 메타데이터에 기록될 것이다.</p><figure id="0cad6fb6-0b72-4d3f-a702-0972592e6df1" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-commit-server-down-metadata-before.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-commit-server-down-metadata-before.png"/></a></figure><p id="18e13ae1-6170-465b-95de-6ceef5d1b437" class="">Parallel Consumer는 메시지를 처리하기 전에 오프셋 메타데이터에 있는 <code>incompleteOffsets</code> 정보를 확인하여 현재 메시지를 처리할지 여부를 판단한다. 여기서 <code>incompleteOffsets</code>에는 5번 오프셋만 있으니 6번, 7번은 건너뛰고 5번 오프셋에 대해서만 처리한다.</p><figure id="42876546-6b4d-4fdd-acb6-5f59dda04576" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-commit-server-down-metadata-after.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-offset-commit-server-down-metadata-after.png"/></a></figure><p id="d7634130-37fe-468b-bddc-649a14862d11" class="">이제 구현을 살펴보자. 앞서 커밋을 할 때 <code>AbstractOffsetCommitter#retrieveOffsetsAndCommit</code>을 호출한다고 했다. 이 안에서는 <code>WorkManager#collectCommitDataForDirtyPartitions</code>를 호출한다.</p><figure id="04282334-ee49-48f8-9bd9-766e499901b0" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractOffsetCommitter-retrieveOffsetsAndCommit.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractOffsetCommitter-retrieveOffsetsAndCommit.png"/></a></figure><p id="72cf4565-01f8-4280-8863-efc754133ddb" class="">이를 따라가 보면 <code>PartitionState#createOffsetAndMetadata</code>에 도달한다. 여기서 커밋할 오프셋과 메타데이터를 만들어 주는 것을 확인할 수 있다. 여기서 <code>PartitionState#tryToEncodeOffsets</code>를 호출한다. <code>PartitionState#tryToEncodeOffsets</code>에서 성공한 것 중 가장 큰 오프셋과, 실패한 오프셋 리스트를 인코딩하여 반환한다.</p><figure id="0752a375-37f6-41c9-8c1e-b2579bfb493c" class="image"><a href="https://d2.naver.com/content/images/2023/10/PartitionState-createOffsetAndMetadata.png"><img src="https://d2.naver.com/content/images/2023/10/PartitionState-createOffsetAndMetadata.png"/></a></figure><p id="b3ecee2d-9e24-4e2e-aff1-eb0e2a2bd1b2" class="">앞서 저장한 메타데이터를 사용해서 <code>PartitionState#isRecordPreviouslyCompleted</code>에서 <code>incompleteOffsets</code>만 처리하게 필터링한다.</p><figure id="903ef604-3efa-47e8-b0d0-b0a7ac7414f9" class="image"><a href="https://d2.naver.com/content/images/2023/10/PartitionState-isRecordPreviouslyCompleted.png"><img src="https://d2.naver.com/content/images/2023/10/PartitionState-isRecordPreviouslyCompleted.png"/></a></figure><h3 id="84a2f023-0714-440e-b1b5-f3e13228c214" class="">우아한 종료</h3><p id="66e35e57-2a30-4b53-ba03-7149f0bc03ea" class="">마지막으로, 종료 시 어떤 일이 벌어지는지 알아보자. Parallel Consumer에는 <code>DrainingMode</code>라는 것이 있다.</p><figure id="0f0580ca-a7ef-4a48-9a11-537bcb3d34cf" class="image"><a href="https://d2.naver.com/content/images/2023/10/drainingmode.png"><img src="https://d2.naver.com/content/images/2023/10/drainingmode.png"/></a></figure><p id="352cf8c7-b5e9-4321-810f-918893b026d9" class=""><code>DrainingMode.DRAIN</code>, <code>DrainingMode.DONT_DRAIN</code> 두 가지 방식이 있다. <code>DrainingMode.DRAIN</code>은 queue에 존재하는 메시지까지 다 처리 후 종료하고 <code>DrainingMode.DONT_DRAIN</code>은 queue에 들어간 메시지를 버린다. 두 방식 모두 종료 시 누적해서 마지막으로 처리한 오프셋에 대한 커밋은 한다.</p><p id="698c3219-d0f0-4153-985f-9b5c5ac221c9" class="">실제 어떻게 사용되는지 코드를 살펴보자. <code>AbstractParallelEoSStreamProcessor</code>는 <code>java.io.Closeable</code>를 구현하여 <code>close</code> 메서드를 제공한다. <code>close</code> 메서드를 타고 들어가면 <code>closeDontDrainFirst</code>라는 메서드가 보인다. 이 메서드에서는 <code>DrainingMode</code>라는 것을 <code>close</code> 메서드에 넘긴다.</p><figure id="87024086-99cc-49ef-bce8-5d2dc2093d2c" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-close.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-close.png"/></a></figure><figure id="017ed13a-da9b-47f7-94be-c16dd5a02c73" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-closeDontDrainFirst.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-closeDontDrainFirst.png"/></a></figure><p id="3cdbe3d5-bbd3-435f-b09d-6cd2bd55eba5" class=""><code>close</code> 메서드를 타고 들어가면 <code>DrainingMode</code>에 따라 다르게 분기하는 것을 확인할 수 있다.</p><figure id="bea09017-98ee-471a-a00e-375e749aed01" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-close-drainmode.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-close-drainmode.png"/></a></figure><p id="8508a78c-745d-46c0-ae35-b60ed4e3ed36" class=""><code>DrainingMode.DONT_DRAIN</code>은 <code>shutdownTimeout</code>에 <code>GRACE_PERIOD_FOR_OVERALL_SHUTDOWN</code>만큼을 추가하여 기다린다. <code>DrainingMode.DRAIN</code>의 경우 <code>drainTimeout</code>만큼 추가로 기다린다. 각 분기에서 <code>transitionToDraining</code>, <code>transitionToClosing</code>를 호출하는데 이는 내부 state를 각각 <code>DRAINING</code>이나 <code>CLOSING</code>으로 바꾼다.</p><figure id="8c63d566-c6d8-4a50-af37-11f6eed79853" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-transitionToDraining.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-transitionToDraining.png"/></a></figure><figure id="493679a4-77bc-4d46-bb24-042519bc778e" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-transitionToClosing.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-transitionToClosing.png"/></a></figure><p id="e717445d-a9f6-4f02-be4d-d1623da6f7c6" class="">이렇게 상태를 바꾸고 <code>AbstractParallelEoSStreamProcessor#waitForClose</code>를 호출한다. <code>AbstractParallelEoSStreamProcessor#waitForClose</code> 내부를 보면 <code>controlThreadFuture.get()</code>을 호출하는 것을 볼 수 있다.</p><figure id="d81332ec-212b-4fa6-a339-de0eabdb4f46" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-waitForClose.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-waitForClose.png"/></a></figure><p id="3b609541-79ee-4163-b121-ccd38e24687f" class=""><code>controlThreadFuture</code>는 앞서 설명한 Controller Thread를 생성할 때 결과를 미리 Future로 바인딩해놓은 변수이다. Controller Thread는 state가 <code>CLOSED</code>가 아니면 계속 도는데 state를 바꿔서 이를 종료하고 결과를 <code>controlThreadFuture</code>에 받아서 종료를 확인한다.</p><figure id="72a8abcf-a6e5-40ea-9425-694c83551506" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-supervisorloop-down.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-supervisorloop-down.png"/></a></figure><p id="b473c033-e9b0-45b9-b8c1-1f12eb44aa06" class=""><code>AbstractParallelEoSStreamProcessor#controlLoop</code> 메서드 내부에서 앞서 설정한 state에 따라 <code>AbstractParallelEoSStreamProcessor#drain</code> 이나 <code>AbstractParallelEoSStreamProcessor#doClose</code>를 호출하는 것을 볼 수 있다. <code>AbstractParallelEoSStreamProcessor#drain</code> <code>AbstractParallelEoSStreamProcessor#doClose</code> 내부에서 오프셋 커밋, 잔여 queue 처리 등의 작업을 한다.</p><figure id="3f37130f-8040-45fc-913b-925aa130729a" class="image"><a href="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-controlloop-drain.png"><img src="https://d2.naver.com/content/images/2023/10/AbstractParallelEoSStreamProcessor-controlloop-drain.png"/></a></figure><h1 id="be708cf5-1dcc-40ae-b996-f2ca9cc3ff5f" class="">성능 비교</h1><p id="5d5f24e8-7937-4a6d-92bf-9ac5a78e744f" class="">지금까지 Parallel Consumer가 어떻게 높은 병렬성을 달성하는지, 어떤 방식으로 순서를 보장하는지 알아보았다. 실제 성능이 어느 정도 차이날지 궁금하여 실제 동작하는 시스템을 일부 변경하여 성능 테스트를 진행해보았다.</p><p id="049cc673-f301-4609-bd21-a271e1abc60b" class="">테스트 Topic에 8개의 파티션을 생성 후 8개 Kafka Consumer를 띄운 것과 2개의 파티션을 생성하여 Parallel Consumer의 순서 보장 방식별로 각각 2개의 컨슈머를 띄운 것으로 테스트했다. 각 컨슈머는 4코어 16메모리로 수행했다. Key의 경우 0~99 사이의 임의의 값을 할당했다.</p><figure id="2054cc02-975c-4ff6-8de1-0ad54b0983ec" class="image"><a href="https://d2.naver.com/content/images/2023/10/parallel-consumer-performance-test.png"><img src="https://d2.naver.com/content/images/2023/10/parallel-consumer-performance-test.png"/></a></figure><p id="e1d097f3-a714-488f-9645-da0e22d5be5b" class="">성능 테스트 결과 Parallel Consumer Unordered, Key 방식이 8개의 Kafka Consumer를 띄운 것보다 오히려 빠르게 처리하는 것을 확인할 수 있었다. Unordered 방식과 Key 방식이 거의 유사한 결과가 나온 이유는 Key를 0~99 사의의 다양한 값으로 균등하게 퍼트렸기 때문으로 보인다. Key 개수는 결국 shard 개수와 비례하기 때문에 많은 Key가 균등하게 분배만 된다면 Unordered와 유사한 수치의 성능을 낼 수 있다.</p><h1 id="f1109128-c458-4030-8be1-a85bfe22d2b0" class="">마치며</h1><p id="227054a0-4be0-4220-b754-aba0f60f34a2" class="">파티션을 늘리는 것이 항상 나쁜 것은 아니다. 트래픽도 적고 현재 파티션 수도 많지 않다는 가정 하에 단순히 파티션 1~2개 정도 더 늘리는 것으로 충분히 해결 가능한 상황도 있을 것이다. 단일 Kafka 메시지 처리 속도를 쉽게 향상시킬 수 있다면 먼저 그 부분을 개선하는 것이 좋다.</p><p id="471e3ff8-91f0-4b54-80cb-35854feebb32" class="">단일 Kafka 메시지 처리 속도를 단기간에 향상시키기 어려운 상황에서 이미 파티션이 과도하게 늘어나 있어 파티션을 더 늘리기 부담스럽다면 Parallel Consumer는 좋은 선택지가 될 수 있다.</p><p id="6143267c-8d97-4eaa-a325-25b43eb90f88" class="">다만 <strong>Partition</strong> 순서 보장 방식은 기존 방식과 큰 차이가 없어 메리트가 없기 때문에 <em>*Key나 Unordered 순서 보장 방식을 사용할 수 있는 환경에서 사용하는 것을 권장한다. *</em> 또한 Parallel Consumer가 트랜잭션 기능도 지원하지만 메시지가 정확히 1번만 전달되어야 하는 강한 제약 조건이 있는 환경에서는 권장하지 않는다. 오히려 디버깅에 어려움을 겪는 상황이 발생할 수 있다.</p><p id="bbce577c-b456-48f6-a23b-e254c33f2b45" class="">참고로 Log&amp;Metric 조직 내에서는 평균 하루 5억 건 이상의 메시지를 처리하는 Kafka Consumer 컴포넌트에서 <strong>Unordered</strong> 방식으로 Parallel Consumer를 문제 없이 잘 활용하고 있다.</p><p id="b4e05888-6207-4d5f-a496-77679f010a30" class="">Parallel Consumer는 이 글 작성 시점 기준 0.5.2.7이 최신 버전이다. 아직 메이저 버전이 나오지 않았기 때문에 추후 버전에서 변경이 많아질 수 있다. 하지만 큰 구조나 개념은 달라지지 않을 것이다. 이 글이 Parallel Consumer가 무엇인지, 어떤 상황에서 사용해야 하는지 이해하는 데 도움이 되었으면 좋겠다.</p><figure id="7cb67cb7-69a8-4514-b26e-e680f0ea089c"><a href="https://d2.naver.com/helloworld/7181840" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Kafka에서 파티션 증가 없이 동시 처리량을 늘리는 방법 - Parallel Consumer</div><div class="bookmark-description">Kafka를 사용하면서 메시지 동시 처리량을 늘릴 수 있는 가장 쉬운 방법 중 하나는 파티션을 증가시키는 것입니다. 다만 파티션 수는 한번 늘어나면 줄일 수 없기..</div></div><div class="bookmark-href"><img src="https://d2.naver.com/favicon.ico" class="icon bookmark-icon"/>https://d2.naver.com/helloworld/7181840</div></div><img src="https://d2.naver.com/content/images/2023/10/PC_170x120_231021.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="29350bd0-2cc8-4500-ae20-db56e568d7cb" class="toggle"><li><details open=""><summary>중복된 트래픽 요청 관리 방안</summary><p id="6fb08df6-725a-4230-bdfc-cf1c9df1512f" class="">중복된 API 요청이 Redis나 서버에 과부하를 유발하고 시스템의 응답 속도를 저하시킬 수 있습니다. 이를 해결하기 위해 중복된 요청을 효율적으로 관리할 수 있는 다양한 방법이 있습니다. 여기서는 이러한 중복 요청을 관리하고 최적화하는 방법에 대해 구체적으로 설명합니다.</p><h2 id="667f0d69-e65f-483d-9c84-ee93bb631dbb" class="">1. <strong>API 중복 요청의 원인과 문제점</strong></h2><h3 id="704478ad-0aa9-431a-8e20-15665a64af8b" class="">a. <strong>API 중복 요청의 원인</strong></h3><ul id="9df0e017-3ddf-4a85-8fb7-7d0e17d2b462" class="bulleted-list"><li style="list-style-type:disc"><strong>사용자 반복 클릭</strong>: 사용자가 페이지 로드 시 여러 번 클릭하거나 새로고침을 하는 경우.</li></ul><ul id="fc58e93a-4fdb-4d3a-8e0a-8347ac8f0ed2" class="bulleted-list"><li style="list-style-type:disc"><strong>네트워크 지연</strong>: 응답 지연으로 인해 사용자가 같은 요청을 여러 번 전송.</li></ul><ul id="9dedffa9-7a44-402d-a65f-3388341575f0" class="bulleted-list"><li style="list-style-type:disc"><strong>클라이언트 오류</strong>: 클라이언트 측에서 요청 중복 방지 로직이 부재하거나 제대로 구현되지 않음.</li></ul><h3 id="7756faee-6f63-4ad0-884b-7ac41881e9df" class="">b. <strong>문제점</strong></h3><ul id="bbf4b385-92a5-4b39-a0df-18ffaefe1550" class="bulleted-list"><li style="list-style-type:disc"><strong>서버 부하 증가</strong>: 불필요한 요청이 서버에 부하를 일으키고, 성능을 저하시킵니다.</li></ul><ul id="a82c3897-c30b-44ea-b2df-564f4360c4cb" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 일관성 문제</strong>: 여러 번의 동일한 요청이 데이터베이스에 중복 입력을 유발할 수 있습니다.</li></ul><ul id="411eff87-f22a-4476-9d19-c5732c4e4a6a" class="bulleted-list"><li style="list-style-type:disc"><strong>사용자 경험 악화</strong>: 응답 지연 및 불필요한 리소스 소비로 인해 사용자 경험이 저하됩니다.</li></ul><h2 id="ed934c4c-31b9-4a41-b879-3fabeb5f9399" class="">2. <strong>중복 요청 관리 방법</strong></h2><h3 id="15e8ed5f-db91-4a36-9c6c-13aad0f1d7bf" class="">2.1 클라이언트 측 중복 방지</h3><h3 id="ddc3ed34-9384-41ba-94fd-e3313339e0a1" class="">a. <strong>요청 제한</strong></h3><ul id="4ea3d8e7-48c5-4196-a02b-ca4d1cc73215" class="bulleted-list"><li style="list-style-type:disc"><strong>디바운스(debounce)와 쓰로틀(throttle) 사용</strong>: 사용자 인터페이스에서 디바운스와 쓰로틀을 적용하여 요청 빈도를 조절합니다.<ul id="7547538d-640d-48ad-86e4-617d20bcb421" class="bulleted-list"><li style="list-style-type:circle"><strong>디바운스</strong>: 사용자가 일정 시간 동안 연속적으로 요청을 보내는 경우, 마지막 요청만 처리합니다.</li></ul><ul id="d0af0b57-8758-40c7-8dd5-5a74034bf9b3" class="bulleted-list"><li style="list-style-type:circle"><strong>쓰로틀</strong>: 일정한 시간 간격 내에 최대 요청 횟수를 제한합니다.</li></ul></li></ul><p id="07d4eb1f-b926-47d4-84c6-563cc5e6a73d" class=""><strong>예시 (JavaScript)</strong>:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="9e7a3073-69a0-48d7-ac77-406267389016" class="code"><code class="language-JavaScript" style="white-space:pre-wrap;word-break:break-all">javascript코드 복사
function debounce(func, wait) {
  let timeout;
  return function(...args) {
    clearTimeout(timeout);
    timeout = setTimeout(() =&gt; func.apply(this, args), wait);
  };
}

function throttle(func, limit) {
  let lastFunc;
  let lastRan;
  return function(...args) {
    if (!lastRan) {
      func.apply(this, args);
      lastRan = Date.now();
    } else {
      clearTimeout(lastFunc);
      lastFunc = setTimeout(() =&gt; {
        if ((Date.now() - lastRan) &gt;= limit) {
          func.apply(this, args);
          lastRan = Date.now();
        }
      }, limit - (Date.now() - lastRan));
    }
  };
}

</code></pre><h3 id="bbd39ab7-b9f1-4f40-9e8e-fd32f67f183c" class="">b. <strong>요청 취소</strong></h3><ul id="d276b6f7-97d8-4a20-aeee-503f5375a8ee" class="bulleted-list"><li style="list-style-type:disc"><strong>AbortController API</strong>: Fetch API를 사용하는 경우, <code>AbortController</code>를 사용하여 중복된 요청을 취소할 수 있습니다.</li></ul><p id="e05e322c-a212-4306-afb5-370ddd8ca931" class=""><strong>예시 (JavaScript)</strong>:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="5b361498-7704-489d-a25f-6a6cb6d61993" class="code"><code class="language-JavaScript" style="white-space:pre-wrap;word-break:break-all">javascript코드 복사
let controller = new AbortController();
let signal = controller.signal;

// 요청을 보내기 전에 중복 요청이 있는지 확인하고 이전 요청을 취소
fetch(&#x27;https://api.example.com/data&#x27;, { signal })
  .then(response =&gt; response.json())
  .then(data =&gt; console.log(data))
  .catch(error =&gt; console.error(&#x27;Request was canceled&#x27;, error));

// 새로운 요청을 보낼 때 기존 요청을 취소
controller.abort();

</code></pre><h3 id="f872dee4-f17d-4170-995c-abb22ca02e78" class="">2.2 서버 측 중복 방지</h3><h3 id="83d16c09-e6af-4c94-aa29-c5c2494b99d4" class="">a. <strong>요청 ID 기반 중복 제거</strong></h3><ul id="d2bc49dd-9d3b-4d8a-bc97-fa7cbd2ad716" class="bulleted-list"><li style="list-style-type:disc"><strong>유니크 요청 ID 사용</strong>: 각 요청에 유니크한 ID를 생성하여 서버에서 동일한 ID의 요청을 처리하지 않도록 합니다.</li></ul><ul id="ce99dad3-2168-45e8-8714-b87d08cd31fb" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis로 요청 ID 관리</strong>: Redis에 요청 ID를 저장하고, 일정 기간 동안 동일한 ID로 들어온 요청을 무시합니다.</li></ul><p id="cfe6eafb-1d17-4cab-85e3-df280838373e" class=""><strong>예시 (Python Flask)</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="39c2e316-7538-44f2-a9de-2c62cc2d0062" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">python코드 복사
from flask import Flask, request
import redis

app = Flask(__name__)
r = redis.Redis(host=&#x27;localhost&#x27;, port=6379, db=0)

@app.route(&#x27;/api&#x27;, methods=[&#x27;POST&#x27;])
def api_endpoint():
    request_id = request.headers.get(&#x27;X-Request-ID&#x27;)
    if r.get(request_id):
        return &quot;Duplicate request&quot;, 400
    else:
        r.set(request_id, &#x27;1&#x27;, ex=60)  # 1분간 유효
        # 실제 처리 로직
        return &quot;Request processed&quot;, 200

</code></pre><h3 id="806cf204-98ba-42c6-87b1-d1d4357586b7" class="">b. <strong>요청 캐싱</strong></h3><ul id="93e2f5e3-51a0-43fa-a1c8-e434c448f66f" class="bulleted-list"><li style="list-style-type:disc"><strong>결과 캐싱</strong>: 동일한 API 요청에 대한 응답 결과를 캐싱하여 중복된 요청이 들어올 경우 캐시된 응답을 반환합니다.</li></ul><ul id="8194cb6d-57e7-4ba4-a54e-d449de7c1f94" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis에 응답 결과 캐싱</strong>: Redis를 사용하여 응답 결과를 캐싱하고, TTL(Time-to-Live)을 설정하여 일정 시간 후 캐시를 무효화합니다.</li></ul><p id="ca563d8b-4373-4238-84bf-a53d8c665506" class=""><strong>예시 (Node.js Express)</strong>:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="181225a4-eabe-4ac8-a1f6-241a0324d9b3" class="code"><code class="language-JavaScript" style="white-space:pre-wrap;word-break:break-all">javascript코드 복사
const express = require(&#x27;express&#x27;);
const redis = require(&#x27;redis&#x27;);
const app = express();
const client = redis.createClient();

app.post(&#x27;/api&#x27;, (req, res) =&gt; {
  const cacheKey = `api:${JSON.stringify(req.body)}`;

  client.get(cacheKey, (err, data) =&gt; {
    if (err) throw err;

    if (data) {
      res.send(data); // 캐시된 응답 반환
    } else {
      // 실제 처리 로직
      const responseData = &#x27;Processed Data&#x27;;

      client.setex(cacheKey, 60, responseData); // 1분간 캐싱
      res.send(responseData);
    }
  });
});

app.listen(3000, () =&gt; {
  console.log(&#x27;Server running on port 3000&#x27;);
});

</code></pre><h3 id="7b3c1081-d1ed-4327-8d4e-8cf294926cfa" class="">c. <strong>트래픽 제한 (Rate Limiting)</strong></h3><ul id="a78c6326-a36d-4f2b-881a-7c1b69475339" class="bulleted-list"><li style="list-style-type:disc"><strong>IP 또는 사용자 기반 요청 제한</strong>: 사용자 또는 IP 주소별로 요청 횟수를 제한합니다. Redis의 카운터를 사용하여 특정 시간 내의 요청 횟수를 추적합니다.</li></ul><p id="e8dbd52f-2bcb-4e72-a094-9331e2a018f6" class=""><strong>예시 (Python Flask)</strong>:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="be61b428-201e-4753-986b-acc5b8429ade" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">python코드 복사
from flask import Flask, request, jsonify
import redis

app = Flask(__name__)
r = redis.Redis(host=&#x27;localhost&#x27;, port=6379, db=0)

@app.route(&#x27;/api&#x27;, methods=[&#x27;POST&#x27;])
def api_endpoint():
    user_id = request.headers.get(&#x27;User-ID&#x27;)
    key = f&quot;rate_limit:{user_id}&quot;
    request_count = r.incr(key)

    if request_count &gt; 100:
        return jsonify({&quot;error&quot;: &quot;Rate limit exceeded&quot;}), 429
    else:
        if request_count == 1:
            r.expire(key, 60)  # 1분간 유효
        # 실제 처리 로직
        return jsonify({&quot;data&quot;: &quot;Processed Data&quot;}), 200

app.run()

</code></pre><h3 id="16ef6320-91a9-499b-932c-53a8c0738178" class="">d. <strong>멀티-레벨 캐싱 (Multi-Level Caching)</strong></h3><ul id="006c1085-5d9f-4b3b-b055-455a508d845e" class="bulleted-list"><li style="list-style-type:disc"><strong>애플리케이션 레벨 캐싱</strong>: 서버 내부에서 메모리 기반 캐시를 사용하여 Redis에 도달하기 전에 캐시에서 데이터가 있는지 확인합니다.</li></ul><ul id="926cfca3-21f4-42e1-973f-493134a7a432" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis와 같은 외부 캐시 시스템을 사용하는 경우</strong>: 캐시 적중률을 높이고 외부 캐시 시스템의 부하를 줄일 수 있습니다.</li></ul><h2 id="4ce297e9-b903-4f3f-b50f-a0ed7e7b4e77" class="">3. <strong>중복 요청 방지 사례</strong></h2><h3 id="bd9765a8-15c6-41a2-b574-8d3265104278" class="">a. <strong>전자 상거래 사이트</strong></h3><ul id="e9dce7c3-27dd-4e6c-a1e2-468f3ad12a3d" class="bulleted-list"><li style="list-style-type:disc">쇼핑 카트 업데이트, 결제 처리 등 중요한 트랜잭션에서 중복 요청을 방지하여 데이터 일관성과 사용자 경험을 향상시킵니다.</li></ul><h3 id="d5a26e20-dfa6-4516-8391-42b272508195" class="">b. <strong>뉴스 및 미디어 사이트</strong></h3><ul id="7aec8c83-de43-4f8f-a640-057a57d85d26" class="bulleted-list"><li style="list-style-type:disc">기사 조회, 추천 시스템 등에서 중복된 요청을 줄여 트래픽을 관리하고 서버의 부하를 감소시킵니다.</li></ul><h3 id="e3b4f103-782c-4dc2-af18-05892bb7dc2b" class="">c. <strong>소셜 미디어 플랫폼</strong></h3><ul id="299f88dd-8dd4-45d7-997d-ca792c0335b4" class="bulleted-list"><li style="list-style-type:disc">게시물 좋아요, 댓글, 메시지 전송 등에서 중복된 요청을 관리하여 데이터베이스의 부하를 줄이고 응답 속도를 개선합니다.</li></ul><h2 id="498c96f5-8d23-4fae-bf0b-57e8c3bc82b4" class="">결론</h2><p id="f21cf060-91bd-426e-b9a8-774b81ffb97f" class="">효율적인 트래픽 관리를 위해 Redis와 클라이언트 측 로직을 사용하여 중복된 API 요청을 관리할 수 있습니다. 이를 통해 서버의 부하를 줄이고 시스템의 안정성과 성능을 향상시킬 수 있습니다. 클라이언트 측 디바운스 및 요청 취소, 서버 측 요청 ID 관리, 요청 캐싱 및 트래픽 제한 등을 통해 중복 요청을 효과적으로 방지할 수 있습니다.</p></details></li></ul><p id="74a4d0e3-0fbd-4623-b562-ea7f8bbfc258" class="">
</p><p id="06c1f5da-10b4-44ed-a795-67d704bfcf0c" class="">동시성 제어</p><ul id="23a5cc1c-86f8-4884-ab0f-3c54aa4e939c" class="toggle"><li><details open=""><summary>자바 스레드와 동기화 이해</summary><h3 id="ea217f93-42b3-497e-902a-56296477b7bd" class=""><strong>1. 자바 스레드와 동기화 이해</strong></h3><p id="5972bc8e-3c7a-4908-b307-9951558b95d4" class="">자바에서 스레드는 프로세스 내의 경량 프로세스로, 프로그램의 동시 실행 흐름을 의미하며, Thread 클래스를 확장하거나 Runnable 인터페이스를 구현하여 생성됩니다; 이를 통해 개발자는 복수의 스레드를 동시에 실행시켜 효율성을 높일 수 있습니다. 스레드 생성 후, start() 메서드를 호출하여 스레드를 실행시키며, 스레드의 생명주기 관리는 join(), sleep(), interrupt()와 같은 기본 API를 통해 이루어집니다. 스레드 활용은 멀티태스킹 및 자원 공유 최적화에 중요한 역할을 하며, 여러 스레드가 동시에 실행될 때 데이터 일관성과 상태 관리를 위해 동기화가 필요합니다.</p><figure id="55395212-dd8c-4b41-8e88-c955ac3a54e9" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/e3ef2dd4-832a-46f0-b923-48dde4e4ec09/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/e3ef2dd4-832a-46f0-b923-48dde4e4ec09/image.png?w=960"/></a></figure><figure id="c3b759ae-51aa-4436-a98e-b29eff17a371" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/092e0398-7e8f-4d82-a768-4b087d071fe5/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/092e0398-7e8f-4d82-a768-4b087d071fe5/image.png?w=960"/></a></figure><p id="8a1fb9ef-fa49-405c-8086-63133d220a46" class="">동기화는 멀티 스레딩 환경에서 중요한 개념으로, 공유 자원에 대한 동시 접근을 제어하여 데이터의 무결성을 보장합니다. 자바에서는 synchronized 키워드를 사용하여 메서드 또는 블록을 동기화할 수 있으며, 이를 통해 특정 시점에 단 하나의 스레드만이 동기화된 코드 영역에 접근할 수 있습니다. 또한, Lock 인터페이스와 구현 클래스들은 더 세밀한 동기화 제어를 가능하게 하며, ReentrantLock은 가장 대표적인 구현체로, 재진입 가능한 락 기능을 제공합니다.</p><p id="c5f18833-5f90-4898-9815-f1df784c3786" class="">자바는 다양한 동기화 도구를 제공하는데, CountDownLatch, CyclicBarrier, Semaphore 등은 스레드 간 협력을 위한 고급 동기화 메커니즘을 제공합니다. 이러한 도구들은 스레드의 실행 순서를 제어하거나, 특정 조건이 만족될 때까지 스레드를 대기시키는 등의 복잡한 동기화 작업을 단순화합니다. 이와 같은 자바의 스레드와 동기화 기능은 멀티 스레딩 애플리케이션 개발 시 필수적으로 이해하고 활용해야 하는 중요한 부분입니다.</p><figure id="faec3aa8-9856-4296-b1ed-1aeb597accb6" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/e7dc8103-18d4-4cb0-be3f-9cd3702f3851/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/e7dc8103-18d4-4cb0-be3f-9cd3702f3851/image.png?w=960"/></a></figure><figure id="09fb8e05-9017-435b-84ee-4213fe75d4ef" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/bb87d6b6-529b-424b-9bcc-d385c8b8bf7a/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/bb87d6b6-529b-424b-9bcc-d385c8b8bf7a/image.png?w=960"/></a></figure><p id="b6faca79-440f-41f7-9a29-1ff95a57977d" class="">그래서 먼저 자바 스레드의 전반적인 개념과 동시성의 문제 그리고 동기화 종류와 기법에 대해 살펴 봅니다.</p><h3 id="c9255f2f-486a-4d76-88ef-83ab2b1808ed" class=""><strong>2. 동시성 프로그래밍</strong></h3><p id="9040ad64-8a3b-41c0-95ca-668e59764044" class="">동시성 프로그래밍에서 스레드 풀은 여러 스레드를 효율적으로 관리하고 재사용하는 방법으로, Executor 프레임워크를 통해 구현되며, 이는 ExecutorService, ScheduledExecutorService와 같은 인터페이스로 구성되어 있고, Callable과 Future 인터페이스를 활용하여 반환 값이 있는 작업을 처리하고 그 결과를 비동기적으로 받을 수 있습니다.</p><figure id="56b0b706-9a82-4ef5-ba53-6b81fb7b674c" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/ff4b8d17-7081-4eb8-ae18-02e92431b8f0/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/ff4b8d17-7081-4eb8-ae18-02e92431b8f0/image.png?w=960"/></a></figure><figure id="e15b9083-4fe4-4266-9711-18a810658173" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/08a607de-55b4-4d34-a329-b206bd6e81ed/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/08a607de-55b4-4d34-a329-b206bd6e81ed/image.png?w=960"/></a></figure><p id="7b4650a5-1c04-4b3a-a276-eefb6c65e231" class="">ExecutorService는 스레드 풀의 실행 및 관리를 담당하며, submit() 메서드를 사용하여 작업을 스레드 풀에 제출하고, shutdown() 또는 shutdownNow() 메서드를 통해 스레드 풀을 안전하게 중단 및 종료할 수 있습니다.</p><p id="b49c07e5-89c1-44ec-aac6-b58b0c825e80" class="">또한, Executors 클래스는 다양한 유형의 스레드 풀을 쉽게 생성할 수 있는 팩토리 메서드를 제공하며, ThreadPoolExecutor는 스레드 풀의 구체적인 실행 메커니즘을 제공하여, 다중 작업 처리 시 성능과 자원 활용을 최적화할 수 있게 해줍니다.</p><p id="92d5a75f-bd16-4216-8815-7e93bc943dfd" class="">이러한 스레드 풀과 관련된 동시성 프로그래밍의 이해는 자바 기반의 멀티 스레딩 애플리케이션 개발에 있어 필수적인 요소이며, 효율적인 자원 관리와 높은 성능의 애플리케이션 구현을 위해 중요합니다.</p><figure id="295f5061-0cd4-4dac-99ed-ed4e88970644" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/78163d3f-019f-4656-9d78-d563ed2a22e2/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/78163d3f-019f-4656-9d78-d563ed2a22e2/image.png?w=960"/></a></figure><p id="b44ab254-dc49-466f-8bc7-b52e48dd6b2a" class="">해당 파트에서는 멀티 스레드 환경에서 동시성 프로그래밍을 쉽고 안전하게 구현하는 방법들을 학습합니다</p><h3 id="6318cfb7-8f12-4758-91b8-de593273006b" class=""><strong>3. 비동기 프로그래밍</strong></h3><p id="e0533bef-b0c4-4699-9f6f-7ae63df351d8" class="">비동기 프로그래밍은 복잡한 애플리케이션에서 필수적인 동시성 패러다임으로, 동기 및 비동기 방식과 그와 관련된 Blocking과 Non-Blocking 호출의 개념을 통해 작업의 실행 흐름을 구조화합니다.</p><p id="99b98927-60f8-4f19-9066-5c1c9fcdda9d" class="">이는 작업이 즉각적으로 완료되지 않을 때, 리소스가 낭비되지 않도록 하고, 프로그램이 다른 작업을 계속할 수 있게 하는 개요 및 구조를 제공합니다.</p><figure id="427ecfc0-7989-4307-9082-2b43e3800a04" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/76d44ec3-039a-4b6b-9c64-2418ed4bb395/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/76d44ec3-039a-4b6b-9c64-2418ed4bb395/image.png?w=960"/></a></figure><p id="aca585d1-bdfb-4da9-a981-36ec51bfea14" class="">자바에서 CompletableFuture는 비동기 프로그래밍을 위한 API 구조를 제공하며, 비동기 작업의 시작, 실행, 그리고 결과 조작을 위한 다양한 메서드를 제공하고, 이는 단일 결과 조작부터 복수의 비동기 작업의 조합에 이르기까지 폭넓게 적용될 수 있습니다.</p><p id="f3142bf1-c082-4e0c-a50e-b1f50d7ab04a" class="">또한, 예외 처리를 위한 메커니즘을 포함하여, 작업의 완료 처리와 더불어 대기 및 취소 처리 기능을 통해 더욱 견고하고 유연한 비동기 프로그래밍을 가능하게 합니다.</p><p id="eebbc8af-f861-446d-bbbc-b61aef2a8e74" class="">이러한 방식으로 비동기 프로그래밍은 시스템의 반응성을 높이고, 리소스를 보다 효율적으로 활용하며, 애플리케이션의 성능을 최적화하는 데 큰 역할을 합니다.</p><figure id="8492d7cd-ddb1-4077-8b44-64af2edf4f36" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/4ed146b0-4958-417c-9503-bc0b1604166f/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/4ed146b0-4958-417c-9503-bc0b1604166f/image.png?w=960"/></a></figure><figure id="d1de9358-864b-400d-a807-1896e5ea1a1e" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/e8b6ac4b-1a50-4426-992e-7593c78aca1b/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/e8b6ac4b-1a50-4426-992e-7593c78aca1b/image.png?w=960"/></a></figure><figure id="5398bd28-80ac-4aa7-b114-39130a9f685c" class="image"><a href="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/7508834c-804c-438a-af8c-6935e16b41e4/image.png?w=960"><img style="width:668px" src="https://cdn.inflearn.com/public/files/courses/Id(value=332448)/builder/7508834c-804c-438a-af8c-6935e16b41e4/image.png?w=960"/></a></figure><p id="71364c9d-04f6-47a4-9f34-0216f22ee316" class="">해당 파트에서는 CompletableFuture 를 활용한 비동기 프로그래밍의 전반적인 내용을 살펴 봅니다.</p><p id="89da6fc2-3e7c-4268-8fd9-623e849efb05" class="">
</p></details></li></ul><ul id="b0e590f2-19e6-4ccb-acff-a05def964912" class="toggle"><li><details open=""><summary>Redisson 분산락을 이용한 동시성 제어</summary><h2 id="88bc615b-9762-4828-ae10-ee754e2b1d32" class="">1. 분산 서버 동시성(Concurrency) 제어</h2><h3 id="8fc67fcb-9a9b-493b-856f-717eadea3500" class="">❓ 왜 필요한가</h3><figure id="78ae8100-282b-45fb-a582-816e511715b0" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/7ff0ca6a-4919-4694-8739-cb834bd2fec7/image.png"><img style="width:576px" src="https://velog.velcdn.com/images/hgs-study/post/7ff0ca6a-4919-4694-8739-cb834bd2fec7/image.png"/></a></figure><ul id="c3465c81-b613-4c3f-9470-e1160630cf0e" class="bulleted-list"><li style="list-style-type:disc">여러 요청들이 한 자원에 대해서 공유할 때, 각 분산 DB의 동기화가 여러 요청의 동기화 속도를 못 따라 가는 상황이 발생합니다.</li></ul><ul id="00f568b4-5e73-45e5-bb7c-d805d2ba70a7" class="bulleted-list"><li style="list-style-type:disc">이에 대해 데이터 정합성은 깨지게 되고, 데이터 동시성 문제가 발생하게 됩니다.</li></ul><ul id="a5dec37a-b238-4ba2-8963-79a75704673b" class="bulleted-list"><li style="list-style-type:disc">예를 들어, 위와 같이 한 번에 여러 구매 요청이 들어왔을 경우 <strong>수량</strong>이라는 자원을 동시에 사용할 경우 여러 수량의 커밋되거나 롤백되는 수량의 동기화가 다른 서버가 따라가지 못해서 정합성이 깨지고, 동시성 문제가 발생할 수 있습니다.</li></ul><h3 id="30af8c70-cd40-4f1c-a9d6-e141877eddce" class="">💡 해결 방안</h3><figure id="098082c7-4f3f-431a-9816-8f035244d14c" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/d5cc9ef8-5da1-45d6-85e6-38bba619e169/image.png"><img style="width:576px" src="https://velog.velcdn.com/images/hgs-study/post/d5cc9ef8-5da1-45d6-85e6-38bba619e169/image.png"/></a></figure><ul id="0ef4e6ec-961c-43cd-a3a6-e55dedc2d5d8" class="bulleted-list"><li style="list-style-type:disc">단적인 예를 들어, 공유 자원인 <strong>수량</strong>을 레디스에 올려놓고 분산락(Distributed Lock)을 활용해서 데이터 동시성 문제를 해결할 수 있습니다.</li></ul><ul id="1c8910a9-1d0c-4e30-961d-aab6eabe8c23" class="bulleted-list"><li style="list-style-type:disc">여러 요청마다 락을 점유하고 데이터 업데이트 하기 때문에 각 서버는 각 DB의 동기화를 기다리지 않아도 되며, 동시성 문제도 해결할 수 있습니다.</li></ul><h2 id="cada2024-f642-4b57-aae3-3f64dda0cfd6" class="">3. Redisson 사용 이유?</h2><blockquote id="f5a42058-80f2-4860-96bb-033e9d50ee4f" class="">Redis 클라이언트 중에 Redisson을 사용하면 좋은 이점을 공유합니다.</blockquote><h3 id="e0e7809b-b70d-4515-b8d5-899fdc0d4a06" class="">🔒 Lettuce의 스핀락</h3><figure id="b4ef45bf-d489-4740-bee8-cb23d0f5c88d" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/e4767c57-2039-4a49-8fa9-1093b6f67b22/image.png"><img style="width:576px" src="https://velog.velcdn.com/images/hgs-study/post/e4767c57-2039-4a49-8fa9-1093b6f67b22/image.png"/></a></figure><ul id="8a81993b-b9b5-489a-ad0f-ed2505b9788f" class="bulleted-list"><li style="list-style-type:disc">Lettuce에서도 락을 제공하고 있습니다. 하지만 Redisson의 락과는 성격이 다릅니다.</li></ul><ul id="e0c70441-5430-43a9-8e27-383d394aacfc" class="bulleted-list"><li style="list-style-type:disc">Lettuce의 락은 <code>setnx</code>메서드를 이용해 사용자가 직접 <code>스핀락</code>형태로 구성하게 됩니다. 락이 점유 시도를 실패했을 경우 계속 락 점유 시도를 하게 됩니다. 이로 인해 레디스는 계속 부하를 받게 되며, 응답시간이 지연됩니다.</li></ul><ul id="840307e2-7a51-402f-8238-468627a8edfa" class="bulleted-list"><li style="list-style-type:disc">추가적으로, 만료시간을 제공하고 있지 않아서 락을 점유한 서버가 장애가 생기면 다른 서버들도 해당 락을 점유할 수 없는 상황이 연출됩니다.</li></ul><h3 id="9d55b426-d5b2-4c93-a1fd-6b86e1841d6f" class="">🔒 Redisson의 분산락</h3><blockquote id="a293f3a7-9967-4cc1-93a4-545c9e6d5f41" class="">Distributed locks are a very useful primitive in many environments where different processes must operate with shared resources in a mutually exclusive way.</blockquote><ul id="58aa1667-ed0b-4b95-a937-882524f3a378" class="bulleted-list"><li style="list-style-type:disc">레디스 공식 홈페이지를 보면 분산락은 <strong>서로 다른 프로세스가 상호 배타적인 방식으로 공유 리소스로 작동해야 하는 많은 환경에서 매우 유용한 기본 요소</strong>라고 설명하고 있습니다.</li></ul><h3 id="1f8f8e1d-accf-4ace-b760-4b7a0d11e4a3" class="">자체 TTL 적용</h3><figure id="081eaca1-ab4e-4277-baa0-daa9200417ac" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/70538ab0-65e7-49e0-b576-1e22e2d03006/image.png"><img src="https://velog.velcdn.com/images/hgs-study/post/70538ab0-65e7-49e0-b576-1e22e2d03006/image.png"/></a></figure><ul id="4191998b-8137-4105-ab92-65670931dc8e" class="bulleted-list"><li style="list-style-type:disc">RedissonLock.java의 <code>tryLockInnerAsync</code>메서드를 확인해보면 Lua Script를 사용해서 자체 TTL을 적용하는 것을 확인할 수 있습니다</li></ul><ul id="1ce1f4c1-3755-4b72-9c40-b8981e44059b" class="bulleted-list"><li style="list-style-type:disc"><code>hincrby </code>명령어는 해당 field가 없으면 increment 값을 설정합니다.</li></ul><ul id="51887728-3b5d-4325-a990-31ca26435ad0" class="bulleted-list"><li style="list-style-type:disc"><code>pexpire</code> 명령어는 <strong>지정된 시간(milliseconds) 후 key 자동 삭제</strong>합니다.</li></ul><figure id="2ceac0e4-8b20-4448-93ca-44d665d6fbac"><a href="https://velog.io/@hgs-study/redisson-distributed-lock" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Redisson 분산락을 이용한 동시성 제어</div><div class="bookmark-description">Redis 클라이언트인 Redisson 분산락(Distributed Lock)을 이용해서 동시성을 제어하는 포스팅을 진행해봤습니다 (예제 포함)</div></div><div class="bookmark-href"><img src="https://static.velog.io/favicons/apple-icon-152x152.png" class="icon bookmark-icon"/>https://velog.io/@hgs-study/redisson-distributed-lock</div></div><img src="https://velog.velcdn.com/images/hgs-study/post/00081b24-5fab-44ab-8efd-2bc94929c2ed/image.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="9a089758-ae88-4407-aaf9-a8a1299d5d4f" class="toggle"><li><details open=""><summary>Saga패턴을 이용한 분산 트랜잭션 제어</summary><h2 id="05d38762-4b79-48d2-80a8-25bbcd63e306" class="">1. 분산 트랜잭션</h2><h3 id="e2ca21e9-5fa3-4b8b-a993-aa077c184ec4" class="">💡 분산 트랜잭션을 왜 제어해야하는가?</h3><ul id="1856bec7-8f0b-4b22-aab7-1b2eebab34b5" class="bulleted-list"><li style="list-style-type:disc">아래 그림은 결제 프로세스를 MSA 분산 환경으로 간략하게 나타냈습니다. 각 도메인은 각각의 DB를 바라보고 있으며, 결제 프로세스는 세 서비스와 DB를 거쳐야 완료됩니다.</li></ul><ul id="4d16adf0-4336-4672-a414-85d9ae541508" class="bulleted-list"><li style="list-style-type:disc">문제없이 항상 완료만 되는 상황이면 좋겠지만 Order 모듈에서 주문을 생성해서 DB에 저장한 후에, <strong>Stock에서 예외처리 혹은 장애</strong>가 나서 롤백해야한다면 어떻게 처리해야할까요?</li></ul><figure id="4ae0992a-9a7a-4447-9b33-24afe1e66130" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/7273f7ae-22a2-4c31-ba62-e8003cf87631/image.png"><img src="https://velog.velcdn.com/images/hgs-study/post/7273f7ae-22a2-4c31-ba62-e8003cf87631/image.png"/></a></figure><h2 id="82d4202c-dd80-4dca-b9f8-43f15872acd2" class="">2. Saga Pattern</h2><h3 id="5ebd4ced-b01d-40f0-8bad-bbf44e04c000" class="">❓ Saga Pattern이란?</h3><ul id="2401f355-3996-4b54-8f56-daea99820a8f" class="bulleted-list"><li style="list-style-type:disc">Saga Pattern은 마이크로 서비스에서 데이터 일관성을 관리하는 방법입니다.</li></ul><ul id="e8ff6d6b-28cb-4513-b3d8-5485a3a4bea5" class="bulleted-list"><li style="list-style-type:disc">각 서비스는 로컬 트랜잭션을 가지고 있으며, 해당 서비스 데이터를 업데이트하며 <strong>메시지 또는 이벤트를 발행</strong>해서, 다음 단계 트랜잭션을 호출하게 됩니다.</li></ul><ul id="ffd05837-dd2d-4245-a949-248fa9761d4d" class="bulleted-list"><li style="list-style-type:disc">만약, 해당 프로세스가 실패하게 되면 데이터 정합성을 맞추기 위해 이전 트랜잭션에 대해 <strong>보상 트랜잭션</strong>을 실행합니다.</li></ul><ul id="11ff182a-6e3d-4e27-b1f0-b128e3330c8d" class="bulleted-list"><li style="list-style-type:disc">NoSQL 같이 분산 트랜잭션 처리를 지원하지 않거나, 각기 다른 서비스에서 다른 DB 밴더사를 이용할 경우에도 Saga Pattenrn을 이용해서 데이터 일관성을 보장 받을 수 있습니다.</li></ul><blockquote id="a5ef3c53-80e0-4708-b522-48a958e973a2" class="">간단히 정리하자면, 각기 다른 분산 서버에 다른 DB 밴더사를 사용하고 있어도, Saga Pattern을 사용하면 데이터 일관성을 보장받을 수 있다. 또한 트랜잭션 실패시, 보상 트랜잭션으로 데이터 정합성을 맞출 수 있다.</blockquote><h3 id="51627fe1-bb7c-4d39-9ef2-3bcf7f04e498" class="">❓ Choreography 방식이란?</h3><blockquote id="1c15d2a4-d960-4f4e-82dc-0af9ab8b3991" class="">Saga Pattern은 Orchestration 방식과 Choreography 방식이 존재하는데 이번 포스팅에서는 Choreography 방식만 소개합니다. Orchestration 방식을 알아보고 싶으시다면 마이크로소프트 공식 홈페이지를 참조해주세요</blockquote><figure id="094c358b-b720-4a66-b6fb-bcf2749b3dd8" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/8894d10a-d687-4e2b-b121-babef08e65ec/image.png"><img style="width:576px" src="https://velog.velcdn.com/images/hgs-study/post/8894d10a-d687-4e2b-b121-babef08e65ec/image.png"/></a></figure><ul id="5d17153b-14bc-4c32-9f9b-499066271559" class="bulleted-list"><li style="list-style-type:disc">Choreography 방식은 서비스끼리 직접적으로 통신하지 않고, 이벤트 Pub/Sub을 활용해서 통신하는 방식입니다.</li></ul><ul id="e573da65-1ff9-42ae-a297-12d84895ccd3" class="bulleted-list"><li style="list-style-type:disc">프로세스를 진행하다가 여러 서비스를 거쳐 서비스(Stock, Payment)에서 실패(예외처리 혹은 장애)가 난다면 <strong>보상 트랜잭션 이벤트</strong>를 발행합니다.</li></ul><ul id="8b7425ec-a8d4-464f-bfd5-5028deb4656c" class="bulleted-list"><li style="list-style-type:disc">장점으론, 간단한 workflow에 적합하며 추가 서비스 구현 및 유지관리가 필요하지 않아서 간단하게 세팅할 수 있습니다.</li></ul><ul id="5080c579-9f10-43c8-8432-09fa59bebc73" class="bulleted-list"><li style="list-style-type:disc">단점으론, 트랜잭션을 시뮬레이션하기 위해 모든 서비스를 실행해야하기 때문에 통합테스트와 디버깅이 어려운 점이 있습니다.</li></ul><h2 id="3349b7ca-1464-4a36-b3c7-985bf8e6d4da" class="">3. 결제 어플리케이션 구성</h2><h3 id="2e270619-d9fa-43a9-8816-60a6959490bc" class="">✅ 정상적인 분산 트랜잭션 프로세스</h3><figure id="08d65d13-1e91-4c79-ae7e-5b31128a9c7a" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/efd07950-91e8-434a-8214-5f58f189294f/image.png"><img style="width:624px" src="https://velog.velcdn.com/images/hgs-study/post/efd07950-91e8-434a-8214-5f58f189294f/image.png"/></a></figure><p id="2062f624-b074-4beb-8091-8250acafdfee" class=""><strong>(1)</strong> 사용자 요청을 받은 Order 서비스에서 주문 번호를 생성해서 DB에 적재</p><p id="d5b26b3b-1915-4fb8-ad4f-5b49e48c6c21" class=""><strong>(2)</strong> Kafka에 주문번호 생성 이벤트 발행</p><p id="1f3cc58d-ba28-4488-b13b-55402adc1702" class=""><strong>(3)</strong> Stock에서 주문번호 생성 이벤트를 구독해서 해당 재고 빼기</p><p id="8f8f5f99-c1d1-45f0-9711-ce7e5eef6f91" class=""><strong>(4)</strong> Kafka에 재고 빼기 이벤트 발행</p><p id="36ad4b9d-277f-4ed3-9bdc-4c92fb1f094c" class=""><strong>(5)</strong> Payment에서 재고 빼기 이벤트를 구독해서 결제 프로세스 진행</p><h3 id="d62a39fc-96c5-4ebb-b634-c2d829d0c319" class="">❌ 실패 분산 트랜잭션 프로세스</h3><figure id="a0d50a04-9ab0-4b00-b96d-d7d697b80b71" class="image"><a href="https://velog.velcdn.com/images/hgs-study/post/d00adf4d-21dc-494e-8b0b-e9fb511162d4/image.png"><img style="width:672px" src="https://velog.velcdn.com/images/hgs-study/post/d00adf4d-21dc-494e-8b0b-e9fb511162d4/image.png"/></a></figure><blockquote id="b7784c30-5255-4861-9ab5-19d84f4b716c" class="">결제 분산 트랜잭션 진행 중, Payment 서비스에서 트랜잭션이 실패할 경우를 가정한 그림입니다. 빨간색 화살표는 Producer, 파란색 화살표는 Consumer를 뜻합니다.</blockquote><p id="f659731a-1eb4-4403-9a9e-7a865d4fb673" class=""><strong>(1)</strong> Payment 서비스에서 트랜잭션 실패</p><p id="2131ba1d-0a17-4cb2-acf3-3201146d5f96" class=""><strong>(2)</strong> Payment에서 <strong>재고 롤백</strong> 이벤트 발행</p><p id="b3a7dad3-35be-4819-ba67-62fb5fd29cf5" class=""><strong>(3)</strong> Stock에서 재고 롤백 이벤트를 구독해서 해당 재고 플러스</p><p id="f4cd2ee2-ef31-4e7c-91b0-f8c9cc177bb3" class=""><strong>(4)</strong> Stock에서 <strong>주문 롤백</strong> 이벤트 발행</p><p id="ff2daa7f-d74c-4380-afe0-b4588e2685de" class=""><strong>(5)</strong> Order에서 주문 롤백 이벤트를 구독해서 해당 주문 삭제</p><figure id="8c3d2018-392e-4d69-9d5a-2abf73ed7868"><a href="https://velog.io/@hgs-study/saga-1" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Saga패턴을 이용한 분산 트랜잭션 제어(결제 프로세스 실습)</div><div class="bookmark-description">이번 포스팅은 MSA에서 분산 트랜잭션을 제어하는 방법 중 하나인 Saga Pattern을 활용해서 분산 서버에서 간단한 결제 프로세스를 구현해봅니다.</div></div><div class="bookmark-href"><img src="https://static.velog.io/favicons/apple-icon-152x152.png" class="icon bookmark-icon"/>https://velog.io/@hgs-study/saga-1</div></div><img src="https://velog.velcdn.com/images/hgs-study/post/72d0ef72-2a95-495f-b247-1d5377df95e8/image.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="b128ec05-0233-4497-b35a-f45bc01210cd" class="toggle"><li><details open=""><summary>MSA 환경에서의 분산 트랜잭션 관리: 2PC &amp; SAGA 패턴</summary><h2 id="d2c8a748-da94-40a0-b6e2-42f31bb8e871" class="">분산 트랜잭션이 필요한 이유</h2><p id="726e7a29-c740-4a07-857b-0daa8da36950" class="">현재 재직중인 회사에서의 시스템은 수십여개의 서버들이 연결된 MSA 형태로 구성되어 있습니다.</p><p id="d94c2cb0-45c9-4281-a04a-f1970afc2925" class="">시스템 별로 각기 DB를 분리하여 독립적으로 관리하고 트랜잭션의 가장 중요한 성질 중 하나는 &#x27;원자성&#x27; 입니다. 단일 DB를 구성할 때와 다르게 DB를 분산하여 운영하게 될 경우 원자성을 만족시키기 어려울 수 있습니다.</p><p id="135a462d-6703-4741-b854-815e036c2cd7" class="">A와 B의 데이터베이스가 분산되어있는경우</p><p id="a9541972-c521-4f2b-8113-b5733744184b" class="">다음과 같은 이유로 분산트랜잭션에 대한 관리가 필요합니다.</p><ol type="1" id="2c905ae1-2344-4189-ba24-28584f1f2f02" class="numbered-list" start="1"><li>네트워크 지연 및 실패 이슈</li></ol><ul id="a22ddacc-07c2-4f52-a73b-b4ca3a748bd2" class="bulleted-list"><li style="list-style-type:disc">분산 시스템에서는 여러 노드가 네트워크를 통해 통신합니다. 네트워크 지연이나 실패로 인해 특정 노드의 응답을 받지 못하거나 지연될 수 있습니다. 이로 인해 트랜잭션의 일부분만 커밋되고 일부분은 롤백되는 상황이 발생할 수 있습니다.</li></ul><ol type="1" id="090c6f1f-ec9f-4bbf-9711-3524c0a323f5" class="numbered-list" start="2"><li>데드락</li></ol><ul id="19943ebd-eec5-4dd9-b06f-047e479e1faf" class="bulleted-list"><li style="list-style-type:disc">여러 노드가 서로의 자원 또는 데이터에 동시에 접근하려 할 때, 상호간의 대기 상태에 빠져서 진행을 할 수 없게 되는 현상입니다. 분산 트랜잭션에서는 데드락을 해결하기 위한 중앙화된 관리 메커니즘이 없어 복잡한 해결 전략이 필요합니다.</li></ul><ol type="1" id="700fa10e-efc9-4bc9-ad44-d9f84fb0186f" class="numbered-list" start="3"><li>데이터 일관성 유지의 어려움</li></ol><ul id="fcc2b618-79bd-4584-8896-f09963a9f074" class="bulleted-list"><li style="list-style-type:disc">분산 시스템에서 데이터의 복제본이 여러 노드에 분산 저장될 수 있습니다. 따라서 한 노드에서의 데이터 변경이 모든 노드에 즉시 반영되지 않으면 일관성 문제가 발생할 수 있습니다.</li></ul><p id="ee6380e6-3dd2-4f8b-a212-de4ba4014144" class="">
</p><p id="51627951-4b17-4579-af59-e28f10821ad1" class="">Spring Boot 대표적으로 <strong>2-Phase-Commit(2PC)</strong> 또는 <strong>SAGA 패턴</strong>을 사용하여 분산 트랜잭션을 관리합니다.</p><p id="eaadf677-32b7-45db-9775-3a8e69c3c7f6" class=""><strong>2PC를 사용하였을 경우의 문제점</strong></p><ul id="e38cd7bd-3369-4e67-a96c-1c985069a956" class="bulleted-list"><li style="list-style-type:disc">트랜잭션의 책임이 Coordinator Node에 있으며 이 부분이 단일 실패지점(SPOF)가 될 수 있습니다.</li></ul><ul id="dd2023c7-5d10-4c8e-8841-e9870cd09788" class="bulleted-list"><li style="list-style-type:disc">전체 트랜잭션이 완료될 때까지 서비스에서 사용하는 리소스가 잠겨 있어 서비스가 완료될 때까지 대기하여야 합니다. 때문에 지연 시간이 늘어나고 리소스가 차단되어 확장이 어려워질 수 있습니다.</li></ul><ul id="f927807b-df75-4066-8d9e-57d825d398c5" class="bulleted-list"><li style="list-style-type:disc">NoSQL은 2PC-분산 트랜잭션을 지원하지 않습니다.</li></ul><h3 id="9324471a-7623-4167-ac01-91214e376021" class=""><strong>SAGA 패턴</strong></h3><p id="0202dd35-fc45-4b9c-91e6-e191a08aeeca" class="">SAGA 패턴은 MSA환경에서 일관성을 지키기 여렵다는 것을 기반으로, 약간의 일관성을 포기하고 Eventual Consistency(최종 일관성)을 보장하여 효율성을 높이기 위한 패턴입니다.</p><p id="f55f25fa-b925-4a2b-862e-df21d7a06c5e" class="">2PC에서는 트랜잭션을 하나의 트랜잭션으로 묶어서 처리를 하지만, SAGA 패턴은 긴 트랜잭션을 여러 개의 짧은 로컬 트랜잭션으로 분리하는 접근 방식입니다. 각 트랜잭션은 다른 트랜잭션의 완료를 기다리지 않고 독립적으로 실행됩니다. 따라서 트랜잭션의 원자성을 지켜줄 방법이 필요합니다. 만약 중간에 문제가 발생하면, <strong>보상(Compenstation) 트랜잭션</strong>이 실행되어 이전 트랜잭션을 롤백하는 것과 같은 효과를 가져옵니다.</p><p id="c26c18cf-fa6a-4db8-ac85-e01ecbb0606f" class="">각 로컬 트랜잭션은 자신의 트랜잭션을 끝내고 다음 트랜잭션을 호출하는 메시지, 이벤트를 생성하게 됩니다.</p><p id="07b84fe3-08b1-4f31-8b0b-590f73a7a718" class=""><strong>그럼 보상 트랜잭션이 뭔데?</strong></p><p id="ae9134c5-3681-4791-a508-b3ad2d02790b" class="">보상 트랜잭션은 분산된 트랜잭션 중 일부가 실패할 경우, 그 실패 전에 성공적으로 완료된 트랜잭션을 <strong>보상</strong> 즉, <strong>되돌리는</strong> 역할을 하는 트랜잭션입니다.</p><p id="a8eec058-1314-48a0-85f7-f2137c34c058" class="">SAGA 패턴의 트랜잭션은 분산된 여러 독립적인 트랜잭션이기 떄문에, 어떤 서비스의 트랜잭션이 실패하면 단일 트랜잭션 처럼 롤백 메커니즘을 사용할 수 없습니다. 대신 보상 트랜잭션을 사용하여 이전에 성공한 트랜잭션의 효과를 취소합니다.</p><p id="d63f3be7-f204-4a96-976e-6423b36a6567" class=""><strong>보상트랜잭션이 실패할 경우에는?</strong></p><p id="4132d437-69a5-433d-a75f-d6bc76841a6e" class="">보상트랜잭션도 하나의 트랜잭션이기 때문에, 다양한 요인들로 인해 실패할 수 있습니다.</p><p id="76f58ee6-d669-43c8-9535-44d0b26a4b2d" class="">이에 대한 대비도 필요합니다!</p><p id="848194a5-f6ad-4b22-805d-6969bc63ed1b" class="">사가 패턴은 <strong>이벤트기반</strong>으로 작동합니다.</p><p id="4b8d8dcb-1af6-453d-a3f9-4177f0069a0b" class="">보상 트랜잭션을 카프카 같은 데이터 스트리밍 서비스 같은곳에서 처리하게 하고 멱등키와 함께 재시도 프로세스를 추가합니다.</p><p id="f1ff1544-a418-485f-aded-84993d9bd19d" class="">이후 N번이상 실패 할경우에는 어쩔수 없지만... 개발자가 수동으로 오류를 해결할 수 있게 알람을 주어야 합니다.</p><p id="a5c547c0-3504-4d73-95b2-0ba730bf4972" class="">멱등키 활용 로직 예시</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8cdd05f2-7bb0-468e-8171-d14fd0f79a97" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">public class CompensationTransaction {
    private IdempotencyKey key; // 멱등키를 활용
    private Event event;

    public CompensationTransaction(IdempotencyKey key, Event event) {
        this.key = key;
        this.event = event;
    }

    public void execute() {
        if(!isProcessed(key)) {
            // 보상 로직 수행
            processCompensation(event);
            markAsProcessed(key);
        }
    }
}</code></pre><blockquote id="41643465-248b-4f79-8d46-1225903caf77" class="">멱등키의 사용 이유는 링크를 참조해주세요.<p id="45df1e0d-163c-451c-8746-6a6703c5ef4f" class="">(토스페이먼츠에서 너무 정리를 잘해주셔서 꼭 보셨으면 좋겠습니다)</p><p id="d6294202-1692-4303-859a-bac5d061a394" class=""><a href="https://velog.io/@tosspayments/%EB%A9%B1%EB%93%B1%EC%84%B1%EC%9D%B4-%EB%AD%94%EA%B0%80%EC%9A%94">https://velog.io/@tosspayments/%EB%A9%B1%EB%93%B1%EC%84%B1%EC%9D%B4-%EB%AD%94%EA%B0%80%EC%9A%94</a></p></blockquote><h3 id="10740c3e-3b21-4637-904f-df4d01841a25" class="">SAGA 패턴의 구현방법</h3><p id="a167be8f-a9fa-41c9-bc9f-447e2598cd46" class="">SAGA 패턴을 구현하는 방법은 두가지가 있습니다.</p><ol type="1" id="3f901bb6-7aae-4935-abc9-ac444e831307" class="numbered-list" start="1"><li>Choreography SAGA(코레오크레피 사가)</li></ol><ol type="1" id="4dd9523d-f54b-4643-aa41-b24e19661120" class="numbered-list" start="2"><li>Orchestration SAGA(오케스트레이션 사가)</li></ol><h3 id="aa2a813e-0bf0-4e7a-aaaa-365d36e7b4fb" class="">1. Choreography SAGA</h3><p id="35ddf9a6-5c83-4413-a5cb-5456f2997bba" class="">Choreography 방식은 각 서비스끼리 이벤트를 주고 받는 방식입니다.</p><p id="1f0df832-011b-4cc4-815e-f0221d1745a5" class="">각 서비스가 다른 서비스의 로컬 트랜잭션을 이벤트 트리거하는 방식으로 이루어 집니다.</p><p id="44570032-3088-458d-8029-3cae3a2c59d4" class="">이 방식은 중앙집중된 지점이 없이 모든 서비스가 메시지 브로커(RabbitMQ, Kafka)를 통해 이벤트를 Pub/Sub 하는 구조입니다.</p><ul id="d8d1158a-69a7-4016-a651-6cef13c5be3c" class="bulleted-list"><li style="list-style-type:disc">중앙 집중형 관리방식이 아니기 때문에 SPOF(단일 실패지점)이 없습니다.</li></ul><ul id="e29b1d6e-7cbe-4311-b0e7-17ee05df8716" class="bulleted-list"><li style="list-style-type:disc">새로운 서비스 추가가 필요할 때 서비스간 연결을 잘 확인해야합니다.</li></ul><ul id="84118499-2dd2-40e4-8488-6fc352629aee" class="bulleted-list"><li style="list-style-type:disc">서비스끼리 이벤트를 주고 받기 때문에 큰 시스템의 경우 구조의 파악이 어려워 질 가능성이 있습니다.</li></ul><ul id="9d446b34-45dc-4ce3-8f3b-88ce3b392b9f" class="bulleted-list"><li style="list-style-type:disc">트랜잭션을 시뮬레이션하기 위해 모든 서비스를 실행해야하기 때문에 통합테스트와 디버깅이 어려운 점이 있습니다.</li></ul><figure id="1e01d06b-e50e-4f25-a177-c722ec8570b2" class="image"><a href="https://blog.couchbase.com/wp-content/uploads/2018/01/Screen-Shot-2018-01-11-at-7.40.54-PM-1024x627.png"><img src="https://blog.couchbase.com/wp-content/uploads/2018/01/Screen-Shot-2018-01-11-at-7.40.54-PM-1024x627.png"/></a></figure><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e8525830-2d30-41c5-99c8-a55f131b4da5" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">public class MessageBroker {
    public static void publish(String event, double amount) {
        // 이벤트 발행 로직
    }

    public static void subscribe(String event, Service service) {
        // 이벤트 구독 로직
    }
}

public class AAccountService {
    public void deductAmount(double amount) {
        if (canDeduct(amount)) {
            MessageBroker.publish(&quot;AmountDeducted&quot;, amount);
        } else {
            MessageBroker.publish(&quot;TransferFailed&quot;, amount);
        }
    }

    @Subscribe(&quot;CreditFailed&quot;)
    public void revertDeduction(double amount) {
        // 보상 로직
    }

    private boolean canDeduct(double amount) {
        return true;
    }
}

public class BAccountService {
    @Subscribe(&quot;AmountDeducted&quot;)
    public void creditAmount(double amount) {
        if (canCredit(amount)) {
            MessageBroker.publish(&quot;AmountCredited&quot;, amount);
        } else {
            MessageBroker.publish(&quot;CreditFailed&quot;, amount);
        }
    }

    private boolean canCredit(double amount) {
        return true;
    }
}</code></pre><figure id="0112c915-451e-41f0-9c49-ed4c834ca0c1" class="image"><a href="https://velog.velcdn.com/images/ch200203/post/ea2115f6-b859-4f3c-a356-57b1ef3c6f1a/image.png"><img src="https://velog.velcdn.com/images/ch200203/post/ea2115f6-b859-4f3c-a356-57b1ef3c6f1a/image.png"/></a></figure><ol type="1" id="b3a148af-b2a5-497c-879f-ce9509897b51" class="numbered-list" start="1"><li>AAccountService에서 금액을 인출하려고 시도합니다.</li></ol><ol type="1" id="7db9d71c-56f2-4f64-aac0-9f9b89b467de" class="numbered-list" start="2"><li>인출에 성공하면, &quot;AmountDeducted&quot; 이벤트가 MessageBroker를 통해 발행됩니다.</li></ol><ol type="1" id="2dd69892-01c0-4340-bace-97f4f9d08714" class="numbered-list" start="3"><li>BAccountService는 &quot;AmountDeducted&quot; 이벤트를 구독하고 있으므로 이 이벤트를 수신하고 금액을 입금하려고 시도합니다.</li></ol><ol type="1" id="3452ced2-bbab-47eb-8e25-ea1f4fa8ecc2" class="numbered-list" start="4"><li>만약 BAccountService에서 입금에 실패하면, &quot;CreditFailed&quot; 이벤트가 발행됩니다.</li></ol><ol type="1" id="b5fc54a1-3b87-488a-a717-97b80697afe6" class="numbered-list" start="5"><li>AAccountService는 &quot;CreditFailed&quot; 이벤트를 구독하고 있으므로 이 이벤트를 수신하고 인출된 금액을 되돌립니다.</li></ol><h3 id="57bb0512-e1a5-4830-89c9-0fbe49433536" class="">2. Orchestration SAGA</h3><figure id="3ad85a26-dbc0-4950-9b59-83193a31f54f" class="image"><a href="https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/cloud-design-patterns/images/saga-3.png"><img src="https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/cloud-design-patterns/images/saga-3.png"/></a></figure><p id="189fdd86-f8c6-4761-bb82-dd0170a9df83" class="">오케스트레이션 사가는 중앙 집중형으로 실행 흐름을 관리하게 됩니다.</p><p id="49c19b7b-9695-4411-8e77-a98146179478" class="">Ochestrator는 요청을 실행, 각 서비스의 상태를 확인하고, 실패에 대한 보상 트랜잭션을 실행합니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="b828ecf3-4b9f-4c85-a7c0-9e0041427a35" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">public class MessageBroker {
    public static void publish(String event, double amount) {
        // Publish event
    }

    public static void subscribe(String event, Service service) {
        // Subscribe
    }
}

public class Orchestrator {
    AAccountService aAccountService;
    BAccountService bAccountService;

    public Orchestrator(AAccountService aService, BAccountService bService) {
        this.aAccountService = aService;
        this.bAccountService = bService;
    }

    public void transferAmount(double amount) {
        if (aAccountService.deductAmount(amount)) {
            if (!bAccountService.creditAmount(amount)) {
                aAccountService.revertDeduction(amount);
            }
        }
    }
}

public class AAccountService {
    public boolean deductAmount(double amount) {
        if (canDeduct(amount)) {
            return true;
        } else {
            return false;
        }
    }

    public void revertDeduction(double amount) {
        // 보상 로직 구현
    }

    private boolean canDeduct(double amount) {
        return true;
    }
}

public class BAccountService {
    public boolean creditAmount(double amount) {
        if (canCredit(amount)) {
            return true;
        } else {
            return false;
        }
    }

    private boolean canCredit(double amount) {
        return true;
    }
}
</code></pre><ul id="153c8e76-8c1e-4c9e-8ec6-df9da93c0c19" class="bulleted-list"><li style="list-style-type:disc">Ochestration은 트랜잭션 처리를 위한 Manager 인스턴스가 별도로 존재합니다.</li></ul><ul id="e64aae4d-6673-4aa6-b917-45b5f3daf296" class="bulleted-list"><li style="list-style-type:disc">Ochestrator가 중앙 집중형 컨트롤러 역할 → 각 서비스에서 실행할 트랜잭션을 관리를 하게됩니다.</li></ul><ul id="c1af335c-8aed-43ac-a020-2497ed2464bf" class="bulleted-list"><li style="list-style-type:disc">Ochestrator는 요청을 실행, 각 서비스의 상태를 확인하고, 실패에 대한 보상 트랜잭션을 실행합니다.</li></ul><ul id="f26fd917-a408-46bc-93d1-237f21f4fe6d" class="bulleted-list"><li style="list-style-type:disc">많은 서비스가 있는 복잡한 워크플로우에 적합합니다.A서비스는 B서비스의 트랜잭션의 결과를 알필요가 없습니다.<ul id="703fa505-f1d3-4d00-805e-ba1780a43276" class="bulleted-list"><li style="list-style-type:circle">흐름을 파악하는데도 좋습니다.</li></ul></li></ul><ul id="0d90cada-64e5-4cd9-b6c0-2f5d295866a7" class="bulleted-list"><li style="list-style-type:disc">Ochestrator가 전체 워크플로우를 관리하기 떄문에 SPOF(단일 실패지점)가 될 가능성이 있습니다.</li></ul><p id="51bebc27-5a1e-4c6e-be8a-3cf2a6cc05fd" class="">
</p></details></li></ul><ul id="c80acd3b-4cae-440b-b8f2-db28e30a3e6e" class="toggle"><li><details open=""><summary>MSA 구조에서 데이터 일관성 유지</summary><h2 id="08b21c7e-ca51-4958-a41b-731a0bb5dcfe" class="">MSA 구조에서 DB 데이터 일관성 유지</h2><p id="4ad33b7f-fba2-44f6-93bc-01f3ed8eb1ec" class="">마이크로서비스 아키텍처(MSA)는 서비스별로 독립된 데이터 저장소를 사용하기 때문에 데이터 일관성(consistency)을 유지하는 것이 중요한 과제입니다. MSA 구조에서 데이터 일관성을 유지하기 위해 다양한 기술과 패턴이 사용되는데, 아래에서 이들 기술과 패턴에 대해 자세히 설명하겠습니다.</p><h3 id="d89a3cb6-c5ae-430b-b7bd-6a2685bd2506" class="">1. <strong>분산 트랜잭션 관리</strong></h3><h3 id="792842c6-c928-4d88-a88f-ee00b465d86e" class="">a. <strong>2-Phase Commit (2PC)</strong></h3><ul id="afeb3afc-a966-45bc-b3de-aeff2e957f97" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 분산 트랜잭션의 일관성을 보장하기 위해 2단계로 트랜잭션을 처리하는 프로토콜입니다.<ol type="1" id="ed866c98-36ee-4e50-9823-2429e216c57f" class="numbered-list" start="1"><li><strong>준비 단계(Prepare Phase)</strong>: 트랜잭션 관리자는 각 참여 서비스에게 트랜잭션을 준비하도록 요청하고, 성공 여부를 확인합니다.</li></ol><ol type="1" id="b156c34d-668b-45c9-b137-06cfdd1d6dd0" class="numbered-list" start="2"><li><strong>커밋 단계(Commit Phase)</strong>: 모든 서비스가 준비 상태에 있음을 확인하면, 트랜잭션 관리자는 트랜잭션을 커밋하거나 롤백하도록 명령합니다.</li></ol></li></ul><ul id="34e3f5ea-014a-47b5-8f77-1cac0d9281af" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 강력한 일관성을 보장합니다.</li></ul><ul id="b3c0befd-8895-4cdc-817e-b064e825ec37" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 참여 서비스의 응답 지연이나 실패 시 전체 시스템이 일시 중단될 수 있는 단점이 있습니다.</li></ul><h3 id="fbcf8ed1-53ef-4770-9ea7-accff0e4277f" class="">b. <strong>XA Transactions</strong></h3><ul id="b99f31aa-b07b-4826-b6b8-3746660b979f" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 2PC를 기반으로 한 확장 가능한 분산 트랜잭션 관리 프로토콜입니다.</li></ul><ul id="89bdafc9-a300-4393-aedf-09fbfd35a93b" class="bulleted-list"><li style="list-style-type:disc"><strong>적용 사례</strong>: 은행이나 금융 시스템과 같이 트랜잭션의 원자성과 일관성이 필수적인 시스템에서 사용됩니다.</li></ul><ul id="759c0060-d98b-4bd2-aa62-6e587f7a2970" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 2PC와 유사한 단점으로 인해 MSA에서는 잘 사용되지 않는 경우가 많습니다.</li></ul><h3 id="94650d7c-30ef-4ba1-8676-c45f3d743cbd" class="">2. <strong>사후 일관성 유지</strong></h3><h3 id="248e9067-1f5f-43e0-b900-eeef305c38f8" class="">a. <strong>Sagas Pattern</strong></h3><ul id="84b0618e-6ac6-4083-bcf8-c6a9fe10316b" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 장기 실행 트랜잭션을 여러 개의 소규모 로컬 트랜잭션으로 분할하고, 각 단계별로 보상(compensation) 트랜잭션을 정의합니다.</li></ul><ul id="bb96aafb-f2f7-4e23-a816-48ed9f201659" class="bulleted-list"><li style="list-style-type:disc"><strong>운영 방식</strong>:<ol type="1" id="c3a23645-9143-4b3c-84b0-e4f19a6b33b5" class="numbered-list" start="1"><li>각 서비스는 자신의 로컬 트랜잭션을 실행하고 성공 여부를 보고합니다.</li></ol><ol type="1" id="d200607e-2ac5-48ca-b5e4-e0d5c4439385" class="numbered-list" start="2"><li>실패가 발생하면, 보상 트랜잭션을 통해 이전에 성공한 트랜잭션의 변경사항을 취소합니다.</li></ol></li></ul><ul id="93a50456-3c9e-4eb0-8593-c9947838862c" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 트랜잭션 중에 다른 서비스의 작업을 기다릴 필요가 없으므로 시스템의 전체적인 지연을 줄일 수 있습니다.</li></ul><ul id="d8463079-cd4f-4531-8139-5038b1b43ed1" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 보상 트랜잭션을 작성하는 것이 복잡할 수 있으며, 시스템의 상태가 일시적으로 일관되지 않을 수 있습니다.</li></ul><h3 id="8d6b05b4-4e9b-4ec2-bc3f-76501c15e411" class="">b. <strong>Event Sourcing</strong></h3><ul id="79650f24-e805-4467-8e8d-ada1d11b58c4" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 상태를 이벤트의 순서로 기록하고, 이벤트를 재생(replay)하여 시스템의 상태를 재구성합니다.</li></ul><ul id="a32d79a2-abc0-43a6-a5fd-af0d2b3f0d40" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 모든 변경사항을 이벤트로 기록하기 때문에, 상태 변경 이력을 완전히 추적할 수 있습니다.</li></ul><ul id="83da8d0a-941b-41c0-8862-096b301d34f1" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 이벤트 저장소를 관리하고 이벤트 재생 로직을 구현하는 것이 복잡할 수 있습니다.</li></ul><h3 id="55924835-3bed-49ab-8067-1547fa292916" class="">3. <strong>데이터 일관성 패턴</strong></h3><h3 id="2c0f9299-97ea-4a53-a097-8558038ddb83" class="">a. <strong>Command Query Responsibility Segregation (CQRS)</strong></h3><ul id="da4c7a16-bff0-403c-bb44-dd667481a30f" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 명령(command)과 조회(query)를 분리하여 각각의 목적에 맞는 데이터 모델을 사용하는 패턴입니다.</li></ul><ul id="fe66ec02-4aad-4faa-90a5-461fc58fd16f" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 쓰기와 읽기에 최적화된 데이터 모델을 각각 사용할 수 있으므로 성능과 확장성이 향상됩니다.</li></ul><ul id="a45438ce-0717-492c-a842-f08bfcac8caf" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 데이터 모델을 두 개 이상 관리해야 하므로 복잡성이 증가할 수 있습니다.</li></ul><h3 id="b184e083-874b-4d93-819d-6bfad5b24c5d" class="">b. <strong>Change Data Capture (CDC)</strong></h3><ul id="111b3766-9deb-4ed8-adab-5ab2da548341" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 데이터베이스에서 변경된 데이터를 캡처하고, 이를 이벤트로 전송하여 다른 서비스에서 처리하도록 하는 방식입니다.</li></ul><ul id="8d2f839e-44ff-4736-9451-5e26598f125d" class="bulleted-list"><li style="list-style-type:disc"><strong>적용 사례</strong>: MSA에서 서비스 간 데이터 동기화를 위해 많이 사용됩니다.</li></ul><ul id="4b73ae06-eab8-4e65-a2ab-c6ac27a76315" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 실시간으로 데이터 변경사항을 반영할 수 있으며, 데이터베이스의 부하를 줄일 수 있습니다.</li></ul><ul id="12093379-7965-4aa7-bf14-fbc07c36f01c" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 복잡한 설정과 유지보수가 필요할 수 있습니다.</li></ul><h3 id="75d3110e-28df-4f8a-883b-78fa5f9d14c9" class="">4. <strong>데이터 동기화 및 복제</strong></h3><h3 id="5364e110-c665-4da6-9a2f-bf89d4b733ff" class="">a. <strong>데이터 복제</strong></h3><ul id="cd90be44-b671-446b-a784-4b11bacc7991" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 서비스별로 분리된 데이터 저장소 간의 데이터 복제를 통해 일관성을 유지합니다.</li></ul><ul id="0eda3ff1-46b0-4057-bd0b-e284f7b4826d" class="bulleted-list"><li style="list-style-type:disc"><strong>적용 방식</strong>: 데이터베이스 수준에서 자동화된 복제 기능을 사용하거나, 애플리케이션에서 수동으로 복제를 구현할 수 있습니다.</li></ul><ul id="2622893c-66a2-41d8-a925-388309adb032" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 데이터가 자동으로 동기화되므로, 데이터 일관성을 유지하기가 쉽습니다.</li></ul><ul id="e2babbc1-b525-49de-bb8f-5b21f9bcea5f" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 데이터 복제 설정이 복잡할 수 있으며, 복제 지연으로 인한 일시적인 불일치가 발생할 수 있습니다.</li></ul><h3 id="f63c47c8-67ae-4be5-a998-a4bec0ca136f" class="">b. <strong>데이터 동기화</strong></h3><ul id="447c183e-5d4a-45c9-aedd-b1fbe50663bb" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 비동기 방식으로 데이터 동기화를 통해 서비스 간 일관성을 유지합니다.</li></ul><ul id="a3ba7c31-6e83-44eb-b2a2-eae636d3d4e6" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 각 서비스가 독립적으로 작동하면서도 일관성을 유지할 수 있습니다.</li></ul><ul id="a3fa8869-4442-4f0b-978e-818c7c8e1ad9" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 데이터 동기화에 시간이 소요될 수 있으며, 일관성 유지에 대한 추가적인 로직이 필요합니다.</li></ul><h3 id="5876b129-e1d8-4db8-8f67-8fd7aefd9fc1" class="">5. <strong>유저 세션 관리 및 데이터 일관성</strong></h3><h3 id="9e902352-8abf-47b8-abb0-2750f1166f78" class="">a. <strong>분산 세션 관리</strong></h3><ul id="394200dd-8bce-45f4-80bf-35fe95de3f8e" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 각 서비스가 사용자 세션을 관리하고, 중앙의 세션 저장소(Redis, Memcached 등)를 사용하여 세션 데이터를 공유합니다.</li></ul><ul id="a3606633-5305-456c-9663-cc456bb140a8" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 사용자의 세션 상태를 쉽게 공유할 수 있으며, 스케일아웃이 용이합니다.</li></ul><ul id="81231e0b-670a-48da-9784-cc48815e5d90" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 중앙 세션 저장소의 가용성이 중요한 이슈가 될 수 있습니다.</li></ul><h3 id="243ef120-839d-4e00-8df9-fa67be36696d" class="">6. <strong>트랜잭션 메시지</strong></h3><h3 id="be52f625-691e-42c9-94b7-5f81fbc1ea36" class="">a. <strong>Outbox Pattern</strong></h3><ul id="ca3bf5ce-842f-4675-82df-1153f4e92365" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 서비스가 데이터베이스에 로컬 트랜잭션으로 메시지(outbox)를 저장하고, 별도의 프로세스를 통해 메시지를 브로커(Kafka, RabbitMQ 등)에 전송합니다.</li></ul><ul id="74890f07-01bd-4366-8c3d-6eeeae6401ed" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 데이터베이스와 메시지 브로커 간의 일관성을 유지할 수 있습니다.</li></ul><ul id="ba50894c-bd1f-4b0e-a9cf-ac6e5263b9e6" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 메시지 브로커와의 통합이 복잡할 수 있으며, 메시지 처리 지연이 발생할 수 있습니다.</li></ul><h3 id="46ea7ec4-fc8e-4b7c-8e44-b176ad519d04" class="">b. <strong>Polling Publisher</strong></h3><ul id="0d8eaaab-cdb5-4dd4-96a7-648adb8a8465" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 데이터베이스에서 일정 주기로 메시지를 폴링하여 브로커로 전송합니다.</li></ul><ul id="4500ce6c-97fe-4a2c-a699-02b88a659c32" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>: 기존 시스템과의 통합이 용이하며, 메시지 전송의 신뢰성을 높일 수 있습니다.</li></ul><ul id="5dbaa1a3-2e38-437d-a69d-788280bd77c3" class="bulleted-list"><li style="list-style-type:disc"><strong>단점</strong>: 폴링 주기에 따라 메시지 처리 지연이 발생할 수 있습니다.</li></ul><h2 id="1a013552-7631-4e46-9136-c554eb9693f1" class="">7. <strong>데이터 일관성 유지의 실제 사례</strong></h2><h3 id="8e51c742-af3a-4630-b76a-93ef2d58f065" class="">a. <strong>전자 상거래 플랫폼</strong></h3><ul id="0d1ce277-2e7a-4e0d-aa3b-e9a9ee43bb42" class="bulleted-list"><li style="list-style-type:disc"><strong>문제</strong>: 주문 및 결제 과정에서의 데이터 일관성 유지.</li></ul><ul id="153e3cb8-8b88-452e-aca1-63f4c51257cc" class="bulleted-list"><li style="list-style-type:disc"><strong>해결</strong>: Sagas 패턴과 Outbox 패턴을 적용하여 주문 상태 변경 및 결제 정보의 일관성을 유지합니다.</li></ul><h3 id="f9e8dad3-ecdd-4461-b26e-f74769647b06" class="">b. <strong>은행 및 금융 서비스</strong></h3><ul id="8d74d8c3-c38c-4792-8eda-fa91acd9d4d1" class="bulleted-list"><li style="list-style-type:disc"><strong>문제</strong>: 계좌 이체 및 트랜잭션 처리에서의 데이터 일관성.</li></ul><ul id="8e5319fd-a093-418c-b213-771c62026cfc" class="bulleted-list"><li style="list-style-type:disc"><strong>해결</strong>: 2PC 및 XA 트랜잭션을 사용하여 트랜잭션의 원자성과 일관성을 보장합니다.</li></ul><h3 id="50a423a7-b22e-4973-ba74-8c16ba0a13f6" class="">c. <strong>소셜 네트워크</strong></h3><ul id="9aa6b21c-83e9-4cc9-bd3f-15d13e9ef3f2" class="bulleted-list"><li style="list-style-type:disc"><strong>문제</strong>: 사용자 프로필 및 게시물 동기화.</li></ul><ul id="e130e9fb-5952-4800-bce2-8c80a163ee90" class="bulleted-list"><li style="list-style-type:disc"><strong>해결</strong>: CQRS와 Event Sourcing을 사용하여 사용자 프로필 변경 사항을 효율적으로 동기화하고, 게시물의 일관성을 유지합니다.</li></ul><h2 id="db037b0c-7700-4382-83c1-099697eb9605" class="">8. <strong>기술 선택 시 고려 사항</strong></h2><h3 id="bbe6dc9d-60b1-458a-be77-24c7d2301975" class="">a. <strong>일관성 요구 수준</strong></h3><ul id="26798036-342c-4913-a0ce-567f465b37ef" class="bulleted-list"><li style="list-style-type:disc">서비스의 특성에 따라 요구되는 데이터 일관성 수준을 평가하고, 이에 맞는 기술을 선택합니다.</li></ul><h3 id="a9c19f47-b07c-4c55-bca0-c47015f66680" class="">b. <strong>성능과 확장성</strong></h3><ul id="a39a4bf6-b3db-4fe5-b92d-3531b47b6733" class="bulleted-list"><li style="list-style-type:disc">일관성을 유지하는 데 필요한 성능과 확장성의 균형을 고려하여 기술을 선택합니다.</li></ul><h3 id="12cc0b46-6bd0-45ad-9896-43435b4a23d5" class="">c. <strong>개발 및 운영 복잡성</strong></h3><ul id="c36c6b2e-3378-4aec-befc-b194820a20b7" class="bulleted-list"><li style="list-style-type:disc">각 기술의 구현 및 운영 복잡성을 고려하여 선택합니다. 기술적 부채를 최소화하는 방향으로 선택하는 것이 중요합니다.</li></ul><h2 id="ee422247-1879-49f5-9fe7-b15b6d609ea9" class="">결론</h2><p id="d3b1cb30-6a07-40e5-8ded-9289d5f70a09" class="">MSA에서 데이터 일관성을 유지하기 위해 다양한 기술과 패턴이 사용됩니다. 서비스의 특성과 요구사항에 맞는 기술을 선택하여 적용하면, 데이터 일관성을 유지하면서도 시스템의 성능과 확장성을 확보할 수 있습니다. Sagas, Event Sourcing, CQRS 등 다양한 패턴을 활용하여 분산 환경에서의 데이터 일관성 문제를 효과적으로 해결할 수 있습니다.</p><p id="1ed3a4cc-090a-80b8-bc0f-dbaa6343de67" class="">
</p></details></li></ul><ul id="27c85fea-b134-42ab-a9dc-93b8f6261704" class="toggle"><li><details open=""><summary>트랜잭션 분리</summary><p id="d5dcfb81-b6e0-47d8-b7ef-612031eb4f66" class=""><strong>[트랜잭션 분리의 중요성]</strong></p><p id="f4ff5a1f-294a-4f1f-a00d-7e1f30d23b60" class="">서버 어플리케이션에서 트랜잭션의 범위를 어떻게 잡는지에 따라서 성능에 영향을 줄 수 있다.</p><ol type="1" id="320f5c76-8e4c-4760-a8d4-445cd2968f5d" class="numbered-list" start="1"><li>문제상황 1번 : 1개의 트랜잭션에 이 있거나, 조회가 가 포함되어 있는 경우<p id="1761fd36-3e1c-4dc3-a89d-1f23498d1082" class=""><span style="border-bottom:0.05em solid">너무 많은 작업</span></p><p id="3097a107-ee5f-4466-acf1-bff527ff031b" class=""><span style="border-bottom:0.05em solid">Slow Read 쿼리</span></p><ul id="abe60d96-4102-486d-9042-c956c4f006cf" class="bulleted-list"><li style="list-style-type:disc">트랜잭션 내에서 테이블의 데이터에 Lock을 잡은 상황이라면 다른 사용자는 트랜잭션이 모두 끝날 때까지 대기해야 하는 문제</li></ul><ul id="ec555756-2f12-44ff-ab0e-42cca9ebc652" class="bulleted-list"><li style="list-style-type:disc">Slow Read 하는 쿼리가 있는 경우 다수의 요청처리에 영향을 줄 수 있다.</li></ul><ul id="e6114724-acff-4bdd-a17f-f386fa410cea" class="bulleted-list"><li style="list-style-type:disc">트랜잭션이 끝나기 직전에 오류가 발생하면 그 때까지 처리한 트랜잭션이 roll back 해야하는 상황이 발생.</li></ul></li></ol><ol type="1" id="0ac7b36d-b880-4902-9d6a-5b1f4811c24e" class="numbered-list" start="2"><li>문제상황 2번 : DB 외적인 작업의 실패로 인해서 트랜잭션 전체가 roll back 하는 경우<ul id="21fa571f-9721-489e-96c1-f9235c5d2fd8" class="bulleted-list"><li style="list-style-type:disc">DB 관련 작업은 끝났는데 외부 API 처리가 오래 걸리는 경우, DB Connection을 불필요하게 오래 가져간다.</li></ul><ul id="4e17cff2-fb56-4a78-9e49-c44d87f3f893" class="bulleted-list"><li style="list-style-type:disc">외부 API 오류가 발생하면 DB 관련 작업까지 모두 트랜잭션 roll back 처리를 하게 된다. DB 자원 낭비 발생.</li></ul></li></ol><p id="c5e0d6c1-6fcc-453a-b2a2-277ef3692130" class="">이렇게 트랜잭션을 길게 가져가면 문제가 다수의 요청에 영향을 줄 수 있다.</p><p id="ebacb75c-72ca-4c25-a3f9-6819abe8edcd" class="">적절하게 트랜잭션 범위를 나눠주는 것이 서버의 성능을 높이는 방법이다.</p><p id="2262b1d2-e8c3-4cca-88c5-76071129391c" class=""><strong>[콘서트 예약시스템에서 예약정보를 데이터 플랫폼에 보내는 트랜잭션이 추가된다면? ]</strong></p><ul id="ed52845d-d3dc-4b98-a2e5-7a934fc27001" class="bulleted-list"><li style="list-style-type:disc">현재 결제 프로세스에서 예약정보를 데이터 플랫폼에 보낸다면 아래와 같은 트랜잭션이 된다.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="02d97bb6-2103-48b7-9323-468abfe723b9" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">public 결제트랜잭션 {
        사용자조회();
        토큰유효성검증();
        좌석상태변경();
        예약상태변경();
        포인트충전();
        결제처리();
        토큰만료처리();
        예약정보 데이터플랫폼에 전송();
}</code></pre><p id="ec96f04e-b6e6-4e17-a9fe-e8695e4d5dcb" class="">위 트랜잭션은 1개의 트랜잭션안에 무려 8개의 작업이 있고, 이 모든 작업들이 정상완료가 되어야 트랜잭션이 성공적으로 끝난다.</p><p id="2e7c3631-c54d-42ee-adce-0d050e49ab78" class="">만약에 예약정보를 데이터플랫폼에 전송하는 작업에 지연이 있거나, 오류가 발생한다면 그 전까지 진행했던 모든 작업들을 roll back 해야 한다. 그래서 위의 트랜잭션을 아래와 같이 4개로 분리해서 서로간의 영향도를 낮추고자 나눴다.</p><p id="a9fe32d9-1fe6-4ee6-a6eb-979611608de0" class=""><strong>[트랜잭션 분리 개선안]</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="22047918-3cc1-4b45-bdd6-b7465114a54a" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">public 트랜잭션1 {
          토큰 검증
          사용자 조회
          결제생성
          토큰 만료
          Outbox 테이블 저장
          이벤트 발행
}

public 트랜잭션2 {
        좌석상태변경
  	예약상태변경
    Outbox 테이블 저장
    이벤트 발행
}

public 트랜잭션3 {
        포인트 사용
        Outbox 테이블 저장
        이벤트 발행
}
public 트랜잭션4 {
        데이터 플랫폼에 정보 전송
}</code></pre><p id="29d9fd3f-4e2a-4c6e-a995-ecb114ff25c8" class="">위와 같이 트랜잭션을 분리한 기준은 &quot;Lock 범위가 적절히 작은 트랜잭션&quot; 입니다.이렇게 분리한 이유는 DB Lock이 필요한 트랜잭션(좌석상태변경, 포인트 사용)에서 Lock의 범위를 축소시켜서 불필요한 대기상태를 줄이는 것에 있습니다. 그리고 트랜잭션4에 해당하는 데이터 플랫폼에 정보를 전송하는 작업은 분리해서 트랜잭션 3가 완벽하게 끝난 이후에 이벤트 처리로 별도로 실행될 수 있도록 설계했습니다.현재 제가 개발하는 환경은 모놀리틱 서버이기 때문에 트랜잭션 1 ~ 3에서는 Outbox Table에 발행할 메시지만 저장하되, 실제로 각각의 트랜잭션에서는 Spring Event의 Publisher/Listner의 기능을 이용해서 트랜잭션이 순차적으로 실행되도록 구현합니다.</p><p id="779eb776-ff85-4e54-a72b-66422ade61ca" class="">그리고 트랜잭션 4번은 데이터 플랫폼 서버가 따로 있다고 가정하고, Kafka를 활용해서 메시지 발행을 구현할 예정입니다.</p><p id="9ef886ab-8979-4246-80cc-d5ca4807de0c" class=""><strong>[트랜잭션을 분리하는 방법]</strong></p><figure id="a050f4e5-9abf-4690-bd48-924c21bb0295" class="image"><a href="https://blog.kakaocdn.net/dn/PGwql/btsHnrP9izn/FJj73GyeiP9q9AHQrE8Fkk/img.png"><img style="width:550px" src="https://blog.kakaocdn.net/dn/PGwql/btsHnrP9izn/FJj73GyeiP9q9AHQrE8Fkk/img.png"/></a></figure><p id="8dd3b49a-0458-4b63-a5dc-57f2b82ffa0c" class="">이벤트 퍼블리셔와 리스너로 트랜잭션 분리</p><ol type="1" id="447eb4db-ad18-45b2-b5ac-04554d129c9d" class="numbered-list" start="1"><li><strong>ApplicationEventPublisher &amp; EventListner / TransactionEventListne</strong>r<ul id="51f16220-c6cd-4901-a714-c16a4c109f77" class="bulleted-list"><li style="list-style-type:disc">스프링에서 제공하는 Spring Event 기능을 사용하여 Publisher와 EventListner를 만들어서 트랜잭션을 분리할 수 있습니다.</li></ul><ul id="7154eb2a-e215-4c59-b712-9b18f475af8d" class="bulleted-list"><li style="list-style-type:disc">Event란?<ul id="9bacbe9b-8fb5-4d0e-b172-27098c926373" class="bulleted-list"><li style="list-style-type:circle">특정 트리거가 작동하면 시작되는 &quot;동작 혹은 사건&quot;을 뜻한다.</li></ul><ul id="407ffad4-d9e2-49a3-a689-48f20c731df8" class="bulleted-list"><li style="list-style-type:circle">ex1) A는 작업이 끝나서 물건을 B에게 직접 전달한다</li></ul><ul id="1f67a638-4158-4d65-a907-f7148bd27143" class="bulleted-list"><li style="list-style-type:circle">ex2) A는 작업이 끝나고, B에게 전화를 한다. 그러면 B가 직접 와서 물건을 가져간다. =&gt; 이게 Event publish/listner로 하는 것</li></ul></li></ul></li></ol><ol type="1" id="962f28cd-d3cb-4f75-8354-e429870fac9a" class="numbered-list" start="2"><li><strong>Kafka 비동기 메시지 통신을 통한 책임 분리</strong><ul id="dc6dd831-0838-4a31-9910-dc6bda9ccfde" class="bulleted-list"><li style="list-style-type:disc">Pub/Sub 방식의 메시지 구독 시스템</li></ul><ul id="b1e23158-5d22-47ec-9967-499f1317c3c2" class="bulleted-list"><li style="list-style-type:disc">메시지큐를 사용하면 발신자와 수신자가 서로를 알 필요가 없어서 느슨한 결합이 가능하다</li></ul><ul id="32352444-1db4-41b7-9002-00f3114e4910" class="bulleted-list"><li style="list-style-type:disc">장애가 발생해도 메시지큐에 발신자가 보낸 메시지가 남아있기 때문에 보장성이 확보된다.</li></ul></li></ol><p id="1153b7b6-dc90-4ca6-b239-e82de9617168" class=""><strong>트랜잭션 분리를 위한 선택 : Kafka 비동기 메시지 통신 채택</strong></p><ul id="c0014e61-c1ad-4225-b1ad-49ea01534e34" class="bulleted-list"><li style="list-style-type:disc">분산시스템, 비동기 메시징 환경에서 추구하는 방향</li></ul><ul id="3fb7fc5a-64e0-47bc-88cd-e8cd86375943" class="bulleted-list"><li style="list-style-type:disc">Out box pattern 적용해서 이벤트 발행 보장</li></ul><p id="97193192-0fd7-496e-8d84-ef2c7d74e59e" class="">이렇게 해서 도메인 로직이 완료되면 이벤트 발행도 보장이 확실하게 된다. 이를 통해서 로직의 정합성 확보.</p><ul id="44fba46a-cbd5-4ee4-b1da-31eef1930a30" class="bulleted-list"><li style="list-style-type:disc">Transactional Outbox Pattern 정의 : 도메인 로직과 이벤트 발행 정보를 기록하는 로직을 하나의 트랜잭션으로 묶는 것</li></ul><p id="808fbea1-3685-4e68-92e5-9c3ac70408ff" class="">이를 통해서 도메인 로직이 정상 완료되면, 이벤트 발행 정보를 생성하는 것도 100% 보장할 수 있게된다.</p><ul id="5e603d75-2cd3-4200-98a9-bc92b3de0ea2" class="bulleted-list"><li style="list-style-type:disc">중간에 서버가 중단 되어도 메시지큐에 메시지가 남아있어서 보장성이 확보되기 때문</li></ul><p id="bd4d21d2-cd77-44bd-a0bd-2a81e36711cd" class="">
</p></details></li></ul><ul id="52f76a25-d402-482c-9bc9-07c14964c906" class="toggle"><li><details open=""><summary>동시성 제어 프로그래밍 방식</summary><h1 id="8e584055-2bdd-4a10-94ca-0fa2efa7ebee" class=""><strong>[동시성 제어 프로그래밍 방식]</strong></h1><p id="91c6e80b-b8b2-4525-9796-e23d6a92a4b0" class="">동시성 제어 프로그래밍은 트랜잭션, 트래픽, 분산 환경 여부 등에 따라 다르게 채택하여 사용할 수 있다.</p><p id="66562d56-388d-427f-8f07-774bb3aee85b" class="">콘서트 예약시스템에서 동시성 이슈가 발생하는 지점은 아래 2가지이다.</p><p id="dd60afb9-6eb9-4964-9273-4b8eeefc9041" class="">1) 좌석 예약</p><p id="10e8f5d0-6018-47d3-9ca0-7125015864da" class="">2) 포인트 충전, 사용</p><p id="371895fe-58ba-4328-8bbc-61a8da89482a" class="">좌석 예약 기능 동시성 제어 프로그래밍</p><h1 id="24175ffb-009d-4ba1-b4a0-3e47b10ff26e" class=""><strong>1. synchornized - 부적합</strong></h1><p id="6ef0a36f-b955-45d5-9fe5-a85ee5f19551" class="">Java에서 제공하는 가장 기본적인 동시성 제어 프로그래밍 방법이다.</p><p id="8ff2aecf-727b-47fc-a9d0-247740a4a415" class="">좌석 예약 메서드에 synchronized를 걸면 싱글 스레드 방식으로 좌석 예약을 할 수 있다.</p><p id="d12f8bd2-69de-4eb1-a75e-92146706b06c" class="">구현 난이도 - 쉬움</p><p id="50dd8918-9886-421e-991c-8d0d51ca6f3f" class="">성능 - 낮음</p><p id="fdd0a7e5-ac2f-4067-91e9-e1280879f4fe" class="">특정 메서드를 단일 스레드 환경으로 걸어버리는 것이기 때문에 해당 메서드에 진입하기 위해서는 앞의 스레드가 작업이 끝날때까지 대기해야 한다. 성능과 효율성이 낮은 동시성 제어 방식이다. 그리고 어플리케이션 내의 메서드에 대해서 단일 스레드 환경으로 처리하기 떄문에</p><p id="13f30434-f23d-4142-9946-4f9dd947f34f" class="">분산환경에서는 적합하지 않다는 단점이 있다. 서버가 여러대이면 synchronized가 의미가 없어진다.</p><h1 id="f5de12d3-cde0-4254-9780-28ac34a36e87" class=""><strong>2. ConcurrentHashMap - 부적합</strong></h1><p id="a2f52e1c-b155-4cc0-b6c4-a03e49d4514c" class="">synchronized 방식보다 개선된 방법이다. ConcurrentHashMap은 데이터별로 Lock을 개별적으로 걸기 때문에 메서드 전체에 잠금을 걸어버리는 synchronized보다 성능이 향상된다.</p><p id="210844f0-fb9f-4ba1-b961-eb6054fd6f2e" class="">구현 난이도 - 쉬움</p><p id="517e7af6-1b73-4d0b-b20f-35d2c8287c67" class="">성능 - 낮음</p><p id="7c1fca25-42b2-41c0-a4b0-52960afb2bd5" class="">하지만 ConcurrentHashMap도 분산환경에서는 적합하지 않다. 여러대의 서버에서 콘서트 좌석 예약을 하는 경우 ConcurrentHashMap으로 동시성을 제어하는데 무리가 있다.</p><h1 id="d294f07d-cc27-469b-84fb-27fe488c9aaf" class=""><strong>3. 낙관적 락 - 부적합</strong></h1><p id="f253f55e-b2c8-40cb-be66-a1918c04c9b6" class="">낙관적 락은 데이터의 version으로 수정여부를 확인하여 동시성을 제어하는 방식이다.</p><p id="1b180a7d-ce5a-463d-978b-483f5ae40191" class="">데이터 수정으로 충돌이 적고, 비즈니스 로직이 중간에 실패해도 문제가 없는 경우에 적합한 락의 방식이다.</p><p id="69c5634e-b147-438d-99e1-bcc0b396a341" class="">그리고 요청의 대기시간도 비관적 락에 비해서 짧다. 그리고 여러개의 요청 중 1개만 성공시키고 나머지 탈락시켜야 하는 경우 사용하면 좋다.</p><p id="b82e2467-67db-4826-b9bb-3e6accdc01f5" class="">구현 난이도 - 쉬움</p><p id="f15f2508-dc21-463b-a17f-5c0c5b57d414" class="">성능 - 보통</p><p id="8f63e0d8-ff1e-4b0c-93ed-af470c197137" class="">위와 같은 장점이 있음에도 낙관적 락을 좌석 예약 시스템에서 채택하지 않은 이유는 몇 만명이 몰리는 경우 모든 요청 중 1건만 성공시키고 나머지는 모두 실패처리를 해야한다. 그리고 그에 따른 재시도 처리를 해야한다. 실패처리가 많을수록 재시도가 많아지고 서버에 부하가 증가하게 되기 때문에 낙관적 락을 채택하지 않았다.</p><figure id="85c4b106-7ced-4644-8bf5-dc23372fb7f3" class="image"><a href="https://blog.kakaocdn.net/dn/brx4w5/btsHbpLHZ33/GhT2bKinsx7MYD54A1JUxk/img.png"><img style="width:700px" src="https://blog.kakaocdn.net/dn/brx4w5/btsHbpLHZ33/GhT2bKinsx7MYD54A1JUxk/img.png"/></a></figure><p id="b8f330fc-33ec-41c1-94d9-9d559193967d" class="">낙관적 락으로 100개의 스레드로 좌석 예약을 시도했을 때 2.987초가 걸렸다.</p><h1 id="42ccfa51-b819-4342-b9bd-26f8d7aa2da1" class=""><strong>4. 비관적 락 - 포인트 충전에 적합</strong></h1><p id="2a886ebc-c126-44ac-9956-60b196c316d6" class="">사용자의 요청이 순차적으로 처리되어야 하는 경우 사용하면 좋다. 주로 금융시스템과 같이 반드시 처리가 되어야 하는 곳에서 많이 사용된다. 그리고 트랜잭션을 짧게 잡을 경우 처리 성능도 빠르게 가져갈 수 있다.</p><p id="bb232f6e-4f79-4545-a252-5213d34240c8" class="">구현 난이도 - 쉬움</p><p id="06036e57-e988-403e-b7ef-e308e795cbca" class="">성능 - 좋음</p><p id="b22d991f-8a1f-456c-8d39-28ffa9dddd9b" class="">특정 좌석에 대해서 비관적 락을 걸면 읽기와 쓰기가 잠긴다. 그래서 다른 스레드는 락이 해제될 때까지 대기해야 한다. 그렇기 때문에 정합성이 높다. 포인트 충전에 비관적 락이 적합한 이유는 충전 요청에 대해서 모두 순차적으로 처리해주기 때문이다. 하나의 요청도 유실되지 않고 요청한 만큼 포인트를 충전하기 때문에 정합성이 높다.</p><figure id="0830ba1d-c796-456d-88f5-e8024ebe78a0" class="image"><a href="https://blog.kakaocdn.net/dn/mMSEZ/btsHb9agjjE/lmGWnEhYQ8VmtGLh6uwhM0/img.png"><img style="width:700px" src="https://blog.kakaocdn.net/dn/mMSEZ/btsHb9agjjE/lmGWnEhYQ8VmtGLh6uwhM0/img.png"/></a></figure><p id="5373ba67-88ba-4b5b-ab87-8cc28df75730" class="">비관적 락의 경우 100개의 스레드로 좌석 예약을 시도하는 경우 3.3초가 소요된다. 낙관적 락보다는 오래 걸리는 것을 확인할 수 있다.</p><h1 id="36d9dc1a-4e58-432a-9b98-23fd2b3e43fb" class=""><strong>5. 분산 락 - 좌석 예약에 적합</strong></h1><p id="47488b48-9053-4529-b0a7-f5e14ad41feb" class="">분산 환경에서 Redis를 활용한 락이다. Pub/Sub 방식의 분산락은 락을 획득하면 해당 락으로 좌석 예약처리를 진행하고, 락을 획득하지 못하면 대기하다가 락이 해제되었다는 이벤트 리스너가 동작하면 그 때 락을 획득해서 처리하는 방식이다.</p><p id="24bf1fbd-ec9b-496c-8837-13fa97c32373" class="">분산 락에는 스핀락, Pub/Sub, 심플락 등 여러가지가 있는데 Pub/Sub 방식이 효율적이다.</p><p id="27afd94c-dd26-47dd-9d22-ccb96ff689e3" class="">구현 난이도 - 쉬움</p><p id="6c349cca-aabc-46b2-99e4-66665da3d95d" class="">성능 - 좋음</p><figure id="0f3e53eb-9a13-4e31-b6a7-07656f71ed3e" class="image"><a href="https://blog.kakaocdn.net/dn/bWuamX/btsHcHK8Nif/V3OhOVz7kHnYPY0WH5cJPK/img.png"><img style="width:700px" src="https://blog.kakaocdn.net/dn/bWuamX/btsHcHK8Nif/V3OhOVz7kHnYPY0WH5cJPK/img.png"/></a></figure><p id="5566eb2e-d215-4d25-9ff4-16001850a730" class="">분산락은 스레드 100개로 좌석 예약을 할 경우 3.189초가 소요되었다.</p><p id="0cc73c0f-72f7-4806-8dea-9a7ffafb380f" class=""><strong>속도 자체는 낙관적 락이 제일 빠르지만 재시도 처리 등을 고려했을 때 비관적 락은 포인트 충전, 분산 락은  좌석 예약에서 적합해보인다.</strong></p><p id="fe63a17f-f6f3-46d6-aecf-7593f8542320" class="">
</p></details></li></ul><ul id="af59ced2-0992-4900-b327-e8ac544e4ece" class="toggle"><li><details open=""><summary>kurly - 풀필먼트 입고 서비스팀에서 분산락을 사용하는 방법 - Spring Redisson</summary><h2 id="523b6518-eb7c-48dc-831b-44c9c0d74e95" class=""><strong>1. 들어가며</strong></h2><p id="90a7bbd4-1ac1-4241-b70c-98038df976ca" class="">안녕하세요. 컬리 풀필먼트 프로덕트에서 입고서비스를 개발하고 있는 임우빈입니다.</p><p id="597fc33b-0682-4006-ae26-4e5bddd84b00" class="">풀필먼트 입고서비스에서는 다양한 동시성 문제들을 맞닥뜨리고 있는데요. 이를 해결하기 위해 시행착오를 겪었던 경험에 대해 공유드리려고 합니다.</p><p id="c43d8c1d-3032-48c4-a9cd-91caca33d8de" class="">현재 입고서비스팀에서는 RMS(Receiving Management System - 입고관리 시스템)라는 프로젝트를 개발 및 운영하고 있습니다.</p><p id="52acb24c-f147-4df1-9c4b-925fee16b3ed" class="">RMS에는 여러 동시성 문제를 가지고 있었습니다.</p><ul id="9b068e81-a641-4040-ae06-73f25344d73c" class="bulleted-list"><li style="list-style-type:disc">카프카로 동시에 들어오는 중복된 발주를 수신하는 경우</li></ul><ul id="77aab27e-afc3-4f80-b0c3-0accdc8d3f8f" class="bulleted-list"><li style="list-style-type:disc">검수/검품 이슈 등록 시 더블 클릭, 네트워크 이슈로 인해 중복된 요청이 동시에 들어오는 경우</li></ul><ul id="d9062203-8f2b-4ed2-887e-5d7e0065a285" class="bulleted-list"><li style="list-style-type:disc">이동 출고시 여러 작업자가 CTA를 동시에 클릭하여 잘못된 재고 트랜잭션이 생성되는 경우</li></ul><p id="349267cd-4412-4c65-b28e-61143233513a" class="">등등 이외에도 다양한 경우의 동시성 이슈가 서비스에 존재했습니다.</p><p id="c87c0f8d-b719-4081-9e1a-82f3920363b2" class="">해당 기능에 대해 Application에서의 예외 처리는 존재했지만 보다 확실하게 동시성 이슈를 처리할 방법이 필요했습니다.</p><p id="713e3d5d-cd39-4429-bc36-9733b47ef3c8" class="">그래서 멀티 인스턴스 환경에서도 공통된 락을 사용할 수 있는 분산 락을 고려하게 되었습니다.</p><h2 id="21d54d60-c1ce-40b1-804b-26f5c1dc41eb" class=""><strong>2. Redis의 Redisson 라이브러리 선정 이유</strong></h2><p id="071c426b-8fd2-4983-9f89-8e5b7585a729" class="">분산락은 <code>Redis, Mysql, Zookeeper</code> 등을 이용해 구현할 수 있습니다.</p><p id="26c2f226-559f-4536-b935-4d8162a4c7e9" class="">그중 Redis를 선택한 이유는 우선 팀에서 해당 기술 스택을 사용 중이어서 추가 인프라 구축이 필요 없다는 점이 컸습니다.</p><p id="6cfb5ac0-bdb5-4709-87be-e46dc3c33aa6" class="">Mysql도 사용 중이었지만 락을 사용하기 위해 별도의 커넥션 풀을 관리해야 하고 락에 관련된 부하를 RDS에서 받는다는 점에서 Redis를 사용하는 것이 더 효율적이라 생각되었습니다.</p><p id="04d3dadf-978e-4a56-9fd0-78e61b72e067" class=""><code>Redisson</code> 은 일반적으로 많이 쓰이는 <code>Lettuce</code> 와 비교했을 때 락 사용 방식에 여러 차이가 있습니다.</p><p id="726b6c0a-4846-4530-a879-4d1f9fbc30b8" class="">그중 <code>Redisson</code>을 선택한 이유는 다음과 같습니다.</p><h3 id="5e85a9e9-4677-4e9a-bc54-01843bf2925f" class=""><strong>Lock interface 지원</strong></h3><p id="911ad402-c75f-45d5-96c1-9f10e8ffa166" class=""><code>Lettuce</code>로 분산락을 사용하기 위해서는 <code>setnx</code>, <code>setex</code> 등을 이용해 분산락을 직접 구현해야 합니다. 개발자가 직접 retry, timeout과 같은 기능을 구현해 주어야 한다는 번거로움이 있습니다.</p><p id="910c9e12-95ce-4571-982e-2b1817bd676a" class="">이에 비해 <code>Redisson</code> 은 별도의 <code>Lock interface</code>를 지원합니다. 락에 대해 타임아웃과 같은 설정을 지원하기에 락을 보다 안전하게 사용할 수 있습니다.</p><h3 id="b4d43a21-ee67-47ab-91cd-35483649badf" class=""><strong>락 획득 방식</strong></h3><p id="fba0af09-3895-44e9-932e-80b84187cdbd" class=""><code>Lettuce</code>는 분산락 구현 시 <code>setnx</code>, <code>setex</code>과 같은 명령어를 이용해 지속적으로 Redis에게 락이 해제되었는지 요청을 보내는 스핀락 방식으로 동작합니다. 요청이 많을수록 Redis가 받는 부하는 커지게 됩니다.</p><p id="2d46002a-f702-435a-b531-6fae60358c59" class="">이에 비해 <code>Redisson</code>은 Pub/Sub 방식을 이용하기에 락이 해제되면 락을 subscribe 하는 클라이언트는 락이 해제되었다는 신호를 받고 락 획득을 시도하게 됩니다.</p><figure id="e30791ee-e3d7-468a-9cd6-345589493f68" class="image"><a href="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-1.png"><img src="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-1.png"/></a></figure><p id="cd405e51-6ce8-414f-9c9f-cdef90e2426b" class="">자세한 내용이 궁금하시다면 아래 링크를 참고해보시길 추천드립니다.</p><ul id="4f78ea76-026d-4ea9-b13b-f8aa3cf3d274" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.baeldung.com/redis-redisson">https://www.baeldung.com/redis-redisson</a></li></ul><ul id="3758e676-8bd6-4173-90f7-881b7667c23c" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/redisson/redisson">https://github.com/redisson/redisson</a></li></ul><h2 id="20c82966-7e74-477e-86b6-347cf10ffd30" class=""><strong>3. 분산락을 보다 손쉽게 사용할 수는 없을까?</strong></h2><p id="b394ce04-e97c-4ac7-9462-70df3f56f9ad" class="">분산락을 도입하며 보다 손쉽고 효율적으로 사용할 수 없을까? 라는 고민을 시작으로 몇 가지 규칙을 만들었습니다.</p><ol type="1" id="1d351622-a6a5-4ffe-877c-9dd6b8faac25" class="numbered-list" start="1"><li>분산락 처리 로직은 비즈니스 로직이 오염되지 않게 분리해서 사용한다.</li></ol><ol type="1" id="d624fc0d-3450-409f-8969-35bd22a48ecf" class="numbered-list" start="2"><li>waitTime, leaseTime을 커스텀 하게 지정 가능하다.</li></ol><ol type="1" id="4eae7383-647b-4c47-a975-d3d124f3e235" class="numbered-list" start="3"><li>락의 name에 대해 사용자로부터 커스텀 하게 받아 처리한다.</li></ol><ol type="1" id="32e954e8-12e0-4f25-8058-4295d32daf4a" class="numbered-list" start="4"><li>추가 요구사항에 대해서 공통으로 관리한다.</li></ol><p id="db0a2178-9272-44b9-a353-fec45208e4f3" class="">다음과 같은 규칙을 충족하기 위해 어노테이션 기반으로 AOP를 이용해 분산락 컴포넌트를 만들었습니다.</p><p id="96d2e1a3-f5fc-4dbb-9b09-24c0f156686e" class="">입고서비스에서 분산락 컴포넌트를 사용하는 방법은 다음과 같습니다.</p><p id="e874735f-1209-4c04-9ae5-44d9c41cc716" class=""><strong>build.gradle</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="06340d9e-e5d5-4e6d-b40d-e4b612980635" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">dependencies {
    // redisson
    implementation &#x27;org.redisson:redisson-spring-boot-starter:3.18.0&#x27;
}</code></pre><p id="71590bde-7455-4386-94dc-421a2144dc61" class="">Redisson 라이브러리를 사용하기 위해 의존성을 추가합니다.</p><p id="10d59bb5-68c0-454b-a9c1-5f0b47e42e77" class=""><strong>RedissonConfig.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="406e368c-cadb-477e-aa20-373032f084c7" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">/*
 * RedissonClient Configuration
 */
@Configuration
public class RedissonConfig {
    @Value(&quot;${spring.redis.host}&quot;)
    private String redisHost;

    @Value(&quot;${spring.redis.port}&quot;)
    private int redisPort;

    private static final String REDISSON_HOST_PREFIX = &quot;redis://&quot;;

    @Bean
    public RedissonClient redissonClient() {
        RedissonClient redisson = null;
        Config config = new Config();
        config.useSingleServer().setAddress(REDISSON_HOST_PREFIX + redisHost + &quot;:&quot; + redisPort);
        redisson = Redisson.create(config);
        return redisson;
    }
}</code></pre><p id="06fd778f-f264-4488-bf58-e0aa59e8b3e0" class=""><code>RedissonClient</code>를 사용하기 위해 Config 설정을 빈으로 등록합니다.</p><p id="e047f4c6-6cad-4c9f-aadf-c9a500aaeff5" class=""><strong>DistributedLock.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e2fc0e32-b2e2-45bf-8498-e2d128ebf366" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">/**
 * Redisson Distributed Lock annotation
 */
@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
public @interface DistributedLock {

    /**
     * 락의 이름
     */
    String key();

    /**
     * 락의 시간 단위
     */
    TimeUnit timeUnit() default TimeUnit.SECONDS;

    /**
     * 락을 기다리는 시간 (default - 5s)
     * 락 획득을 위해 waitTime 만큼 대기한다
     */
    long waitTime() default 5L;

    /**
     * 락 임대 시간 (default - 3s)
     * 락을 획득한 이후 leaseTime 이 지나면 락을 해제한다
     */
    long leaseTime() default 3L;
}</code></pre><p id="4b18415a-e90f-4f46-a3c1-24a17cf08d79" class=""><code>DistributedLock</code> 어노테이션의 파라미터는 key는 필수, 나머지 값들은 커스텀 하게 설정할 수 있도록 작성했습니다.</p><p id="5cde73f3-bd03-42af-b23e-ba7f8b6c2889" class=""><strong>DistributedLockAop.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="c02bde6d-04f6-4e42-9b54-1486cbadc560" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">/**
 * @DistributedLock 선언 시 수행되는 Aop class
 */
@Aspect
@Component
@RequiredArgsConstructor
@Sl4j
public class DistributedLockAop {
    private static final String REDISSON_LOCK_PREFIX = &quot;LOCK:&quot;;

    private final RedissonClient redissonClient;
    private final AopForTransaction aopForTransaction;

    @Around(&quot;@annotation(com.kurly.rms.aop.DistributedLock)&quot;)
    public Object lock(final ProceedingJoinPoint joinPoint) throws Throwable {
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        Method method = signature.getMethod();
        DistributedLock distributedLock = method.getAnnotation(DistributedLock.class);

        String key = REDISSON_LOCK_PREFIX + CustomSpringELParser.getDynamicValue(signature.getParameterNames(), joinPoint.getArgs(), distributedLock.key());
        RLock rLock = redissonClient.getLock(key);  // (1)

        try {
            boolean available = rLock.tryLock(distributedLock.waitTime(), distributedLock.leaseTime(), distributedLock.timeUnit());  // (2)
            if (!available) {
                return false;
            }

            return aopForTransaction.proceed(joinPoint);  // (3)
        } catch (InterruptedException e) {
            throw new InterruptedException();
        } finally {
            try {
                rLock.unlock();   // (4)
            } catch (IllegalMonitorStateException e) {
                log.info(&quot;Redisson Lock Already UnLock {} {}&quot;,
                        kv(&quot;serviceName&quot;, method.getName()),
                        kv(&quot;key&quot;, key)
                );
            }
        }
    }
}</code></pre><p id="0c5b017c-4b54-474b-94a7-deba528cd1a7" class="">다음은 <code>@DistributedLock</code> 어노테이션 선언 시 수행되는 aop 클래스입니다.</p><p id="7d061f96-2489-4e99-a47a-a0bf3d7345a7" class=""><code>@DistributedLock</code> 어노테이션의 파라미터 값을 가져와 분산락 획득 시도 그리고 어노테이션이 선언된 메서드를 실행합니다.</p><ol type="1" id="a8707d75-b6af-4c0e-a650-6940d843ee98" class="numbered-list" start="1"><li>락의 이름으로 RLock 인스턴스를 가져온다.</li></ol><ol type="1" id="f7da455c-3a0a-43fa-87c0-a354af7ff537" class="numbered-list" start="2"><li>정의된 waitTime까지 획득을 시도한다, 정의된 leaseTime이 지나면 잠금을 해제한다.</li></ol><ol type="1" id="4856256f-87be-4b62-97a3-55c24668da11" class="numbered-list" start="3"><li>DistributedLock 어노테이션이 선언된 메서드를 별도의 트랜잭션으로 실행한다.</li></ol><ol type="1" id="85b6841a-dbf0-439c-ae6f-7402b04ddf58" class="numbered-list" start="4"><li>종료 시 무조건 락을 해제한다.</li></ol><p id="b0a1ac65-2d48-45fd-b0c5-43af158d3fe9" class="">여기서 주의해서 볼 부분은 <code>CustomSpringELParser</code> 와 <code>AopForTransaction</code> 클래스입니다. 이 클래스들은 분산락 컴포넌트에서 어떤 역할을 맡고 있을까요??</p><p id="111f7acf-481f-4fdf-ae75-609c6b3f27dd" class=""><strong>CustomSpringELParser.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="9a18b1dd-3e3b-458a-9067-7710b80d7384" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">/**
 * Spring Expression Language Parser
 */
public class CustomSpringELParser {
    private CustomSpringELParser() {
    }

    public static Object getDynamicValue(String[] parameterNames, Object[] args, String key) {
        ExpressionParser parser = new SpelExpressionParser();
        StandardEvaluationContext context = new StandardEvaluationContext();

        for (int i = 0; i &lt; parameterNames.length; i++) {
            context.setVariable(parameterNames[i], args[i]);
        }

        return parser.parseExpression(key).getValue(context, Object.class);
    }
}</code></pre><p id="fd29ca0b-290b-4881-9a47-c5700a7a6aa7" class=""><code>CustomSpringELParser</code> 는 전달받은 Lock의 이름을 <code>Spring Expression Language</code> 로 파싱하여 읽어옵니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="fc3a0526-3f82-413e-bdf1-f3c71b12f901" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">// (1)
@DistributedLock(key = &quot;#lockName&quot;)
public void shipment(String lockName) {
    ...
}

// (2)
@DistributedLock(key = &quot;#model.getName().concat(&#x27;-&#x27;).concat(#model.getShipmentOrderNumber())&quot;)
public void shipment(ShipmentModel model) {
    ...
}


ShipmentModel.java
public class ShipmentModel {
    private String name;
    private String shipmentNumber;

    public String getName() {
        return name;
    }

    public String getShipmentNumber() {
        return shipmentNumber;
    }

    ...
}</code></pre><p id="99e87186-96dd-4379-8507-1ec2b2879eb9" class=""><code>Spring Expression Language</code>를 사용하면 다음과 같이 Lock의 이름을 보다 자유롭게 전달할 수 있습니다.</p><p id="eab3e85d-8848-467f-8193-609253546d25" class=""><strong>AopForTransaction.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="cb602c3b-422d-4bfd-8d21-0b9aa65d2498" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">/**
 * AOP에서 트랜잭션 분리를 위한 클래스
 */
@Component
public class AopForTransaction {

    @Transactional(propagation = Propagation.REQUIRES_NEW)
    public Object proceed(final ProceedingJoinPoint joinPoint) throws Throwable {
        return joinPoint.proceed();
    }
}</code></pre><p id="c7330751-61f4-4a56-b2b6-fafb73a8cc95" class=""><code>@DistributedLock</code> 이 선언된 메서드는 <code>Propagation.REQUIRES_NEW</code> 옵션을 지정해 부모 트랜잭션의 유무에 관계없이 별도의 트랜잭션으로 동작하게끔 설정했습니다.</p><p id="ee9f4754-eff9-4bf5-b93a-6ac1eeb2319c" class="">그리고 반드시 트랜잭션 커밋 이후 락이 해제되게끔 처리했습니다.</p><p id="50e9ac7b-a10c-4906-a6ac-6d04b92a8171" class="">왜 트랜잭션 커밋 이후 락이 해제되어야 할까요??</p><blockquote id="8bd79bc9-92ed-4eae-9f4e-5de8fbd1a646" class="">바로 동시성 환경에서 데이터의 정합성을 보장하기 위해서입니다.</blockquote><p id="22d537c7-d29f-459f-ad13-6f741eaceffe" class="">동시성 예제로 자주 등장하는 재고 차감을 예로 들어보겠습니다.</p><p id="6ef330b3-f04a-4bb1-a584-6a083867e85d" class="">A라는 상품의 재고가 10개 존재합니다. 여러 명의 작업자들이 동시에 해당 재고를 사용한다고 가정해 보겠습니다.</p><p id="1230f030-bfdf-4db0-ad0c-a6cc15e950a8" class="">이때, 락의 해제 시점이 트랜잭션 커밋 시점보다 빠르면 어떻게 동작할까요?</p><figure id="18e31a61-8a5b-4c9c-a305-3ef80dc18162" class="image"><a href="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-2.png"><img src="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-2.png"/></a></figure><p id="d034ed64-92fa-4081-b2f3-298636698c0a" class="">1) Client1, Client2 두 사용자가 재고 차감을 위해 메서드에 동시에 접근한다.</p><p id="d4a8bb62-429d-44f2-9a43-16fb8c56f6fb" class="">2) Client1이 간발의 차이로 락을 먼저 선점하고 재고를 조회하여 현재 재고가 10인 것을 확인한다.</p><p id="caef4f33-04a7-4cdd-9103-a3990d1c0b1e" class="">3) Client1는 재고를 하나 차감하고 락을 해제한다(재고는 10-1=9개), 이때 트랜잭션은 커밋 되지 않은 상태이다.</p><p id="39e4181e-d279-4ee4-b365-1d3bc44419aa" class="">4) Client2는 락이 해제되었다는 신호를 받고 락을 획득하고 재고를 조회한다.</p><p id="5d659ef6-4678-4ac8-ac4d-87a80e53992f" class="">5) Client1에서 재고를 차감했지만 아직 트랜잭션 커밋이 되지 않은 상태이기에 Client2는 재고 조회 시 10으로 조회한다.</p><p id="841b586d-3d83-4e20-bacd-f50360813777" class="">6) Client2는 동일하게 재고를 하나 차감하고 락을 해제하고 커밋 한다. (db에는 10-1=9 로 재고가 반영된다)</p><p id="6bb7cb8e-3684-47cf-b5a2-c51e2d365ff4" class="">결국 두 사용자가 동시에 접근하여 재고를 차감했지만 실제 DB에 차감된 재고는 2개가 아닌 1개입니다. 이렇듯 락의 해제가 트랜잭션 커밋보다 먼저 이뤄지면 데이터 정합성이 깨질 수 있습니다.</p><p id="930da9e3-337a-4181-af87-b68f1ed39709" class="">반대로 트랜잭션 커밋 이후 락을 해제하면 어떻게 될까요? 그림을 통해 확인해 보겠습니다.</p><figure id="3315d630-a4bf-4002-8c87-0f8abb2f96cb" class="image"><a href="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-3.png"><img src="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-3.png"/></a></figure><p id="aab229df-c893-41cd-b746-0f806e5916b5" class="">1) Client1, Client2 두 사용자가 재고 차감을 위해 메서드에 동시에 접근한다.</p><p id="519223a0-3384-4903-8556-c71b62203f1b" class="">2) Client1이 간발의 차이로 락을 먼저 선점하고 재고를 조회하여 현재 재고가 10인 것을 확인한다.</p><p id="cc67890d-0529-44ef-84b3-371fee0aa517" class="">3) Client1는 재고를 하나 차감하고 트랜잭션을 커밋 한다.(재고 = 9)</p><p id="34721e03-677f-4a43-bf60-f1f545029d16" class="">4) Client1는 락을 해제하고 Client2는 락이 해제되었다는 신호를 받고 락을 획득한다.</p><p id="cc9090ff-799f-414b-8559-442357a7aba0" class="">5) Client2는 락 획득 후 재고를 조회한다, 이때 재고는 9개이다.</p><p id="5606795a-cdb4-4776-87a6-08a957a6b5fd" class="">6) Client2는 재고를 하나 차감하고(재고 9-1=8) 트랜잭션 커밋 후 락을 해제한다.</p><p id="8daee96f-74b1-4a54-ad5e-318df9c0085a" class="">두 사용자가 동시에 접근한 경우에도 재고가 모두 정상적으로 차감되게 됩니다. 락의 해제가 트랜잭션 커밋보다 뒤에 이뤄진 덕분에 동시성 환경에서도 데이터 정합성을 보장할 수 있습니다.</p><h2 id="0ae5c555-c00e-48e7-a2e5-50de197904ec" class=""><strong>4. 테스트 시나리오를 검증해 보자</strong></h2><p id="e21a1f33-3a07-4c88-8f04-0a750421aaaa" class="">분산락은 다양한 경우에 쓰일 수 있습니다.</p><p id="1f0fca77-2d07-471d-b4c6-b3a8b1e3c86d" class="">쿠폰 발급과 같이 수량을 차감하는 경우에도 쓰일 수 있고 동시에 들어오는 데이터의 중복을 방지하는 용도로도 사용할 수 있습니다.</p><p id="97ee7bce-aac7-4dcf-a601-ca78cae524f5" class="">위 두 가지 케이스에 대해 테스트 코드로 검증해 보겠습니다.</p><h3 id="7903ae1c-50c2-4eac-a687-f7b801f4489b" class=""><strong>1. 쿠폰 차감 테스트 시나리오</strong></h3><p id="f752b9f2-d56c-4510-81aa-eb2e4ace608c" class=""><code>KURLY_001</code>라는 쿠폰 100개를 고객들에게 이벤트로 발급한다고 가정해 보겠습니다. 이때 100명의 고객들이 쿠폰을 받기 위해 쿠폰 발급 요청을 하게 됩니다.</p><p id="87d4b991-3ebc-4667-a1e0-ba235bb2a259" class=""><strong>Coupon.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="48574152-6faa-416f-9c8f-0e3132c12cb3" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Entity
@NoArgsConstructor(access = AccessLevel.PROTECTED)
public class Coupon {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    private String name;

    /*
     * 사용 가능한 재고수량
     */
    private Long availableStock;

    public Coupon(String name, Long availableStock) {
        this.name = name;
        this.availableStock = availableStock;
    }

    public void decrease() {
        validateStockCount();
        this.availableStock -= 1;
    }

    private void validateStockCount() {
        if (availableStock &lt; 1) {
            throw new IllegalArgumentException();
        }
    }
}</code></pre><p id="a58d1bba-1337-4191-b5de-3b9d49378749" class=""><strong>CouponDecreaseService.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="a8f2ada1-560a-402d-9ce1-082a5e35a05b" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Component
@RequiredArgsConstructor
public class CouponDecreaseService {
    private final CouponRepository couponRepository;

    @Transactional
    public void couponDecrease(Long couponId) {
        Coupon coupon = couponRepository.findById(couponId)
                .orElseThrow(IllegalArgumentException::new);

        coupon.decrease();
    }

    @DistributedLock(key = &quot;#lockName&quot;)
    public void couponDecrease(String lockName, Long couponId) {
        Coupon coupon = couponRepository.findById(couponId)
                .orElseThrow(IllegalArgumentException::new);

        coupon.decrease();
    }
}</code></pre><p id="f12cbc06-9f50-46a7-a28e-5fdc99efe860" class="">분산락이 있는 경우와 없는 경우 어떻게 동작하는지 확인해 보기 위해 두 개의 메서드를 선언했습니다.</p><p id="8cfb615b-81a6-4424-993e-be7ac7a253ee" class="">테스트 코드로 다음 예제를 검증해 보겠습니다.</p><p id="5995c0d1-798f-4e9f-a332-7d87b8725b06" class=""><strong>CouponDecreaseLockTest.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="052de8bd-1403-4169-878a-d5fbaa09fd83" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@BeforeEach
void setUp() {
    coupon = new Coupon(&quot;KURLY_001&quot;, 100L);
    couponRepository.save(coupon);
}

/**
 * Feature: 쿠폰 차감 동시성 테스트
 * Background
 *     Given KURLY_001 라는 이름의 쿠폰 100장이 등록되어 있음
 * &lt;p&gt;
 * Scenario: 100장의 쿠폰을 100명의 사용자가 동시에 접근해 발급 요청함
 *           Lock의 이름은 쿠폰명으로 설정함
 * &lt;p&gt;
 * Then 사용자들의 요청만큼 정확히 쿠폰의 개수가 차감되어야 함
 */
@Test
void 쿠폰차감_분산락_적용_동시성100명_테스트() throws InterruptedException {
    int numberOfThreads = 100;
    ExecutorService executorService = Executors.newFixedThreadPool(numberOfThreads);
    CountDownLatch latch = new CountDownLatch(numberOfThreads);

    for (int i = 0; i &lt; numberOfThreads; i++) {
        executorService.submit(() -&gt; {
            try {
                // 분산락 적용 메서드 호출 (락의 key는 쿠폰의 name으로 설정)
                couponDecreaseService.couponDecrease(coupon.getName(), coupon.getId());
            } finally {
                latch.countDown();
            }
        });
    }

    latch.await();

    Coupon persistCoupon = couponRepository.findById(coupon.getId())
            .orElseThrow(IllegalArgumentException::new);

    assertThat(persistCoupon.getAvailableStock()).isZero();
    System.out.println(&quot;잔여 쿠폰 개수 = &quot; + persistCoupon.getAvailableStock());
}</code></pre><figure id="08b604bb-28b9-464b-aae0-23c91e8f714a" class="image"><a href="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-4.png"><img src="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-4.png"/></a></figure><p id="738ff96d-4341-4339-9b34-61315c730997" class="">100장의 쿠폰에 대해 100명이 동시에 요청한 경우 정확하게 쿠폰이 100명 모두에게 발급된 것을 확인할 수 있습니다.</p><p id="478e3107-18c7-4422-82b5-8643572e09cb" class="">만약 100명이 아닌 그 이상의 사용자가 발급을 요청하더라도 <code>validateStockCount</code> 예외로직에 의해 발급에 실패하겟죠??</p><p id="14a1f4f3-b0be-4851-8205-8ade1f59a4b2" class="">이번엔 분산락이 적용되지 않는 버전의 테스트 코드를 호출해 보겠습니다.</p><p id="fc9fa0e7-5d9a-499c-9626-154982275580" class=""><strong>CouponDecreaseLockTest.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="05a0d238-4732-41d4-adac-f59995aa73d3" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Test
void 쿠폰차감_분산락_미적용_동시성100명_테스트() throws InterruptedException {
    int numberOfThreads = 100;
    ExecutorService executorService = Executors.newFixedThreadPool(numberOfThreads);
    CountDownLatch latch = new CountDownLatch(numberOfThreads);

    for (int i = 0; i &lt; numberOfThreads; i++) {
        executorService.submit(() -&gt; {
            try {
                // 분산락 미적용 메서드 호출
                couponDecreaseService.couponDecrease(coupon.getId());
            } finally {
                latch.countDown();
            }
        });
    }

    latch.await();

    Coupon persistCoupon = couponRepository.findById(coupon.getId())
            .orElseThrow(IllegalArgumentException::new);

    assertThat(persistCoupon.getAvailableStock()).isZero();
    System.out.println(&quot;잔여 쿠폰 갯수 = &quot; + persistCoupon.getAvailableStock());
}</code></pre><figure id="337d5d38-5d9c-417b-94d2-50da5b77e145" class="image"><a href="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-5.png"><img src="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-5.png"/></a></figure><p id="8b8ce86d-9eaa-413f-a984-6c7acea5ba4f" class="">100명이 동시에 발급을 요청했지만 100개의 쿠폰 중 남은 쿠폰은 79개입니다.</p><p id="4a912c9d-677f-459d-966e-ccbae03d0473" class="">락이 없다 보니 동시에 요청이 왔을 때 각자 읽은 쿠폰의 잔여갯수가 다르기에 결국 데이터의 정합성이 깨져버렸습니다.</p><h3 id="487adfbd-1a8c-492e-8c68-1505ffcde4b1" class=""><strong>2. 중복 발주 데이터 동시 수신</strong></h3><p id="10fd5c1f-7235-4332-b448-e8b86af9a6b7" class=""><code>KURLY_001</code>라는 발주 데이터 10개가 서비스에 중복으로 수신되었다고 가정해 보겠습니다.</p><p id="a4be5d36-f86f-4a80-878a-695b834e6ff6" class="">시스템 상 중복 발주는 허용하지 않습니다.</p><p id="965a2156-2abc-4438-aacd-f19145ae6cca" class=""><strong>Purchase.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="b644c2ec-36e3-46b1-a185-5f1f66ea159c" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Entity
@NoArgsConstructor(access = AccessLevel.PROTECTED)
public class Purchase {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    private String code;

    public Purchase(String code) {
        this.code = code;
    }
}</code></pre><p id="84ed3fa2-1477-4aa8-9b54-8344e8f289eb" class=""><strong>PurchaseRegisterService.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="6d370ec8-73e2-49d9-8a4f-20b0ae96d538" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Service
@RequiredArgsConstructor
public class PurchaseRegisterService {
    private final PurchaseRepository purchaseRepository;

    @DistributedLock(key = &quot;#lockName&quot;)
    public void register(String lockName, String code) {
        boolean existsPurchase = purchaseRepository.existsByCode(code);
        if (existsPurchase) {
            throw new IllegalArgumentException();
        }

        Purchase purchase = new Purchase(code);
        purchaseRepository.save(purchase);
    }

    @Transactional
    public void register(String code) {
        boolean existsPurchase = purchaseRepository.existsByCode(code);
        if (existsPurchase) {
            throw new IllegalArgumentException();
        }

        Purchase purchase = new Purchase(code);
        purchaseRepository.save(purchase);
    }
}</code></pre><p id="24f2739e-946b-4ed1-8e2f-b6f0590ab64b" class="">발주 등록 시 중복 발주에 대한 <code>validation logic</code>을 수행합니다.</p><p id="d804c64c-1a9b-4bd9-9d20-4ef0a4057453" class="">그리고 분산락이 있는 경우와 없는 경우 어떻게 동작하는지 확인해 보기 위해 두 개의 메서드를 선언했습니다.</p><p id="d39566c8-5956-46df-b1bd-89d766d5fe01" class=""><strong>PurchaseRegisterLockTest.java</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="63f9a7bc-4ae7-48f6-805c-a21f59a20fa9" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">/**
 * Feature: 발주 등록 동시성 테스트
 * &lt;p&gt;
 * Scenario: KURLY_001 라는 이름의 발주 10개가 동시에 등록 요청됨
 *           Lock의 이름은 KURLY_001이라는 발주코드로 설정함
 * &lt;p&gt;
 * Then 중복된 발주 10개가 동시에 들어오더라도 한 건만 등록 되어야 함
 */
@Test
void 발주등록_분산락_적용_테스트() throws InterruptedException {
    String 발주_코드 = &quot;KURLY_001&quot;;

    int numberOfThreads = 10;
    ExecutorService executorService = Executors.newFixedThreadPool(numberOfThreads);
    CountDownLatch latch = new CountDownLatch(numberOfThreads);

    for (int i = 0; i &lt; numberOfThreads; i++) {
        executorService.submit(() -&gt; {
            try {
                // 분산락 적용 메서드 호출
                purchaseRegisterService.register(발주_코드, 발주_코드);
            } finally {
                latch.countDown();
            }
        });
    }

    latch.await();

    Long totalCount = purchaseRepository.countByCode(발주_코드);

    System.out.println(&quot;등록된 발주 = &quot; + totalCount);
    assertThat(totalCount).isOne();
}</code></pre><figure id="d145ea30-5995-4592-99e8-d62736ecbe0d" class="image"><a href="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-6.png"><img src="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-6.png"/></a></figure><p id="711da86c-0c5c-4ecf-954e-75f92f6bcd4d" class="">분산락이 적용된 버전의 메서드에 대한 테스트 결과입니다. 10건의 요청이 들어와도 정상적으로 한 건의 발주만 등록된 것을 확인할 수 있습니다.</p><p id="ed58b3cc-aef9-4d44-9cec-dbbc80d6e52d" class="">그럼 분산락 미적용 버전의 메서드를 확인해 보겠습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="f3665935-af6c-4d32-8f98-236fc818cef8" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Test
void 발주등록_분산락_미적용_테스트() throws InterruptedException {
    String 발주_코드 = &quot;KURLY_001&quot;;

    int numberOfThreads = 10;
    ExecutorService executorService = Executors.newFixedThreadPool(numberOfThreads);
    CountDownLatch latch = new CountDownLatch(numberOfThreads);

    for (int i = 0; i &lt; numberOfThreads; i++) {
        executorService.submit(() -&gt; {
            try {
                // 분산락 미적용 메서드 호출
                purchaseRegisterService.register(발주_코드);
            } finally {
                latch.countDown();
            }
        });
    }

    latch.await();

    Long totalCount = purchaseRepository.countByCode(발주_코드);

    System.out.println(&quot;등록된 발주 = &quot; + totalCount);
    assertThat(totalCount).isOne();
}</code></pre><figure id="2b326362-8ddc-4b41-94bc-471419291f9d" class="image"><a href="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-7.png"><img src="https://helloworld.kurly.com/post-img/distributed-redisson-lock/distributed-lock-image-7.png"/></a></figure><p id="286bb56d-026a-4f3f-95f3-ce6facf4a1ce" class="">메서드에 작성된 <code>validation logic</code>에 예외가 걸리지 않고 모두 등록되었습니다.</p><p id="47da5f43-658f-4036-9321-81bb17dcfc53" class="">(등록 개수는 테스트마다 그리고 테스트 환경의 connection pool size에 따라 다를 수 있습니다)</p><p id="86407bc7-5123-4bf0-b902-d118c3bb8184" class="">이렇게 분산락의 유무에 따라 시스템이 어떻게 동작하는지 테스트 코드로 검증해 보았습니다.</p><h2 id="1094bc26-7d96-465b-aa1a-76648c43d50d" class=""><strong>5. 마치며</strong></h2><p id="069dfb76-f2ae-4f7c-8768-ef558a5e072f" class="">여기까지 입고서비스팀에서 동시성 환경에서 분산락 컴포넌트를 사용하는 방법에 대해 소개해 드렸습니다.</p><p id="5c915637-e015-477c-8d33-252721d18322" class="">분산락을 도입하며 한 층 더 수준 높은 락 처리를 할 수 있게 되었고, 락 사용에 대해 생산성도 올라가고 핵심 로직과도 분리해 사용할 수 있어 가독성 측면에서도 훨씬 수월하게 사용할 수 있었습니다.</p><p id="f85c5615-7840-4aae-ba85-b6966eef049a" class="">지금까지 읽어주셔서 감사합니다~</p><h3 id="4dd9c534-1cfb-4563-8504-4edeaf780445" class=""><strong>Reference</strong></h3><ul id="b1836004-4243-433d-9bab-ee15d9730a8e" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.baeldung.com/redis-redisson">https://www.baeldung.com/redis-redisson</a></li></ul><ul id="ac00b02c-aaf2-48af-9022-d4b22c326336" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/redisson/redisson">https://github.com/redisson/redisson</a></li></ul><ul id="6ca9bc2b-b093-4127-8f27-79a0de7df8f2" class="bulleted-list"><li style="list-style-type:disc"><a href="https://javadoc.io/doc/org.redisson/redisson">https://javadoc.io/doc/org.redisson/redisson</a></li></ul><figure id="57239ecc-3798-43f8-a0e4-8d38d6b22b86"><a href="https://helloworld.kurly.com/blog/distributed-redisson-lock/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">풀필먼트 입고 서비스팀에서 분산락을 사용하는 방법 - Spring Redisson</div><div class="bookmark-description">어노테이션 기반으로 분산락을 사용하는 방법에 대해 소개합니다.</div></div><div class="bookmark-href"><img src="https://helloworld.kurly.com/assets/logo/ico_192.png" class="icon bookmark-icon"/>https://helloworld.kurly.com/blog/distributed-redisson-lock/</div></div><img src="http://thefarmersfront.github.io/assets/logo-square.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="6e1d860c-64fd-4075-b3b0-4fd0a73d1fec" class="toggle"><li><details open=""><summary>배민 - 선물하기 시스템의 상품 재고는 어떻게 관리되어질까?</summary><h2 id="927059be-1ec7-4cd4-8ba2-6ff8b4f8b0cd" class=""><strong>선물하기 시스템</strong></h2><p id="584e913a-02a2-440d-8611-8625b539d9fe" class="">선물하기 서비스는 상품의 속성을 정의하고, 관리하는 <code>상품시스템</code>, 정의된 상품을 어느 카테고리에 매핑시켜 노출시킬지를 결정하는 <code>전시시스템</code>, 상품을 상품권화 시키기 위해 고객님의 구매가 이루어질 수 있도록 하는 <code>구매시스템</code>, 상품권을 음식주문시 사용할 수 있도록 하는 <code>상품권 시스템</code> 총 4가지 시스템으로 이루어져 있습니다.</p><p id="2a1311bf-376d-4d85-86b9-539a10e0b5cf" class="">재고라는 속성은 상품의 속성이라고 판단이 되었고, 재고량(총 재고량, 재고 사용량)의 관리는 <code>상품시스템</code>에서 관리를 하도록 결정을 하였습니다.</p><figure id="4b612957-f160-4191-996d-6e4998fc42bb" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2011.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2011.png"/></a></figure><blockquote id="7813c4d1-627d-4669-8206-3c31eb6684e3" class="">상품시스템의 초간단 ERD</blockquote><p id="e19d8699-baa2-409a-9d79-8f09343619c7" class="">상품시스템의 ERD를 간단히 보면, 위와같이 <code>상품</code>, <code>판매상품</code>, <code>가격정책</code>의 엔티티로 이루어져있습니다.</p><p id="0c371117-9fbe-4e6d-b471-c98fbf93ec8a" class=""><code>상품 엔티티</code>는 상품명, 상품이미지 등 보여지는 요소에 대한 속성을 정의하며, <code>판매상품 엔티티</code>는 정의된 상품이 어떤식(판매기간)으로 판매될지를 결정합니다.</p><p id="f199fd6d-dfcf-427d-9683-a412a0410298" class="">마지막으로 <code>가격정책 엔티티</code>는 어떻게 판매될지 결정된 판매상품을 어떠한 가격에 얼만큼 팔지(원금액, 할인금액, 인당재고, 총재고)를 결정합니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1150debc-8609-4185-9f57-2928522178b6" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">class SalesProductPrice(
    type: DiscountType,
    salesProduct: SalesProduct,
    priceCommonId: Long,
    price: Long,
    defaultFlag: Boolean,
    /** 할인 정보 **/
    amount: Long?,
    rate: Int?,
    charge: Long?,
    sellerCharge: Long?,
    franchiseCharge: Long?,
    discountStatus: DiscountStatus?,
    /** 재고 정보**/
    totalQuantity: Long?, // 총 재고수량
    perLimitTotalQuantity: Long?, // 인당 구매제한수량
    stockStatus: StockStatus?,
    status: SalesProductPriceStatus
) : BaseUuidEntity() {
 ...
}

enum class SalesProductPriceStatus(
    description: String
) {
    ON(&quot;활성&quot;),
    OFF(&quot;비활성&quot;),
    SOLD_OUT(&quot;품절&quot;);
}</code></pre><blockquote id="a7de4f2d-b1be-47ca-86c8-9960093fe946" class="">가격정책 엔티티를 통해서 총 재고 수량과 인당 구매제한 수량을 관리한다.<p id="c6276f14-7edc-4288-8192-d5263fbe2e9c" class="">총 수량을 정해두고, 사용량이 총수량을 넘어설 경우 가경정책 상태를 SOLD_OUT 처리한다.</p></blockquote><h2 id="7a128876-fb9b-4537-8793-635a444fc394" class=""><strong>재고관리 요구사항</strong></h2><p id="aa857760-e5b6-4e1c-8958-24a46a288816" class=""><code>프랜차이즈 상품권</code> 판매를 위해서 추가로 구현되어야 할 주된 기능중 하나인 <code>재고관리</code> 기능은 아래와 같은 요구사항을 만족해야했습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="852e242b-4dd9-43b6-8dd6-3874f4aba32d" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">1. 상품의 권종별로 전체 재고수량과 인당 재고수량이 관리되어야 한다.
2. 상품은 전체재고량을 초과하여 판매되면 안된다.
3. 판매가 시작된 상품의 전체 재고수량은 감소시킬 수 없다.</code></pre><ol type="1" id="8cc2f0db-7e8e-4202-b466-2ff00805ab51" class="numbered-list" start="1"><li>상품의 권종별로 전체 재고수량과 인당 재고수량이 관리되어야 한다.<blockquote id="53848cb3-dcad-4fc8-a79f-39a7af3a7b22" class="">하나의 상품은 여러개의 권종일 가질 수 있습니다.<p id="6ebbcca9-4ff4-448e-ac1d-b6a9affb531f" class="">재고는 권종별로 관리가 되어지며, 고객 한분당 구입이 가능한 수를 제한해야하고, 권종 전체의 구입 가능한 수를 제한해야했습니다.</p></blockquote></li></ol><ol type="1" id="d865aa14-b20e-44df-a806-bb47c2375a15" class="numbered-list" start="2"><li>상품의 권종은 전체 재고량을 초과하여 판매되면 안된다.<blockquote id="c547030a-be0d-4986-bed5-4f7a63777bec" class="">권종별로 제한된 재고량은 절대 초과하여 판매되면 안됩니다.<p id="710128df-c164-45be-a647-b356cad26b18" class="">상품이 덜 판매되어서 재고량이 남는 이슈가 생길지언정 절대 초과하여 상품이 판매되면 안되어야 합니다.</p></blockquote></li></ol><ol type="1" id="a7074a41-fb79-4b3f-9ceb-d484df5bfd15" class="numbered-list" start="3"><li>판매가 시작된 상품의 전체 재고수량은 감소시킬 수 없다.<blockquote id="103d33a3-3d70-4ce7-9d12-e7251aea6dc0" class="">판매가 한번 시작된 상품의 경우에는 재고량 수정이 가능하나 최초 설정된 재고량 이상을 설정할 수 없어야 합니다.</blockquote></li></ol><h2 id="14c13085-ad68-45bc-a3ac-2a1d27c3d25e" class=""><strong>재고관리 설계</strong></h2><p id="55099c43-5e9d-415c-9b8b-d73eca436371" class="">위와 같은 요구사항을 만족시키기 위해서는 재고관리 시스템을 설계할때 아래의 부분을 중심으로 고려해야 했습니다.</p><ol type="1" id="21a901cc-6936-4981-b94f-8b7ad72e1285" class="numbered-list" start="1"><li>전체 재고량의 관리와 트랜잭션이 일어나는 재고 사용량은 분리하여 저장한다.<blockquote id="770b9c07-9e57-4228-96ef-a63909594af7" class="">전체 재고량의 경우 RDB에 저장하여 관리하고, 트랜잭션이 일어나는 재고사용량의 관리는 연산속도가 빠른 in-memory DB를 사용한다.</blockquote></li></ol><ol type="1" id="7873c611-98fc-420d-98c2-89da3dddabeb" class="numbered-list" start="2"><li>재고 사용량의 증가와 감소시 동시성 이슈는 없어야 한다.<blockquote id="a68b0db6-21d7-4a97-9f73-115dae16e1db" class="">연산처리는 단일 스레드에서 처리하는 Redis를 이용하여 동시성 이슈를 해결한다.</blockquote></li></ol><ol type="1" id="a10199d5-229d-41e1-bba1-07dbcdb1d96f" class="numbered-list" start="3"><li>재고 사용량 데이터는 유실되어서는 안된다.<blockquote id="e246bb75-22af-4bef-89d4-9055d588c4e6" class="">in-memory DB는 휘발성 데이터로 데이터 유실이 일어날 수 있으므로, 재고 사용량 데이터를 RDB에 싱크할 수 있도록 한다.</blockquote></li></ol><ol type="1" id="d53ba10d-77ed-4cb9-b108-838bc528f8cb" class="numbered-list" start="4"><li>재고 사용량의 관리는 Redis 의 Set 자료구조에 구매번호를 저장하여 관리한다.<blockquote id="b55487e8-7c3d-468b-b0cc-5791b19fae8e" class="">구매번호는 유니크한 값이고, Redis의 Set 자료구조는 중복을 허용하지 않기때문에 구매번호를 Set에 저장할 경우 SCARD 오퍼레이션을 통해 손쉽게 사용량을 가져올 수 있다.</blockquote></li></ol><p id="a4cd4ff4-68ce-46ac-8103-aa9883fa2e2c" class="">저희는 재고관리 시스템에 <code>RDB</code>와 <code>Redis</code>를 함께 사용하기로 하였습니다.</p><p id="77d44f8b-f5d0-44b4-8c92-2da1d96b75e2" class="">실제 상품권 구매에 대한 트랜잭션에 대해서는 Redis를 사용하여 동시성 이슈를 처리하였고, 데이터 유실을 방지하기 위해 트랜잭션 시점에 RDB에 데이터를 싱크하도록 하였습니다.</p><p id="05a6833a-3027-470c-9a2d-7678cd2c5974" class="">데이터 싱크를 위한 RDB 는 아래와 같이 구매 시점, 구매취소 시점에 판매상품번호, 구매번호, 구매한회원번호, 구매가격, 타입만을 저장하는 단일 엔티티로 단순 설계하여</p><p id="9f9c1f20-e452-44d7-b426-b85eb942b3a3" class="">재고량 증가 혹은 감소시점에 <code>insert</code> 쿼리만 발생하도록 하였습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="64248bb9-6d31-43e6-beff-fb2eabf8e7c1" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Entity
@Table(
    name = &quot;stock_history&quot;,
    indexes = [
        Index(name = &quot;idx_stock_history_sales_product_number&quot;, columnList = &quot;salesProductNumber&quot;),
        Index(name = &quot;idx_stock_history_purchase_number&quot;, columnList = &quot;purchaseNumber&quot;),
        Index(name = &quot;idx_stock_history_member_number&quot;, columnList = &quot;memberNumber&quot;)
    ]
)
class StockHistory(
    salesProductNumber: String,
    purchaseNumber: String,
    memberNumber: String,
    price: Long,
    type: StockHistoryType
) : BaseUuidEntity() {

    @Column(nullable = false, length = 10)
    var salesProductNumber: String = salesProductNumber

    @Column(nullable = false, length = 10)
    var purchaseNumber: String = purchaseNumber

    @Column(nullable = false, length = 20)
    var memberNumber: String = memberNumber

    @Column(nullable = false)
    var price: Long = price

    @Enumerated(EnumType.STRING)
    @Column(nullable = false, length = 20)
    var type: StockHistoryType = type
}

enum class StockHistoryType(
    val description: String
) {
    PLUS(&quot;재고사용량 증가&quot;),
    MINUS(&quot;재고사용량 감소&quot;);
}</code></pre><p id="5daf211b-6b18-460c-a0e1-725e535a560f" class="">Redis의 경우에는 아래와 같이 전체 실시간 재고와, 인당 실시간 재고를 관리하도록 Key 값을 정하였고, 자료구조는 <code>Set 자료구조</code>를 선택하였습니다.</p><p id="641b4246-ff81-4022-9489-17767ee30431" class="">각 Key (전체 실시간 재고, 인당 실시간 재고)에 해당하는 Value에는 유니크한 구매번호를 저장하도록 하였습니다. (레디스의 Set 자료구조는 기본적으로 값에 대한 중복을 제거해 줍니다.)</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="cc6fa026-03c5-48bf-bd4f-d4f5e5ad14c2" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">데이터구조 Set 자료구조
- 전체 실시간 재고 Key = :stock:total
- 인당 실시간 재고 Key =

예시
- 재고사용량 증가
// G0AA0001JR 구매 발생 전체 재고량 사용량 증가
redis&gt; SADD S0630000RU:5000:stock:total G0AA0001JR
(interger) 1
// G0AA0001JR 구매 발생 인당 재고량 사용량 증가
redis&gt; SADD S0630000RU:5000:stock:201209320003 G0AA0001JR
(interger) 1

// G0AA0001JQ 구매 발생 인당 재고량 사용량 증가
redis&gt; SADD S0630000RU:5000:stock:total G0AA0001JQ
(interger) 1
// G0AA0001JQ 구매 발생 인당 재고량 사용량 증가
redis&gt; SADD S0630000RU:5000:stock:201209320003 G0AA0001JQ
(interger) 1

// G0BB0001JQ 구매 발생 인당 재고량 사용량 증가
redis&gt; SADD S0630000RU:5000:stock:total G0BB0001JQ
(interger) 1
// G0BB0001JQ 구매 발생 인당 재고량 사용량 증가
redis&gt; SADD S0630000RU:5000:stock:201209320003 G0BB0001JQ
(interger) 1

- 재고 사용량 조회
// 전체 재고사용량 조회
redis&gt; SCARD S0630000RU:5000:stock:total
(integer) 3 // G0AA0001JR,G0AA0001JQ,G0BB0001JQ
// 인당 재고사용량 조회
redis&gt; SCARD S0630000RU:5000:stock:201209320003
(integer) 3 // G0AA0001JR,G0AA0001JQ,G0BB0001JQ

- 재고사용량 감소
// G0BB0001JQ 구매취소 발생 전체 재고사용량 감소
redis&gt; SREM S0630000RU:5000:stock:total G0BB0001JQ
(interger) 1
// G0BB0001JQ 구매취소 발생 인당 재고사용량 감소
redis&gt; SREM S0630000RU:5000:stock:201209320003 G0BB0001JQ
(interger) 1

- 재고 사용량 조회
redis&gt; SCARD S0630000RU:5000:stock:total
(integer) 2 // G0AA0001JR,G0AA0001JQ
redis&gt; SCARD S0630000RU:5000:stock:201209320003
(integer) 2 // G0AA0001JR,G0AA0001JQ</code></pre><p id="409d7a3b-83d5-4de5-aeb8-ada22be0a19b" class="">아래 코드는 재고 사용량의 증가,감소,사용량 조회에 관련된 레디스 오퍼레이션 코드입니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="5048c485-b128-4a16-8513-3bd3fce7d604" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">/**
* 재고관리 데이터 클래스
**/
data class Stock(
    val salesProductNumber: String,
    val price: Long,
    val purchaseNumber: String? = null,
    val memberNumber: String? = null
)

/**
 * 전체 재고 사용량 체크 레디스 오퍼레이션
 * 자료구조 : Set
 */
class TotalStockOperation {
    companion object {
        val log = logger()
        private var key = &quot;stock:total&quot;

        /**
         * SADD Operation
         */
        fun add(redisOperations: RedisOperations&lt;String, String&gt;, stock: Stock) {
            val key = getKey(&quot;$&quot;)
            redisOperations.opsForSet().add(key, stock.purchaseNumber)
            log.info
        }

        /**
         * SREM Operation
         */
        fun remove(redisOperations: RedisOperations&lt;String, String&gt;, stock: Stock): Long? {
            val key = getKey(&quot;$&quot;)
            val popCnt = redisOperations.opsForSet().remove(key, stock.purchaseNumber)
            log.info
            return popCnt
        }

        /**
         * SCARD Operation
         */
        fun totalUsedCount(redisOperations: RedisOperations&lt;String, String&gt;, stock: Stock): Long {
            val key = getKey(&quot;$&quot;)
            val size = redisOperations.opsForSet().size(key) ?: 0
            log.info
            return size
        }

        fun getKey(keyPrefix: String) = &quot;$keyPrefix:$key&quot;
    }
}

...

/**
 * 회원당 재고 사용량 체크 레디스 오퍼레이션
 * 자료구조 : Set
 */
class MemberStockOperation {
    companion object {
        val log = logger()
        private var key = &quot;stock&quot;

        /**
         * SADD Operation
         */
        fun add(redisOperations: RedisOperations&lt;String, String&gt;, stock: Stock) {
            val key = createKey(&quot;$&quot;, stock.memberNumber!!)
            redisOperations.opsForSet().add(key, stock.purchaseNumber)
            log.info
        }

        /**
         * SREM Operation
         */
        fun remove(redisOperations: RedisOperations&lt;String, String&gt;, stock: Stock): Long? {
            val key = createKey(&quot;$&quot;, stock.memberNumber!!)
            val popCnt = redisOperations.opsForSet().remove(key, stock.purchaseNumber)
            log.info
            return popCnt
        }

        /**
         * SCARD Operation
         */
        fun totalUsedCount(redisOperations: RedisOperations&lt;String, String&gt;, stock: Stock): Long {
            val key = createKey(&quot;$&quot;, stock.memberNumber!!)
            val size = redisOperations.opsForSet().size(key) ?: 0
            log.info
            return size
        }

        private fun createKey(keyPrefix: String, keyPostFix: String) = &quot;$keyPrefix:$key:$keyPostFix&quot;
    }
}</code></pre><h2 id="f72be47b-2f51-4e31-a1a2-d38f84ec79bf" class=""><strong>재고 사용량 증가/차감 흐름</strong></h2><p id="8c1d6ede-b2d2-4ede-8636-3a01b1038007" class="">재고시스템에서 재고 사용량의 증가 &amp; 차감의 전체적인 시스템 흐름을 재고 사용량 증가, 재고 사용량 감소로 나누어서 말씀드리겠습니다.</p><h3 id="c632390a-e56c-4cd1-a0da-706614ac5224" class=""><strong>1. 재고 사용량 증가</strong></h3><p id="0d3ff64e-8471-4f65-8a69-052d0a4d7844" class="">먼저 재고 사용량 증가는 아래와 같은 흐름으로 진행이 되게 됩니다.</p><figure id="7d34e94a-b624-4645-9af7-f985e2eef211" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2012.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2012.png"/></a></figure><p id="49a407f2-1bec-4dd5-9827-774d6b3c52f0" class=""><code>구매 시스템</code>에서는 상품권의 구매가 발생하면 구매 API 가 호출됩니다.</p><p id="45d2f166-e666-41cf-bed1-3c03403ef820" class="">구매 시스템에서는 인증 정보 조회를 위해서 회원시스템 호출, 상품 유효성 검증 및 재고사용량 증가를 위한 상품 시스템 호출, 결제를 위한 결제시스템 호출 등 상품권 구매를 완료하기 위해 여러 타 시스템을 호출하게 됩니다.</p><p id="873e770e-354a-43fa-bb0e-9b12cb04b380" class="">이러한 일련의 과정들은 구매에 영향을 미치는 요소이기 때문에, (구매가 정상적으로 이루어지지 않았는데 재고사용량이 증가되어 있으면 안되니까요) 모두 구매가 일어나는 API와 <code>동기 방식</code>으로 얽혀서 진행되게 되어집니다.</p><p id="d1c02bc1-0393-4c0c-8d5e-fc67cb681d80" class="">구매시스템에서 구매가 진행되면, 상품 시스템의 재고사용량 증가 API가 호출되게 됩니다. 상품 시스템에서는 아래와 같은 흐름으로 재고사용량을 증가 시킵니다.</p><blockquote id="0f3cf1d6-dbe8-41e2-8094-6d608979f7c3" class="">1) (RDB) 트랜잭션 시작 (BEGIN Transaction)<p id="25fb3e4a-d521-4a1b-8652-06d9e71711c2" class="">2) 현재 구매가 가능한 상태인지 유효성 검증 과정을 거칩니다.</p><p id="277a4c79-64fe-43d4-a595-12051c23f320" class="">3) 구매가 가능할경우 Redis에 구매번호를 Add 해줍니다.</p><p id="76f7e062-cb35-4f40-bc43-cec0b9496ccb" class="">4) 구매가 가능할경우 RDB의 StockHistory 엔티티에 구매정보를 Insert 합니다.</p><p id="df1fae65-e34d-4533-ac44-9ef1537b48bf" class="">5) (RDB)트랜잭션 커밋 (COMMIT Transaction)</p></blockquote><p id="1a8f3aef-656c-4152-b047-9f376c68d54f" class=""><code>구피</code>라는 회원(회원번호: 201209320003)이 <code>오늘도 수고했어</code>(판매상품번호: S0630000RU) <code>5000원</code>권의 상품권을 구매(구매번호: G0AA0001JR)하는 시나리오로 설명을 드려보겠습니다.</p><p id="5a336a0f-0b2d-4869-adda-fb0b34d6818b" class="">위의 재고시스템 설계에서 데이터 유실과 동시성 이슈를 해결하고자 저장소를 RDB(재고 히스토리 관리)와 Redis(재고 사용량 관리) 두곳을 사용한다고 말씀을 드렸는데요.</p><p id="c2f1ab96-d500-4b0f-ad85-4f77f0ba34a2" class="">재고 사용량 증가를 위해서 먼저 <code>1)RDB 트랜잭션이 시작</code>되게 되고, 현재 <code>2)구매가 가능한 상태인지 유효성검증</code>을 하게 됩니다.</p><p id="3166ab73-1b2e-4c1b-8279-134a607ece9b" class="">Redis의 SCARD 오퍼레이션을 통해서 현재 구매가 발생된 상품권의 갯수를 조회하게 되고, 가격정책 엔티티(SalesProductPrice)에 저장된 총 재고수량(totalQuantity)와 인당 구매제한 수량(perLimitTotalQuantity)을 조회하여 두값을 비교하게 됩니다.</p><blockquote id="072a8f8f-dfb7-456c-93d4-2734ca59aa4c" class="">[재고 사용량 유효성 검증]<p id="6f87945b-ffb3-4711-aa2f-9d4af51456cf" class="">SalesProductPrice.totalQuantity = 1,000 // 총 재고수량 1,000개</p><p id="bf9de9ef-1668-4250-81b1-f563dbc31786" class="">SalesProductPrice.perLimitTotalQuantity = 2 // 인당 구매 제한수량 2개</p><p id="01ca3c13-df32-4be6-a9e4-7cf167e8d050" class="">SCARD S0630000RU:5000:stock:201209320003 = 0 // 구피(201209320003)회원이 구매한 상품권 0개</p><p id="97579459-f5e0-41ae-9a15-0389220d9cd5" class="">SCARD S0630000RU:5000:stock:total = 100 // 현재 구매된 상품권 100개</p><p id="d0d6a419-5686-464d-99f5-4bd5aaf1bfe1" class="">perLimitTotalQuantity &gt; 회원 재고 사용량</p><p id="8474ec49-2c20-4996-9aba-20819c30f909" class="">totalQuantity &gt; 전체 재고 사용량</p></blockquote><p id="94349094-9367-4988-8f50-b8587a9dbd9a" class="">유효성 검증이 통과되면 <code>3)Redis에 전체 재고 사용량 정보와 인당 재고 사용량 정보를 증가</code>시키게 됩니다.</p><p id="a62aec8d-b1d2-4412-b98e-c8bede3d8ec2" class="">이때, 인당 재고사용량과 전체 재고사용량을 하나의 트랜잭션에서 처리하기 위해서 redis 의 multi(), exec() 명령어로 묶어 줌으로써 두 오퍼레이션에 대한 트랜잭션을 보장하도록 처리하였습니다.</p><blockquote id="7b9928d9-0f19-4b16-a0d8-dd67dbf93fb0" class="">[재고 사용량 증가]<p id="50a3ecb0-e337-4d8a-96cf-37b88f9d32c5" class="">redis&gt; multi</p><p id="c00a4a8a-0ef2-4fdc-b7ff-f661cca1a652" class="">// G0AA0001JQ 구매 발생 인당 재고량 사용량 증가</p><p id="81ed81f5-529c-4a8f-b222-9cac138e430f" class="">redis&gt; SADD S0630000RU:5000:stock:total G0AA0001JQ</p><p id="4196eb82-d38d-44a2-bb9c-004a70c16c30" class="">// G0AA0001JQ 구매 발생 인당 재고량 사용량 증가</p><p id="09734dd6-51ac-4510-90a8-fe63801ae480" class="">redis&gt; SADD S0630000RU:5000:stock:201209320003 G0AA0001JQ</p><p id="b630abce-33a1-4076-bac1-a379697f2361" class="">redis&gt; exec</p></blockquote><p id="7b023db8-afec-4e18-b3c7-298deb106db8" class="">Redis에 재고 사용량이 업데이트 되게되면 <code>4)RDB의 재고 히스토리정보에 Insert 쿼리가 발생하게 되어 히스토리 정보를 저장</code>하게 됩니다.</p><blockquote id="292af13a-0d01-4326-ad2d-d09bd3a51ae0" class="">[재고 히스토리 저장]<p id="0084047b-6841-4ae4-8b76-4935d033ea03" class="">insert into stock_history (sales_product_number, purchase_number, member_number, price, type) values(‘S0630000RU’, ‘G0AA0001JR’, ‘201209320003’, ‘5000’, ‘PLUS’)</p></blockquote><p id="c5c15936-5538-4f1a-bcc3-4cbcb1417eb4" class="">재고사용량을 증가하게되면 마지막으로 <code>5)RDB 트랜잭션이 COMMIT</code> 되면서 재고사용량 증가에 대한 모든 프로세스가 완료되어지게 됩니다.</p><p id="25d7e274-7c6b-45ee-91e4-ad10280750c7" class="">지금까지 말씀드린 재고사용량 증가에 대한 코드는 아래와 같습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="fc9d2ae4-459e-487c-9f03-bfe12ca84e32" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">/**
* 레디스의 여러 오퍼레이션을 하나의 트랜잭션에서 처리하기 위해 multi() / exec() 연산으로 묶어준다.
**/
object RedisTransaction {
    fun transaction(operations: RedisOperations&lt;String, String&gt;, command: (operation: RedisOperations&lt;String, String&gt;) -&gt; Unit) {
        operations.execute(object : SessionCallback&lt;Void?&gt; {
            @Throws(DataAccessException::class)
            override fun &lt;K, V&gt; execute(callbackOperations: RedisOperations&lt;K, V&gt;): Void? {
                callbackOperations.multi()
                command.invoke(operations)
                callbackOperations.exec()
                return null
            }
        })
    }
}

@Service
@Transactional // 1) 트랜잭션 Begin 5) 트랜잭션 Commit
class StockHistoryDomainService(
    private val redisTemplate: RedisTemplate&lt;String, String&gt;,
    private val stockHistoryRepository: StockHistoryRepository,
    private val saleProductDomainService: SalesProductDomainService
) {
    ...
    @Synchronized
    fun increaseStock(data: StockHistoryData, totalQuantity: Long, perLimitTotalQuantity: Long): StockResult {
        val stock = Stock(
            salesProductNumber = data.salesProductNumber,
            purchaseNumber = data.purchaseNumber,
            memberNumber = data.memberNumber,
            price = data.price
        )

        // 2) 유효성 검증 (인당 제한 수량 체크)
        if (!validationMemberQuantity(perLimitTotalQuantity, stock)) {
            return StockResult.MEMBER_LIMIT
        }

        // 2) 유효성 검증 (전체 재고 수량 체크)
        return if (validationTotalQuantity(totalQuantity, stock)) {
            RedisTransaction.transaction(
                redisTemplate
            ) { operations -&gt;
                log.info
                // 3) 재고 사용량 증가
                TotalStockOperation.add(operations, stock)
                MemberStockOperation.add(operations, stock)
                // 4) 히스토리 정보 추가
                stockHistoryRepository.save(StockHistoryConverter.toEntity(data))
            }

            // 재고 품절처리
            this.checkSoldOut(totalQuantity, stock)
            StockResult.SUCCESS
        } else {
            StockResult.TOTAL_LIMIT
        }
    }

    fun validationMemberQuantity(
        perLimitTotalQuantity: Long,
        stock: Stock
    ): Boolean {
        return validateQuantity(total = perLimitTotalQuantity, quantity = MemberStockOperation.totalUsedCount(redisTemplate, stock))
    }

    fun validationTotalQuantity(
        totalQuantity: Long,
        stock: Stock
    ): Boolean {
        return validateQuantity(total = totalQuantity, quantity = TotalStockOperation.totalUsedCount(redisTemplate, stock))
    }

    private fun validateQuantity(total: Long, quantity: Long): Boolean {
        log.info )&quot; }
        return total &gt; quantity
    }

    private fun checkSoldOut(totalQuantity: Long, stock: Stock) {
        val totalUsedCount = TotalStockOperation.totalUsedCount(redisTemplate, stock)
        log.info
        if (totalQuantity &lt;= totalUsedCount) {
            saleProductDomainService.updateSoldOut(
                salesProductNumber = stock.salesProductNumber,
                price = stock.price
            )
        }
    }

}</code></pre><h3 id="49653622-ba7b-4a94-a58b-9281b7a596e0" class=""><strong>2. 재고 사용량 차감</strong></h3><p id="5f3e546d-ca13-45a4-8655-c88c3ea895f1" class="">재고 사용량의 차감은 아래와 같은 흐름으로 진행이 됩니다.</p><figure id="1880a9a9-f65f-4eda-b6cb-b80b650e745b" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2013.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2013.png"/></a></figure><p id="c36799a6-04d1-43fc-9c5f-e83029e0f41d" class="">구매가 취소되거나, 구매시 API 호출이 실패했을 경우, <code>구매시스템</code>에서는 <code>event-queue</code>에 재고사용량을 차감시키라는 이벤트를 <code>비동기방식</code>으로 발행하게 됩니다.</p><p id="08c9a79f-915b-49a9-a276-c24c6b4ef945" class=""><code>상품</code> 시스템의 이벤트 워커(product-event-worker)에서는 재고 사용량 차감이벤트가 발행되면, event-queue를 구독하여 재고사용량을 차감하게 됩니다.</p><blockquote id="78e38aab-7857-4fdd-953f-8f801f03d6c6" class="">1) (RDB) 트랜잭션 시작 (BEGIN Transaction)<p id="b162cfe4-266e-4526-9870-f6eae0447ce3" class="">2) Redis SREM 오퍼레이션으로 Set 에서 구매번호 제거</p><p id="ab789549-297e-4e95-9610-1b231e743d6d" class="">3) RDS StockHistory 엔티티에 재고량 감소 구매정보 데이터 저장</p><p id="eadaeb93-323f-4ff1-a3e1-dd5611c6b1f4" class="">4) (RDB)트랜잭션 커밋 (COMMIT Transaction)</p></blockquote><p id="b322330e-8f4f-45e1-9332-5b997b2af1a1" class="">재고 사용량 증가때 구매가 이루어진 <code>G0AA0001JR</code> 구매번호의 상품권이 <strong>구매취소</strong> 가 일어나거나 혹은 구매시 <strong>재고 사용량 API 증가 호출 과정에서 에러</strong> 가 발생했을 경우, <code>구매시스템</code>에서는 재고 사용량을 차감 하기위해 이벤트를 발행하게 됩니다.</p><blockquote id="dac0ec6c-9be2-45ab-9004-23ae49324bc2" class="">[이벤트 발행]<p id="80cd5970-bebb-420b-835d-f4e0457e59ea" class="">gift-product-purchase-stock-event-queue &gt;&gt; ‘G0AA0001JR’</p></blockquote><p id="4b456eed-5e36-4327-b8b8-15dd2bca2355" class="">상품시스템의 이벤트 워커에서는 재고사용량 감소를 위한 큐를 구독하고 있다가 이벤트가 수신되었을 경우 해당 이벤트를 수신하여 재고사용량을 차감 시켜줍니다.</p><p id="282f9ebb-95da-4157-9746-f1dc62819822" class="">레디스의 SET 자료구조를 사용했기 때문에, Set 안에 구매번호가 존재한다면 정상적으로 차감 처리가 이루어질 것이고, 그렇지 않다면 재고사용량은 차감되지 않을것 입니다.</p><blockquote id="e95c1b8e-abca-4937-add7-82c47df31fea" class="">[재고사용량 차감]<p id="3dc0d0d4-69e1-4339-8894-2cd1ad0ebff0" class="">redis&gt; multi</p><p id="9fc90db8-f2f6-4e91-b105-9892d54519bf" class="">redis&gt; SREM S0630000RU:5000:stock:total G0AA0001JR</p><p id="bebeb8a3-ffeb-4e62-a1cd-3bc16485b988" class="">redis&gt; SREM S0630000RU:5000:stock:201209320003 G0AA0001JR</p><p id="ec0ef475-cb65-49c6-a26c-e308e3b91dce" class="">redis&gt; exec</p></blockquote><p id="c12318a0-cc7e-4ef8-b2d0-bb04e4fdd6c4" class="">정상적으로 Redis 오퍼레이션이 수행되었다면, RDB의 재고 히스토리 정보에 차감 내역을 Insert 해주게 됩니다.</p><blockquote id="73364929-bc77-4e0d-ac4c-768ca39a1ccf" class="">[재고 히스토리 저장]<p id="d8b9be7a-4875-4327-b5f5-6a93f316f17b" class="">insert into stock_history (sales_product_number, purchase_number, member_number, price, type) values(‘S0630000RU’, ‘G0AA0001JR’, ‘201209320003’, ‘5000’, ‘MINUS’)</p></blockquote><p id="4d0e7a34-27a3-4cbe-b67e-90af5d7b7d0d" class="">마지막으로 트랜잭션이 COMMIT 되고, 재고 사용량 차감에 대한 프로세스가 완료되게 됩니다.</p><p id="d34ba1d0-7785-4757-a6c1-272b2e92a012" class="">재고사용량 차감에 대한 프로세스를 <code>비동기 방식</code>으로 처리한 것에 대한 의문이 있으실 수 있을것 같습니다. 재고사용량 차감의 경우에는 아래와 같은 이유로 <code>비동기 방식</code>으로 처리가 가능했습니다.</p><ol type="1" id="438f7197-7486-454d-aa50-2439d0b1fefb" class="numbered-list" start="1"><li>전체 재고량을 관리하고 재고 사용량을 증가 혹은 차감 시키는 방식을 사용한다.</li></ol><ol type="1" id="4adb1a93-f88a-4086-90de-c340ea94323a" class="numbered-list" start="2"><li>재고사용량 증가 방식을 동기 방식으로 처리함으로써, 절대 재고가 더 팔리는일은 발생하지 않는다.</li></ol><ol type="1" id="11742575-ad0b-4055-a6be-005842461514" class="numbered-list" start="3"><li>Redis의 SET 자료구조를 사용함으로써, 재고사용량 차감에 대한 잘못된 구매번호의 이벤트가 발행되어도 재고사용량 차감에 영향을 미치지 않는다.</li></ol><p id="16256bde-7667-4457-94ed-86b49f7734a0" class="">재고사용량 차감에 대한 처리 코드는 아래와 같습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="66ca21c2-d203-477a-b02b-1b7d5c5a9ad4" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">/**
* 재고사용량 차감 이벤트 서브스크라이버
**/
@Component
class StockNotificationSubscriber(
    private val stockNotificationProcessor: StockNotificationProcessor
) {

    val log = logger()

    @SqsListener(
        value = [&quot;$&quot;],
        deletionPolicy = SqsMessageDeletionPolicy.NEVER
    ) // 재고사용량 차감에 대한 이벤트를 수신한다.
    fun receivePurchaseStockEvent(
        @Header(&quot;ApproximateReceiveCount&quot;) receiveCount: String,
        @Header(&quot;MessageId&quot;) messageId: String,
        @Payload payLoad: StockPurchasePayload,
        acknowledgment: Acknowledgment
    ) {
        try {
            log.info(&quot;[StockNotificationSubscriber][receivePurchaseStockEvent] messageId : $messageId | payload: $payLoad&quot;)
            stockNotificationProcessor.process(payLoad) // 이벤트 프로세서에서 차감 로직을 수행하도록 호출한다.
            acknowledgment.acknowledge()
        } catch (e: Exception) {
            log.error(&quot;[StockNotificationSubscriber][receivePurchaseStockEvent] ERROR messageId : $messageId, receiveCount : $receiveCount&quot;, e)
        }
    }
}

...

/**
* 재고사용량 차감 이벤트 프로세서
**/
@Component
class StockNotificationProcessor(
    private val stockHistoryDomainService: StockHistoryDomainService
) {

    val log = logger()

    fun process(payLoad: StockPurchasePayload) {
        log.info(&quot;[StockNotificationProcessor][process] 이벤트 프로세싱 시작: $payLoad&quot;)
        stockHistoryDomainService.decreaseStock(convertData(payLoad)) // 재고 사용량을 차감한다.
        log.info(&quot;[StockNotificationProcessor][process] 이벤트 프로세싱 끝 | payload: $payLoad&quot;)
    }

    private fun convertData(payLoad: StockPurchasePayload) = StockHistoryData(
        salesProductNumber = payLoad.salesProductNumber,
        purchaseNumber = payLoad.purchaseNumber,
        memberNumber = payLoad.memberNumber,
        price = payLoad.price,
        type = StockHistoryType.MINUS
    )
}

/**
* 재고사용량 감소 서비스레이어
**/
@Service
@Transactional
class StockHistoryDomainService(
    private val redisTemplate: RedisTemplate&lt;String, String&gt;,
    private val stockHistoryRepository: StockHistoryRepository,
    private val saleProductDomainService: SalesProductDomainService
) {
    ...
    fun decreaseStock(data: StockHistoryData) {
        val stock = Stock(
            salesProductNumber = data.salesProductNumber,
            purchaseNumber = data.purchaseNumber,
            memberNumber = data.memberNumber,
            price = data.price
        )

        RedisTransaction.transaction(
            redisTemplate
        ) { operations -&gt;
            log.info
            TotalStockOperation.remove(operations, stock) // Redis 전체 재고 사용량 차감
            MemberStockOperation.remove(operations, stock) // Redis 인당 재고 사용량 차감
            stockHistoryRepository.save(StockHistoryConverter.toEntity(data)) // 히스토리 저장
        }
    }
}</code></pre><h2 id="6fe40257-a72c-4019-a502-6e5e0eb80cf5" class=""><strong>마치며</strong></h2><p id="8443c3e6-9e87-4be7-8f51-d9d382e86ae1" class="">이제까지 배민의 선물하기 서비스에서 상품 재고관리를 어떻게 관리하는지에 대해서 소개해드렸습니다.</p><p id="8c8c6027-4164-4958-8828-fc94cf233dc0" class="">재고관리 시스템을 설계하며 재고가 더 팔리면 어떻게하지?, 데이터가 유실되면 어떻하지? 라는 고민과 걱정을 많이하며 데이터 싱크와 동시성 이슈에 대해서 많은 고민을 하며 진행을 했었습니다. 이러한 고민이 글을 읽어주신 분들에게 조금이나마 도움이 되었으면 좋겠습니다.</p></details></li></ul><p id="ee474d80-60e1-48ee-a751-7de1a2803b95" class="">
</p><p id="06e80b80-3bf6-4eb2-bbcf-47ed0c3bbdaa" class="">MSA</p><ul id="15b3a4cc-090a-8048-8729-c4bcf2e8bfc4" class="toggle"><li><details open=""><summary>MSA 적용 사례</summary><figure id="15b3a4cc-090a-8082-8552-fc939b7f8ff4" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%203.png"><img style="width:792.984375px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%203.png"/></a></figure></details></li></ul><ul id="63e33c12-0926-4404-bc65-98a0c52167a5" class="toggle"><li><details open=""><summary>MSA 구조 개요</summary><h3 id="be9e63a9-66ca-4755-9b96-ddcfeb6eb819" class=""><strong>MSA란?</strong></h3><p id="411f2c3d-b295-449f-b613-711b87eb9e22" class="">MSA에 대해 본격적으로 설명하기 전, 우선 &#x27;모놀리틱 시스템&#x27;에 대해 설명드리겠습니다. 모놀리틱 시스템이란 소프트웨어 애플리케이션을 하나의 단일한 독립 시스템으로 구축하는 소프트웨어 아키텍처 스타일을 말합니다. 즉 하나의 애플리케이션에 모든 비즈니스 로직을 통째로 모아놓은 구조이죠. 모놀리틱 시스템은 소규모 프로젝트에 적합하고, 개발/빌드/배포/테스트가 용이하며 인프라 구조가 단순하여 운영 비용 부담이 없다는 장점이 있었습니다.</p><p id="693cac44-6792-4533-9ff3-62d452f15356" class="">하지만 기업의 시스템 규모가 점점 커지고 복잡해지면서 모놀리틱 시스템의 단점이 부각되기 시작했습니다. 작은 수정사항에도 전체 빌드 및 배포가 이뤄져야 해서 시간이 오래 걸리고, 많은 양의 코드가 몰려 있어 유지보수가 어려웠죠. ▲일부 오류가 전체에 영향을 미치는 점 ▲스케일 아웃 설정이 복잡한 점 역시 문제가 되었습니다.</p><p id="d95f3a81-ed6c-4b38-bea3-18ae66941672" class="">MSA는 이러한 모놀리틱 시스템의 대안으로 등장하였습니다. <strong>MSA는 소프트웨어 시스템을 여러 작은 독립적인 서비스로 분할하여 개발하고 배포하는 방식입니다.</strong> 하나의 애플리케이션을 구분 가능한 여러 개의 작은 서비스로 나눠 사용자의 요청을 처리하는 구조이죠.</p><p id="50270b98-1be8-4107-9be6-1bde81ffd05c" class=""><strong>MSA는 각 서비스별 소스 코드 수정이 쉽고, 수정한 서비스만 배포 가능하며, 배포 시 전체 서비스 중단이 없습니다. 또한 장애 시 해당 서비스에만 한정되고, 전체 장애로 확장될 가능성이 적습니다. 스케일 아웃이 필요한 경우에는 해당 서비스만 추가하여 리소스의 효율적 사용이 가능합니다.</strong></p><figure id="b90de240-0ca0-4da1-b613-7bd05b488197" class="image"><a href="https://metanetglobal.com/ckeditor/uploads/%EA%B7%B8%EB%A6%BC1%286%29.png"><img style="width:700px" src="https://metanetglobal.com/ckeditor/uploads/%EA%B7%B8%EB%A6%BC1%286%29.png"/></a></figure><h3 id="d0d621b9-6ec8-4a2f-914e-6170a0012c30" class=""><strong>MSA의 인기 요인</strong></h3><p id="cf0a487e-f28b-409b-9e1e-cc091ea3774f" class="">모놀리틱 시스템은 초기 생산성이 높지만, 시스템 복잡도가 진행될수록 생산성이 급격히 떨어지기 시작합니다. <strong>MSA의 경우 초기 생산성은 모놀리틱 시스템보다 떨어지지만, 시스템 복잡도가 진행되어도 생산성이 소폭 감소할 뿐 거의 유지된다고 볼 수 있습니다. 클라우드 기반의 복잡한 시스템 구축 시 MSA의 필요성이 커지는 이유입니다.</strong></p><p id="e73a3418-3708-4881-8a5a-8ac4e0baea8a" class="">MSA의 장점에 대해 더 자세히 살펴보겠습니다.</p><p id="f6243611-7de4-4874-b6b0-c07ec9d0b202" class=""><strong>① 개발 유연성의 한계 극복</strong></p><p id="fdb08913-9656-421f-82e0-359deee8bf7d" class="">기존 모놀리틱 방식은 모든 구성요소가 하나의 애플리케이션으로 구성되어 있어 변화에 대한 대응이 어렵습니다. 새로운 기능 추가를 위해 전체를 빌드/배포해야 하는 문제가 있었죠. MSA는 독립적 서비스 단위 구성으로 수정 및 빌드/배포가 신속히 가능합니다.</p><h3 id="662bb388-9faf-4367-a826-85e27b445f11" class=""><strong>② 요구사항 처리 시 모놀리틱 시스템 대비 빠른 대처 가능</strong></h3><p id="53a05dd7-4e94-42bb-8887-0c147c57c24f" class=""><strong>③ 배포/롤백 리스크의 획기적 감소</strong></p><p id="73a52582-bb03-4bb3-826c-5f4b2a84902d" class="">MSA는 여러 개의 서비스로 구성되어 있습니다. 이 중 수정이 필요한 부분만 빠르게 찾아 정확한 대응이 가능합니다.</p><p id="14ef5022-4577-411f-ac4a-d47c280737c7" class="">또한 쿠버네티스 기능을 사용하여 서비스 무중단 배포를 할 수 있습니다.</p><p id="5bc1be83-a48d-420a-95eb-a5c390b536cf" class=""><strong>④ 장애 격리의 신뢰성</strong></p><p id="7c03aebd-2ca3-4e6e-963e-55588d2ccb01" class="">모놀리틱은 단일 애플리케이션으로 이뤄져있어 특정 부분에 문제가 발생하면 전체 시스템 장애로 이어지게 됩니다. MSA는 각각의 서비스가 약한 결합도를 가지고 있기 때문에, 특정 서비스 장애가 타 서비스에 영향을 최소로 주거나 아예 주지 않도록 구성이 가능합니다. 이를 통해 장애 서비스만 빠르게 복구할 수 있습니다.</p><p id="ab53350c-eb1b-4183-bb7a-e66473b5ceb0" class=""><strong>⑤ 리소스의 효율적 사용</strong></p><p id="c8eddebb-b568-473c-884f-9c10d5a86ca4" class="">모놀리틱은 단일 구조로 되어 있기에, 통으로 확장이 필요해 리소스의 낭비가 발생하게 됩니다. 이에 비해 MSA 시스템은 사용자 부하 발생시 부하 발생 서비스만 스케일 아웃 기능을 통한 확장이 가능하여 리소스를 효율적으로 사용할 수 있습니다.</p><figure id="d7e1ff31-cce6-4ee9-a325-fd102fa15248" class="image"><a href="https://metanetglobal.com/ckeditor/uploads/%EA%B7%B8%EB%A6%BC2%281%29.png"><img style="width:700px" src="https://metanetglobal.com/ckeditor/uploads/%EA%B7%B8%EB%A6%BC2%281%29.png"/></a></figure><h3 id="7cde914a-5a8d-4aa2-af9e-c57efefa4e67" class=""><strong>MSA 아키텍처의 구성 요소</strong></h3><p id="7002f4b3-4a3b-4b1e-8a2d-ec50bc3f9280" class="">MSA를 구성하는 주요 요소는 다음과 같습니다.</p><p id="2107da11-63fb-4133-8acc-9d5d9bba543e" class=""><strong>① Config Management: </strong>MSA 구조는 서비스의 재빌드/재부팅 없이 설정사항을 반영합니다.</p><p id="14505f34-0365-4e81-a4bf-5d6c40857e3d" class=""><strong>② Service Discovery: </strong>쿠버네티스 기능을 통해 여러 개의 서비스 상태를 파악할 수 있고, 서비스 검색 및 등록 등 관리가 용이합니다.</p><p id="089dd021-d61b-487b-8de3-3780dc60690d" class=""><strong>③ API Management: </strong>API 게이트웨이는 외부 요청과 내부 서비스 간 통신을 관리합니다. 클라이언트 접근 요청을 일원화합니다.</p><p id="3029d0fa-33c9-4038-89a4-8b86c79e0c3f" class=""><strong>④ Centralized Logging: </strong>서비스 별로 로그가 나눠져있는 가운데, 이 로그를 중앙 집중하여 한 곳에서 관리할 수 있습니다.</p><p id="ed8cdba2-5422-468e-b8b0-31b847f6eb8d" class=""><strong>⑤ Distributed Tracing: </strong>마이크로서비스 간의 호출을 추적합니다.</p><p id="da0e6f01-876e-4d77-af84-844faa107149" class=""><strong>⑥ Centralized Monitoring: </strong>여러 서비스의 정보를 중앙집중하여 복잡성을 줄이고 관리를 쉽게 합니다.</p><p id="b0d40667-b061-47b1-b76e-4bd233f40a07" class=""><strong>⑦ Resillience &amp; Fault Tolerance: </strong>MSA 구조에서 한 서비스의 오류가 다른 서비스에 파급 효과를 발생시키지 않도록 하기 위한 계단식 실패 방지 구조입니다.</p><p id="0b6590b1-e60d-41d8-b3aa-13deaf55fd49" class=""><strong>⑧ Auto Scaling &amp; Self Healing: </strong>부하 발생 시 자동 스케일 아웃 설정이 가능하고, 서비스 장애시 복구 자동화를 통해 서비스 관리를 효율적으로 할 수 있습니다.</p><hr id="6591cdcb-9710-48be-b942-d52954adcf2a"/><p id="6d2228a4-5535-45f9-b5b1-dc15fd7ef231" class="">MSA 아키텍처는 기업의 IT 운영에 있어서 중요한 역할을 합니다. 특히 클라우드 네이티브 환경에 적합한 아키텍처인 MSA는 기업들이 클라우드의 유연성과 확장성을 최대한 활용하여 애플리케이션을 개발하고 운영하는 데 도움을 줍니다. 기업들은 MSA 아키텍처의 도입을 통해 유연성, 확장성, 유지보수의 용이성, 개발속도 향상 등의 이점을 얻을 수 있습니다.</p><p id="d4969bc1-3fc2-4221-b824-12ca91f54ec7" class="">
</p></details></li></ul><ul id="08e6b23c-391e-4a54-8143-31f180635ed3" class="toggle"><li><details open=""><summary>MSA 구성 요소</summary><figure id="e1358375-9f20-4d8e-a4e6-6139dea50866" class="image"><a href="https://velog.velcdn.com/post-images%2Ftedigom%2Fb6bae160-fb10-11e9-9ef4-395edd3ef4d0%2F%EA%B0%80%ED%8A%B8%EB%84%88MSAComponent.png"><img src="https://velog.velcdn.com/post-images%2Ftedigom%2Fb6bae160-fb10-11e9-9ef4-395edd3ef4d0%2F%EA%B0%80%ED%8A%B8%EB%84%88MSAComponent.png"/></a></figure><p id="d8d96e1e-5053-4c13-a126-130be0263d11" class="">MicroService Architecture는 크게 Inner Architecture와 Outer Architecture로 구분할 수 있습니다. 위 그림에서 남색 부분은 Inner Architecture의 영역이고, 회색 부분은 Outer Architecture 부분입니다.</p><h2 id="9620f27a-7ae3-4b8f-8b84-7cf3888267b8" class="">Inner architecture</h2><figure id="43d5a4f4-e84d-49d9-883c-86136645fe4b" class="image"><a href="https://velog.velcdn.com/post-images%2Ftedigom%2F052a8e50-fbdd-11e9-9256-3bbc0d52572a%2FInner.PNG"><img src="https://velog.velcdn.com/post-images%2Ftedigom%2F052a8e50-fbdd-11e9-9256-3bbc0d52572a%2FInner.PNG"/></a></figure><p id="c0b48144-b1f7-49c0-b133-069d3efdf3b1" class="">Inner architecture는 내부 서비스와 관련된 architecture입니다. 쉽게 말해, 내부의 서비스를 어떻게 잘 쪼개는지에 대한 설계입니다.</p><p id="d608c5e0-7e40-4210-88eb-6b4bbf31e6c6" class="">Inner Architecture에서 고려해야 할 부분은 다음과 같습니다.</p><h3 id="247a2498-2146-451f-b5f3-dc76cdbb1845" class=""></h3><ul id="a95d1e5f-8919-4c0a-b1b6-7d15c3f854b5" class="bulleted-list"><li style="list-style-type:disc">(마이크로)서비스를 어떻게 정의할 것인가?<p id="a043b2e4-f4e2-49c8-bcf7-87c3d8a1e4cc" class="">쇼핑몰에서, 주문하기 부분과, 카트에 넣기를 같은 서비스로 넣을 것인지, 다른 서비스로 분리할 것인지는 그 비즈니스나 시스템의 특성에 따라 정의되어야 합니다.</p><p id="0fe33fa4-b398-47e9-b54d-bec0c8947bbd" class="">서비스를 정의하기 위해 고려해야 할 사항은 비즈니스 뿐만 아니라, 서비스 간의 종속성, 배포 용이성, 장애 대응, 운영 효율성 등 굉장히 많습니다.</p><h3 id="51a3927d-a21b-4ff2-9d85-743664c27baa" class=""></h3></li></ul><ul id="e846b8b0-4462-4428-b49a-90dc7e144937" class="bulleted-list"><li style="list-style-type:disc">DB Access 구조를 어떻게 설계할 것인가?<p id="16a614d8-1dc0-4d68-871d-866ff182fb16" class="">Microservice가 사용하는 데이터는 일반적으로 일관된 API를 통해서 접근합니다. 또한 각 마이크로 서비스에는 자체의 데이터베이스를 가질 수 있는데, 일부의 비즈니스 트랜잭션은 여러 microservices를 걸쳐 있기 때문에, 각 서비스에 연결된 데이터베이스의 정합성을 보장해 줄 수 있는 방안이 필요합니다.</p></li></ul><ul id="fee79fe0-4001-4de6-a71b-4b6579987e64" class="bulleted-list"><li style="list-style-type:disc">(마이크로)서비스 내 api를 어떻게 설계할 것인가?</li></ul><ul id="11d971ed-9818-4f9c-bf05-815dcfaafe96" class="bulleted-list"><li style="list-style-type:disc">논리적인 컴포넌트들의 layer를 어떠한 방식으로 설계할 것인가? 등등...</li></ul><h3 id="6ceb1288-e639-4753-ba74-7124425aa8c6" class=""></h3><p id="691fd113-f2c4-4b76-91ff-f22a7b30021c" class="">Inner Architecture는 비즈니스마다, 서비스마다, 시스템마다 각각의 특성이 있기 때문에 딱히 정해져 있는 것이 없습니다.( 표준이 없습니다.) 따라서 이 부분은 MSA를 설계하는 데에 가장 어려운 부분이기도 합니다.</p><h1 id="224907df-4e78-4c91-9c5b-527f83d757ae" class=""></h1><h2 id="9a5bc697-ce5d-4da1-a28e-d3f66219e62f" class="">Outer architecture</h2><p id="73b842eb-6ffc-47ea-a845-9fc898e05bc5" class="">맨 위의 그림에서와 같이 Gartner에서는 MSA의 Outer architecture을 총 6개의 영역으로 분류하고 있습니다.</p><ul id="07c77ab2-e8da-4dab-abde-9edb75e39876" class="bulleted-list"><li style="list-style-type:disc">External Gateway</li></ul><ul id="17d0e9a7-4264-4c75-89d4-bf5691bd65f1" class="bulleted-list"><li style="list-style-type:disc">Service Mesh</li></ul><ul id="e827a7d3-4250-430d-aa7a-0271f197173e" class="bulleted-list"><li style="list-style-type:disc">Container Management</li></ul><ul id="37a6411c-7bf3-4533-99fe-a7bd6ba45061" class="bulleted-list"><li style="list-style-type:disc">Backing Services</li></ul><ul id="75b84462-8d14-4fee-a177-a9f46275239c" class="bulleted-list"><li style="list-style-type:disc">Telemetry</li></ul><ul id="3bb25ffd-1b99-442d-9f82-c570a0237681" class="bulleted-list"><li style="list-style-type:disc">CI/CD Automation</li></ul><h3 id="3c349f6f-4411-4907-8fdf-63dd5d8b1c1b" class=""></h3><p id="e8ad8549-c796-4bbb-928f-224514d32468" class="">이번 글은 &#x27;아키텍처의 개요&#x27; 이므로, 위 6가지 요소가 어떠한 것인지 맛보기로만 간단하게 알아보도록 하겠습니다.</p><blockquote id="75caaac5-0c0d-46b6-9bcb-f847bf130e60" class="">위 6가지 요소에 대한 세부 내용은 이어지는 글에서 상세하게 다루어볼 예정입니다.</blockquote><h3 id="078961b5-488d-45fe-b9c6-d9f8eca64642" class="">1. External Gateway</h3><p id="aab2edf4-fa55-44cf-a91b-f5cf1ea5bb1a" class="">External Gateway는 전체 서비스 외부로부터 들어오는 접근을 내부 구조를 드러내지 않고 처리하기 위한 요소입니다. 사용자 인증(Consumer Identity Provider)과 권한 정책관리(policy management)를 수행하며, API Gateway가 여기서 가장 핵심적인 역할을 담당합니다.</p><figure id="e4982f14-2b2a-4815-91bf-7c5007f58975" class="image"><a href="https://velog.velcdn.com/post-images%2Ftedigom%2F78ec1240-fd32-11e9-ba49-23d182ee1325%2Fapigateway.png"><img src="https://velog.velcdn.com/post-images%2Ftedigom%2F78ec1240-fd32-11e9-ba49-23d182ee1325%2Fapigateway.png"/></a></figure><p id="ec6d3670-72ce-4aa4-98e4-2ebfa3775214" class="">API Gateway는 서버 최앞단에 위치하여 모든 API 호출을 받습니다. 받은 API 호출을 인증한 후, 적절한 서비스들에 메세지를 전달될 수 있도록 합니다.(routing)</p><h3 id="382d461a-c948-4d70-acdd-d4ec3f5bcaf2" class="">2. Service Mesh</h3><figure id="d7cde231-692e-43b9-a5ad-36bfc228e6b8" class="image"><a href="https://velog.velcdn.com/post-images%2Ftedigom%2Fc47c3fa0-fd32-11e9-a0de-716e91f77b84%2FserviceMesh.png"><img src="https://velog.velcdn.com/post-images%2Ftedigom%2Fc47c3fa0-fd32-11e9-a0de-716e91f77b84%2FserviceMesh.png"/></a></figure><p id="0f896faf-9892-4cdb-83b7-3c947831cbca" class="">Service Mesh는 마이크로서비스 구성 요소간의 네트워크를 제어하는 역할을 합니다. 서비스 간에 통신을 하기 위해서는 service discovery, service routing, 트래픽 관리 및 보안 등을 담당하는 요소가 있어야 합니다.</p><p id="4552cbf1-2cf1-462e-a5a5-9487d7421f2e" class="">Service Mesh는 위에 언급된 기능들을 모두 수행합니다.</p><h3 id="fa6c9ca4-677b-4658-b26f-c3414077cb5a" class="">3. Container Management</h3><figure id="24fcef71-7286-41b8-92d5-3ae45c0cb3d5" class="image"><a href="https://velog.velcdn.com/post-images%2Ftedigom%2Ffc7292b0-fd32-11e9-ba49-23d182ee1325%2Fcontainer-management-diagram.png"><img src="https://velog.velcdn.com/post-images%2Ftedigom%2Ffc7292b0-fd32-11e9-ba49-23d182ee1325%2Fcontainer-management-diagram.png"/></a></figure><p id="eb391077-ff2a-4b50-8a8f-3984867a7850" class="">컨테이너 기반 어플리케이션 운영은 유연성과 자율성을 가지며, 개발자가 손쉽게 접근 및 운영할 수 있는 인프라 관리 기술이기 때문에 MSA에 적합하다고 평가받고 있습니다.</p><p id="0b84ea19-af3d-4337-953a-d5a8663270d9" class="">대표적인 컨테이너 관리 환경인 Kubernetes가 Container management에 많이 사용되고 있습니다. 특히 AWS의 EKS, Google cloud platform의 GKE는 kubernetes를 지원하는 클라우드 서비스로, 앞으로의 어플리케이션 운영 환경을 많이 변화시킬 것으로 예상됩니다.~(아직은 많은 개선이 필요한 서비스입니다.)~</p><h3 id="26fbf857-aa15-4119-8e2a-17a111b53d60" class="">4. Backing Service</h3><p id="f9bb64c0-5704-4708-9b02-39cf4b78b318" class="">Backing Service는 어플리케이션이 실행되는 가운데 네트워크를 통해서 사용할 수 있는 모든 서비스를 말하며, My SQL과 같은 데이터베이스, 캐쉬 시스템, SMTP 서비스 등 어플리케이션과 통신하는 attached Resource들을 지칭하는 포괄적인 개념입니다.</p><figure id="2178e537-dd33-4c19-91ae-94f0257532a6" class="image"><a href="https://velog.velcdn.com/post-images%2Ftedigom%2F1f0216d0-fd37-11e9-ae72-731624d4042b%2Fmessagequeue.png"><img src="https://velog.velcdn.com/post-images%2Ftedigom%2F1f0216d0-fd37-11e9-ae72-731624d4042b%2Fmessagequeue.png"/></a></figure><p id="bdee8ada-89a9-48e0-9da1-41cde0ff40ef" class="">MSA에서의 특징적인 Backing service들 중 하나는 Message queue입니다. MSA에서는 메세지의 송신자와 수신자가 직접 통신하지 않고 Message Queue를 활용하여 비동기적으로 통신하는 것을 지향합니다.</p><p id="a429d370-79ba-4008-b372-80ca30a10d0f" class="">예를 들어, MSA를 적용한 프로젝트에서 장애 발생이 일어났다고 가정해 봅시다. 이 경우, 마이크로서비스 오케스트레이션이 진행되면서, 새로운 마이크로 서비스를 신규 생성하거나 재생성 등의 작업을 진행하게 됩니다.</p><p id="01bd2d52-59ed-490a-a206-187f0d3e1c75" class="">만약 Message Queue를 사용하지 않는 강한 결합 구조의 경우, 여러 서비스를 걸치는 실시간 트랜잭션을 처리할 때, 하나의 서비스가 죽어버린다면 트랜잭션이 끊어지기 때문에 해당 서비스 요청을 보존할 수 없고 큰 에러가 발생하게 됩니다. 또한 REST 통신으로 트랜잭션 실패에 대한 처리를 구현하는 방법은 굉장히 복잡합니다.</p><p id="efbfa43b-86c1-4bfb-bdd9-5df4cce29c4e" class="">MSA에서 데이터 변경이나, 보상 트랜잭션과 관련된 처리는 Message Queue를 활용한 비동기 처리가 효율적입니다.</p><h3 id="04019af7-d937-456a-9e57-7655f8e1fbce" class=""></h3><h3 id="6c0fd583-37de-4471-90f7-258a45720114" class="">5. Telemetry</h3><p id="348c5598-4273-4fda-b015-53d67b476368" class="">Telemetry의 어원은 Tele(먼 거리) + metry(측정)입니다. 즉, 실시간으로 먼 거리에서 원격으로 측정할 수 있다... 뭐 이런 의미가 되겠네요.</p><p id="5c123b12-707f-437f-b4a3-943369e9d4a4" class="">MSA에서는 상당수의 마이크로서비스가 분산환경에서 운영되기 때문에 서비스들의 상태를 일일이 모니터링하고, 이슈에 대응 하는 것은 굉장히 힘들고 오랜 시간이 걸립니다. Telemetry는 서비스들을 모니터링하고, 서비스별로 발생하는 이슈들에 대응할 수 있도록 환경을 구성하는 역할을 합니다.</p><h3 id="8a68432c-bd28-4099-a2db-65fbd0a4a9dd" class=""></h3><h3 id="2c91bda7-7638-43b8-88b4-8b81884670d4" class="">6. CI/CD Automation</h3><p id="6aac067f-94ae-48f0-8db1-4403a4b6a124" class="">CI/CD는 어플리케이션 개발 단계를 자동화하여, 어플리케이션을 보다 짧은 주기로 고객에게 제공하는 방법입니다.</p><p id="83972821-b667-47c5-9063-12ae1cab96b9" class="">지속적인 통합(Continuous Integration), 지속적인 전달(Continuous Delivery), 지속적인 배포(Continuous Deployment)가 CI/CD의 기본 개념으로, 이를 자동화하는 것은 배포가 잦은 MSA 시스템에 꼭 필요한 요소 중 하나입니다.</p><p id="c9327754-c103-4a0f-8691-4b6397c29085" class="">
</p></details></li></ul><ul id="fe7f2871-6e4e-44e1-b6d1-146e3dc1f703" class="toggle"><li><details open=""><summary>Cloud 기반의 커머스 시스템 설계</summary><h3 id="bd2a5015-304f-4ba1-b667-e5e10f2d5a23" class="">클라우드 환경에서의 Public Zone과 Private Zone 컴포넌트 배치</h3><ul id="6668b5c7-204d-439d-b897-96c8ddbd9270" class="bulleted-list"><li style="list-style-type:disc"><strong>Public Zone (퍼블릭 존)</strong><ul id="2e9cf98c-b14e-4d91-9661-27abfa29185f" class="bulleted-list"><li style="list-style-type:circle">인터넷에 직접 노출되는 컴포넌트들을 배치하는 영역입니다.</li></ul><ul id="6bdcec27-796f-474e-bca2-1d66b75943bb" class="bulleted-list"><li style="list-style-type:circle">사용자 트래픽을 직접적으로 받는 컴포넌트들로 구성됩니다.</li></ul></li></ul><ul id="4dfcc9a0-2c1f-4cb3-bcd2-f59c7a69dfef" class="bulleted-list"><li style="list-style-type:disc"><strong>Private Zone (프라이빗 존)</strong><ul id="ae4403f6-41e5-4616-886b-f8f47e00c97a" class="bulleted-list"><li style="list-style-type:circle">외부 트래픽이 직접 접근할 수 없는 내부 네트워크 영역입니다.</li></ul><ul id="432970e5-1ab1-4a7e-86fb-71aa8da3c1df" class="bulleted-list"><li style="list-style-type:circle">데이터베이스나 백엔드 서비스처럼 보안이 필요한 컴포넌트들을 배치합니다.</li></ul></li></ul><h3 id="1c185b27-c5cc-48ba-af9e-b181578e159d" class="">Public Zone 컴포넌트</h3><ol type="1" id="0cb8ea90-a2f4-4b8a-a50f-07576ec5dafc" class="numbered-list" start="1"><li><strong>로드 밸런서 (Load Balancer)</strong><ul id="bf341767-8bd9-41c5-bcde-2645eabf4282" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 여러 인스턴스로 구성된 프론트엔드 또는 API 게이트웨이에 대한 트래픽을 분산시킵니다.</li></ul><ul id="c6c8ca28-1704-4ae9-a605-c9d0bfa5c8f2" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: AWS ELB (Elastic Load Balancing), Google Cloud Load Balancer, Azure Load Balancer</li></ul></li></ol><ol type="1" id="d7be7950-0d3d-4ac7-92a1-c2de15e32fd6" class="numbered-list" start="2"><li><strong>프론트엔드 (Frontend)</strong><ul id="05d6186d-1d9b-4000-89ed-451f9adcff21" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 사용자에게 웹 인터페이스를 제공합니다.</li></ul><ul id="7cac90ef-e456-4df1-8a96-a33be8aa388a" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: CDN(CloudFront, Cloud CDN)을 통해 전 세계 사용자에게 빠르게 콘텐츠를 제공합니다.</li></ul></li></ol><ol type="1" id="cd9d5569-4fcc-4ec1-8f26-0e069909a442" class="numbered-list" start="3"><li><strong>API 게이트웨이 (API Gateway)</strong><ul id="ceae6784-e135-47b4-906f-df39508bd317" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: API 요청을 적절한 백엔드 서비스로 라우팅하고, 인증 및 로깅 등의 기능을 수행합니다.</li></ul><ul id="1f478ab3-9ddd-4ed7-96ef-e5bcb013caf2" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: AWS API Gateway, Kong, Nginx</li></ul></li></ol><h3 id="b9ea02c7-437a-4217-815f-1510a2db00ce" class="">Private Zone 컴포넌트</h3><ol type="1" id="1902fef1-0442-4940-8583-28059bb45f09" class="numbered-list" start="1"><li><strong>상품 서비스 (Product Service)</strong><ul id="d3dfc242-40e3-488a-add4-276c722b33d1" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 상품 정보를 관리합니다.</li></ul><ul id="77d39050-5d6d-4887-b684-276ca86c25da" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: Kubernetes, ECS, EKS</li></ul></li></ol><ol type="1" id="d9f3973d-93ef-4216-a25c-43962e2da509" class="numbered-list" start="2"><li><strong>주문 서비스 (Order Service)</strong><ul id="572b0b74-ee72-490e-bb75-bd50145ddfa8" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 주문 처리 및 관리합니다.</li></ul><ul id="e56ffe4d-586f-408f-846f-ed1784911cd0" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: Kubernetes, ECS, EKS</li></ul></li></ol><ol type="1" id="eded172a-978f-4a46-92b8-e8dc77cc71c7" class="numbered-list" start="3"><li><strong>결제 서비스 (Payment Service)</strong><ul id="3df9466b-051f-4ae2-9050-1bd7f5d0b9b2" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 결제 프로세스를 관리합니다.</li></ul><ul id="a1a686fd-a5ea-4961-8a0b-1324af08f9ef" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: Kubernetes, ECS, EKS</li></ul></li></ol><ol type="1" id="0a26d0d1-4be2-4532-ba02-a1366eaae0c8" class="numbered-list" start="4"><li><strong>재고 관리 서비스 (Inventory Service)</strong><ul id="a7c9768b-eb4b-4964-8529-b3a37c65c2fd" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 재고 사용량 및 상태를 관리합니다.</li></ul><ul id="e2ffe440-6397-4a58-a5cf-59cf900a9081" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: Kubernetes, ECS, EKS</li></ul></li></ol><ol type="1" id="065399dd-de0a-4f17-b942-98012956c6a7" class="numbered-list" start="5"><li><strong>사용자 서비스 (User Service)</strong><ul id="f70074cc-4528-496f-bd41-a48f644b7bc4" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 사용자 인증 및 관리를 담당합니다.</li></ul><ul id="1e68627c-de02-4be2-aed9-2baf21e3a7a4" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: Kubernetes, ECS, EKS</li></ul></li></ol><ol type="1" id="d7efcc6d-8638-4a5c-a093-cf3051b7f83a" class="numbered-list" start="6"><li><strong>추천 시스템 서비스 (Recommendation Service)</strong><ul id="10b92695-09da-46af-8610-4589f259c2e3" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 사용자에게 상품 추천을 제공합니다.</li></ul><ul id="be2d0730-61df-413c-b634-b602f55f698d" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: Kubernetes, ECS, EKS</li></ul></li></ol><ol type="1" id="3c63eeb9-bb40-4631-9d69-1edf4107f299" class="numbered-list" start="7"><li><strong>알림 서비스 (Notification Service)</strong><ul id="8e31774f-c418-4d9b-b7ed-725e28401038" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 사용자에게 다양한 채널을 통해 알림을 제공합니다.</li></ul><ul id="e7c6f55a-20ad-4333-ad7c-93c473e74cb7" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: Kubernetes, ECS, EKS</li></ul></li></ol><ol type="1" id="21eea1e2-a1a2-430e-856d-e6cd56c7d526" class="numbered-list" start="8"><li><strong>로깅 및 모니터링 서비스 (Logging &amp; Monitoring)</strong><ul id="1095b574-e574-4bc4-a30c-1443f02f6e64" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 서비스의 로그 및 성능을 모니터링합니다.</li></ul><ul id="5b6bbd66-631f-46b2-884e-d0c37d314e25" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: ELK Stack, Prometheus, Grafana</li></ul></li></ol><ol type="1" id="eab8c357-3071-481c-8a5a-583add25f9b1" class="numbered-list" start="9"><li><strong>데이터베이스 (Database)</strong><ul id="871d6a53-9596-46ac-a5ed-fb828d17dddd" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 데이터 저장 및 관리합니다.</li></ul><ul id="89e654e7-a80a-498e-ad62-644f1d92da06" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: Amazon RDS, Google Cloud SQL, Azure SQL Database, MongoDB Atlas</li></ul></li></ol><ol type="1" id="693452f6-37fc-4d0c-bdd5-217dc0946b76" class="numbered-list" start="10"><li><strong>Redis 캐시 (Redis Cache)</strong><ul id="56d2a6e3-5d11-488d-bb71-bdea3f83f495" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 재고 사용량, 세션 데이터, 캐싱 데이터를 관리합니다.</li></ul><ul id="934f2d2d-a693-4156-93f5-a054eb6db2ba" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: Amazon ElastiCache, Redis Labs</li></ul></li></ol><ol type="1" id="c109097b-eeb9-48d7-8230-61c24a5e805a" class="numbered-list" start="11"><li><strong>Kafka 클러스터 (Kafka Cluster)</strong><ul id="feadfdaf-4ee9-4474-a1c4-3810c717bdff" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 서비스 간의 이벤트 스트리밍 및 메시지 큐 기능을 제공합니다.</li></ul><ul id="820b8f45-56ac-47cd-bf5d-891d0b646f7d" class="bulleted-list"><li style="list-style-type:disc"><strong>구성</strong>: AWS MSK, Confluent Kafka, Kafka on Kubernetes</li></ul></li></ol><h3 id="697c3701-6cb9-4440-ab28-6ab270b443bd" class="">트래픽 분산 및 이벤트 처리 구성</h3><h3 id="bf95e7e1-e269-47ae-89d4-7060ea86c189" class="">CQRS (Command Query Responsibility Segregation) 구성</h3><ul id="64d4b495-ef6a-4c7d-a3ea-8e0625a0e9e3" class="bulleted-list"><li style="list-style-type:disc"><strong>설명</strong>: CQRS 패턴은 읽기와 쓰기를 분리하여 서로 다른 모델로 관리합니다. 이를 통해 트래픽을 분산하고 성능을 최적화합니다.</li></ul><ul id="127fe184-63ad-42e2-87a0-60ef1afda0c4" class="bulleted-list"><li style="list-style-type:disc"><strong>구성요소</strong>:<ul id="c3766f84-9de9-40d6-ac52-a1f2692a4051" class="bulleted-list"><li style="list-style-type:circle"><strong>Command Model</strong>: 쓰기 전용 모델로, 데이터 변경 작업을 처리합니다.</li></ul><ul id="fa981a59-b67c-479b-9695-02c32f01c91a" class="bulleted-list"><li style="list-style-type:circle"><strong>Query Model</strong>: 읽기 전용 모델로, 데이터 조회 작업을 처리합니다.</li></ul></li></ul><ul id="ca1ef166-19fe-4765-9c28-d144c775ad96" class="bulleted-list"><li style="list-style-type:disc"><strong>트래픽 분산 효과</strong>:<ul id="a7177b32-19e0-4056-af10-e57cafdd4397" class="bulleted-list"><li style="list-style-type:circle"><strong>쓰기 연산</strong>은 데이터베이스를 통해 수행되고, Kafka를 통해 이벤트를 발행합니다.</li></ul><ul id="f8be779d-1fc8-41f5-be19-486d9e3920fc" class="bulleted-list"><li style="list-style-type:circle"><strong>읽기 연산</strong>은 Redis 캐시에서 데이터를 조회하여 빠른 응답을 제공합니다.</li></ul></li></ul><h3 id="d5365532-3472-4810-8d2c-4625a5d6a1e9" class="">MSA (Microservices Architecture) 구조</h3><ul id="b7a57d97-0913-4782-9b54-0f64ed35be47" class="bulleted-list"><li style="list-style-type:disc"><strong>설명</strong>: 각 기능별로 독립적인 서비스로 구성하여 유연성과 확장성을 높입니다.</li></ul><ul id="d7e95784-e90a-45c1-b377-39489c534fbd" class="bulleted-list"><li style="list-style-type:disc"><strong>구성요소</strong>:<ul id="4d24b1ff-4525-4220-8703-cf4028f9059b" class="bulleted-list"><li style="list-style-type:circle"><strong>서비스 분리</strong>: 사용자, 주문, 상품, 결제 등 각 기능을 독립적인 서비스로 분리합니다.</li></ul><ul id="b964ec70-b094-4df4-b728-ea7ad971e30a" class="bulleted-list"><li style="list-style-type:circle"><strong>API 통신</strong>: 서비스 간의 통신은 REST API 또는 gRPC를 사용합니다.</li></ul></li></ul><ul id="0df98a70-b39a-4a9f-9dd8-e1e1de8ef516" class="bulleted-list"><li style="list-style-type:disc"><strong>장점</strong>:<ul id="da33e059-290f-4bbf-b87c-93184a200847" class="bulleted-list"><li style="list-style-type:circle">각 서비스의 독립적인 배포 및 확장이 가능하여 유연성을 높입니다.</li></ul><ul id="1326b39a-3c78-42d4-9ce6-aab95aa98e37" class="bulleted-list"><li style="list-style-type:circle">서비스 간의 의존성을 최소화하여 유지보수성을 높입니다.</li></ul></li></ul><h3 id="5a987159-afcd-4234-bc71-a2ce7e236323" class="">Kafka를 통한 이벤트 처리</h3><ul id="561ac798-eb8d-4856-9c11-697e3bf66001" class="bulleted-list"><li style="list-style-type:disc"><strong>설명</strong>: Kafka를 사용하여 서비스 간의 이벤트 스트리밍을 처리하고, 비동기식 통신을 구현합니다.</li></ul><ul id="6118cb68-28bd-47d0-9cad-62e309e5bbb6" class="bulleted-list"><li style="list-style-type:disc"><strong>구성요소</strong>:<ul id="06d90613-51d4-4987-b0e1-bd4ffc9dea9c" class="bulleted-list"><li style="list-style-type:circle"><strong>Producer</strong>: 이벤트를 생성하고 Kafka 토픽에 발행합니다.</li></ul><ul id="32bc5729-3e79-4551-b051-ec4d7689053e" class="bulleted-list"><li style="list-style-type:circle"><strong>Consumer</strong>: Kafka 토픽에서 이벤트를 수신하고 처리합니다.</li></ul><ul id="3702a3c0-c6b6-4b61-bfec-25b0788614c1" class="bulleted-list"><li style="list-style-type:circle"><strong>Broker</strong>: Kafka 클러스터에서 메시지를 관리합니다.</li></ul></li></ul><ul id="3e567948-2b82-4b54-bc34-708954e38a83" class="bulleted-list"><li style="list-style-type:disc"><strong>이벤트 처리 흐름</strong>:<ol type="1" id="4f2250f1-7b47-4556-82db-339325f11b86" class="numbered-list" start="1"><li>주문 서비스가 새로운 주문 이벤트를 생성합니다.</li></ol><ol type="1" id="004e8a78-c460-44c5-8409-d27843a57f0c" class="numbered-list" start="2"><li>Kafka Producer가 주문 이벤트를 Kafka 토픽에 발행합니다.</li></ol><ol type="1" id="43e8316e-b680-4f82-9669-69e183fdd737" class="numbered-list" start="3"><li>재고 관리 서비스와 알림 서비스가 Kafka Consumer로서 토픽에서 이벤트를 수신합니다.</li></ol><ol type="1" id="a988255e-559f-453d-baf9-fad6c6037c7b" class="numbered-list" start="4"><li>재고 관리 서비스는 재고를 업데이트하고, 알림 서비스는 사용자가 주문을 확인할 수 있도록 알림을 보냅니다.</li></ol></li></ul><h3 id="b7f12a5c-29aa-47e7-b7ef-d3fefd7fba7b" class="">Redis 캐시 구성</h3><ul id="900f2273-cdf3-475d-beb4-f0fd22675e7f" class="bulleted-list"><li style="list-style-type:disc"><strong>설명</strong>: Redis를 사용하여 자주 조회되는 데이터를 캐싱하고, 데이터베이스의 부하를 줄입니다.</li></ul><ul id="56a43d50-6c3b-47c8-af5b-2c018b51e821" class="bulleted-list"><li style="list-style-type:disc"><strong>구성요소</strong>:<ul id="884f40b0-116c-4276-a141-60e527c4f2a2" class="bulleted-list"><li style="list-style-type:circle"><strong>Session Store</strong>: 사용자 세션을 Redis에 저장하여 세션 관리의 효율성을 높입니다.</li></ul><ul id="07ce98c0-1f6d-49d5-ad4a-70782a169b7e" class="bulleted-list"><li style="list-style-type:circle"><strong>Cache Store</strong>: 자주 조회되는 데이터를 캐싱하여 빠른 응답을 제공합니다.</li></ul></li></ul><ul id="d5b33980-d7bb-491c-9aaa-b3022193d278" class="bulleted-list"><li style="list-style-type:disc"><strong>트래픽 분산 효과</strong>:<ul id="3615720d-d7fe-48db-b587-bcf926f5037e" class="bulleted-list"><li style="list-style-type:circle">자주 사용되는 데이터 (예: 상품 정보, 사용자 정보)를 Redis에 캐싱하여 데이터베이스의 부하를 줄입니다.</li></ul><ul id="599a263f-450b-4d35-beae-9a625190f340" class="bulleted-list"><li style="list-style-type:circle">사용자 세션을 Redis에 저장하여 세션 관리의 효율성을 높입니다.</li></ul></li></ul><h3 id="4804aaea-35be-4735-86cd-ff7ec654700e" class="">클라우드 기반의 전체 아키텍처 다이어그램</h3><h3 id="ae2c4ea0-1047-4f2e-a3f3-e6e5877f3d21" class="">트래픽 흐름 예시</h3><ol type="1" id="c98f0ded-27c6-445f-8868-736c5eb14a2c" class="numbered-list" start="1"><li><strong>사용자가 상품을 검색할 때</strong><ul id="99255d1d-8de9-4c94-983d-8853390daa1b" class="bulleted-list"><li style="list-style-type:disc">사용자가 웹 또는 모바일 앱을 통해 상품 검색을 요청합니다.</li></ul><ul id="7e54b221-b62f-4edd-a980-07733a8e7cab" class="bulleted-list"><li style="list-style-type:disc">프론트엔드에서 API 게이트웨이로 상품 검색 요청을 보냅니다.</li></ul><ul id="a2f716b5-5f9b-4c8d-8b29-cf1cd8248b19" class="bulleted-list"><li style="list-style-type:disc">API 게이트웨이는 상품 서비스로 요청을 라우팅합니다.</li></ul><ul id="1069b6fc-8ea6-4677-b920-bb9bb8e5c97f" class="bulleted-list"><li style="list-style-type:disc">상품 서비스는 Redis 캐시에서 상품 정보를 조회합니다.</li></ul><ul id="a3640551-7518-446a-ab14-b0511afd5bff" class="bulleted-list"><li style="list-style-type:disc">캐시에 데이터가 없는 경우, 데이터베이스에서 조회하여 결과를 Redis에 캐싱합니다.</li></ul><ul id="f6f868c2-462e-473f-a358-d8df73069bd0" class="bulleted-list"><li style="list-style-type:disc">API 게이트웨이는 상품 검색 결과를 프론트엔드에 전달하고, 프론트엔드는 사용자가 볼 수 있도록 결과를 렌더링합니다.</li></ul></li></ol><ol type="1" id="4e36c1df-a119-4d2d-82bd-06ecd986c159" class="numbered-list" start="2"><li><strong>사용자가 주문을 생성할 때</strong><ul id="bdee76b3-5e2b-49ad-bc62-b94122fa2b06" class="bulleted-list"><li style="list-style-type:disc">사용자가 장바구니에 담은 상품을 주문합니다.</li></ul><ul id="fb63994f-c481-4ff8-b507-4d189339ec7c" class="bulleted-list"><li style="list-style-type:disc">프론트엔드에서 API 게이트웨이로 주문 생성 요청을 보냅니다.</li></ul><ul id="49169882-d4ba-46c0-8e9e-d01ab4a6c60a" class="bulleted-list"><li style="list-style-type:disc">API 게이트웨이는 주문 서비스로 요청을 라우팅합니다.</li></ul><ul id="bc10f043-0ba3-43d4-b9c8-2ccc9aa14897" class="bulleted-list"><li style="list-style-type:disc">주문 서비스는 Kafka를 통해 주문 이벤트를 발행합니다.</li></ul><ul id="9e8c309f-a16d-4c82-a44f-d4efde74bf3e" class="bulleted-list"><li style="list-style-type:disc">재고 관리 서비스는 Kafka Consumer로서 주문 이벤트를 수신하고, 재고를 업데이트합니다.</li></ul><ul id="c0e44e8d-ffa2-453f-9aaa-ae7f4c3e8913" class="bulleted-list"><li style="list-style-type:disc">결제 서비스는 주문 이벤트를 수신하고, 결제 프로세스를 진행합니다.</li></ul><ul id="cf77e23d-157a-4936-aab3-a739f982a43e" class="bulleted-list"><li style="list-style-type:disc">결제 서비스가 결제 완료 이벤트를 Kafka에 발행합니다.</li></ul><ul id="e7eb96bd-5e8b-4006-b8bb-fdb8a6f33fa7" class="bulleted-list"><li style="list-style-type:disc">주문 서비스는 결제 완료 이벤트를 수신하고, 주문 상태를 업데이트합니다.</li></ul><ul id="e5dd1512-b09a-4fb0-a9eb-62680d147e2e" class="bulleted-list"><li style="list-style-type:disc">알림 서비스는 주문이 완료되었음을 사용자에게 알립니다.</li></ul></li></ol><ol type="1" id="7f06059d-1cdc-4ce5-b376-b1706d7edccb" class="numbered-list" start="3"><li><strong>사용자가 결제를 완료할 때</strong><ul id="25d07688-167d-4fe0-b586-b81fbd817972" class="bulleted-list"><li style="list-style-type:disc">사용자가 결제 페이지에서 결제를 완료합니다.</li></ul><ul id="88053228-6885-451e-8d49-c8b7d5c9b185" class="bulleted-list"><li style="list-style-type:disc">프론트엔드에서 API 게이트웨이로 결제 요청을 보냅니다.</li></ul><ul id="e0bbecf9-bb0c-40d9-b753-ee81d868c4c9" class="bulleted-list"><li style="list-style-type:disc">API 게이트웨이는 결제 서비스로 요청을 라우팅합니다.</li></ul><ul id="c7157130-023b-40c9-831f-8d56ab0d14e0" class="bulleted-list"><li style="list-style-type:disc">결제 서비스는 Kafka를 통해 결제 완료 이벤트를 발행합니다.</li></ul><ul id="85f51253-b0d2-410f-971c-75a8fd2b6875" class="bulleted-list"><li style="list-style-type:disc">주문 서비스는 Kafka Consumer로서 결제 완료 이벤트를 수신하고, 주문 상태를 업데이트합니다.</li></ul><ul id="4c02297f-38a7-40ac-8e2c-ae107080d6d3" class="bulleted-list"><li style="list-style-type:disc">재고 관리 서비스는 결제 완료 이벤트를 수신하고, 재고를 업데이트합니다.</li></ul></li></ol><ol type="1" id="73b39343-4f09-41bb-968b-a21bb98af103" class="numbered-list" start="4"><li><strong>사용자가 주문 내역을 조회할 때</strong><ul id="0ac11da4-4a81-4392-8e18-126ee84d6989" class="bulleted-list"><li style="list-style-type:disc">사용자가 주문 내역 페이지에서 자신의 주문 내역을 조회합니다.</li></ul><ul id="1c892ed2-0e7d-4673-a833-5716fcff8592" class="bulleted-list"><li style="list-style-type:disc">프론트엔드에서 API 게이트웨이로 주문 내역 조회 요청을 보냅니다.</li></ul><ul id="6d8d8ca5-8999-4690-9a7b-a6115199d0ce" class="bulleted-list"><li style="list-style-type:disc">API 게이트웨이는 주문 서비스로 요청을 라우팅합니다.</li></ul><ul id="5bffe280-4d6d-47ec-b998-7c785b2cc898" class="bulleted-list"><li style="list-style-type:disc">주문 서비스는 Redis 캐시에서 주문 내역을 조회합니다.</li></ul><ul id="0338eb36-4ac1-4450-b352-15303e142296" class="bulleted-list"><li style="list-style-type:disc">캐시에 데이터가 없는 경우, 데이터베이스에서 조회하여 결과를 Redis에 캐싱합니다.</li></ul><ul id="8817d2cf-2be2-41e9-a454-651dfd39375c" class="bulleted-list"><li style="list-style-type:disc">API 게이트웨이는 주문 내역을 프론트엔드에 전달하고, 프론트엔드는 사용자가 볼 수 있도록 결과를 렌더링합니다.</li></ul></li></ol><h3 id="7b2032c9-1f86-4ee4-aae0-921a9770a845" class="">결론</h3><p id="6733ac01-b6ff-4233-8be5-c811ac035db0" class="">이 설계는 클라우드 기반의 퍼블릭/프라이빗 존을 활용하여 보안성과 확장성을 동시에 달성하고, CQRS 패턴과 MSA 구조를 통해 트래픽을 효과적으로 분산시킵니다. Kafka를 통한 이벤트 스트리밍으로 서비스 간의 비동기 통신을 지원하며, Redis 캐시를 사용하여 데이터베이스의 부하를 줄입니다. 이러한 아키텍처를 통해 대규모 트래픽을 처리할 수 있는 온라인 커머스 시스템을 구축할 수 있습니다.</p><p id="0c6f5163-ad1d-48b2-a39a-4f733bd9f279" class="">
</p></details></li></ul><ul id="35f7fbc3-bdb7-405a-8ebf-de3c96089154" class="toggle"><li><details open=""><summary>배민 - 배달의 민족 마이크로서비스 여행기</summary><h2 id="4878cba7-eacb-4bc2-885b-71bebafd8bd8" class=""><strong>MSA</strong></h2><p id="3e334807-c3b5-4d3c-9f62-bf63ea2ba9f4" class=""><strong>Why - 왜 MSA를 도입해야 했을까?</strong></p><p id="041a7dfa-f914-4abd-9c25-a11e59a6c4ca" class="">배달의 민족의 초기 서버는 PHP, Ruby DB의 스펙으로 작성되었습니다.</p><p id="561fab00-345a-4bb5-8a6a-8d559d2aaa4a" class="">사업적 요구사항을 처리하며 점점 비대해진 시스템은 많은 장애를 유발했고, <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#833f9847cb6d46db8ada518c715f22cf">모놀리식 아키텍처</a>였기에 각 도메인의 장애는 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#f5dd156a0df2421b8a7ab7b149a088e3">단일 장애점</a>으로 동작합니다.</p><figure id="30a430f1-c14c-4406-b51e-5219cff0c9df" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F53e4219d-5bc9-4037-917f-9192c032b1ca%2FUntitled.png&amp;blockId=547b0458-a4c1-4b7c-9fec-702c68f9eb9e"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F53e4219d-5bc9-4037-917f-9192c032b1ca%2FUntitled.png&amp;blockId=547b0458-a4c1-4b7c-9fec-702c68f9eb9e"/></a></figure><p id="445fd050-9ecc-4f24-8d46-fa3ad23b7df8" class="">2015년 당시의 모놀리틱 구조 서버.</p><figure id="9a337e1f-9bff-45c1-b343-7394c1b48908" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6b3f2fe7-3e48-4373-8e5e-90c1158adbf2%2FUntitled.png&amp;blockId=cf727cf3-32a8-4684-8dae-ddcdc781cc92"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6b3f2fe7-3e48-4373-8e5e-90c1158adbf2%2FUntitled.png&amp;blockId=cf727cf3-32a8-4684-8dae-ddcdc781cc92"/></a></figure><p id="fc2ab4d8-b4e8-48ab-a9b9-d7d9a91beb80" class="">루비 서버에서 장애가 나면 모든 서비스가 중지된다.</p><p id="c7ab161a-0c13-4dea-b588-e15342c07681" class="">하지만 예컨데 리뷰 작성이 안 된다고 하여 가게 상품 목록을 못 보는 일은 없어야 겠죠. 리뷰와 관련된 코드를 따로 분리하여 별도 서버에서 처리한다면, 리뷰 장애가 발생하더라도 사용자는 상품 주문에는 영향을 받지 않을겁니다.</p><p id="9bf0b14e-bdd7-4bcc-a4e6-3fa796c384d7" class="">위와 같이, <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#7b13ab4ff2e84ae7b540055aa239b4f4">bounded context</a> (도메인의 범주)에 따라 서버를 분리한 패턴을 MSA(Micro Service Architecture)라고 부릅니다.</p><p id="99e8c1b1-5438-417c-a4db-0932081cd240" class="">서버를 장애로부터 구원하기 위해 MSA 아키텍처를 도입하기로 결정합니다.</p><p id="f8e4d136-ec70-4091-bd2e-798cae30e2ac" class="">1.</p><p id="256db58c-67fc-426e-b022-6a8e1094c65a" class="">모놀리식 아키텍처 Monolithic architecture : 한 개의 서버 코드로 모든 비지니스 요구사항을 처리하는 아키텍처</p><p id="e6bb4f35-6a34-49f2-a292-cc84ec8d9998" class="">2.</p><p id="1d41b98e-a724-48d4-bf07-92b80760b6f9" class="">단일 장애점 : 시스템 구성 요소 중, 동작하지 않으면 전체 시스템이 중단되는 요소</p><p id="2d62876e-149f-4223-9f95-59b29ab66a3f" class="">3.</p><p id="b158e8ec-3df5-4951-bab3-90a988f13a96" class="">bounded context : 각각의 도메인의 경계. 자세한 내용은 <a href="http://www.yes24.com/Product/Goods/5312881">eric evans의 Domain-Driven-Design</a> 참고</p><p id="aef15c39-74b0-43fa-a6fd-5e5c914ee344" class=""><strong>How - 어떻게 MSA를 도입했을까?</strong></p><p id="6244f5ce-bec4-4ff9-a4d6-90a37df24190" class="">2016년, 결제 서비스를 기존 서비스로부터 분리합니다. 이 때 가장 잦은 장애 원인이 되던 데이터베이스를 새롭게 구축합니다. 결제 서비스가 다운되어도 전화주문 등은 가능하기에, 전사 장애로 전파되는 것을 막을 수 있습니다.</p><p id="5c671853-6c35-4faa-a083-87d5cd69e49d" class="">데이터베이스의 경우 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#35084c63883441d4b17c6928c856f270">IDC</a>에서 구축되어 있는 Ruby DB로 부터 AWS cloud로 이전하는 과정을 거칩니다. (결제 DB는 법의 제약으로 IDC에 설치)</p><p id="bc82f0b3-da99-43be-8293-bbfa40cf848f" class="">다양한 경로로 들어오는 주문(전화, POS, 고객센터)을 처리하는 주문중계 서비스는 Node js를 활용해 빠르게 분리합니다.</p><figure id="fe543276-82a1-4307-9233-d9817bb2624a" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fbb09324e-8e91-489c-8d21-09c9b47724ce%2FUntitled.png&amp;blockId=5f7e9e3b-031c-4133-890a-fbabe40a64bf"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fbb09324e-8e91-489c-8d21-09c9b47724ce%2FUntitled.png&amp;blockId=5f7e9e3b-031c-4133-890a-fbabe40a64bf"/></a></figure><p id="4261875c-c328-4645-86d8-ae6c3d8a23e8" class="">결제를 마이크로 서비스로 독립</p><figure id="1cccbec0-2bcc-43ab-b5b5-7ef35a30b70b" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F04227b34-6f09-4f7f-a8a9-c550b0543b4f%2FUntitled.png&amp;blockId=b36ecb25-911f-4ab7-9358-643e14cde1a6"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F04227b34-6f09-4f7f-a8a9-c550b0543b4f%2FUntitled.png&amp;blockId=b36ecb25-911f-4ab7-9358-643e14cde1a6"/></a></figure><p id="33a0c46d-149f-4947-a032-98a5b067914d" class="">대용량 트래픽 처리보다 빠른 구현이 중요하여 Node 활용을 통해 분리</p><p id="875b1170-dbbb-4ab5-aeb1-0553dce07929" class="">2017년 이후 트래픽이 가파르게 상승해 하루가 멀다하고 장애가 발생하고, 장애 원인이 되던 서비스들을 하나하나 분리하기 시작합니다.</p><figure id="e2f55c6c-0aa1-4c76-81b1-e4fb61047807" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F42fe5e2d-4bd3-4a85-8618-30f19f717c0f%2FUntitled.png&amp;blockId=1d75daeb-76f7-46d4-80f4-fd569392c4e6"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F42fe5e2d-4bd3-4a85-8618-30f19f717c0f%2FUntitled.png&amp;blockId=1d75daeb-76f7-46d4-80f4-fd569392c4e6"/></a></figure><p id="125c6bd5-3613-4eb6-b9b3-469eccdcd901" class="">검색, 메뉴, 정산 시스템 독립</p><figure id="e32e9ecd-6afc-4d8e-9466-902352532146" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F916367f3-be26-4239-a5d4-b7dd5aba20ab%2FUntitled.png&amp;blockId=7dea2cba-da47-43f9-b6c9-624023b183de"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F916367f3-be26-4239-a5d4-b7dd5aba20ab%2FUntitled.png&amp;blockId=7dea2cba-da47-43f9-b6c9-624023b183de"/></a></figure><p id="867d8a14-051d-47ac-babb-b02cfdcda9b7" class="">쿠폰, 주문, 포인트 시스템 독립</p><p id="ce0c17b9-e66f-4532-acb2-ec8569eb4791" class="">함부로 이전할 수 없던 레거시 시스템들이 남았습니다.</p><p id="558cba5d-c026-4b4c-85ea-46386725a9e1" class="">1.</p><p id="49d9445f-5707-4687-b48a-3af094dc5856" class="">엮어있는 시스템이 많아 조금만 잘못되어도 전사 장애로 이어짐</p><p id="6fcdde16-015f-4226-94ad-1a59f7a3343b" class="">2.</p><p id="45de0c00-1d0c-4bec-9d43-d12007744ec5" class="">기존 데이터베이스 테이블 하나 하나가 수 백개의 칼럼으로 이루어진 복잡도</p><p id="08f5b1d2-1062-4f07-9cd1-0bc106617afe" class="">개발팀에선 레거시 시스템의 이전을 위해 최소 3개월의 시간을 필요했고, 레거시 이전의 중요성을 인정받아 18년 12월, <strong>프로젝트 먼데이</strong>라는 이름의 레거시 개편 프로젝트로 이어집니다.</p><p id="6b0df0a3-98bb-431d-8784-fb8cce7de6ad" class="">우아한형제들은 프로젝트 먼데이 기간동안 장애 전파를 막고 다수 트래픽의 고성능 조회를 위해서 이벤트 기반 아키텍처와 CQRS 아키텍처를 도입합니다.</p><p id="ceec230b-4273-40b0-8326-5232d43aa9ed" class="">이벤트 기반과 CQRS는 하단에서 이어 다루겠습니다.</p><figure id="1e77cf4c-ac22-4df0-a6a9-4e19165a09ac" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F07a24a49-e084-441d-9473-8484a4140620%2FUntitled.png&amp;blockId=5fc29f85-8baf-4a9e-bd88-853f86ab1511"><img style="width:432px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F07a24a49-e084-441d-9473-8484a4140620%2FUntitled.png&amp;blockId=5fc29f85-8baf-4a9e-bd88-853f86ab1511"/></a></figure><p id="7593fe91-395b-4298-ac26-ef2225fc2da1" class="">레거시 시스템을 제거하고 MSA 이전을 마친 모습</p><p id="7c9f3232-969e-4e24-8e87-3a457f7f8a3e" class="">1.</p><p id="80be528b-44c5-4cfe-9b33-88ac96d35980" class="">IDC (Internet Data Center) : 서버 컴퓨터와 네트워크를 제공하는 시설.</p><p id="55df220f-0225-4a75-8adf-f640372507d9" class=""><strong>What - MSA를 도입한 결과는?</strong></p><p id="933cf462-d2f9-4bb4-b468-ab3768acc55e" class="">MSA의 도입 결과로</p><p id="096da2f9-2382-448d-8022-cbd0c917334e" class="">1.시스템 일부 장애에 대한 저항력을 키워 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#71d61ad370024c7fa61e333c7c7bed1a">시스템 신뢰성</a>를 높이고,</p><p id="ba816961-f897-4644-9a76-a9ef1e5e50ed" class="">2.리뷰 작성 이벤트, 쿠폰 이벤트 등 각 부문별에 증가할 트래픽에 맞서 자유로운 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#bb8f375e751142d7858edbda18eee310">스케일링</a>이 가능해졌습니다.</p><p id="9f3ed4e7-8e2c-4bb3-ac42-f13191850b3c" class="">
</p><p id="7366f505-76b7-475e-99dd-d5164f30828f" class="">1.시스템 신뢰성 : 시스템이 정상 요청으로부터 정상 응답을 보낼 수 있는 정도를 나타냄. <a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&amp;ejkGb=KOR&amp;barcode=9791188621088">사이트 신뢰성 엔지니어링</a> 참고</p><p id="9acfa557-033c-4f19-9fbb-f8ee832fd741" class="">2.스케일링 Scaling : 트래픽 증가로 서버의 부하가 커졌을 때, 서버를 증설하는 것. 양을 늘리는 스케일 아웃과 성능을 높이는 스케일 업이 있다.</p><p id="8466b3bd-47bd-465f-8cbf-30d8a0514157" class="">
</p><p id="517053b1-a120-4613-90d9-a9cdd44bf90d" class=""><strong>이벤트 기반 아키텍처</strong></p><p id="608a324b-f029-4b37-97ca-12b741e64528" class=""><strong>why - REST api 중심에서 이벤트 중심으로 바꾼 이유는?</strong></p><p id="5f3f1464-fedd-4e67-a977-969b6718cfa1" class="">MSA 아키텍처를 적용하면 서버 수가 늘어나고, 서버간의 소통을 위한 Rest API 호출이 빈번해집니다. 해당 API에서 장애가 나게 되면 어떻게 될까요?</p><figure id="1cc974e1-4bc3-44a3-bb77-b9598b64b8ff" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F99fb413b-ebf9-4ce8-a480-af97ed318cba%2FUntitled.png&amp;blockId=10504440-0401-4a62-8bed-91520cbdb134"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F99fb413b-ebf9-4ce8-a480-af97ed318cba%2FUntitled.png&amp;blockId=10504440-0401-4a62-8bed-91520cbdb134"/></a></figure><p id="a96691e7-db08-46e4-93d7-9dce03c0900a" class="">각각의 화살표는 API 요청이다.</p><figure id="f1a92840-c6fb-475c-9ce4-7b87cb0b6dbd" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F02f7dd56-4e10-48ea-acda-d86d64b7b5fc%2FUntitled.png&amp;blockId=686a7252-d5a7-4dcc-849e-2e54386742da"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F02f7dd56-4e10-48ea-acda-d86d64b7b5fc%2FUntitled.png&amp;blockId=686a7252-d5a7-4dcc-849e-2e54386742da"/></a></figure><p id="c0f5ea13-155e-4f16-b7f2-3fc6cd5cb951" class="">이 중 리뷰시스템에 장애가 난다면?</p><p id="210cee6e-61d3-4d78-a9d9-bfb8762b88f3" class="">예를들어 리뷰 시스템은  리뷰를 작성해 달라는 푸쉬 알림을 위해 주문 완료 정보가 필요합니다. 이는 주문 시스템에서 리뷰 시스템으로 전달해주어야 하는데, 리뷰 시스템 측 API에서 timeout 또는 500에러가 발생하는 상황이 있을 수 있습니다.</p><p id="a12de264-9d89-4ea2-88e6-eb05534b6bea" class="">장애의 전파를 막기위해 도입한 MSA인데, 해당 API 요청이 실패함으로써 주문시스템도 어떤 식으로든 영향을 받게 됩니다.</p><p id="588487a0-5f49-4ddd-a747-2199d11ee6f0" class="">또한 주문 시스템을 개발하는 개발자는 리뷰 시스템, 레거시 DB, 라이더스 시스템에 대해 이해하고 주문 서버 소스 코드에 변경이 있을 때마다 이에 대한 여파를 고민해야 합니다.</p><p id="2b548113-4ea8-4b6a-a302-eca0a19153a4" class="">해당 난점을 극복하기 위해 서버간의 메시지를 전달하는 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#2e4dcabcbdc1468a9fe62ce98a3390bd">미들웨어</a>인 메시징 큐를 도입하고, 각각의 서버는 이벤트를 통해 소통하는 이벤트 기반 아키텍처를 구성합니다.</p><p id="79c3dbac-6599-4a02-8841-05dfd6867adf" class="">1.</p><p id="ea3ce157-6e42-4d15-8d84-343e125cee4d" class="">미들웨어 : 서로 다른 어플리케이션이 서로 통신하는데 사용되는 소프트웨어.</p><p id="c780d501-a943-441e-a3cf-a69c78dceb50" class=""><strong>how - 어떻게 이벤트 기반 아키텍처를 구현할까?</strong></p><p id="41add98b-08b9-4819-93e3-11ade9209fdf" class="">다른 어플리케이션에서 필요한 주문 정보를, 이벤트라는 이름으로 정의합니다.</p><p id="2145ec70-0df1-4d8d-bf80-1c3b6698e0d0" class="">이후 메시징 큐에 이벤트를 발행하면, 필요한 어플리케이션에서 해당 이벤트를 <strong>구독</strong>해갑니다. (pub-sub 패턴)</p><p id="93bd2352-ac17-4258-a46b-0a681db1732f" class="">pub-sub 기반의 메시징 큐에는 Apache Kafka 등 다양한 종류가 있으나, 당시 개발팀에 <a href="https://aws.amazon.com/ko/sqs/">AWS SNS</a>(Simple Notification Service)와 <a href="https://aws.amazon.com/ko/sns/?whats-new-cards.sort-by=item.additionalFields.postDateTime&amp;whats-new-cards.sort-order=desc">AWS SQS</a>(Simple Queue Service)에 대한 이해도가 있었으므로 발행자 역할로SNS, 구독자 역할로 SQS를 활용합니다.</p><figure id="862049f6-92fc-4977-9a26-4c39cb35fb16" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F796b7885-6b63-43e8-b76a-2c3724169ab7%2FUntitled.png&amp;blockId=8ea37fe9-82ab-4dca-af80-a8d7b5c82905"><img style="width:528px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F796b7885-6b63-43e8-b76a-2c3724169ab7%2FUntitled.png&amp;blockId=8ea37fe9-82ab-4dca-af80-a8d7b5c82905"/></a></figure><p id="87753c16-6526-4a8f-a624-574e203cc235" class="">이벤트 기반 아키텍처를 선택한 후</p><p id="abe61f5e-8dcf-4a1d-997e-6b7a1117dd27" class="">해당 구조에서 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#30fc0e0ce15c4235a1f90f347da324a6">why</a>에서 들었던 주문 시스템 예시를 다시 들어보겠습니다. 주문이 생성된다면 SNS에 해당 이벤트를 <strong>발행</strong>합니다. 리뷰 시스템은 SQS를 활용해 주문시스템이 이벤트를 발행하는 SNS를 <strong>구독</strong>하고 있다가, 이벤트를 수신하면 리뷰 알림을 전달해주는 방식으로 활용할 수 있습니다.</p><p id="4be88602-ed83-4813-b127-91c51fc7232e" class="">이 아키텍처에는 여러가지 장점이 있습니다.</p><p id="deb58953-aa98-4a0c-86f9-ff46c2275c5f" class="">1.설사 리뷰 시스템이 다운 되더라도, 향후 복구되었을 때 SQS에 있는 이벤트를 재수신하여 처리할 수 있습니다.</p><p id="8d5f8ec4-e09a-4dfb-8c73-15594cbd9ccc" class="">2.주문 시스템에서 주문 생성이 실패하는 문제가 발생하면, 문제가 되었던 부분을 찾아 이벤트를 재발행하는 것으로 해소됩니다.</p><p id="7dcdf216-2e4b-4950-a2b0-0fc794858dd4" class="">3.주문 시스템이 더이상 다른 시스템에 대해 자세히 알 필요가 없어집니다. 주문 이벤트를 발행하고 나면, 그 이벤트로 각 도메인에 특화된 비즈니스 로직을 수행하는 건 각 시스템의 역할로 맡겨집니다.</p><p id="1ca1eb8a-87a4-4ef0-a7f8-1c5e19c1f447" class="">이 과정에서 생긴 여러가지 노하우는 다음과 같습니다.</p><figure id="f9a8a682-d46a-427f-a808-b37b81382494" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F511f54db-05a0-463f-99cb-3923193df28c%2FUntitled.png&amp;blockId=9cf8afcd-e5fa-4ff5-8dd8-614a6b01f59b"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F511f54db-05a0-463f-99cb-3923193df28c%2FUntitled.png&amp;blockId=9cf8afcd-e5fa-4ff5-8dd8-614a6b01f59b"/></a></figure><figure id="3c71aff1-3976-4f19-9471-31680613f3da" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc23c58b7-87ab-493d-90e9-81736b30f432%2FUntitled.png&amp;blockId=bc41cae2-1ae9-480b-a924-1bb3bcce1523"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc23c58b7-87ab-493d-90e9-81736b30f432%2FUntitled.png&amp;blockId=bc41cae2-1ae9-480b-a924-1bb3bcce1523"/></a></figure><p id="e3548354-f6a0-4f54-8df6-1ff45e48cc79" class="">1.</p><p id="3b33199c-3746-4e10-b58f-475936dc1b36" class="">메시지의 전달이 지연되면, 각 서버간의 데이터가 동기화되어 있지 않을 수 있습니다. 이런 데이터의 정합성 문제를 다루기 위해 Eventually Consistency, 최종적 일관성이라는 개념을 활용합니다. 데이터는 이벤트가 다 전달되고 나면 최종적으로 완전한 상태가 된다는 개념으로, 이벤트의 전달이 수백 ms에서 늦어도 3초 안에는 이루어진다는 경험적 토대를 갖추고 있습니다.</p><p id="9a55a6b9-93ed-4067-9d40-05f43c9a3670" class="">a.</p><p id="f67d92d7-20cc-4210-9951-15462c38da92" class="">만약 문제가 발생하면 해당 시스템이 문제되는 이벤트를 재발행하는 방식으로 오류를 복구할 수 있습니다.</p><p id="f8e13954-915c-4251-a9b6-3131f73a76be" class="">2.</p><p id="cffe337b-9001-465d-bba0-cdced618a0cf" class="">Zero-Payload 방식은 이벤트에 변경사항에 대한 내용이 모두 들어있는게 아니라 이벤트의 종류 와 키 값 만 전달하는 방식입니다.</p><p id="fc1d0408-5d35-4903-ba82-46fb8f27a08a" class="">a.</p><p id="b26e7848-5f17-4b64-8809-565bbc24ba5a" class="">이는 두 가지 이유 때문입니다.</p><p id="5e9554b7-6b0f-4470-87a0-b9bd81de72d4" class="">i.</p><p id="9a68e116-827a-406a-a29d-95b5544f5b60" class="">첫번째는 이벤트의 순서를 고려하지 않기 위함입니다. 이벤트에 모든 변경정보를 담게 되면 서버에 정보를 재조회할 필요가 없지만, 그러면 이벤트의 순서가 중요해집니다. 이를 보정하는 것이 불가능한 건 아니지만, 시스템 복잡도를 줄이기 위해 API를 재조회하는 방식을 활용합니다.</p><p id="cf1d2a32-5704-4716-94f1-bb91c424351a" class="">ii.</p><p id="686ccbcf-7db4-4f11-9e45-fbcb9092e5f8" class="">두번째는 각 시스템마다 원하는 데이터가 다르기  때문입니다. 모든 정보를 이벤트에 담는 것은 네트워크 부하를 유발하기에, 모든 데이터를 담기보단 각 서비스가 동일 이벤트로 다른 API를 활용할 수 있도록 각 서비스에 특화된 API를 제공합니다.</p><p id="c451afdb-7ea7-4756-b098-824e201e3008" class="">b.</p><p id="b6505a1d-fad5-4639-a33c-708b93c8f908" class=""><strong>구독</strong>하고 있는 서비스에선 이후 이벤트와 관련된 추가 정보가 필요하다면, 해당 키 값으로 해당 서비스가 필요한 정보를 담고 있는 API를 요청합니다.</p><p id="015da91d-6224-4130-a73e-c8a4de3c992e" class="">3.</p><p id="49aa32c9-17af-46a7-a358-2062b0a28321" class="">최소 데이터 보관 원칙은 각 서비스에서 타 도메인 정보가 필요한 경우, 필요한 최소한의 정보만 저장하는 것입니다. 이를 통해 내 서비스에서 필요하지 않은 타 도메인의 변경사항에 민감하게 반응할 필요 없어집니다.</p><p id="c6760e20-f351-4357-a626-a5e71823a319" class=""><strong>what - 이벤트 중심 아키텍처로 전환한 결과는?</strong></p><p id="2fa77fa5-7eb9-4f87-9de2-692fbc206f32" class="">이벤트 중심 아키텍처로의 전환 후</p><p id="2e3098c2-63df-409c-928d-2109985974c2" class="">1.</p><p id="dfebfd22-4997-4221-b9b1-a84449a676e8" class="">각 서비스간의 의존성이 낮아지고</p><p id="97295ae7-dbee-4580-81c4-6f62dd310aae" class="">2.</p><p id="071f0c67-f883-4a7f-92b6-a18dc7a13413" class="">각 서비스가 다운되는 상황에서 이벤트를 통해 쉽게 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#8df8a130a8aa466c98816343811c08a3">페일 오버</a>할 수 있습니다.</p><p id="6ddd6fb0-ccda-4f51-844c-94055643e6b5" class="">1.</p><p id="1b190e1e-17c4-44f5-9e84-737ef0f0c96c" class="">페일 오버 fail over : 장애 대비 기능을 의미합니다. 페일 오버의 예로 장애 발생시 예비 시스템으로 전환, 장애 내용에 대한 후처리 등이 있습니다.</p><p id="17795df5-0a2d-464a-921b-0f206b5aa971" class=""><strong>CQRS (명령과 조회 분리)</strong></p><p id="e6003aef-1f53-47a5-9071-313afdcb1b07" class=""><strong>why - 왜 명령과 조회를 분리해야 했을까?</strong></p><p id="13fff80b-7615-4c0a-bd9f-431c60ab35bb" class=""><a href="https://docs.microsoft.com/ko-kr/azure/architecture/patterns/cqrs">CQRS 패턴</a>은 데이터베이스에 대한 읽기와 수정, 삭제 작업은 명령 (command)으로, 조회 작업은 조회(query)로 정의하고 두 작업을 <strong>분리</strong>하는 패턴을 의미합니다. (Command and Query Responsiblillity Segregation)</p><p id="7364c385-807d-4cd7-a7c1-51127d3b187e" class=""><strong>분리</strong>라는 말의 의미는<strong> </strong>데이터베이스 내부에서 동일한 도메인에 대해 조회용 모델과 명령용 모델을 분리하는 것을 의미합니다. 이 아키텍처에서 조회 요청은 조회용 모델을 통해, 명령 요청은 명령용 모델을 통해 수행합니다.</p><figure id="f6c0e8e3-ce84-4b01-8755-8ea4e3ca7001" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F666cbbae-3e48-4cad-ab98-76b6f275f862%2FUntitled.png&amp;blockId=a8d71987-c9fc-434b-9ed7-48cc7df04440"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F666cbbae-3e48-4cad-ab98-76b6f275f862%2FUntitled.png&amp;blockId=a8d71987-c9fc-434b-9ed7-48cc7df04440"/></a></figure><p id="9e51d4c1-0665-4678-9f66-d03c14bc8ad1" class="">기존의 데이터베이스 접근 모델. 조회와 명령에 대한 구분 없이 동일한 데이터베이스에 질의한다.</p><figure id="29921be5-a5a4-44d6-b398-e32d135f6508" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff71cc44f-ea19-4b1a-9fad-2dd24d9d0b7c%2FUntitled.png&amp;blockId=f1cc4c09-0bae-4510-b922-645b56a8f25e"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff71cc44f-ea19-4b1a-9fad-2dd24d9d0b7c%2FUntitled.png&amp;blockId=f1cc4c09-0bae-4510-b922-645b56a8f25e"/></a></figure><p id="6935d0ac-e667-4765-a479-0697e84cd70b" class="">CQRS 적용 모델. 명령은 write model 에, 조회는 read model을 통해 수행한다.</p><p id="8643c9e3-34cb-4060-8278-22a879d2cd2c" class="">이 작업은 2018년 배달의민족에서 가장 큰 장애원인 중 하나였던 가게상세 시스템에 필요했습니다. 트래픽이 상승하며 기존 PHP 코드로 감당할 수 없는 부하가 들어온 건데요, 이는 조회시 DB에서 필요한 정보를 모두 조회하기 때문에 과도한 트래픽을 받으면 장애가 발생할 확률이 높았습니다.</p><figure id="2f650bd9-1c1b-49b0-8e89-0c15a3da7820" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe0aa6a70-4fb1-4f3b-a537-9f0ca5306721%2FUntitled.png&amp;blockId=492fe976-ae34-46a7-a958-7af73c027514"><img style="width:432px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe0aa6a70-4fb1-4f3b-a537-9f0ca5306721%2FUntitled.png&amp;blockId=492fe976-ae34-46a7-a958-7af73c027514"/></a></figure><p id="39134e61-3e8d-45e9-b033-7ce15cf67f40" class="">가게 상세 초기 모델. PHP로부터 상세 정보 요청을 받으면, 필요한 데이터를 모두 조회해 응답한다.</p><p id="feb72233-4386-4fd1-bed3-377be883392b" class="">초기엔 DB 서버에 대한 스케일업(성능 향상)으로 대응했지만, 스케일업엔 물리적으로도 소프트웨어 적으로도 한계가 있습니다.</p><p id="238b939c-b441-403e-b2af-435dae31f4d5" class="">이 상황을 해결하기 위해 CQRS 아키텍처를 도입합니다.</p><p id="cabdc775-bfe7-4f6c-8c6d-efc9e24112e2" class=""><strong>how - CQRS를 도입하기</strong></p><p id="baef532d-08e5-4fb9-a439-65c85a3286ba" class="">처음 진행한 것은 대용량 트래픽 처리에 적합한 JAVA 도입과, 리드용 모델로 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#2def0f7803b94e028a0d2051eca17eeb">AWS 다이나모 DB</a>를 적용한 것입니다.</p><figure id="5257fe16-ded6-46b3-8f4c-fc1ca576dedf" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F9e40beac-19a9-4baf-a354-82bea26c12ee%2FUntitled.png&amp;blockId=465a47b4-81b8-4c68-8ec9-945420130856"><img style="width:432px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F9e40beac-19a9-4baf-a354-82bea26c12ee%2FUntitled.png&amp;blockId=465a47b4-81b8-4c68-8ec9-945420130856"/></a></figure><p id="42ea8fdd-6596-45f8-9994-a871ed2373a3" class="">가게상세 CQRS 초기 모델</p><p id="b9bcd229-5d7e-4279-9527-ed77068bc5f9" class="">1분 ~ 5분 간격의 스프링 배치 프로그램을 돌립니다. 이 때 작업은 기존 데이터베이스로부터 가게에 대한 ID를 key로 하여 다이나모 DB에 프론트 노출에 필요한 정보를 모두 저장하는 것입니다. 이후 가게에 대한 조회 요청이 들어오면 더이상 기존 DB에서 조회하지 않고 가게 ID를 가지고 다이나모 DB에서 조회합니다.</p><p id="8ff54229-e5dc-4040-9057-e354f438d2ff" class="">이 방식은 더 이상 기존 DB가 조회요청을 처리하지 않으므로 조회 트래픽이 증가한다고 하여 장애가 발생하지 않습니다.</p><p id="33840831-4857-468b-b11d-ce298f709160" class="">하지만 이 방식의 아래와 같은 문제가 있어 완전하지 않습니다.</p><p id="2ac18187-b97e-43de-8638-baa276bc450b" class="">1.배치의 작동 주기가 1분 ~ 5분이므로 데이터의 동기화가 늦습니다.</p><p id="df6144c5-6165-4d80-a1d3-c5e29289853a" class="">2.요구사항이 변경되면 배치에서 다이나모 DB로 업데이트 하는 쿼리를 일일이 수정해야 합니다.</p><p id="dc2f1427-69cc-4e1d-8bdc-a07d01745af6" class="">위 문제를 극복하기 위해 먼데이 프로젝트에선 MSA와 이벤트 중심 기반의 설계로 전환하는 것에 더해 위 한계를 극복한 CQRS를 적용하는 과제를 포함합니다.</p><p id="dad6ed91-1413-42ef-8f95-712476ef9596" class="">앞서 MSA에서의 주요한 도입 이유 중 하나를 장애의 전파를 방지하는 것이라 적었는데요, CQRS 아키텍처도 이와 밀접한 연관이 있습니다.</p><p id="8b4698a3-ea3e-48ba-b043-9ba5bd351698" class="">아래와 같은 MSA 아키텍처를 완성하였습니다. 노란 화살표는 조회 API를, 빨간 화살표는 명령 API를 의미합니다.</p><figure id="b81cc357-1703-4e1d-8625-1d71dc51afbe" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2d896a49-0586-4892-9b40-7da9194e176c%2FUntitled.png&amp;blockId=0b3cea4e-681a-4d5a-b1e4-50a7c97b2ab6"><img style="width:480px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2d896a49-0586-4892-9b40-7da9194e176c%2FUntitled.png&amp;blockId=0b3cea4e-681a-4d5a-b1e4-50a7c97b2ab6"/></a></figure><p id="81f5ecc0-33c7-4057-bbe3-7068557ac280" class="">서로 다른 서비스를 조회하는 MSA구조</p><p id="ba4be3c1-7333-4df1-820c-a7a6668730d5" class="">위 구조는 두 가지 상황에 취약합니다.</p><ul id="7d8a2bd4-a2b6-4902-9298-b3e7bfe8697a" class="bulleted-list"><li style="list-style-type:disc"></li></ul><p id="4d8e8b0d-f52d-4b7b-aacd-abb733c8baa8" class="">원장 데이터를 포함한 서비스가 장애가 생긴 경우, 앞단 서비스로 장애가 전파됩니다.</p><figure id="785be568-34c6-4986-bee0-bb0f0847935f" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb49c2484-738d-47df-b3d7-0b5c76ce6151%2FUntitled.png&amp;blockId=47a0e06f-e016-4465-bf64-03bf506c6a59"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb49c2484-738d-47df-b3d7-0b5c76ce6151%2FUntitled.png&amp;blockId=47a0e06f-e016-4465-bf64-03bf506c6a59"/></a></figure><p id="6dd48d6f-73e2-4c29-b09a-f263a40bc9ff" class="">광고 시스템에 장애가 생기면 광고 리스팅, 가게노출이 장애가 난다.</p><figure id="69998159-7713-4590-841e-086020def016" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6442af48-1ed5-414a-85d6-3c39dad7e08e%2FUntitled.png&amp;blockId=97a7a7d5-22a9-477b-9df1-0935d3369c04"><img style="width:331px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6442af48-1ed5-414a-85d6-3c39dad7e08e%2FUntitled.png&amp;blockId=97a7a7d5-22a9-477b-9df1-0935d3369c04"/></a></figure><p id="e2437554-1636-4247-8e7e-cdcea8e5ea63" class="">가게/업주 시스템에 장애가 생기면 바로결제 서비스, 광고 리스팅, 가게 노출서비스에 장애가 난다.</p><ul id="f0705731-e155-4fcd-9d98-ea8381fa8c67" class="bulleted-list"><li style="list-style-type:disc"></li></ul><p id="c9d499b6-b9a8-4a83-bce8-a5dc364fbf8c" class="">큰 트래픽을 받으면, 뒷단의 서비스들로 트래픽이 전파됩니다.</p><figure id="8984d5ab-25ea-433c-a979-17e8e2cc201a" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F035b8319-aba0-4908-abe6-ac655c7fa316%2FUntitled.png&amp;blockId=de416582-d5b3-4b1d-8dcf-ca8541fee072"><img style="width:480px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F035b8319-aba0-4908-abe6-ac655c7fa316%2FUntitled.png&amp;blockId=de416582-d5b3-4b1d-8dcf-ca8541fee072"/></a></figure><p id="45183aca-470e-40b9-b982-a9ccdbf2d291" class="">초당 15000회의 조회를 받으면, 광고 및 가게/업주 시스템까지 동일한 트래픽을 받게 된다.</p><p id="95e6cf37-6c8e-41d3-8014-34adfc5e880c" class="">먼데이 프로젝트의 주요 목표 중 하나는 <strong>가게, 광고 같은 내부 시스템이나 DB에 장애가 발생해도 고객 서비스를 유지하고 주문도 가능해야 한다</strong>는 점이었습니다.</p><p id="4af412a1-60ad-4bce-98ab-580cb2d25031" class="">이를 위해 전사 시스템을 Command 시스템과 Query 시스템으로 분리하는 CQRS 아키텍처 적용를 적용하기로 의사결정합니다.</p><p id="93813055-fa1e-457d-b66a-e0aac359673d" class="">앞서 설명한 가게상세의 시스템도 <strong>DB 장애와 사용자 서비스를 격리</strong>하는 효과가 있었지만, 1분 ~ 5분의 동기화 문제점이 있었죠. 이를 해결하기 위해 이벤트 중심 아키텍처를 활용합니다.</p><figure id="c8f2b749-9a43-473f-a0a6-a53b6009c42f" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb512c346-b73f-4e9b-be7c-559793b6b9bd%2FUntitled.png&amp;blockId=1a0f729f-74a1-4be5-8d39-66507ead141c"><img style="width:480px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb512c346-b73f-4e9b-be7c-559793b6b9bd%2FUntitled.png&amp;blockId=1a0f729f-74a1-4be5-8d39-66507ead141c"/></a></figure><p id="6dccea90-7b06-42a7-a2be-ffeaed1b56a8" class="">이벤트 중심 아키텍처를 활용한 CQRS 아키텍처</p><p id="e482bc21-d46a-4cef-b32a-eea8446d0d9a" class="">이제 사용자 서비스는 더이상 광고 및 가게/업주 서비스를 직접 호출하지 않습니다. 사용자 서비스에서 직접 조회용 DB를 만들어 고객의 요청에 응답합니다.</p><p id="872bedd1-e22c-44d5-b84f-3a8b78db0747" class="">이제 광고와 가게/업주 DB는 명령형 시스템(어드민 페이지)에서만 호출합니다.</p><p id="4f63b4db-10d3-4a04-8127-32a7084ab317" class="">명령형 시스템에 변경 사항이 생기면, 조회용 시스템이 이를 수신할 수 있도록 이벤트를 발행합니다.</p><figure id="3b7c59f7-d7d3-4b51-b82b-da89cc82b3fd" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff8c0481a-de31-4c70-939c-bde274ddf449%2FUntitled.png&amp;blockId=adc9a05b-d490-4843-ba1e-e09fde73f393"><img style="width:528px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff8c0481a-de31-4c70-939c-bde274ddf449%2FUntitled.png&amp;blockId=adc9a05b-d490-4843-ba1e-e09fde73f393"/></a></figure><p id="e8d2d664-29c4-4887-9b36-7f57e27dcf12" class="">가게/업주 변경 데이터가 필요한 서비스들은 가게/업주 이벤트를 구독하면 된다.</p><p id="56b7f37b-8c5c-4dd0-b8cc-233f8e8fc090" class="">이벤트가 발행되면, 각각의 서비스는 데이터를 수신해 서비스 자체 DB를 업데이트 합니다.</p><p id="c1d82e05-10a9-4bdd-961b-a384fadf5417" class="">이 때 어떤 DB를 활용할지는 각각의 서비스에 특화하여 사용할 수 있습니다. 데이터의 엄밀성이 중요한 가게/업주 시스템은 RDB를, 검색이 포함된 광고리스팅 서비스에선 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#f78c95c979254a318d9fbd0ca52f9c9d">ES</a>를, 가게 노출엔 <a href="https://sihyung92.oopy.io/architecture/woowa-msa-travel#626120634d624584b861c7caece59c5d">Redis</a>나 다이나모 DB를 활용하는 자율성도 얻을 수 있습니다.</p><figure id="62012c87-d523-4668-87c8-a68dad95b7ef" class="image"><a href="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0e3ce94e-a603-4044-b2a9-0ed5cc88a35c%2FUntitled.png&amp;blockId=5df2a40a-b867-43b2-bf4f-d25ab21cd48e"><img style="width:528px" src="https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0e3ce94e-a603-4044-b2a9-0ed5cc88a35c%2FUntitled.png&amp;blockId=5df2a40a-b867-43b2-bf4f-d25ab21cd48e"/></a></figure><p id="bf2e39c8-ab72-486f-b205-5311da5c72be" class="">데이터 동기화에도 장애 상황이 발생할 수 있습니다.</p><p id="3120a19c-b5b1-4557-ae9b-bd0937a0246d" class="">1.</p><p id="7c4ea771-8ec8-4e2f-b54d-38b41859f31d" class="">장애의 주체가 이벤트를 발행하는 서비스라면 문제가 생긴 이벤트를 재발행 해주면 됩니다.</p><p id="a62f7f44-2a97-4067-b7e0-cf4a7c5a3ccf" class="">2.</p><p id="b3d88600-a8ba-4575-b735-e6dc791a68d2" class="">간혹 이벤트를 전달해주는 큐 자체에 장애(SNS, SQS)가 생길 때가 있습니다. 상황을 대비해 최근 변경사항을 메시지 큐를 대신해 전달할 수 있는 Import API를 구현합니다.</p><p id="ebbf748a-5150-44fc-a019-d28c6f94a279" class="">1.</p><p id="06d1de1a-efce-44f3-a479-46d860a4dcc6" class=""><a href="https://aws.amazon.com/ko/dynamodb/?trk=048f3e6b-4524-4a68-b4dd-337aeabc08f8&amp;sc_channel=ps&amp;sc_campaign=acquisition&amp;sc_medium=ACQ-P|PS-GO|Brand|Desktop|SU|Database|DynamoDB|KR|EN|Text&amp;s_kwcid=AL!4422!3!489215167672!e!!g!!amazon%20dynamodb&amp;ef_id=CjwKCAjws8yUBhA1EiwAi_tpEW4W9ivoy6pVA3z5fn8wrzR0AmPBMk_ykbUtHc7Xa_XDm1Zrut9ExRoCANwQAvD_BwE:G:s&amp;s_kwcid=AL!4422!3!489215167672!e!!g!!amazon%20dynamodb">AWS 다이나모 DB</a> : key-value 형태로 값을 저장하는 NoSql 데이터베이스. 10밀리초 미만 기반의 응답과 무제한에 가까운 데이터 저장이 가능한 것이 특징이다.</p><p id="1fdb24f0-20aa-44ed-a0dc-67f6a30a1a99" class="">2.</p><p id="450ac1a1-1864-4714-9c35-fb3d261c2b8f" class="">ES, elastic search : 문자열 검색에 특화된 오픈소스 NoSQL 데이터베이스.</p><p id="7936450d-fafd-47ea-bac8-b2986acfb25c" class="">3.</p><p id="687dc7f2-b682-4076-ac00-4ce6fc899448" class="">Redis : key-value 형식의 메모리 데이터베이스. 하드디스크가 아닌 메모리에 데이터를 저장하므로 데이터 조회가 빠르다는 특징이 있다.</p><p id="dfed1689-2089-47e4-8699-834d52b40e4a" class=""><strong>what - CQRS 적용으로 얻은 것</strong></p><p id="34691f76-c66a-40e3-8b96-82d649590c3e" class="">CQRS의 적용을 통해 대량 트래픽이 발생하는 시스템에서 조회와 명령간의 불균형을 해소할 수 있었습니다.</p><p id="bc02800f-d708-4ff6-a967-2990c3465c7b" class="">이를 통해 성능이 중요한 외부 시스템과 비즈니스 명령이 많은 내부 시스템을 분리할 수 있고, 다양한 상황에 대해 유연하게 대처할 수 있습니다.</p><h2 id="e35a7c58-69d5-447c-94db-8e2929d6c506" class=""><strong>마치며</strong></h2><p id="59d9b0dd-4801-46a2-b2a7-64a14c2f3517" class="">100명이 사용하는 서비스를 만드는 것과 100만명이 사용하는 서비스를 만드는 것에는 고민할 지점이 다르다는 것이 인상깊습니다. 이 글을 정리하며 요즘 유행하는 MSA에 대해 생각해보게 되었는데, 저만의 결론은 다음과 같습니다.</p><p id="72b90272-3de2-4c48-bc64-85e9df02fd75" class="">1.MSA는 대량 트래픽과 고도화된 시스템을 다루는 기법이다.</p><p id="997bd0c8-3c86-4114-abef-5f83b94cffbf" class="">2.그러므로 MSA를 도입하기 앞서 내 시스템이 <strong>어느 지점에 와있는가? </strong>를 파악하는 것이 우선이다. MSA를 구축하는 비용이 크기 때문에 1. 고도화된 장애격리 정책 &amp; 확장성이 더 중요한지, 2. 비즈니스 로직을 구현해내는게 더 중요한지 판단하고 그에 맞춰 결정해야 한다.</p><p id="cfce4533-450b-4b84-954b-b0a23920e68b" class="">또 이벤트 중심 설계와 CQRS 패턴의 설계를 통해 대용량 트래픽을 제어할 수 있다는 점을 알게 된 것도 큰 수확이라고 생각합니다.</p><p id="432690ff-c617-4de4-ab49-4a39c9b78f36" class="">
</p></details></li></ul><ul id="2c0013af-52b8-43b0-9939-4dab1bd8e54f" class="toggle"><li><details open=""><summary>오늘의집 - MSA Phase 1. Aggregator 공통모듈</summary><h1 id="8d5d7da3-7974-4f67-b842-97c9364c057d" class=""><strong>오늘의집 MSA Phase 1. Aggregator 공통모듈</strong></h1><p id="a847b9e8-ae8b-47bd-ab40-14d68716b41b" class="">1년차 백엔드 개발자의 MSA 공통모듈 개발기</p><p id="8f0f9ebb-fa26-4596-8a27-7a183488f5ac" class="">2022년 3월 2일멀린</p><p id="7a2bb716-4ba4-4d8f-84e4-a13e343f6955" class="">안녕하세요. 오늘의집 커머스 서비스 Backend의 Software Engineer 멀린입니다. 이번 포스팅에서는 오늘의집의 MSA 전환 과정에서 개발한 Aggregator 공통 모듈에 대해 소개해 드리겠습니다.</p><h1 id="a8677dab-393b-4909-90e1-f5d5011b6153" class=""><strong>Background</strong></h1><p id="7e1df911-bfb9-4ebb-8129-eee0f4ea1a96" class="">MSA 전환 phase 1 기간 동안 제가 속한 커머스 서비스 Backend의 주요 목표는 기존의 오늘의집 모놀리식(Monolithic) 서비스에서 저희 팀이 담당하고 있던 기능들을 Microservice 형태로 분리해 내는 것이었습니다.</p><p id="db272a99-456e-4e75-97fb-d4a30d456c51" class="">&lt;오늘의집 MSA Phase 1. 백엔드 분리작업(<strong><a href="https://www.bucketplace.com/post/2022-01-14-%EC%98%A4%EB%8A%98%EC%9D%98%EC%A7%91-msa-phase-1-%EB%B0%B1%EC%97%94%EB%93%9C-%EB%B6%84%EB%A6%AC%EC%9E%91%EC%97%85/">클릭</a></strong>)&gt;에서 소개한 것처럼 이 과정에서 저희는 원활한 전환을 위해 Branch by Abstraction 전략을 취하기로 했습니다.</p><figure id="396c858b-4415-4eb7-81c0-704356f1f480" class="image"><a href="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1645508548/M_01.jpg"><img style="width:700px" src="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1645508548/M_01.jpg"/></a></figure><ul id="c382d3dc-f4d9-4e05-a22c-ea3fdc54265e" class="bulleted-list"><li style="list-style-type:disc">이미지 출처 (https://martinfowler.com/bliki/BranchByAbstraction.html)</li></ul><p id="cb0954ac-331a-412b-8e3e-c190166ba1d3" class="">Branch by Abstraction은 소프트웨어에 큰 변화를 줄 때 취할 수 있는 방법 중 하나로 위와 같이 Flawed Supplier와 Client 사이에 Abstraction Layer를 삽입하여 이후 Flawed Supplier를 쉽게 교체할 수 있도록 하는 방식입니다.</p><p id="5c0d7ec6-f544-499e-b2ac-7e36a6b438e0" class="">이러한 전략을 선택한 주요한 이유는 팀 간 의존성과 데이터 소유권 문제 때문이었는데요. 오늘의집 서비스는 크게콘텐츠, 커머스, O2O 그리고 물류 서비스라는  4개의 도메인을 가지고 있으며 이러한 도메인에 따라 서비스를 만들어나가는 팀도 분리되어 있습니다.</p><p id="661eae1a-d611-4041-846e-80603cc88c33" class="">하지만 기존의 오늘의집 서비스는 하나의 거대한 Ruby on Rails 모놀리스 서비스에 모든 도메인과 프론트까지 함께 불편한 동거를 하며 일부만 작은 마이크로서비스 형태로 분리돼 붙어있는 형태였습니다.</p><p id="648ceb77-bcee-4ca2-8aaa-6b96d57d2c12" class="">더 큰 문제는 콘텐츠, 커머스를 모두 제공하는 서비스 특성상 도메인 간 데이터 조회가 필요한 케이스가 많음에도 불구하고, 모놀리스 서비스 내에서조차 도메인에 따른 분리가 잘 되지 않은 상태였다는 것입니다.</p><figure id="49b65cab-b3ce-4d9a-ba8b-f59d77e5e68f" class="image"><a href="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1645508732/M_02.jpg"><img style="width:700px" src="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1645508732/M_02.jpg"/></a></figure><p id="666bbf41-5efd-4055-837e-41eb957167d4" class="">기존 모놀리스 서비스에서는 위 사진의 기능들과 같이 특정 데이터가 필요할 경우 그 자리에서 직접 DB를 조회하거나 도메인 구분 없이 모든 데이터를 함께 Join하여 가져오고 변경하는 등 분리하기 어려운 형태로 작성되어 있었습니다.</p><p id="18bb1d59-a923-4a6e-a7fc-574253cbfe3d" class="">따라서 그저 Path 단위로만 커머스 영역을 분리하게 되면 여전히 다른 도메인 데이터에 접근하게 되는 바람직하지 않은 형태가 될 수밖에 없었습니다. 그래서 오늘의집 커머스 서비스 Backend팀에서는 분리한 레거시 커머스 서비스에서 외부 의존성을 전부 제거하기로 했습니다. 의존성이 제거됨에 따라 다른 마이크로 서비스에 존재하는 데이터를 가져오는 기능이  필요하게 되었습니다. 이를 위해 서비스 앞단에 Gateway를 두고, Gateway 바로 뒤에서 Branch by Abstraction 형태의 방법으로 다른 서비스의 데이터를 가져오는 Layer를 만들었는데요. 이를 위해 새롭게 추가된 모듈은 의존성 데이터들을 모아주는 기능에서 착안해 Aggregator로 명명하였습니다.</p><figure id="5ff93402-927d-4e0f-87b6-6682d38d2720" class="image"><a href="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1645508821/M_03.jpg"><img style="width:700px" src="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1645508821/M_03.jpg"/></a></figure><p id="81857bc5-75e6-4e21-b90d-094bbd6bf335" class="">커머스와 콘텐츠팀 각각 Aggregator를 두어 커머스에서는 스타일링샷이나 스크랩, 좋아요 등의 정보를, 콘텐츠팀에서는 태그된 상품 정보 등을 요청하여 기존과 같은 API 응답을 유지할 수 있는데요.</p><p id="4853712b-dc28-43bb-b674-79cbd6dba52a" class="">여기까지 전환에 대한 계획은 세워졌고, 이제 Aggregator를 개발하기만 하면 되지만 문제는 Aggregator의 개발이 생각보다 간단하지 않다는 것이었습니다.</p><p id="0cf09a4f-e34f-486a-91d5-cab838c4abbd" class="">기존 모놀리스의 API들은 페이지 단위로, 하나의 페이지를 그리는데 필요한 모든 데이터를 하나의 API에서 전부 내려주는 방식으로 개발되어 있었습니다. 그러다 보니 API에 따라 몇 천 줄이나 되는 JSON Body를 갖는 경우도 있었고, 이 안에서 타 팀에 의존성을 가진 필드들을 전부 찾아서 API 종류별로 모아 데이터를 요청해야 하는 힘든 작업을 필요로 하고 있었습니다. (받아온 데이터를 다시 알맞은 곳에 넣어주는 작업 또한 API 별로 해줘야 하는, 상상만 해도 지치는 상황입니다 😅)</p><p id="ef57d0e8-9c16-4d46-88b6-1ced3d698f3a" class="">자연스럽게 이 같은 작업들을 자동으로 해주는 기능의 필요성을 느끼게 되었고 MSA 전환 기간 초반부에 걸쳐 Auto-Aggregation Module(가칭)을 개발하게 되었습니다.</p><h1 id="9c4cbbf1-96d8-47d1-9351-912cd31ff73a" class=""><strong>Concept</strong></h1><p id="2d210074-f56b-4072-b82a-7ab2b9571fe5" class="">Aggregator 서비스가 가진 역할은 위에서도 언급했듯이 다음과 같은 3가지 단계를 수행해야 합니다.</p><ol type="1" id="008e9603-6ab0-4dbd-a4c1-4581e9da1b88" class="numbered-list" start="1"><li>응답 내에서 의존성을 가진 부분을 탐색</li></ol><ol type="1" id="81cfb502-879f-42f7-b1e8-bb2ff63f1fac" class="numbered-list" start="2"><li>의존성을 해소해 주는 타 팀 API에 따라 분류 및 요청</li></ol><ol type="1" id="e111794c-a44c-4899-9d1d-0bda94bde65f" class="numbered-list" start="3"><li>받아온 데이터로 응답을 변형(의존성의 해소)해 반환</li></ol><p id="19efd73e-a233-4799-9f41-70e37698c6c9" class="">이렇게 탐색, 요청, 해소의 3단계를 자동화하기 위해 다음과 같이 Resolver 인터페이스를 정의하였습니다.</p><figure id="2e09ca84-d6de-4efc-ad02-9ceb6cc63683" class="image"><a href="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1645508966/M_04.jpg"><img style="width:700px" src="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1645508966/M_04.jpg"/></a></figure><p id="73542cd0-8d3e-4073-beed-789da15b247f" class="">각각의 Resolver들은 특정 객체가 가진 의존성에 대한 요청과 해소를 담당해 주는 주체 역할을 하게 됩니다. JSON Payload를 파싱하는 과정에서 각 Resolver의 Queue에 해소해야 하는 Target 객체를 수집하고, 파싱이 끝난 후 각 Resolver들은 서로 비동기적으로 동작하면서 의존성을 해소하게 됩니다.</p><h1 id="1e83e1c9-c302-4612-8e59-fb9ee0831c0f" class=""><strong>Interface</strong></h1><p id="ab9d5677-1ac6-445b-8e8c-199c3eaf5e16" class="">모듈의 개발에 있어 가장 중요하게 생각했던 부분은 사용자의 작업을 필요로 하는 Boilerplate를 최대한 줄이고, 공통 로직의 재사용성을 높이는 것이었는데요. 해당 모듈에서 제공하는 API를 사용하면 하나의 Path에 대한 응답을 파해서, 저장할 DTO(Data Transfer Object)와 해당 DTO 내의 의존성들을 해소할 Resolver들만 작성하면 작업이 끝나게 됩니다.</p><p id="9d170ab4-6bf2-4c79-a0b6-c725090a6443" class="">간단한 예시를 통해 인터페이스를 소개해 보겠습니다.</p><p id="25216105-026f-4049-a0fb-929d82ffff2d" class=""><strong>상품 DTO의 스크랩 정보 해소</strong></p><p id="8e6b7352-2a4b-4520-80f8-926f05594044" class=""><code>@Resolvabledata class Product(	val id: Long,	var scrap: Boolean,	...)</code></p><p id="6e20afbc-3226-433a-9c0a-871fd59023f0" class="">위처럼 상품 DTO의 Scrap 필드를 해소해 주어야 할 경우에는 Product를 Target으로 갖는 Resolver를 정의하면 됩니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="a21dfd3b-96cd-4ded-ab95-46a8ef704dc4" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Resolverclass ProductScrapResolver(	val scrapService: ScrapService) : FieldResolver&lt;Product, Boolean&gt;() {	suspend fun getFields(list: List&lt;Product&gt;): List&lt;Boolean&gt; {		return scrapService.getScrap(list)	}	suspend fun resolveTarget(target: Product, fieldVal: Boolean) {		target.scrap = fieldVal	}}</code></pre><p id="bc7ab43a-bc15-4978-b718-f10bd8b7cd75" class="">FieldResolve &lt;Target, Field&gt;는 DTO의 특정 Field를 변경해 주기 위한 Resolver Abstract Class의 하나로, 내부에 Resolve 해야 할 Target을 담는 Queue를 갖습니다. FieldResolver의 구현은 Queue의 Target 목록을 변형하기 위해 필요한 Field 정보를 요청해 가져오는 getFields와 가져온 Field 정보로 각 Target을 변형해 주는 ResolveTarget의 두 단계를 갖게 됩니다.</p><p id="9d46f2b8-1944-4160-a8ce-36a261e65d73" class="">이렇게 작성되어 모듈에서 제공하는 @Resolver, @Resolvable로 Annotate된 DTO와 Resolver Class들은 Aggregation Context Bean에 의해 수집되어 자동적인 Aggregation에 사용됩니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8441afd0-f259-4fc0-8e0c-8343af74104f" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">val body: String = webClient	.get()	.uri( ... ) //legacy endpoint	.retrieve()	.BodyToMono(String::class.java)	.awaitSingle()val aggregated: Product = aggregationContext.readValue(body, Product::class)</code></pre><p id="2e11450e-62f7-489c-a3a1-04eeb17319fc" class="">위와 같이 Legacy Service의 응답 JSON String에 대해 Aggregation Context가 제공하는 Suspending ReadValue Function을 마치 ObjectMapper로 파싱하듯 적용하면, 작성한 Resolver들이 동작하면서 요청과 동시에 데이터 기입을 수행해 줍니다.</p><h1 id="957ee14b-282d-4123-8394-850314ed88f3" class=""><strong>Additional Features</strong></h1><p id="0eecd308-e134-4ac7-8d1d-4b91c408c61d" class="">위에서 설명드린 인터페이스를 기본으로 코드의 재사용성과 서비스의 안정성, 성능 향상 등을 위해 여러 가지 추가적인 기능들을 구현했습니다. 간단히 정리하면 다음과 같습니다.</p><ul id="f6b86311-c954-4470-b6de-e046c8cd1742" class="bulleted-list"><li style="list-style-type:disc"><strong>Resolver 순서 지정 기능</strong><p id="39f2db32-4ab6-4536-91b4-69770da09adf" class="">기본적으로 서로 Asynchronous하게 동작하는 Resolver들 간 순서를 지정하여 특정 Resolver들이 모두 작동하고 나서 작동하도록 설정할 수 있다.</p></li></ul><ul id="77e3a996-0e33-466e-ad90-9ecdf52c950c" class="bulleted-list"><li style="list-style-type:disc"><strong>Error Handling</strong><p id="467b7d3f-886e-48cb-81ed-8aab953e1bec" class="">각 Resolver 내에서 발생한 Exception Handling을 자유롭게 추가할 수 있다.</p></li></ul><ul id="f91c67fe-0bc5-48e5-a60e-92d455f6bc9b" class="bulleted-list"><li style="list-style-type:disc"><strong>HTTP Attribute 주입</strong><p id="d676e8a3-cf02-4f5d-a553-b2bdf999892c" class="">Aggregator가 Proxy해주는 HTTP 요청과 응답 정보(HEADER, URI, BODY)들을 각 Resolver에 주입하여 구현 시 사용할 수 있다.</p></li></ul><ul id="834e8241-7810-4587-bfeb-2440cab4a2bf" class="bulleted-list"><li style="list-style-type:disc"><strong>Retry</strong><p id="eba3dcbd-803b-4a42-9b31-8aafae8f2441" class="">동작 중 실패 시 Max Retry 회수를 Resolver 별로, 또는 일괄로 설정할 수 있다.</p></li></ul><ul id="00e1c63c-996c-43c6-bebc-7cdc18cf9a28" class="bulleted-list"><li style="list-style-type:disc"><strong>Resolvable class 다형성 지원</strong><p id="5960ddd1-a6e2-4db7-b7c2-b412786068ab" class="">Resolver의 Target Class를 Superclass로 갖는 DTO들에 대해서도 해당 Resolver가 작동한다.</p><p id="8630defc-4bd7-40e5-b1a4-109f1d8b1e57" class="">이를 이용해 서로 모양이 다른 DTO에 대해서도 같은 Resolver로 처리할 수 있다.</p></li></ul><ul id="7389be7b-51a5-42ff-b69a-2d50b5c9e0dd" class="bulleted-list"><li style="list-style-type:disc"><strong>Spring Integration</strong><p id="4f33805e-bb30-405b-b0a3-ba812d472669" class="">Spring Bean들을 Constructor로 주입받아 각 Resolver 내에서 자유롭게 이용할 수 있다.</p></li></ul><h1 id="40b37488-ba23-4f53-b7a4-e13e82948644" class=""><strong>Under the hood</strong></h1><p id="551d7520-f090-4275-bc4c-916021b1c630" class="">모듈의 개발에는 Spring webflux, Jackson, Kotlinx.coroutines, Java Reflections를 사용하였습니다. 여기에 추가로 Commerce Aggregator에서 해당 모듈과 함께 사용할 Spring Cloud Gateway와의 Integration을 위한 Extension들을 제공합니다.</p><p id="5382cdf9-52cf-4568-92d6-dea03efe65d8" class="">모듈이 이러한 Library들을 사용해 어떻게 동작하는지를 간단히 정리해보겠습니다.</p><p id="2c28a61d-1002-4aff-8101-8f5c4e3932c7" class="">먼저 위에서 소개해 드렸듯이 AggregationContext Class의 Singleton Bean에서 전체적인 Aggregation 과정을 관리합니다. 이때 AggregationContext는 두 개의 InfoHolder Bean들로부터 사용자가 정의한 Resolver, Resolvable Class 정보를 제공받습니다. 각 InfoHolder들은 Java Reflections의 기능을 이용해 Class 정보를 Bean이 만들어지는 시점에 수집하여 갖게 됩니다. Class 정보 외에도 순서 관계, Retry 등의 기타 세팅 정보들 또한 수집하여 제공합니다.</p><p id="1f962772-b609-4b8c-96ad-4d97ef5f13c6" class="">이렇게 수집된 정보를 토대로 생성되는 Resolver들은 각 ReadValue 리퀘스트 별로 새로이 생성되고 사용되어야 합니다. 따라서 이러한 Resolver들의 생명주기를 관리할 수 있도록 AggregationContext는 ReadValue 요청마다 ReadContext를 생성하고, ReadContext가 Resolver들의 생성과 실행을 담당하게 됩니다.</p><p id="b2840fce-4cfc-4271-a899-a70253d69613" class="">Resolver들의 초기화가 끝나면 JSON Body로부터 해소가 필요한 객체들의 탐색과 수집이 이루어집니다. 객체의 탐색은 Jackson ObjectMapper가 Json을 파싱하는 과정을 Override해서 JSON 파싱과 의존성 탐색, 수집을 모두 한 번에 진행하도록 구현하였습니다. ObjectMapper에 Custom Deserializer와 Deserailizer Modifier를 등록하여 각 오브젝트가 파싱되었을 때 해당 Class의 오브젝트를 Target으로 갖는 Resolver들의 Queue에 해당 오브젝트를 넣어주도록 하였습니다.</p><p id="77e280e8-c434-458d-9b12-212f73c8987a" class="">수집이 끝나면 Queue가 비어있지 않은 모든 Resolver들은 서로 다른 Coroutine에서 ResolverExecutor에 의해 실행됩니다. Executor들은 서로 Kotlinx.coroutines Channel을 이용해 통신하고, 지정된 순서 관계에 따라 각 Resolver가 실행될 시점을 기다렸다가 종료 시 완료 이벤트를 공유합니다.</p><p id="72e45e7a-d962-405c-a6b0-112362c57adf" class="">모든 Resolver의 작동이 끝나면 AggregationContext에서 변경된 DTO를 요청자에게 최종적으로 반환합니다.</p><p id="039b795e-d57e-495e-a853-220c062fcfa8" class="">그림으로 요약하면 다음과 같습니다.</p><figure id="1974511d-5d60-4e73-bbd7-6891a357e9e7" class="image"><a href="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1646200130/image.png"><img style="width:700px" src="https://res.cloudinary.com/bucketplace-co-kr/image/upload/v1646200130/image.png"/></a></figure><h1 id="9be0fd58-93ba-4868-969c-b30b47fbe2cf" class=""><strong>Transition</strong></h1><p id="40c7c915-cf0f-487a-8827-49122aaca719" class="">모듈을 이용한 Aggregator의 개발을 마친 후 실 서비스 전환을 앞두고 다음의 세 가지 검증 단계들을 거치면서 Aggregator 응답 결과의 정합성을 검증하고 버그를 찾는 시간을 가졌습니다.</p><ol type="1" id="5bd9a18d-b008-4e22-9605-d9fa196b50ca" class="numbered-list" start="1"><li><strong>Load Test</strong><p id="9fb1f4e8-755e-4875-ba71-a1919f1eb6b0" class="">DevOps팀에서 구축해 주신 Production과 거의 동일한 테스트 환경과 Ngrinder 툴을 이용해 팀 내 동료 개발자분들께서 로드 테스트를 진행해 주셨습니다. 특히, 기존 Legacy 서버와 Aggregator의 성능 차이가 큰 만큼 두 서버의 적절한 Pod 비율을 찾는 것에 집중하였습니다.</p></li></ol><ol type="1" id="68be9034-fc8c-42c1-bfc4-c3193741db93" class="numbered-list" start="2"><li><strong>Traffic Shadowing</strong><p id="75d12e96-8dc6-4220-baf3-591ba3a6f532" class="">기존 서비스가 받고 있는 요청들 중 일부를 새로운 서비스에 똑같이 흘려주어 새로운 서버가 기존 요청들을 제대로 처리할 수 있을지 확인하였습니다. 이 과정에서 Platform팀에서 준비해 주신 두 서버 간의 응답 비교기능(Diffchecker)을 이용해 데이터 누락 및 변형을 잡아낼 수 있었습니다.</p></li></ol><ol type="1" id="bb1e2659-22d7-42e5-abfb-3e3c5522b081" class="numbered-list" start="3"><li><strong>Traffic Control</strong><p id="607e5994-d946-4980-9e93-bf1ec22b9d59" class="">마지막으로 <strong><a href="https://www.bucketplace.com/post/2021-10-29-%EC%98%A4%EB%8A%98%EC%9D%98%EC%A7%91-a-b-%EC%8B%A4%ED%97%98-%ED%94%8C%EB%9E%AB%ED%8F%BC-%EA%B5%AC%EC%B6%95%EA%B8%B0/">A/B 테스트 플랫폼</a></strong>을 이용하여 오늘의집 서비스로 들어오는 요청들을  신규 서비스로  전환을 진행하였으며 신규 서비스에서의 에러를 확인하며 점진적으로 트래픽을 전환하여 마침내 100% 전환을 이루었습니다.</p></li></ol><h1 id="ccbda59f-5adb-4152-8c8a-9f937cc6cc65" class=""><strong>Aggregator를 이용한 Monolithic To MSA 전환의 장점</strong></h1><p id="bf33b9a4-400c-45a8-9187-db598b92526a" class=""><strong>1. 작업량이 적고 버그 발생 가능성 또한 낮습니다.</strong></p><p id="3244216a-2319-4fe0-aa91-6c761097d7ea" class="">검증 단계에서 상당히 놀라웠던 점은 생각 이상으로 버그가 적게 발생했다는 것입니다. 이는 저희가 취한 전략의 특성상 Legacy 코드에는 최소한의 변경(의존성 제거)만이 이루어지기 때문에 기존 동작과 달라질 여지가 적었던 점이 작용했다고 생각합니다.</p><p id="1958e375-6ade-4a56-8845-d361c97273f7" class=""><strong>2. 새로운 기술의 도입 및 Tech Stack 전환에도 이점이 있습니다.</strong></p><p id="1e9751b9-7b35-4328-914b-789751c2b87f" class="">오늘의집에서는 기존 Ruby on Rails에서 Kotlin Spring으로 Tech Stack 전환이 이루어지고 있으며, 이번 MSA Phase 1을 기점으로 내부 마이크로서비스 간의 통신 프로토콜을 gRPC로 정하였는데요. Aggregator를 도입함으로써 gRPC로 새롭게 개발된 의존성 API들을 기존 RoR 이 아닌 Spring 기반 Aggregator에 도입하는 것이 가능해졌습니다.</p><p id="5d88b010-b454-451b-b2ce-1288ce91477c" class=""><strong>3. 이후 진행할 MSA 작업에 있어서도 이점을 줍니다.</strong></p><p id="3f496719-2204-47b4-9923-62440b9c66da" class="">타 팀에서 제공받아야 할 (혹은 제공해야 할) API들을 미리 정리하고 개발해두었기 때문에 이후 남은 레거시를 리팩토링할 때에도 다른 팀과의 일정 조율이나 개발 요청 없이도 원활한 작업 진행이 가능해졌습니다.</p><p id="3e9db4e7-8f9a-418c-adc9-74dc83829987" class="">이 외에도 모듈에서 비동기적인 Batch Get과 에러 핸들링에 대한 인터페이스를 지원하기 때문에 성능 면에서의 이점과 마이크로서비스 구조에서 발생할 수 있는 장애 전파에 대한 안정성도 얻을 수 있었습니다.</p><h1 id="45fc4664-361a-4923-a0c1-108e07fbdd0c" class=""><strong>Future</strong></h1><p id="be422a46-c37a-436b-887d-a558ffb71f2b" class="">오늘의집 서비스가 목표로 하는 최종적인 서비스 구조는 Backend Microservice들과 Client 사이에 BFF(Backend for Frontend) 서버를 두어 필요한 데이터의 수집을 담당하게 하는 것입니다.</p><p id="0916792e-7ff5-442b-ad77-9df5c2bc1b07" class="">아쉽게도 이번에 개발된 Aggregator 서비스들은 구버전 응답 유지 정도의 역할만을 하게 될 예정입니다. 하지만 약 4개월이라는 짧은 기간 안에 많지 않은 인원으로 전환에 성공했고 성능적인 검증 또한 마쳤기 때문에 Aggregator가 최종 형태에 도달하기까지의 중간다리 역할을 훌륭하게 수행해낼 수 있음을 보였다고 생각합니다. 이번 포스팅에서는 ‘모듈 개발기’라는 주제에 초점을 맞춰 소개해 드렸지만 모듈 개발과 이후 Aggregator의 개발, 테스트 등 이 모든 과정은 오늘의집 동료 개발자분들의 도움과 기여가 있었기에 가능한 일이었습니다.</p><p id="4c705259-4d46-4360-acd4-5fd230858968" class="">개발된 Aggregator 모듈은 이후 기능을 조금 변경하여 Backend에서 맡게 될 Mobile BFF 서버의 개발에 사용할 계획이며, 타사에서도 오늘의집의 성공적인 MSA Phase 1을 참고할 수 있도록 오픈소스로 공개하는 것에 대해서도 논의 중에 있습니다. 공개하게 된다면 정돈된 코드와 문서로 다시 한번 소개해 드리도록 하겠습니다.</p><p id="5a097401-3be8-4788-8054-1e9f3100dcb4" class="">오늘의집 MSA Phase 2에서는 분리해낸 Legacy 서비스를 MSA 형태로 분리하고 BFF서버를 구축하는 작업이 진행될 예정인데요. 앞으로의 MSA 진행을 위해 오늘도 오늘의집 개발팀은 새로운 도전을 이어나가고 있습니다.</p><p id="ff919dae-6970-4a00-b30c-5f3556228635" class=""><strong>👨‍💻 오늘의집 개발팀을 더 자세히 알고 싶다면? (</strong><strong><a href="https://bucketplace-eng.oopy.io/">클릭</a></strong><strong>)</strong></p><figure id="4539c9e6-37c1-4b99-a75d-ef86bcaea1f8"><a href="https://www.bucketplace.com/post/2022-02-22-오늘의집-msa-phase-1-aggregator-공통모듈/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">오늘의집 MSA Phase 1. Aggregator 공통모듈 - 오늘의집 블로그</div><div class="bookmark-description">1년차 백엔드 개발자의 MSA 공통모듈 개발기</div></div><div class="bookmark-href"><img src="https://www.bucketplace.com/img/apple-touch-icon.png" class="icon bookmark-icon"/>https://www.bucketplace.com/post/2022-02-22-오늘의집-msa-phase-1-aggregator-공통모듈/</div></div><img src="http://res.cloudinary.com/bucketplace-co-kr/image/upload/v1647428382/Aggregator_%EC%8D%B8%EB%84%A4%EC%9D%BC.jpg" class="bookmark-image"/></a></figure></details></li></ul><ul id="c141c4ea-cc55-4252-b7fd-ae5e2a604f31" class="toggle"><li><details open=""><summary>카카오 - 광고 플랫폼 MSA 적용 사례 및 API Gateway와 인증 구현에 대한 소개</summary><figure id="cdd4f5a9-7c38-4079-9736-a78008697e19"><a href="https://www.slideshare.net/slideshow/msa-api-gateway/113145634" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">카카오 광고 플랫폼 MSA 적용 사례 및 API Gateway와 인증 구현에 대한 소개</div><div class="bookmark-description">카카오 광고 플랫폼 MSA 적용 사례 및 API Gateway와 인증 구현에 대한 소개 - Download as a PDF or view online for free</div></div><div class="bookmark-href"><img src="https://public.slidesharecdn.com/_next/static/media/favicon.7bc3d920.ico" class="icon bookmark-icon"/>https://www.slideshare.net/slideshow/msa-api-gateway/113145634</div></div><img src="https://cdn.slidesharecdn.com/ss_thumbnails/2018-r5-14-180906045729-thumbnail.jpg?width=640&amp;height=640&amp;fit=bounds" class="bookmark-image"/></a></figure></details></li></ul><ul id="abcfacef-63c3-46b3-a953-5066972e10f3" class="toggle"><li><details open=""><summary>Toss - 은행 최초 코어뱅킹 MSA 전환기</summary><p id="b3e12016-5d18-4b2a-a7d9-dede784d26e9" class="">토스뱅크는 기존의 공급자 중심의 뱅킹 서비스를 고객 중심으로 변화시키기 위해 많은 노력을 기울이고 있어요.</p><p id="6481383f-6ee5-4aa6-9d7f-fab9c4e9598a" class="">그러나 기존의 전통적인 뱅킹 시스템을 구현하는 방식으로는 안정적인 고객 중심 뱅킹 서비스 제공에 여러 기술적 한계가 있었죠.</p><p id="db9c1ffd-30f7-4f14-b659-f89bf19e6ba4" class="">이번 아티클에서는 토스뱅크가 어떤 방식으로 기술적 한계를 극복했고, 어떤 기술로 고객 중심의 뱅킹 서비스를 제공해 드리고 있는지에 대해 소개해 드릴게요.</p><h1 id="91c6053b-9c89-4c1f-bf93-3f6e723ac152" class=""><strong>현재 은행 시스템에 대한 소개</strong></h1><h1 id="7bd0d2ab-f988-483e-a1dc-f0766fb52d3a" class=""><strong>채널계와 코어뱅킹(계정계)</strong></h1><figure id="84fd44b9-9915-42f8-bd57-f4ce9f75d2c1" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/6f9b32aa-b93c-4bd3-99d7-4393fedeb493/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_03.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/6f9b32aa-b93c-4bd3-99d7-4393fedeb493/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_03.png"/></a></figure><p id="db65a0bc-9bd0-4518-9588-8ad63f055977" class="">먼저, 일반적인 은행 시스템의 아키텍처에 대해 알아볼게요.</p><p id="16954a3e-75b9-4160-8fb2-760c3a69522a" class="">은행에는 크게 고객의 요청을 코어뱅킹 서버로 전달하는 채널계와 금원과 관련된 메인 비즈니스 로직을 처리하는 코어뱅킹(계정계)라고 하는 두 개의 서버를 중심으로 하는 아키텍처로 구성되어 있어요.</p><p id="9bf3a2ad-0625-423e-b2d4-2274b3643f27" class="">여기에 코어뱅킹 서버는 대부분의 은행에서 거대한 모놀리식 아키텍처로 구성되어 있죠.</p><h1 id="e1145ad1-9606-4852-a67c-9a8afe456a21" class=""><strong>코어뱅킹 시스템 아키텍처 히스토리</strong></h1><figure id="e753f50b-561d-456e-80d7-80f6d40a7974" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/6a4cbcbb-b8e6-432b-88d1-7df7774fe466/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_06.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/6a4cbcbb-b8e6-432b-88d1-7df7774fe466/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_06.png"/></a></figure><p id="1f8d89dc-1b96-42a0-a85b-11ae9b46aaaa" class="">코어뱅킹 시스템이 모놀리식 아키텍처를 유지해온 이유는 은행 시스템의 변천사를 알면 그 힌트를 얻을 수 있는데요.</p><p id="007031ad-e72e-46f1-b548-feda82552995" class="">1970년대부터 은행의 계좌 데이터를 적절하게 가공하고 처리해야 하는 니즈가 생기면서, 1세대와 2세대 코어뱅킹 아키텍처가 생겨났고, 2000년대에 디지털 붐이 일면서 모바일 뱅킹, 웹 뱅킹, 텔레뱅킹 등 다양한 거래 요청을 한 곳에서 적절하게 처리해줄 수 있도록 현재의 모놀리식 코어뱅킹 아키텍처가 생겨나게 되었어요.</p><p id="43ea45eb-32bb-4585-b383-f788d3c875ad" class="">지난 20여 년간 코어뱅킹 아키텍처는 운영체제와 개발언어의 크고 작은 변화는 있었지만, 현재의 모바일 트렌드와는 맞지 않는 20년 전의 모놀리식 아키텍처를 대부분의 은행에서 사용하며, 현재의 거대한 모놀리식 형태로 몸집을 불려가고 있었죠.</p><figure id="6aa7debb-8531-4dba-a0d0-724632099cc5" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/64401911-0cf9-42ba-b112-dbae7a19a3f0/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_12.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/64401911-0cf9-42ba-b112-dbae7a19a3f0/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_12.png"/></a></figure><p id="c62f1956-373d-45c7-b23b-39757da535dc" class="">현재 토스뱅크의 채널계는 기존 토스의 DNA를 이어받아 모두 MSA 환경으로 구성되어 있어요. 반면에, 기존의 코어뱅킹 시스템은 Redis, Kafka 등의 모던한 기술을 사용하고는 있었지만, 여타 은행과 다름없이 채널계와의 통신을 위한 MCI, 대외연계를 위한 FEP, 대내 단위 시스템과의 연계를 위한 EAI가 코어뱅킹 서버에 강결합되어 있는 구조로 여타 은행과 다른 없는 거대한 모놀리식 시스템으로 구성되어 있었죠.</p><p id="046ada68-7c66-46c7-a069-06b45a0d05c1" class="">그렇다면, 모놀리식 코어뱅킹 아키텍처가 어떤 한계가 있었기에 MSA로 전환했어야 했을까요? 모놀리식 코어뱅킹 시스템의 장점과 단점을 곱씹어보며, 그 이유를 살펴볼게요.</p><figure id="9416652d-8a5d-44ea-89ae-34558b362baa" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/760ee8f9-703c-4773-8f7e-40ebc028457e/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_13.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/760ee8f9-703c-4773-8f7e-40ebc028457e/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_13.png"/></a></figure><p id="20028caf-4037-4a3b-b43f-f78d267c9a3b" class="">물론 모놀리식 코어뱅킹 시스템도 장점이 있습니다.</p><p id="e4f7ef54-8de4-4842-b0ec-efe8e5276840" class=""><strong>모놀리식 코어뱅킹 시스템의 장점</strong><br/>• 트랜잭션 관리의 용이성 : 로컬 DB 트랜잭션으로 여러 하위 도메인의 데이터를 ACID하게 변경할 수 있음.<br/>• 개발의 단순성 : 모든 코드가 단일 코드 베이스에 있으므로 개발하기가 단순함.<br/>• 보편성 : 대부분의 코어뱅킹 시스템이 모놀리식으로 구성되어 있으므로, 인력 수급과 개발이 용이함.<br/></p><figure id="820c27f7-ac36-4ef8-aa51-06a0db59b809" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/7df34e4a-671c-4011-850c-e43c72ae8c2a/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_14.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/7df34e4a-671c-4011-850c-e43c72ae8c2a/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_14.png"/></a></figure><p id="b2a964d6-0081-4d0c-83de-c0027a74fd58" class="">그렇지만, 모놀리식으로 구성된 시스템은 트래픽이 갑자기 몰렸을 때, 특정 코어뱅킹 서비스만 스케일 아웃을 하는 전략을 가져갈 수 없어요.</p><figure id="c55f9177-b375-422b-b078-393e5138f2cf" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/3a92d446-be9e-48f0-ace9-c567d23e433a/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_15.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/3a92d446-be9e-48f0-ace9-c567d23e433a/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_15.png"/></a></figure><p id="37d802e3-d8b2-4954-a5ff-11ff10c31cc2" class="">또한, 1개의 서버이기 때문에 장애가 발생한 서비스 외에 다른 서비스들의 영향도를 제한할 수 없어, 안정성이 부족하다는 단점도 있죠. 즉, 한 개의 컴포넌트에서 장애가 발생하면, 전 업무가 마비되는 구조로 이어질 수 있다는 건데요.</p><p id="8f08234e-c8d8-4f12-8697-a6c010544285" class="">예컨대, 토스뱅크가 카드 결제 시 결제 금액의 30%를 환급해주는 파격적인 이벤트를 모놀리식 시스템 구조에서 진행한다고 해볼게요.</p><p id="c8ab51a3-0532-47ac-add3-8a4388ce9bf5" class="">카드 서비스는 평소보다 훨씬 많은 트래픽이 들어올 것이고, 이 트래픽이 수용할 수 있는 임계점을 넘어서면, 이벤트를 진행하는 카드 서비스 뿐만 아니라 전혀 상관 없는 계좌 개설이나, 대출 약정 서비스들까지도 마비 될 거에요.</p><p id="9fc065ba-bdcc-4d21-9d8d-d2fc75b71485" class="">미리 이벤트를 알고 있다고 하더라도, 카드 서비스만 스케일 아웃을 할 수 없기 때문에 전체 시스템의 가용성을 확보해두어야 하는 비효율도 발생할 것이고요.</p><p id="2549b570-c723-40ba-b9d8-c69fe4f9108f" class="">모놀리식 아키텍처의 서비스 영향도 제한이 어려운 이유에 대해 조금은 이해가 되셨나요?</p><p id="47da1ff6-2d06-4b3a-8391-adbe2a4683ab" class="">토스뱅크는 고객분들에게 가치를 제공해드리기 위해 하루에도 수차례씩 혁신적인 실험과 기능 추가를 위한 배포를 하고 있어요. 그러면서 Market Fit에 맞는 제품과 서비스들을 빠른 속도로 찾아가고 있고, 그만큼 토스뱅크를 애용해주시는 고객분들도 많이 늘어나고 있죠.</p><p id="3443aa5c-0a5c-4ac6-b07b-9edf61a315f9" class="">하지만 토스뱅크의 서비스가 고객분들의 사랑을 받아 나날이 성장하는 만큼 기존의 모놀리식 아키텍처를 유지하면서 토스뱅크의 혁신적인 서비스들을 안정적으로 제공해드리기는 점점 어려워졌어요.</p><figure id="3143c3f3-1a1b-4599-9492-0d2373bde519" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/19e82732-02fd-439b-9b56-258c0f7671e9/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_17.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/19e82732-02fd-439b-9b56-258c0f7671e9/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_17.png"/></a></figure><p id="2f62200a-781b-4a47-b279-11a0ce33118e" class="">그래서 저희는 현재의 차세대 코어뱅킹 아키텍처를 대량 트래픽에 특화되어 있고, 각 업무별 서비스 영향도를 분리할 수 있는 MSA로 전환하기로 결정했습니다.</p><p id="79eaea3f-2ceb-4773-9e16-2bdbad485534" class="">그중에서도 저희는 토스뱅크 서비스 중에서 가장 트래픽이 많으면서, 토스뱅크의 대표 서비스 중 하나인 지금 이자 받기 서비스를 모놀리식 코어뱅킹 시스템에서 분리하여 MSA로 전환하기로 했답니다.</p><h1 id="dde106c7-441d-41e4-8bdb-4d513aa0c479" class=""><strong>개발 방법</strong></h1><h1 id="09c2342f-850c-46d6-bddd-c493a09e71d9" class=""><strong>기술 스택 선정</strong></h1><figure id="98a99aab-8aba-4406-b6a5-21e0acaeed19" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/e9d47a28-6d51-419e-9743-c1e45d871fc9/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_33.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/e9d47a28-6d51-419e-9743-c1e45d871fc9/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_33.png"/></a></figure><p id="458a6904-780c-4db8-91bc-214028b99008" class="">먼저 기술 스택은 현재 토스뱅크 채널 서버에서 사용하고 있는 기술들을 대부분 채택했어요. Kubernetes위에 Spring boot, Kotlin, Jpa 등을 기반으로 개발했고, 비동기 메시지 처리와 캐싱은 Kafka, Redis를 사용하기로 결정했어요.</p><p id="d93f4c2a-8326-4464-a3fc-dd9fab7067d7" class="">그런데 개발하자마자 첫 번째 고민에 봉착했는데요. 현재 모놀리식으로 강결합되어있는 업무별 비즈니스 의존성을 어느 정도까지 느슨하게 가져갈 것이냐였어요.</p><p id="f2e0c363-c7d4-4af5-a365-0938d0a9c47e" class="">지금 이자 받기를 위해 필요한 도메인은 고객 정보 조회를 위한 고객, 금리조회를 위한 상품 그리고 이자의 회계 처리를 위한 회계 정보가 필요했어요. 이 모든 것을 하나의 마이크로 서버에서 처리하는 것은 MSA의 장점을 활용하지 못할 것이라 판단하여, 도메인 단위로 서비스를 나누기로 결정했어요.</p><figure id="c834148a-9e09-48c0-aef2-daaa09c3cc3b" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/819ab103-a33f-4b00-9b01-8bac44685580/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_39.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/819ab103-a33f-4b00-9b01-8bac44685580/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_39.png"/></a></figure><p id="6b626cd8-e6e0-4a2d-ad95-25054a060a9f" class="">고객의 지금 이자 받기 요청은 고객 정보 조회를 거쳐, 금리 조회와 이자계산, 이자 송금, 회계처리를 한개의 트랜잭션으로 처리하고 있었는데요.</p><figure id="980b7e06-7651-4c59-a474-9c324a76c673" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/0cdb1fb5-299c-4545-bb18-8ea4233c2061/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_40.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/0cdb1fb5-299c-4545-bb18-8ea4233c2061/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_40.png"/></a></figure><p id="45f8efe1-9b55-44c2-8d5f-f163b24ab4cf" class="">새로운 코어뱅킹 아키텍처에서는 트랜잭션으로 엮이지 않아도 되는 도메인은 별도의 마이크로 서버로 구성했고, 각 서버의 API 호출을 통해 비즈니스 의존성을 느슨하게 가져가도록 구성했어요.</p><p id="2fdd4807-c051-4bb9-876b-18b1ad2a74b0" class="">그러면 이제 실제 이자지급 서버를 어떻게 개발했는지 알아볼게요.</p><h1 id="493178aa-8b66-4be1-b392-1a8184a4f216" class=""><strong>동시성 제어</strong></h1><p id="b977f213-449d-439b-b39a-a6f69fc0052d" class="">먼저 은행 시스템의 안정성과 직결되는 부분인 동시성 제어입니다.</p><figure id="06c61a58-b992-4417-b82a-6597c0812c18" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/c94f3a00-6697-43cf-a8df-aee1e1653b9a/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_48.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/c94f3a00-6697-43cf-a8df-aee1e1653b9a/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_48.png"/></a></figure><p id="38786509-31a3-43bc-a14a-2f6be5009160" class="">일단 적절하게 동시성 제어가 안되었을 때, 어떤 문제가 있을지 살펴볼까요?</p><p id="c88e1bef-f4d5-4782-a64b-ebc14886d939" class="">0.01초 사이에 Transaction1을 통해 이자를 받았고, Transaction2를 통해 입금을 받았다고 가정해보면, Transaction1에서는 현재 잔액 기준인 100원에 지금 이자 받기를 한 100원을 더해 200원으로 갱신을 할 거예요.</p><p id="7b9ee746-a52f-4409-bb19-4360fd3ca037" class="">그리고 Transaction2에서는 Transaction1의 요청이 있었는지를 알 수 있는 방법이 없으므로, 처음에 조회한 100원의 잔액에 타행으로부터 입금받은 300원의 잔액을 더해 400원이라는 엉뚱한 금액으로 잔액을 갱신할 거예요.</p><p id="81f587c3-d058-4d9d-95c7-f7293402cb96" class="">이렇게 되면, 어떤 고객도 토스뱅크의 시스템을 신뢰하지 않겠죠.</p><figure id="7b6025b4-5e9d-469e-b600-5776c463588c" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/99b5949c-e074-4612-a892-19b2fcd4ba5e/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_44.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/99b5949c-e074-4612-a892-19b2fcd4ba5e/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_44.png"/></a></figure><p id="f53b804c-069a-4d0e-adcb-561f178ecaf2" class="">이렇듯 은행에서 고객 잔액의 갱신은 앱을 통한 거래는 물론이고, 타행을 통한 입금, ATM을 통한 이체, 자동이체 등으로 잔액를 갱신하는 트랜잭션의 채널이 매우 많아요.</p><p id="f5423c2f-37ef-4f6c-bda8-1129961b693a" class="">그렇기 때문에 일반적으로 사용되는 Redis Global Lock 만으로는 은행 시스템 환경에서 동시성 제어 이슈는 해결하기가 어렵죠.</p><p id="14efa6b1-dcf3-444c-86d8-6f5a1be130cd" class="">그래서 동시성 이슈를 해결하는 것이 코어뱅킹 개발에 있어서 필수 조건이라고 할 수 있습니다.</p><figure id="bb4a38e6-eea4-4b35-90a8-2f1b5a49936e" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/5442135e-df38-4e8a-9516-7f4d996b8ac1/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_49.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/5442135e-df38-4e8a-9516-7f4d996b8ac1/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_49.png"/></a></figure><p id="27602c6c-b659-4978-8405-29c843235e5f" class="">저희는 이 문제를 Redis Global Lock과 더불어 DB Layer에서 동시성을 제어하기 위한 JPA의 @Lock 어노테이션을 통해 해결했어요.</p><figure id="722aa5cd-bcfa-4c56-a4df-6932cd116c15" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/a6e8d585-beaf-4404-a685-628c72fb8612/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_54.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/a6e8d585-beaf-4404-a685-628c72fb8612/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_54.png"/></a></figure><p id="b98fa3f4-6dbc-4618-ade6-1df794b1f315" class="">앞에 예시로 다시 돌아가 볼게요.</p><p id="c1c6c1bb-ac56-4534-92ae-c35fab5726af" class="">Transaction2는 DB Layer에서 Lock으로 동시성을 제어하고 있기 때문에 Transaciton1이 끝날 때까지 대기합니다.</p><p id="daeb76f4-4d74-417f-9bea-a2b251a70d4a" class="">그리고, Transaction1의 commit이 끝난 이후의 변경된 잔액을 참조하겠죠. 그러면 잔액은 최초에 예상했던 500원으로 commit이 되고 트랜잭션의 동시성은 안전하게 보장됩니다.</p><p id="16512708-e97b-4dca-9e26-0797ea9e235b" class="">그런데 이 때, DB Lock을 사용할 때는 주의해야 하는 점이 있어요.</p><p id="b4864f45-b7b2-47ad-9960-85374305a4fe" class="">Lock을 잡아야 하는 데이터를 명확히 식별하고, 갱신하는 데이터에 대해서만 Lock을 획득해야 데드락과 시스템 성능 저하를 예방할 수 있다는 점인데요.</p><p id="fbe49c52-cb7c-49b2-87a7-a38d0cf729e4" class="">지금 이자 받기API의 경우 잔액을 갱신하는 이벤트가 메인 비즈니스 로직이기 때문에, 계좌 단위 현재 잔액 데이터에 대해서만 고유하게 Row Locking이 걸리도록 개발하여, 동시성을 보장하도록 구현했어요.</p><p id="47c3acf4-a90b-4773-8365-ef47684b5eb9" class="">또한, Transaction2의 동시성이 발생하였을 때, Transaction1을 끝날 때까지 기다릴 수 있도록 재시도할 수 있는 로직과 적절한 타임아웃을 적용해주어서 고객 관점에서 Lock이 걸렸는지도 모르게 안정적으로 이자를 받을 수 있게 구현했죠.</p><h1 id="1d7f6022-f6b2-4746-83a4-a9f75158ffa3" class=""><strong>성능 개선을 위한 비동기 처리</strong></h1><p id="cc4dab71-cd4b-40c4-8cba-29c717a9a88b" class="">두번째는 카프카를 활용한 비동기 트랜잭션 구현입니다. 기존 코어뱅킹 시스템에서는 1번의 이자를 지급받기 위해 20개의 테이블에 80번의 UPDATE, INSERT가 이루어지는 복잡한 구조였어요.</p><p id="0ba97d33-f5b7-4415-b858-e04d21521282" class="">그렇기 때문에 지금 이자 받기 서비스의 속도도 평균 300ms로 전체 코어뱅킹 서비스 중에서 느린 편에 속했죠. 이 정도면 정규화가 잘 되어 있는 데이터 모델과 정교하게 잘 설계된 인덱스 구조로도 빠른 응답 속도를 기대하기는 어려운 구조였어요. 그래서 기존 지금 이자 받기 트랜잭션에서 분리가 가능한 테이블은 카프카를 이용해 트랜잭션에서 분리했어요.</p><p id="a7b271a9-4e8f-4a8c-9d91-b92ce018ba4b" class="">트랜잭션 분리에 대한 기준은 고객의 잔액과 통장 데이터 관점에서 DB 쓰기 지연이 발생하였을 때, 실시간으로 문제가 발생하느냐? 로 접근하였고, 반드시 트랜잭션이 보장되어야 하는 데이터 모델과 즉시성을 요하지 않는 즉, 세금 처리와 같이 지금 이자 받기 트랜잭션과 묶이지 않아도 되는 데이터 모델의 DML은 트랜잭션을 분리했죠.</p><figure id="8f2e3561-6542-4ba3-804c-dbe6c67957c5" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/8d732a65-a59d-4d7f-a42a-ec9dd37932ec/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_62.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/8d732a65-a59d-4d7f-a42a-ec9dd37932ec/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_62.png"/></a></figure><p id="be4e701d-318f-4c77-b25e-c39e4a5cda27" class="">구체적으로 살펴보면, 지금 이자 받기 서버에서 지금 이자 받기의 트랜잭션 종료와 동시에 세금 카프카 토픽에 메시지를 Produce하고, 비동기 처리 서버가 Consume해서 세금 DB에 저장하도록 구현했어요. 정상적인 상황이라면, 이자 DB와 세금 DB에도 준실시간으로 업데이트가 되었을 것이기 때문에 지금 이자 받기의 거래는 정상적으로 종료될 거에요.</p><p id="539e64cb-214e-4ed3-8f1d-b9d41bd296da" class="">그렇지만, 카프카 메시지가 정상적으로 처리되지 않는 경우도 있기 때문에, dead letter queue를 이용해서 세금DB에 대한 트랜잭션을 안정적으로 보장할 수 있도록 했어요. 또, 재처리시 중복으로 세금이 업데이트 안되도록 API도 멱등하게 설계했죠.</p><p id="d325d8bd-6f9f-4a04-b455-e168d7abf2b2" class="">그 결과 세금 DML을 지금 이자 받기 트랜잭션에서 분리함으로써, 기존 80회의 DML이 이루어지던 지금 이자 받기 트랜잭션을 50회의 DML로 줄이는 개선 효과를 얻을 수 있었습니다.</p><h1 id="20aa12a9-1eac-4d4d-91f9-65fb32a2ca0e" class=""><strong>Redis를 활용한 캐싱 전략</strong></h1><p id="a834e72d-4fb8-4c27-95fa-b2aa2112a6d8" class="">마지막으로는 Redis를 활용한 캐싱 전략입니다.</p><figure id="fdc665f2-2d6a-4c12-b71f-9c4a30d50cda" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/8ef7e73e-6bdf-461f-a310-996cb1aea2dd/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_66.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/8ef7e73e-6bdf-461f-a310-996cb1aea2dd/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_66.png"/></a></figure><p id="7042f112-4935-4732-a81a-5f9345719f18" class="">기존 코어뱅킹 시스템에서의 이자 계산은 RDB 기반의 일자별 거래내역DB를 조회해서 연산하는 방식으로 구현되어 있었어요.</p><p id="aa13d80e-c397-4d08-8609-7640cbff4212" class="">고객이 지금 이자 받기를 할 때마다, 계좌의 매일 매일 거래내역을 참조해서 이자 계산과 세금을 계산하는 구조이므로 성능적으로 오래 걸릴 수 밖에 없는 구조였죠. 그러나 고객은 하루에 1번 밖에 이자를 못받기 때문에 Redis를 활용하면, 하루에 1번만 DBIO를 발생시킬 수 있을 것이라 판단해서 Redis를 이용해 캐시를 활용하기로 했어요.</p><figure id="37d88b9a-96aa-4945-abd4-e734f3642cdc" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/fc78dce8-9217-4ccd-bc8d-5c0b5cfb4ad5/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_72.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/fc78dce8-9217-4ccd-bc8d-5c0b5cfb4ad5/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_72.png"/></a></figure><p id="0a6ff591-6e77-491e-a839-f17892815ea6" class="">기존의 이자금액은 고객이 계좌 상세탭에 접근할 때마다, 이자계산을 위한 DB I/O가 발생하고 있었는데요. 이를 고객이 하루 중 처음으로 계좌 상세탭에 접근할 때에만 DB에 접근하도록 구현했고, 이자예상조회의 결과를 Redis에 캐싱해 두도록 구현했어요.</p><figure id="8133023d-74c3-4bbe-9361-e3d3a93bfc5b" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/3f03cccd-b49e-41df-a1ad-ac7e851cc925/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_73.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/3f03cccd-b49e-41df-a1ad-ac7e851cc925/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_73.png"/></a></figure><p id="615b7a32-2a67-477e-824c-b324dd5194af" class="">그래서 고객이 하루에 2번 이상 계좌 상세탭에 접근할 경우에는 Redis에 미리 저장되어 있던 이자계산 결과를 리턴하도록 했죠. 그래서 불필요하게 DB 리소스가 낭비되는 것을 예방했습니다.</p><p id="2c51b80d-cddc-439f-bbab-accb91c6ecbe" class="">또한, Redis에 캐싱 된 이자 데이터의 만료일자도 하루로 두어서, 이자금액이 잘못 계산 되는 케이스도 원천적으로 방지했어요. 그래서 매일 자정 이후 고객이 계좌 상세탭에 처음 접근할 때만, 이자예상조회의 결과를 캐싱해서 이자 데이터의 정합성도 안정적으로 보장할 수 있었죠.</p><h1 id="75ce6ced-2d6e-47fc-b21b-39dc44d7a8ba" class=""><strong>기존 시스템을 안정적으로 전환하는 방법</strong></h1><p id="80ebe5e2-bcc2-45b6-a50a-0302c17fc4a2" class="">이자 지급 마이크로 서버에 이자 조회 거래, 지금 이자 받기 거래를 개발 완료했어요. 이제 기존 코어뱅킹(계정계)를 참조하던 서비스를 이자 지급 마이크로 서버를 바라보도록 전환해야 하죠.</p><p id="8a367df9-0a3d-4eb3-8ad7-6e22a8655c7c" class="">시스템을 전환하기에 앞서, 이자 지급 마이크로 서버 API에 대한 검증이 필요했는데요. 어떤 검증 방식을 활용할 수 있을까요?</p><h1 id="33fdfb14-df6a-4fb3-98de-7d11c4356348" class=""><strong>첫 번째 방법: 실시간 검증을 통한 건별 검증 방식</strong></h1><p id="a60a1632-06dc-487c-8066-ec8caafa861d" class="">첫 번째 방법인 온라인 검증 방식을 도식화한 그림입니다.</p><figure id="dfee5f71-5cfa-4f4e-8f70-49d8b18f062d" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/81ffdac8-3800-440c-8220-b7627c4f263f/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_78.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/81ffdac8-3800-440c-8220-b7627c4f263f/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_78.png"/></a></figure><p id="fb8e05c2-b08f-4454-85e2-fd0ebd19aaf8" class="">먼저, 앱에서 고객이 이자 조회 거래를 일으키면 채널계에서 MCI를 통한 기존 코어뱅킹 서버에 이자 조회 서비스를 호출하고, 동시에 이자 지급 마이크로 서버의 API를 호출했어요.</p><figure id="ea672055-a722-4298-9dbc-5b6b8d44fc68" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/ec6ef2bf-f775-4462-bee9-727aed79b0cc/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_80.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/ec6ef2bf-f775-4462-bee9-727aed79b0cc/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_80.png"/></a></figure><p id="ab130999-a687-4179-bd14-9e8803f418bf" class="">코어뱅킹 서버에서 리턴된 이자 값과 이자 지급 마이크로 서버에서 리턴된 이자 값을 각각 리턴 받아, 두 이자 값이 불일치할 경우 토스뱅크 내부 모니터링 채널에 해당 내용을 알림으로 받도록 했어요. 채널에 알림이 오면 대상 및 로그를 확인하고 원인을 확인하여 이자 계산 로직을 수정해주는 과정을 거쳤어요.</p><h1 id="bd39faa8-d9d7-439b-8945-f99c66a88e31" class=""><strong>두 번째 방법: 배치를 활용한 대량 검증 방식</strong></h1><p id="113eccaf-1ff3-47c5-a804-fb8d77addeb6" class="">다음은 배치를 활용한 대량 검증 방식입니다.</p><figure id="283a8580-7b78-473a-9c4a-f5e7d503623b" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/b6f1c5ba-6c1c-407e-8a5c-438b3a561482/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_85.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/b6f1c5ba-6c1c-407e-8a5c-438b3a561482/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_85.png"/></a></figure><ul id="ecd54b7d-92c9-4106-a1ff-8d0756e6780c" class="bulleted-list"><li style="list-style-type:disc">Staging 환경이란? 실제 운영환경과 동일하게 구성된 내부 API 테스트용 환경.</li></ul><p id="7f0b9e83-44ea-4852-939a-8d07d7e20e4c" class="">Staging 환경에서 채널계 배치를 활용해 매일 대량의 검증 대상 목록을 추출했고, 온라인 검증 방식과 동일하게 코어뱅킹 서버와 이자 지급 마이크로 서버를 각각 호출해주었어요. 대상 목록에 대한 검증이 모두 끝나면, 이자 리턴 값이 불일치했던 건들에 대한 내용을 담아 내부 모니터링 채널에 알림으로 받았고, 로직 수정을 반복해주었습니다.</p><p id="29551b07-fba0-403a-8990-1fa4a3bed617" class="">이렇게 저희는 두 가지 방식을 활용해서 이자 조회 거래에 대한 검증을 완료했습니다.</p><p id="fff0da17-e81c-4f5c-8dae-85b214bfdb11" class="">그런데 실제 이자를 지급받는 지금 이자 받기 거래의 경우 코어뱅킹 DB 원장에 잔액을 갱신하고 거래내역을 쌓고, 회계 처리를 해주는 등의 작업이 필요했기 때문에, 거래가 발생했을 때 실제 데이터가 정확하게 쌓이고 갱신되었는지 추가로 검증해야 했어요.</p><p id="70d3ceef-0b84-43e2-908d-e3c34ca8aada" class="">그래서 지금 이자 받기 거래의 데이터 정합성 검증을 위해, 상세한 도메인 기반의 테스트 시나리오를 작성했어요.</p><h1 id="ac6bbf98-fc77-42cb-b60c-1ce8239d4ae5" class=""><strong>테스트 시나리오 작성을 통한 E2E 통합 테스트 수행하기</strong></h1><p id="906aaf46-9271-46cb-933d-1d699813cf29" class="">토스뱅크 통장은 잔액을 구간별로 나누어 이자를 차등 지급하고 있는데요. 잔액 구간별로 나누어 차등 계산되어 이자가 지급되었는지 검증이 필요했어요.</p><figure id="7b563644-8ea4-4259-ab78-b194d5a4f30c" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/b5b51255-7acf-4eeb-b165-0be48fef6475/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_97.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/b5b51255-7acf-4eeb-b165-0be48fef6475/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_97.png"/></a></figure><p id="919509b2-1efe-4b56-a71e-0650007516fb" class="">그리고 명의도용, 해킹 피해, 사망 등 토스뱅크 고객의 상태에 따른 검증이 필요했고, 계좌의 상태 및 출금/입금 정지 상태에 따른 검증이 필요했죠.</p><p id="76deeb50-270a-42e1-adba-5fcaf0743aaf" class="">해당 검증 케이스들을 고려해서 테스트 시나리오를 수립했고, 케이스 별로 테스트를 진행하여 이자 계산 및 실제 DB에 데이터가 정확하게 갱신되었는지를 확인하며 로직을 수정해주는 과정을 거쳤습니다. 이 과정을 통해, 이자 받기 거래에 대한 정합성 검증을 완료할 수 있었어요.</p><h1 id="347a676c-ba0a-4988-9cbe-0eef6c9038cb" class=""><strong>순차 배포를 통한 안정적인 마이그레이션하기</strong></h1><p id="68a06c5f-8687-4663-b9d6-8ccbb5b317aa" class="">이제 API에 대한 검증은 완료되었으니, 코어뱅킹을 바라보던 서비스를 fade out 시키고 이자 지급 마이크로 서버 API만을 바라보도록 전환해줘야 했어요.</p><p id="b5cf912a-a01f-471e-88f4-1c4e86e84894" class="">API를 전환할 때 대상 모수를 점차 늘려가며, 순차적으로 오픈했는데요. 먼저 토스뱅크 수신개발팀에 오픈하여 직접 이자 받기 거래를 일으키며 데이터 결과값을 검증했어요. 특이사항이 없는 것을 확인하여 토스뱅크 내부 팀원에게 오픈하였고, 모니터링을 진행했어요.</p><figure id="190b4696-bb7a-403e-8d90-9d865135f2a4" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/09ebb73f-a31b-414d-8961-1cb8e2546c37/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_91.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/09ebb73f-a31b-414d-8961-1cb8e2546c37/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_91.png"/></a></figure><p id="17483792-abe5-46b6-a8ae-e239d2c65393" class="">다음으로는 일부 고객을 대상으로 오픈하고 점차 모수를 늘려가며 순차 오픈하여 전체 고객을 대상으로 전환을 완료하는 방식을 선택했습니다.</p><figure id="a94ce12f-21da-4bca-bb46-1efd77b5931b" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/a6d103ca-1016-4169-ba5e-b0b5c79971ea/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_99.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/a6d103ca-1016-4169-ba5e-b0b5c79971ea/slash23_%EC%9E%A5%EC%84%B8%EA%B2%BD%EC%A1%B0%EC%84%9C%ED%9D%AC_99.png"/></a></figure><p id="50dba07b-c23d-4f2b-af2e-ccc73a40d02d" class="">순차 배포 과정을 살펴보면, 코어뱅킹 서버를 바라보던 API 호출량과 이자 지급 마이크로 서버를 바라보던 API 호출량을 조절하여 이자 지급 마이크로 서버의 트래픽을 점차 늘려가는 형태로 진행했습니다.</p><p id="d583fb0e-9527-44de-bb97-fb61dd155440" class="">그렇게 저희는 순차 배포 방식을 채택 함으로써 기존에 운영하고 있던 시스템을 중단하지 않고도 안정적으로 시스템을 전환 할 수 있었어요.</p><p id="ef06d03d-7ec8-44c5-8e54-15abc70f1f38" class="">마지막으로 코어뱅킹 MSA 전환의 성과에 대해 공유 드리며, 이번 아티클을 마무리 해볼게요.</p><p id="352bacd4-d4e7-4957-9965-432913c22247" class=""><strong>코어뱅킹 MSA 전환의 성과</strong><br/>1. 코어뱅킹 시스템의 세대 전환<br/>2. 오픈소스 기반의 개발 환경 변화에 따른 유연성 및 확장성 증가<br/>3. 지금 이자 받기 거래의 성능 170배 개선<br/>4. 계정게 서버로부터 독립적인 서버를 구축함으로써 안정성 증가<br/>5. 지금 이자 받기 피크타임 트래픽에도 개별적으로 이자 지급 서버 스케일 아웃 가능<br/>6. 도메인 단위로 분리하여 효율적인 MSA 코어뱅킹 시스템 구축<br/>7. 빅뱅 배포 방식을 탈피하여 무중단 시스템 전환 가능<br/></p><figure id="7d71a898-5c8f-46fb-afac-93d07e3a464f"><a href="https://toss.tech/article/22563" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">은행 최초 코어뱅킹 MSA 전환기 (feat. 지금 이자 받기)</div><div class="bookmark-description">수십 년간 정체되어 있던 전통적인 은행 시스템의 모놀리식 소프트웨어 아키텍처를 MSA로 전환할 수 있을까요?  토스뱅크의 ‘코어뱅킹 MSA 전환’ 사례를 통해 향후 은행 시스템이 나아가야 할 방향을 소개합니다.</div></div><div class="bookmark-href"><img src="https://static.toss.im/tds/favicon/favicon-196x196.png" class="icon bookmark-icon"/>https://toss.tech/article/22563</div></div><img src="https://static.toss.im/career-resource/techblog_slash23_og_02.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="533c95fb-247c-44c2-add0-3ace4b85f65c" class="toggle"><li><details open=""><summary>Toss - 토스는 Gateway 이렇게 씁니다</summary><p id="9ec6be13-cc31-4ae3-9c25-fcdc438eaf15" class="">토스에서는 목적에 맞는 다양한 Gateway를 사용하고 있는데요. 저는 이번 글에서 이러한 Gateway 아키텍처를 통해 토스가 누리고 있는 장점들과 이를 위해 어떠한 노력을 하고 있는지에 대해 간단히 소개하려고 합니다.</p><h1 id="215b8984-7ee9-46a5-a7cc-0b0aee36ee9b" class=""><strong>Gateway 란?</strong></h1><p id="af5cff28-6510-4626-9cc2-90addb83a2b2" class="">우선 Gateway에 대해 간단히 알아보겠습니다. Gateway는 라우팅 및 프로토콜 변환을 담당하며 마이크로 서비스의 중개자 역할을 하는 서버입니다. 이를 통해 서비스는 클라이언트와 독립적으로 확장할 수 있으며 보안, 모니터링을 위한 단일 제어 지점을 제공합니다. Netflix Zuul을 통해 잘 알려졌으며 현재는 Saas나 플랫폼으로도 사용할 수 있게 대중화되었습니다.</p><p id="4953716b-d623-4a8e-aad8-1f54272e6a7a" class="">그림을 통해 예를 들어 보겠습니다. 서비스가 적고 트래픽이 적다면 클라이언트에서 서비스를 직접 호출하고 각각의 서비스에서 모든 로직을 처리해도 큰 부담이 되지는 않습니다. 그러나 스케일이 커지면 공통의 로직을 모든 서버에 적용하고 배포하는 것도 큰일이 됩니다.</p><figure id="d5e1c224-9e2a-4aff-885a-bd908b3e1138" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/1421525f-78ab-45f7-acf3-e1de50f5111c/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_05.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/1421525f-78ab-45f7-acf3-e1de50f5111c/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_05.png"/></a></figure><p id="7f05f55f-7c8d-46cc-be51-068bb33e107b" class="">서버가 무수히 많아지는 MSA 특성상 공통 로직을 서버마다 두기에는 어려움이 있다</p><p id="aed9887d-5cb6-4572-8249-4ab86073eb20" class="">이러한 필요성을 위해 개발된 게 Gateway 패턴입니다. Gateway는 서버들에서 필요한 공통 로직을 통합하여 처리합니다. 모든 서비스에서 필요한 유저 정보, 보안 정책 등을 Gateway에서 처리하고 이를 업스트림 서버로 넘겨줍니다.</p><figure id="b7497ed6-6aa4-43c4-82f2-b1de702afd89" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/59242743-0c5b-439a-84bc-18977cb97a2f/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_07.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/59242743-0c5b-439a-84bc-18977cb97a2f/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_07.png"/></a></figure><p id="f99cefcb-9771-45b5-80f8-c6897cbafe23" class="">Gateway 에서 요청을 1차로 받아서 공통 로직을 처리하고 서비스로 요청을 넘긴다</p><p id="90424730-8fbb-4eb4-8078-1e471aab3d28" class="">Gateway는 요청이 오면 정의된 설정에 따라 요청을 라우팅하고 사전에 설정된 필터들을 작동시킵니다. 설정은 Route 단위로 구성이 되며 Route는 다시 Predicate와 Filter로 구성됩니다. Predicate는 요청을 구분할 때 사용하는 값인데, Path, Method, Host 등으로 요청을 매칭하고 Filter는 매칭된 요청에 대한 전처리나 서비스의 응답에 대한 후처리를 구현합니다.</p><figure id="e68c90ae-b162-43a2-95d2-41e61ff7c9cd" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/ee00a05c-2f8a-4927-af98-4cb9e5ef5c18/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_08.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/ee00a05c-2f8a-4927-af98-4cb9e5ef5c18/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_08.png"/></a></figure><p id="e561a19c-7c23-4054-a91c-58f0b806301e" class="">저희는 이러한 Gateway 들을 Spring Cloud Gateway를 사용하여 구성하고 개발하고 있습니다. Spring Cloud Gateway는 스프링 Webflux를 통해 구현되어 있으며 내부적으로 Reactor-Netty를 사용하여 비동기 처리를 지원하고 있습니다. 또한 필터 개발에 Kotlin Coroutine을 적극 활용하고 있으며 Istio의 Ingress / Egress Gateway 및 Envoy 필터와 함께 유기적으로 개발하고 있습니다.</p><h1 id="e18d40f3-40b3-47cd-a299-0409fa53695f" class=""><strong>공통 로직 처리</strong></h1><p id="40b33b12-79ee-4ace-9327-fabe5324295c" class="">이제 앞에서 소개 드렸던 공통 로직들을 저희가 어떻게 개발하고 사용하고 있는지에 대해 간단히 소개해 드리겠습니다.</p><p id="9d820734-a5ea-4e17-9328-8864c4acab0a" class="">Gateway에서 공통 로직을 처리하는 부분은 크게</p><ul id="5608a954-cff4-4756-b661-44b54fc1cb4d" class="bulleted-list"><li style="list-style-type:disc">Request에 대한 전처리, 후처리</li></ul><ul id="a5df4805-350c-41e9-8183-cf2db484d0a6" class="bulleted-list"><li style="list-style-type:disc">유저 정보를 이용한 로직 수행</li></ul><ul id="80f6c36f-da4d-41fe-9496-571700f353c6" class="bulleted-list"><li style="list-style-type:disc">보안 그리고 서비스 안정화를 위한 설정</li></ul><p id="0fbd282d-086e-4a6a-a680-457531ef2333" class="">등이 있는데, 몇 가지 사례와 그림을 토대로 설명드리도록 하겠습니다.</p><h1 id="5751e34a-fa95-437d-ba80-a90a1988c561" class=""><strong>Sanitize</strong></h1><p id="c9fb5063-af91-4d4a-9005-8a477d370b1f" class="">우선 Request 처리입니다. Gateway에서 우선적으로 처리해 줘야 하는 것은 Request를 Sanitize 하는 것입니다. Sanitize는 Client로부터 올바르지 않은 요청이 올 경우 이를 지우거나 올바른 값으로 바꿔주는 것을 의미합니다. 그림처럼 사용자가 악의적으로 값을 주고 요청하더라도 Gateway에서 이를 올바른 값으로 바꿔서 서비스에 넘겨줍니다.</p><figure id="a2142253-d398-4f22-86e8-b531e0d40206" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/b18c45df-e996-44fc-8c82-a556e3a7d886/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_16.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/b18c45df-e996-44fc-8c82-a556e3a7d886/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_16.png"/></a></figure><h1 id="787f2b89-33bf-4157-b48c-993037e426bf" class=""><strong>유저 Passport</strong></h1><p id="8bccb3c3-1a77-4a85-aa7c-dc2cd597abbd" class="">토스 내부 서비스들도 기존에는 모든 서비스에서 유저 정보가 필요할 때 유저 API를 호출하는 방식으로 유저 정보를 가져오고 있었는데요 이는 트랜잭션 내에 불필요한 중복 요청을 유발하고 서버 리소스의 낭비로 이어졌습니다. 이를 개선하기 위해 저희는 Netflix의 Passport 구조를 참고하였습니다.</p><p id="60ef490e-7b44-4802-a958-5cbda003f2c0" class="">Netflix는 유저 인증 시에 Passport 라는 id 토큰을 트랜잭션 내로 전파하는 방법을 사용하고 있는데요. 저희는 Netflix의 Passport 구조를 저희 팀에 맞게 변경하여 토스 Passport를 구현했습니다.</p><p id="e3b6680b-953d-4de6-9087-6a1619abfeaf" class="">Passport는 사용자 기기 정보와 유저 정보를 담은 하나의 토큰인데요. 앱에서 유저 식별키와 함께 API를 요청하게 되면 Gateway에서 이 키를 토대로 인증 서버에 Passport를 요청합니다. Passport에는 디바이스 정보와 유저 정보가 담겨 있으며 Gateway는 이를 serialize 하여 서비스에 전파합니다. 유저 정보가 필요한 서비스는 유저 정보 호출 없이 Passport 정보를 통하여 유저에 대한 정보를 사용할 수 있습니다.</p><figure id="0f697b38-74b9-46cf-b129-e6cc519a176e" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/5749635d-598a-4579-8076-12a9805e072d/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_21.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/5749635d-598a-4579-8076-12a9805e072d/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_21.png"/></a></figure><p id="41180ea3-37b4-4cc3-9275-32c30b7fabdd" class="">트랜잭션 내에서 마치 여권처럼 사용자 정보를 들고 다니게 됩니다.</p><h1 id="6b0a2225-1b42-4713-9f08-84f5b84cd9d2" class=""><strong>보안과 안정성</strong></h1><p id="8d62c9ea-4ebe-4a27-a154-b4740d9632d4" class="">토스는 금융 앱인 만큼 높은 수준의 보안 요구사항이 존재합니다. 저희는 Gateway에서 이러한 요구사항을 만족하기 위하여 다양한 보안 로직을 수행하고 있는데요. 아래에서는 Gateway가 핵심적으로 수행하고 있는 부분을 몇 가지 소개해 드리겠습니다.</p><h1 id="ed17268f-e8ff-4ee1-981a-b0b6c944440e" class=""><strong>종단간 암호화</strong></h1><p id="4ee5d7f2-bfd9-4e05-b4d2-bb72c7ce9305" class="">토스 앱에서 사용하고 있는 대부분의 API는 종단간 암호화를 통해 패킷 분석의 허들을 높여 안전하게 정보를 전달하고 있습니다. 앱에서 암호화 키를 사용하여 요청 바디를 암호화하고 Gateway에서 이를 복호화 하여 서비스에 전달합니다. 복호화 과정에서 인증 / 인가 로직이 처리되고 복호화 된 데이터와 유저 정보를 서비스로 넘겨주게 됩니다. Gateway에서 이 과정을 전부 처리하기 때문에 서비스에서는 편하고 안전하게 사용자의 요청을 처리할 수 있게 됩니다.</p><figure id="bfb8ce9f-4261-46ca-9423-89b40306e1c6" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/2c4c8402-9dbf-4733-a7e2-9b5976d43384/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_23.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/2c4c8402-9dbf-4733-a7e2-9b5976d43384/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_23.png"/></a></figure><h1 id="9643cb7f-59c6-4497-9828-aac5009c96d4" class=""><strong>Dynamic Security</strong></h1><p id="cc98a3e7-a4fb-499a-bd66-8e379e790795" class="">토스는 위에서 말한 인증 / 인가를 넘어서 각 요청이 실제로 위변조 되지 않은 토스 앱에서 만들어진 요청인 지도 검증을 합니다. 토스 앱은 내부적으로 매 요청을 서명할 아주 짧은 유효기간을 가진 안전한 키 값과 변조되지 않은 토스 앱에서만 알 수 있는 정보를 활용하여 각 요청을 서명하고 이를 Gateway로 보내게 됩니다.</p><p id="9d987b30-540a-4191-8340-91283b1e625d" class="">Gateway에서는 각 요청에 들어있는 서명 값을 통해서 토스 앱에서 만들어진 요청인지, 중복해서 사용되지 않았는지, 그리고 유효기간이 만료된 키로 만들어지진 않았는지 검증하여 앱 위변조, delayed request, replaying attack을 방지하고 의심스러운 요청이 발견되면 FDS(fraud detection system)를 통해 계정을 비활성화하여 사용자를 안전하게 보호하고 있습니다.</p><figure id="6580154f-cae5-43dc-a3f6-5a83793e0076" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/b4cfb15c-e2ca-4cbb-90e0-4618f1464c8a/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_26.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/b4cfb15c-e2ca-4cbb-90e0-4618f1464c8a/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_26.png"/></a></figure><h1 id="ee9743d8-023a-4dc5-9108-72ea41fc417e" class=""><strong>인증서를 이용한 인증 / 인가</strong></h1><p id="790ca5b5-d42a-4f1c-bef4-1b718f8aa406" class="">Gateway에서는 토스 앱 뿐만 아니라 외부 회사나 내부 개발자의 서비스 호출을 위해 클라이언트 인증서를 이용한 mTLS API 호출도 지원하고 있습니다. 기본적으로 Istio에서 제공하는 mTLS flow 위에 Gateway 애플리케이션을 두어 인증 / 인가 처리를 하고 있습니다. Istio 만 이용하여 인증/인가를 처리할 수도 있지만 코드 베이스의 애플리케이션이 Istio의 matching rule보다 자유도도 높고, Auditing 등의 로직을 처리할 수 있으며 카나리 배포의 이점을 누릴 수 있기 때문에 Gateway에서 인증 / 인가 처리를 담당하게 되었습니다.</p><figure id="65ecbdc5-f8f7-4870-8738-fe6026763cfd" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/70a44aba-41e7-467d-93be-bccdbe6e7f37/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_28.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/70a44aba-41e7-467d-93be-bccdbe6e7f37/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_28.png"/></a></figure><p id="b3f9bff9-976f-4ad9-9985-73d469c497ca" class="">Edge에서 Istio는 Client 인증서의 CA 유효성을 확인한 후, 해당 인증서 정보를 헤더에 실어서 모든 트래픽을 Gateway에 전달해 줍니다. 이렇게 받은 인증서를 Decode 하여 X.509 extensions 중 <strong>Subject Alternative Name</strong>을 활용하여 인증서로부터 사용자 정보를 얻게 됩니다. 이렇게 얻은 사용자 정보와 도착지 호스트 및 요청 경로를 활용하여 각 요청에 대한 인증 / 인가 및 Auditing 처리를 하고 있습니다.</p><figure id="41a70237-1adb-4115-8625-12d3f66e7a41" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/3f075816-dd04-4e67-9d57-88058a8c25b1/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_30.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/3f075816-dd04-4e67-9d57-88058a8c25b1/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_30.png"/></a></figure><h1 id="348b89a8-5fcf-452c-9919-b4eac8e70b64" class=""><strong>Circuit breaker</strong></h1><p id="815e043b-99b8-4b96-b413-4ec9d4565f67" class="">사용하는 마이크로 서비스 아키텍처 패턴은 많은 서비스들이 거미줄처럼 서로 상호작용을 하고 있습니다. 따라서 그중 하나의 서비스에서 응답 지연이 발생하면, 해당 서비스에 의존하는 수많은 서비스들에게 응답 지연이 전파됩니다. 이렇게 퍼져 나간 응답 지연이 시스템의 자원을 점유하여 모든 시스템이 먹통이 되는 상황이 발생합니다. 이를 방지하기 위해서는 응답 지연을 유발하는 서비스에게 요청을 더 이상 보내지 않고 빠르게 실패하게 하여 부하를 겪고 있는 서비스가 회복할 수 있게 돕고, 이러한 응답 지연이 전체 서비스로 확산되지 않게 하는 것이 중요합니다. 이를 서킷 브레이크 라고 부릅니다.</p><figure id="be6b78ba-0730-4e8f-b5c5-5faf4dbd3c4f" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/a8e37529-2688-46a3-a22d-395238268282/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_35.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/a8e37529-2688-46a3-a22d-395238268282/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_35.png"/></a></figure><p id="accf8630-7ee7-4d41-9e6e-4674606f656b" class="">또한 내부 서비스 간의 서킷 브레이킹도 중요하지만 근원적인 트래픽을 발생시키는 Client에게 백프레셔를 빠르게 주기 위해서는 Gateway에서 서킷 브레이킹을 거는 것이 중요합니다. 서킷 브레이크를 적용하는 방법에는 Istio를 활용한 인프라 레이어의 서킷 브레이킹 혹은 Resilience4J나 Hystrix와 같은 라이브러리를 이용한 애플리케이션 레이어의 서킷 브레이킹이 있습니다.</p><p id="4d8dfcbd-59dd-4470-be90-03a67cadc4d9" class="">각 방법에는 장단점이 존재하는데요, Istio를 활용한다면 호스트 단위로 쉽고 빠르게 전체 적용이 가능하며 애플리케이션의 개발 주기와 독립적으로 관리될 수 있다는 장점이 있지만 Istio는 호스트 단위로만 서킷 브레이킹 설정이 가능하며, 설정할 수 있는 룰에도 한계가 있습니다.</p><p id="e2c162d2-9490-4ec7-83e3-f5c7380c6af7" class="">따라서 토스에서는 보이는 것 같이 각 애플리케이션이나 Gateway에 서킷 브레이킹을 적용함으로써 호스트나 Route 단위 혹은 기능단위로 정교하게 서킷 브레이킹을 걸고 있습니다.</p><h1 id="dab3721c-9042-49d2-9c62-f9bc0d3e1e6d" class=""><strong>모니터링</strong></h1><p id="9b1c55fb-f143-46b4-b8e8-3a6ac43e55bd" class="">Gateway는 토스의 모든 서비스가 거치는 컴포넌트인 만큼 보다 꼼꼼한 모니터링이 필요합니다. 모니터링에 중요한 요소로는 로깅, 메트릭, 트레이싱이 있는데요, 저희 팀에서 각각 어떻게 기록하고 모니터링하는지 소개하겠습니다.</p><h1 id="a041e412-b3c0-4e52-a107-e10ef224d8ba" class=""><strong>로깅</strong></h1><p id="de4c00be-477e-4035-9ca2-2b78fdd077ac" class="">저희는 Gateway를 지나는 모든 요청, 응답의 Route id와 method, URI, 상태 코드 등을 Elasticsearch에 남기고 있습니다.</p><p id="d4d1318b-c4a0-41cd-b438-dc2fb1c6f285" class="">덕분에 요청이 어떤 Route로 들어왔는지, 업스트림으로 어떤 URI를 호출했는지에 대한 정보를 바로 확인할 수 있습니다.</p><figure id="03fee583-ca2a-4304-9fb0-1072c5a9bcde" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/83bfd396-ca89-45c3-9386-860c2d69121a/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_54.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/83bfd396-ca89-45c3-9386-860c2d69121a/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_54.png"/></a></figure><h1 id="b9d849bb-be16-4108-9e97-6579dd863ae6" class=""><strong>메트릭</strong></h1><p id="02fbd512-8fef-44fc-9b15-86a527b7012c" class="">다음은 메트릭입니다. 메트릭에는 크게 시스템에서 수집하는 메트릭과 애플리케이션에서 수집하는 메트릭이 있습니다. 두 메트릭 모두 Prometheus가 수집하는데요, Node Exporter를 통해 수집된 시스템 메트릭과 Spring의 actuator를 통해 수집된 애플리케이션 메트릭을 Grafana를 이용해 시각화하고 슬랙으로 알림을 보내고 있습니다.</p><figure id="f48470de-e992-43f6-9844-79f4dfd673ff" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/a88b9fe4-b029-4abf-8644-a0a548ea2120/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_57.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/a88b9fe4-b029-4abf-8644-a0a548ea2120/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_57.png"/></a></figure><p id="7f216e49-2972-49cb-8ff1-1d3f8a6f46ab" class="">시스템 메트릭에는 CPU, memory, 네트워크 RX, TX 트래픽 등이 포함되어 애플리케이션 수정 사항이 시스템에 주는 영향을 1차로 파악할 수 있고, 문제가 생기는 경우 현상과 원인 파악에 활용할 수 있습니다.</p><figure id="aa6655b4-4256-4e06-8710-2a5b9a069efd" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/e7057903-8559-4865-90ee-97487356e2e0/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_58.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/e7057903-8559-4865-90ee-97487356e2e0/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_58.png"/></a></figure><p id="b66f4f71-13dd-4966-b98e-f00d84e61e8a" class="">애플리케이션 메트릭에서는 JVM thread block 상황이나 세대별 메모리 할당을 파악하고 full GC 발생 여부 등을 확인하고 있습니다.</p><figure id="782ea5e6-ecfb-4b72-aabe-046ec102b78c" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/d950a08a-3141-4452-8748-e1a184a71e9e/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_60.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/d950a08a-3141-4452-8748-e1a184a71e9e/slash23_%EC%B5%9C%EC%A4%80%EC%9A%B0_60.png"/></a></figure><p id="290bdd6a-be51-4b43-aa7c-54dade872979" class="">Spring Cloud Gateway에서는 Route 별 메트릭도 제공하는데요, 저희는 여기에 Path 값을 더해 API Path 별 Route 메트릭을 확인하기도 합니다.</p><h1 id="6b7a7e5f-5ffe-4a64-b688-69e0b72b926b" class=""><strong>마무리</strong></h1><p id="48ff964b-6ab4-461a-8fbc-045bbe245c61" class="">토스팀에서 Gateway를 사용하여 해결하고 있는 몇 가지 사례에 대해 소개해 드렸습니다. 사례들처럼, Gateway는 외부에 노출되는 엔드포인트에 대해 중앙 집중식으로 관리할 수 있도록 도와줍니다. 이를 통해 트래픽을 모니터링하고 속도를 제한하거나 요청 및 응답을 요구사항에 맞게 수정하는 등 거대한 마이크로 서비스 아키텍처 클러스터를 보다 쉽게 확장, 관리 및 모니터링 할 수 있도록 합니다.</p><p id="9abfdb42-4f3b-4a7c-b6bc-c9cc4e64d7ea" class="">위 글을 통해 Gateway 사용에 많은 인사이트를 얻으셨길 바라면서 소개 드린 사례들 외에도 더 많은 사례들을 보고 싶으시다면 SLASH23 영상도 같이 보시는 것도 좋을 것 같습니다.</p><p id="4710bd05-02cc-4a11-80bc-9dac0f0965cc" class="">
</p><figure id="91fdd0b7-1375-4d92-a07b-4f2d0a7a797b"><a href="https://toss.tech/article/slash23-server" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">토스는 Gateway 이렇게 씁니다</div><div class="bookmark-description">더 안전하고 안정적인 서비스 운영을 위해서 ‘gateway’를 어떻게 사용해야 할까요?  토스의 수많은 마이크로서비스 로직을 공통화하기 위한 gateway 운영 방법에 대해 소개합니다.</div></div><div class="bookmark-href"><img src="https://static.toss.im/tds/favicon/favicon-196x196.png" class="icon bookmark-icon"/>https://toss.tech/article/slash23-server</div></div><img src="https://static.toss.im/career-resource/techblog_slash23_og_05_최준우.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="7b8395ed-66a8-44f1-a8f2-f93b056673f9" class="toggle"><li><details open=""><summary>Oauth2</summary><h1 id="9c8dd22a-2c9a-4845-b90e-b6d039cc4afe" class=""><strong>Oauth2 인증과정</strong></h1><p id="1938afd7-7895-41cc-adb3-860092529de6" class="">먼저 일반적인 Oauth2 인증과정이 어떻게 일어나는지 알아보도록 하겠습니다.</p><figure id="99378e9a-dac3-4623-839f-b676d53af56d" class="image"><a href="https://taes-k.github.io/images//posts/trick_basic/2019-06-20-spring-msa-4/1.png"><img src="https://taes-k.github.io/images//posts/trick_basic/2019-06-20-spring-msa-4/1.png"/></a></figure><p id="115467a8-1bc4-4ed8-8487-ca4bffade078" class="">위의 다이어그램에서 확인 할수있듯이 먼저, 인증서버로부터 토큰을 발급받아 API Gateway로 Token을 포함시켜 요청하게되면 API Gateway에서는 요청 api를 매칭하여 받은 토큰을 함께 보내주게됩니다. 이과정을 relay token이라고 지칭합니다. 이후 토큰과 request를 받은 api 서버는 해당 토큰이 유효한 토큰인지를 확인하기위해 인증 서버로 토큰을 보내 확인후, 유효한 토큰이라면 설정에 따라 결과를 반환해 줍니다.</p><p id="8582959e-b6f3-406e-8fab-5a457615138b" class="">위 과정중 마지막 4번 단계에서 토큰을 다시 인증서버로 보내 재 인증하는 과정이 나오는데, 이는 JWT(Json Web Token)의 사용으로 인증과정을 조금더 간편하게 만들어 줄 수 있습니다. JWT는 필요한 정보를 자체적으로 지닌상태로 암호화된 토큰 입니다. JWT를 사용한 인증과정은 다음과 같습니다.</p><figure id="09e93efc-c2bf-42b9-9f96-f72c3bec9f27" class="image"><a href="https://taes-k.github.io/images//posts/trick_basic/2019-06-20-spring-msa-4/2.png"><img src="https://taes-k.github.io/images//posts/trick_basic/2019-06-20-spring-msa-4/2.png"/></a></figure><p id="56e8695f-06bd-4a2a-a439-ec547cc881fc" class="">이번 MSA 예제 프로젝트의 인증과정은 위와같이 JWT를 사용하여 구현해보도록 하겠습니다.</p><p id="ce95d4be-69c6-40b8-b206-ae0a781a917d" class="">
</p><figure id="11dd188a-42b5-45d0-a0a1-eb7b6844bb2c" class="image"><a href="https://blog.kakaocdn.net/dn/baYmz0/btrm5yf1gRK/UaARAdK34RDK6XyjFFkRS1/img.png"><img src="https://blog.kakaocdn.net/dn/baYmz0/btrm5yf1gRK/UaARAdK34RDK6XyjFFkRS1/img.png"/></a></figure><p id="e4fee890-9604-4627-afb2-53e92b6cd2ed" class="">출처:</p><p id="582d5587-44ee-4357-92c7-3078785805e4" class=""><a href="https://inpa.tistory.com/entry/WEB-%F0%9F%93%9A-OAuth-20-%EA%B0%9C%EB%85%90-%F0%9F%92%AF-%EC%A0%95%EB%A6%AC">https://inpa.tistory.com/entry/WEB-📚-OAuth-20-개념-💯-정리</a></p><p id="bf6b1eb4-bdb0-46fa-a7cf-2f9ec3ba771b" class="">
</p></details></li></ul><ul id="2fe67696-5f60-40d4-94ca-23ec0ea2dca7" class="toggle"><li><details open=""><summary>Oauth2</summary><h2 id="f82f67cf-62c1-470b-8828-3e7473a5b7ae" class="">✏️ OAuth 프로토콜이란?</h2><p id="abfa8c70-b55b-461b-a6b5-b389a7a607f9" class="">우리가 웹 서비스를 개발할 때 인증 과정을 어떻게 구현할 것인가는 항상 중요한 문제가 됩니다.</p><p id="94faccb7-7cae-48dd-a4c9-1a5dac7ad737" class="">인증은 보안에 있어서 가장 핵심적인 문제이기 때문에, 개발자 입장에서는 심혈을 기울여서 설계를 해야합니다 🤔</p><p id="89281c78-d748-4dcf-80aa-b4b46a4aed3a" class="">OAuth 는 이러한 개발자의 고민을 해결해줍니다.</p><blockquote id="723d826c-67da-40b5-86d3-8fe9fdf4cd1c" class="">OAuth 2.0(Open Authorization 2.0) 은 인증을 위한 개방향 표준 프로토콜 입니다.</blockquote><p id="2dd7755d-e151-44b9-842c-7b3d3884d235" class="">요즘 우리가 사용하는 대다수의 웹 서비스는 로그인 시 <em><strong>외부 소셜 계정</strong></em>을 기반으로 간편하게 인증하는 인증 서비스를 제공합니다 🧑🏼‍💻</p><p id="40d59b06-b699-4e6d-8486-a2ad0db12a02" class="">카카오, 구글, 페이스북 등 자신이 해당 플렛폼의 계정을 갖고만 있다면 손쉽게 로그인이 가능합니다.</p><p id="9e25eb8a-e6aa-4816-9f87-426607bc6dbf" class="">이렇게 Third-Party 프로그램(우리가 개발하는 웹) 이 Client를 대신해 리소스 서버에서 제공하는 자원에 대한 접근 권한을 위임받는 방식을 OAuth 방식이라고 합니다 💡</p><blockquote id="646821f8-c242-4173-a71a-acc8f17ce227" class="">이번 포스팅에서는 현재 가장 최신 버전인 OAuth 2.0을 기준으로 설명합니다 ❗️</blockquote><h2 id="78df576b-34b1-47de-b103-2c231276d3f6" class="">✏️ OAuth 2.0 주체</h2><p id="4594b808-87c4-4bb5-a009-8ca069c8d1ec" class="">OAuth 동작 원리를 본격적으로 알아보기 전에 관련 용어를 공부해보겠습니다.</p><p id="2de25836-4eb0-4665-b962-dc1362d34315" class="">1) <strong>Resource Owner</strong></p><p id="c04d1a73-4b98-47a3-a4a6-70610d2f35d8" class="">리소스 소유자를 말합니다.</p><p id="3251ef82-112a-49ac-95da-bad3147a8367" class="">여기서 리소스란 외부 소셜 서비스(API)를 이야기합니다.</p><p id="c15884bb-feb0-4f27-b8cf-7c27958cb887" class="">즉 해당 플랫폼에서 리소스를 소유하고 있는 사용자를 의미합니다.</p><p id="52f1ecf7-4f6a-428e-9e1e-12891d61a40a" class="">우리의 웹 서비스를 이용하는 유저를 의미하는거겠죠? 🙆🏻</p><p id="89c38ad7-698d-4483-b79e-092fad25abc9" class="">2) <strong>Authorization Server</strong></p><p id="e4dce284-7ffb-49cf-9c71-c90ea06cc8d5" class="">Authorization Server는 Resource Owner를 인증하고, 우리가 개발한 웹 서비스에게 Access Token을 발급해주는 서버입니다.</p><p id="13224e01-5d35-4c2c-99fb-4fb9eac106d8" class="">즉 외부 플랫폼 리소스에 접근할 수 있는지 인증을 하는 서버를 의미합니다 👨‍💻</p><p id="5526c6a2-623a-4cf4-b255-4465d74ab83d" class="">3) <strong>Resource Server</strong></p><p id="2c29caef-ae87-43c0-b80b-3043f0ef4fa0" class="">구글,페이스북, 카카오와 같이 보호되는 리소스를 가지는 서버를 말합니다 ✅</p><p id="723c6063-c8a7-4243-8d08-3de7194c74c6" class="">4) <strong>Client</strong></p><p id="a48a470f-9af8-4db6-94e3-ba40af57a8f0" class="">개인적으로 Client 라는 용어가 가장 이해하기 어려웠습니다.</p><p id="b0bc68b1-c2cc-4097-b88d-2f12ab04c8ef" class="">Client란 Resource Owner 를 대신해 Authorization Server &amp; Resource Server 에 접근하는 주체입니다.</p><p id="ebc6c34d-fb1b-4271-8dcc-d9e803debde7" class="">우리가 개발하려는 서비스가 되겠죠?</p><p id="09ffa108-11e7-4114-a257-406f1eb3233e" class="">우리가 개발하려는 서비스를 Client라고 정의한 이유는 우리 서비스가 Authorization Server &amp; Resource Server 입장에서 클라이언트이기 때문입니다 ✔️</p><h2 id="234b0633-efa7-4c9d-ac5b-76632877b833" class="">✏️ OAuth 2.0 동작 매커니즘</h2><p id="c8018e9a-355a-425d-86ae-bf24e8795b02" class="">OAuth 2.0 동작 원리를 알아보기 전에 선행되어야 할 것이 있습니다.</p><p id="33014d77-8e39-44dd-97aa-1dbc5d320b7b" class="">우리가 개발하려는 웹 서비스(Client) 를 Resource Server 에 등록해야 합니다 🎮</p><p id="0b27a1c8-7da4-4f91-99e7-b70cdf166da1" class="">이때 Redirect URI도 함께 등록해야 하는데, 해당 위치는 사용자가 OAuth 2.0 서비스에서 인증을 마치고 리다이렉션 시킬 위치입니다.</p><p id="2f48643e-ab73-482a-b81c-ab709dcdd56b" class="">웹 서비스 등록을 성공적으로 마치면, <strong>Client ID 와 Client Secret 을 얻을 수 있습니다.</strong></p><p id="4f99443f-a452-48e4-9528-bcd7cb16d689" class="">두 정보는 추후 Access Token을 획득하는데 중요한 역할을 함으로, 외부로 유출되어서는 안됩니다 ⛔️</p><figure id="8376d067-1ac9-4628-aa73-8ee60ce0231f" class="image"><a href="https://velog.velcdn.com/images/choidongkuen/post/85655c10-d631-40be-9cfc-f1bc7894cca2/image.png"><img src="https://velog.velcdn.com/images/choidongkuen/post/85655c10-d631-40be-9cfc-f1bc7894cca2/image.png"/></a></figure><p id="dc1e4961-338a-4755-8d00-a0cec5bbba0e" class="">해당 이미지는 OAuth 2.0 동작과정 시퀀스 다이어그램 입니다.</p><h3 id="ac0189f2-704c-4266-9fc5-306bc541a093" class="">📌 1 ~ 2. 로그인 요청</h3><p id="85f867ec-a517-43c3-b449-aacd03acfc7b" class="">Resource Owner가 우리가 설계한 서비스의 &#x27;카카오로 로그인하기&#x27; 등의 버튼을 클릭해 로그인을 요청합니다.</p><p id="6aab9bdd-421e-4d7c-ba30-6b57eddc06f1" class="">Client는 OAuth 프로세스를 시작하기 위해 Resource Owner의 브라우저를 Authorization Server로 보냅니다.</p><p id="22825aad-ff40-4b37-b72d-9426d848b2fb" class="">Client는 이때 Authorization URL에 response_type, client_id, redirect_uri, scope 등의 매개변수를 쿼리 스트링으로 포함하여 보냅니다 🧑🏼‍💻</p><ul id="9bbb8fda-ba3b-47c2-93d8-d080da64fb6f" class="bulleted-list"><li style="list-style-type:disc">response_type : 반드시 code로 값을 성정해야 합니다.<p id="a28fac72-bfbb-4cca-9be2-faa7d309f538" class="">인증이 성공할 경우 Client는 후술할 Authorization Code를 받습니다.</p></li></ul><ul id="0b76ea78-aeb8-457a-a2bb-d5fc9ed7739b" class="bulleted-list"><li style="list-style-type:disc">client_id : 웹 서비스를 Resource Server에 등록했을 때 발급받은 Client ID을 의미합니다.</li></ul><ul id="3e0fe774-936f-4668-84c5-b26c586a1649" class="bulleted-list"><li style="list-style-type:disc">redirect_uri : 웹 서비스를 Resource Server에 등록했을 때 등록한 redirect URI을 의미합니다.</li></ul><ul id="bcbba3f7-d609-4b68-8bcd-6b3e4a5f6037" class="bulleted-list"><li style="list-style-type:disc">scope : Client가 부여받은 리소스 접근 권한을 의미합니다.</li></ul><h3 id="bc7237cc-106b-48d0-a503-22abbca28d47" class="">📌 3 ~ 4. 로그인 페이지 제공 및 ID/PW 입력</h3><p id="1aa1498b-afd2-49ac-aefe-bd4730dc5fbc" class="">Client 로부터 Authorization URL로 이동된 Resource Owner는 제공된 로그인 페이지에서 ID/PW을 입력하여 인증을 할 것입니다.</p><h3 id="fc571818-3d0c-4d04-b8f7-7a5987076881" class="">📌 5 ~ 6. Authorization Code 발급 및 Redirect URI로 리다이렉트</h3><p id="a23b99b6-4490-477e-9773-35ba424103d4" class="">Authorization URL에서 인증이 성공했다면, Authorization server는 기존에 설정한 Redirect URL에 <strong>Authorization Code</strong> 를 포함하여 사용자를 리다이렉션 시킵니다.</p><p id="43e0dc62-96f8-4d4f-9f5b-3a3642b7e30a" class=""><strong>Authorization code</strong>란 리소스 접근을 위한 Access Token을 획득하기 위해 사용하는 임시 코드이며, 수명은 매우 짧습니다 🧑🏼‍💻</p><h3 id="952b392b-d89c-49ff-805a-7653e04e97c3" class="">📌 7 ~ 8. Authorization Code와 Access Token 발급</h3><p id="8f517266-de9e-4062-858e-2d7ebebea7fe" class="">Client는 다시 Authorization Server에 Authorization Code를 전달하고, Access Token을 발급받습니다.</p><p id="b67b1b3a-3c9a-4d8b-9ab8-0cf8389af59b" class="">Client는 자신이 발급받은 Resource Owner의 Access Token을 데이터베이스에 저장하고, 이후 Resource Server에서 Resource Owner의 리소스에 접근하기 위해 Access Token을 사용합니다 🧑🏼‍💻</p><p id="13e988f4-199b-486d-97ca-6057012edd35" class="">Access Token은 절때 유출되서는 안됩니다 ⛔️</p><h3 id="870018c1-6210-4c97-9451-ecc1106ac903" class="">📌 9. 로그인 성공</h3><p id="5a94a3d2-8b0a-4ff4-9ff1-809c0d131238" class="">위 과정을 모두 성공적으로 마치면 Client는 Resource Owner에게 로그인이 성공하였음을 알립니다.</p><p id="677ed317-d897-4180-8532-a20c285c67d8" class="">이제 Access Token을 가지고 접근 가능한 Resource 에 접근할 수 있습니다 🙌</p><h3 id="0d7367fb-32e9-4757-995c-b32120e11e95" class="">📌 10 ~ 13. 서비스 요청 및 Access Token을 이용하여 리소스 접근 및 이용</h3><p id="32e6c89b-40d1-4914-af81-ae4da0a090ee" class="">이제 Access Token을 발급 받았기 때문에 정해진 Scope 내에서 다양한 리소스를 이용 할 수 있습니다 💡</p><h2 id="889af4e5-98c7-4d4f-907f-e38d85dafb1d" class="">✏️ OAuth 2.0 Scope 란?</h2><p id="fde9a776-b562-47d8-907b-387297bb48ec" class="">앞에 설명한 OAuth 2.0 동작 원리에서 처음 로그인 요청시 scope를 정할 수 있다고 했습니다.</p><p id="00bac26c-bdc3-4848-b6b8-1a10b680735d" class="">scope란 Client가 사용 가능한 Resource 접근 범위를 제한하는 것입니다.</p><p id="a7fb63b1-ee29-434d-82ce-0442acdc1b0a" class="">예를 들어 구글 플렛폼을 Resource Server로 사용할 때, 사용자의 연락처를 받아오고 싶다면,</p><p id="6d93c031-5337-4733-aed5-24903e90ea90" class="">scope에 연락처 scope 문자열을 포함하여 서버에 요청하면 됩니다 💪</p><p id="eb0f34ba-0986-4004-9fc3-132ca50d28c5" class="">이러한 방식으로 발급된 Access Token은 Scope 정보를 가지고 있어 권한을 제한합니다 ❗️</p><h2 id="61cec3dc-29d0-4db5-82b5-cd696552d7cc" class="">✏️ OAuth 2.0 에서 백엔드와 프론트엔드</h2><p id="fae38ab8-2d9f-4bd7-9d64-a09486a3513a" class="">우리가 개발하는 웹 서비스(Client)에서도 백엔드와 프론트엔드의 역할을 나누어야 합니다.</p><p id="2015e4f5-aaea-4aef-bf65-b332eceb8af2" class="">Client가 인증을 위해 Authorization URL을 통해 Authorization Server로 이동할 때 해당 URL은 누가 생성할까요? 🤔</p><p id="06968570-d8c1-4bbb-b6bc-8ab11fa580b1" class="">백엔드 프론트엔드 어느곳에서나 생성해도 정상적인 동작에 지장은 없지만, Client ID , Scope와 같은 정보들은 백엔드 쪽에서 가지고 있기 때문에 응집도 측면에서 백엔드에서 생성하는것이 좋습니다 👍</p><p id="472a7866-f01f-40bd-9781-6ed1368a583c" class="">이렇게 생성한 Authorization URL을 프론트엔드가 가져와 사용자를 Authorization Server로 리다이렉 시킵니다.</p><p id="745e4a13-6b3a-4ad3-bd67-c2b92eace7a7" class="">인증을 모두 마치면 지정한 Redirect URL로 돌아옵니다. 보통 Redirect URL 은 프론트쪽으로 설정합니다.</p><p id="43036f60-d58e-4b86-937c-c5fa09635c0e" class="">이때 Authorization Code와 함께 온다고 말했었죠?</p><p id="e16e44af-2ea6-4f95-b80a-1d3fa65bd762" class="">Authorization Code를 받은 프론트엔드는 다시 해당 Code를 백엔드 API를 통해 백엔드 쪽으로 보냅니다.</p><p id="25468b1e-d099-4559-82b2-c8d72b827cb8" class="">그러면 백엔드는 Authorization Code, Client ID, Client Secret 등으로 Access Token을 받습니다 🧑🏼‍💻</p><p id="ad8bf2f7-1580-4d60-8204-9aa71d32ff1e" class="">[프론트 &amp; 백 역할 정리]</p><ul id="e82f3a20-5923-4576-b566-c7c48d5f4b80" class="bulleted-list"><li style="list-style-type:disc">Authorization URL 은 Client 백엔드가 생성한다.</li></ul><ul id="c51cf030-f1f7-44a4-ba1c-45c6dc38a0a8" class="bulleted-list"><li style="list-style-type:disc">Client 프론트단은 해당 URL을 리다이렉트 시켜 브라우저가 인증을 가능하게 하도록 한다.</li></ul><ul id="efefedce-e786-4ba8-aa15-4d0277c59474" class="bulleted-list"><li style="list-style-type:disc">인증 결과로 받은 Authorization Code는 Client 프론트단에서 받는다.</li></ul><ul id="a31d8d01-64dc-40b6-880d-a6c2c6fccd11" class="bulleted-list"><li style="list-style-type:disc">프론트단은 Authorization Code를 백단으로 다시 보낸다.</li></ul><ul id="11db28af-34a6-4756-bf21-c4670ecf6cca" class="bulleted-list"><li style="list-style-type:disc">백단에서 Authorization Code와 더불어 다양한 정보로 Authorization Server 로부터 Access Token을 발급 받는다.</li></ul></details></li></ul><ul id="da77b0c7-0171-4e47-bdb4-47196e271e4b" class="toggle"><li><details open=""><summary>Payco OAuth 2.0 인증 </summary><h3 id="0981fe27-1030-483c-b93c-e3fb759154d1" class="">OAuth 2.0 인증 과정</h3><figure id="cdb5501e-341f-413e-aa80-bfdc6a8136c9" class="image"><a href="https://velog.velcdn.com/images/hyg8702/post/e6b2e207-4866-4c11-85d4-078cac9bd97d/image.png"><img src="https://velog.velcdn.com/images/hyg8702/post/e6b2e207-4866-4c11-85d4-078cac9bd97d/image.png"/></a></figure><h3 id="d0bf5b3d-8771-4b26-a56f-14d07c617efa" class="">OAuth 2.0 프로세스</h3><figure id="9571f510-e2e8-43f4-beab-27f11f05c170" class="image"><a href="https://velog.velcdn.com/images/hyg8702/post/58d06586-9b3e-46c6-82ba-59d79e8527d2/image.png"><img src="https://velog.velcdn.com/images/hyg8702/post/58d06586-9b3e-46c6-82ba-59d79e8527d2/image.png"/></a></figure><p id="b7f1db0d-b0dd-4e5d-af3b-a802e03e4536" class="">사진 출처: 페이코 개발자센터 OAuth 2.0 프로세스</p><p id="a1efad8b-8c9c-40a8-a834-63224c11641c" class="">1-5 단계는 Authorization Code 발급 요청 URL을 통해 진행</p><p id="5f622949-3ddb-498d-a485-964e65a0b4a0" class="">7-8 단계는 서비스에서 callbackURL을 통해 전달받은 Authorization Code를 사용하여 Access Token을 요청 API를 통해 진행</p><p id="b260e838-ac6c-4735-ac16-bbb30e75ff66" class="">8단계에서 발급받은 Access Token은 서비스에 자체적으로 저장, 관리</p><p id="944644cb-7940-4209-b61e-0470dd7e9ad4" class="">10-11단계 사용자의 서비스 요청시 회원정보가 필요하다면 AccessToken을 통해 API를 호출할 수 있습니다.</p><h2 id="3b68b4b9-4b86-4c1b-bf74-cca274a7a754" class="">🕒 인증 종류</h2><h3 id="9d78f76a-fd63-4fa7-8e23-40e50ed86ef1" class="">📌1. Authorization Code Grant</h3><ul id="0f51b0ce-92f2-4f8c-85a2-1d95df420bb7" class="bulleted-list"><li style="list-style-type:disc">서버 사이트 코드로 인증하는 방식</li></ul><ul id="77b6ad39-ceb6-4a27-b198-ff640a046fe7" class="bulleted-list"><li style="list-style-type:disc">권한 서버가 클라이언트와 리소스서버간의 중재 역할</li></ul><ul id="3b8c9c56-def4-4a2d-bacb-71d4fc9ba235" class="bulleted-list"><li style="list-style-type:disc">AccessToken을 바로 클라이언트로 전달하지 않아 잠재적 유출을 방지</li></ul><ul id="07ba27e0-8f2a-47f5-bdac-405ce34368f2" class="bulleted-list"><li style="list-style-type:disc">로그인시에 페이지에 URL에 <code>response-type=code</code> 라고 넘김</li></ul><h3 id="cf7e2c10-e041-4d8c-ba9c-69c93919438f" class="">📌2. Implicit Grant</h3><ul id="df67da5d-a10f-458a-a60c-2304dcb85efd" class="bulleted-list"><li style="list-style-type:disc">token과 scope에 대한 스펙 등은 다르지만 OAuth1.0과 가장 비슷한 인증 방식</li></ul><ul id="0d531035-22af-4054-81c3-40f9f1a931ed" class="bulleted-list"><li style="list-style-type:disc">Public Client인 브라우저 기반의 애플리케이션이나 모바일 애플리케이션에서 이 방식을 사용하면 된다.</li></ul><ul id="131a6902-f1a2-4563-ae53-333d6f8c44f6" class="bulleted-list"><li style="list-style-type:disc">OAuth 2.0에서 가장 많이 사용되는 방식</li></ul><ul id="3c0debe5-5155-44df-9e5b-9c2e660ddd95" class="bulleted-list"><li style="list-style-type:disc">권한 코드 없이 바로 발급돼서 보안에 취약</li></ul><ul id="4f47bfb2-c1bd-4775-8834-76eb791e35e5" class="bulleted-list"><li style="list-style-type:disc">주로 Read Only인 서비스에 사용</li></ul><ul id="91f681c4-f5d3-4e1e-a36e-96be97a28e8d" class="bulleted-list"><li style="list-style-type:disc">로그인시에 페이지 URL에 <code>response_type=token</code> 라고 넘김</li></ul><h3 id="068a4eac-9c91-4b7b-9dff-146470a44193" class="">📌3. Password Credentials Grant</h3><ul id="2a41805c-0073-459b-9e4c-61d35281feb3" class="bulleted-list"><li style="list-style-type:disc">Client에 ID/PW를 저장해 놓고, ID/PW로 직접 accesstoken을 받아오는 방식</li></ul><ul id="1019462a-b209-4ba9-9a0e-c04b245be12a" class="bulleted-list"><li style="list-style-type:disc">Client를 믿을 수 없을 때에는 사용하기 위험해 APi 서비스의 공식 어플리케이션이나 믿을 수 있는 Client에 한해서 사용하는 것을 추천</li></ul><ul id="0ba8c2f2-90a9-4b70-ba9d-bb99eba59fd1" class="bulleted-list"><li style="list-style-type:disc">로그인시에 API에 POST로 <code>grant_type=credentails</code>라고 넘김</li></ul><h3 id="67e55dbe-54d9-4f31-9093-9e3b5e32ed26" class="">📌4. Client Credentails Grant</h3><ul id="75cb05b0-188b-4e3f-8fcd-a3e186eef6e2" class="bulleted-list"><li style="list-style-type:disc">어플리케이션이 Confidentail Client일 때, ID와 Secret을 가지고 인증하는 방식이다.</li></ul><ul id="f4679073-062a-4c08-9518-7c82ab640377" class="bulleted-list"><li style="list-style-type:disc">로그인시에 API에 POST로 <code>grant_type=client_credentails</code>라고 넘김</li></ul><h2 id="71c037c2-99db-4a23-879f-578639bf92e0" class="">🕓 Token</h2><h3 id="823be5b6-fd00-469e-a909-4871acfc67dd" class="">📌Access Token</h3><p id="5b022760-5661-4524-996a-4a11a629fb45" class="">앞서 말한 4가지 방식 모두 정상적인 인증을 마치면 Access Token이 발급됩니다. 이 Token은 보호된 리소스에 접근할 때 권한 확인용으로 사용됩니다. 계정 ID와 PW 등 계정 인증에 필요한 형태들을 Token으로 표현함으로써, 리소스 서버는 여러 가지 인증 방식에 각각 대응 하지 않아도 권한을 확인 할 수 있게 됩니다.</p><h3 id="eae98530-7856-4da8-933d-ca94cc52e5b7" class="">📌Refresh Token</h3><p id="6eb698aa-1567-4c7a-8a4d-fbea79b3bed4" class="">한번 발급받은 Access Token 은 사용할 수 있는 시간이 제한되어 있습니다. Access Token이 만료되면, 새로운 Access Token을 얻어야 하는데 그때 Refresh Token 이 활용됩니다.</p><p id="7816e59b-ce64-4a39-aba7-ecf74c83ba7f" class="">권한 서버가 Access Token 을 발급해주는 시점에 Refresh Token 도 함께 발급하여 주기 때문에, 다른 절차 없이 Refresh Token을 미리 가지고 있습니다. 단 권한 서버에서만 활용되며 리소스 서버에는 전송되지 않습니다.</p><h3 id="eceefc57-069e-4bc3-9cd2-7c5424b121b6" class="">📌토큰의 갱신 과정</h3><p id="833b5ace-9aa9-4b63-867e-ef8eb85b6dc5" class="">시간이 흐른 후 Access Token이 만료되면, 리소스 서버는 이후 요청들에 대해 오류를 응답하게 됩니다. Client는, 받아 두었던 Refresh Token을 권한 서버에 보내어 새로운 Access Token을 요청합니다. 갱신 요청을 받은 권한 서버는 Refresh Token의 유효성을 검증한 후, 문제가 없다면 새로운 액세스 토큰을 발급해줍니다. 이 과정에서 옵션에 따라 Refresh Token 도 새롭게 발급 될 수 있습니다</p><h3 id="fd2b94aa-6ceb-4fd3-bf9d-a6bc87c9e288" class="">🔅레퍼런스</h3><ul id="c1a21726-01c6-4024-92b6-925dcd39ac15" class="bulleted-list"><li style="list-style-type:disc">Naver D2: <a href="https://d2.naver.com/helloworld/24942">https://d2.naver.com/helloworld/24942</a></li></ul><ul id="4796cfc8-62a5-4294-b30c-4cb4f8dbed71" class="bulleted-list"><li style="list-style-type:disc">HMAC: <a href="https://ko.wikipedia.org/wiki/HMAC">https://ko.wikipedia.org/wiki/HMAC</a></li></ul><ul id="200131e7-0365-45b5-9abe-81df83728e7a" class="bulleted-list"><li style="list-style-type:disc">호우의 블로그: <a href="https://showerbugs.github.io/2017-11-16/OAuth-%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C">https://showerbugs.github.io/2017-11-16/OAuth-%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C</a></li></ul><ul id="f80d723b-2604-4e6c-9d11-3d5314e3906a" class="bulleted-list"><li style="list-style-type:disc">PAYCO 개발자센터: <a href="https://developers.payco.com/guide/development/apply/web">https://developers.payco.com/guide/development/apply/web</a></li></ul><p id="718742cb-3025-4db9-a158-efe84af3a180" class=""><strong><a href="https://velog.io/@hyg8702/posts">석준</a></strong></p><p id="2befb393-5904-4697-979e-bae9da002428" class="">
</p></details></li></ul><ul id="e17e0739-bf87-412a-b672-d077f51c554e" class="toggle"><li><details open=""><summary>API Gateway 인증</summary><figure id="e709edeb-e2cb-4901-a134-69b381e82533"><a href="https://saysimple.tistory.com/161" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">API Gateway를 이용한 인증과정</div><div class="bookmark-description">API Gateway의 목적 MSA(Micro Service Architecture)로 서비스를 만들 때 가장 중요한 요소 중 하나로, 서버 앞에서 이들의 기능을 적절하게 라우팅해주기 위해 사용된다. 일반적으로 JSON/REST 기반으로 구성되어 최소한의(해야만 하는 일만 하는) 기능만 하도록 한다. AWS에서 제공하는 API Gateway 도식표 (출처 : Amazon Web Service) AWS의 경우에는 REST 뿐만 아니라 스트리밍 데이터에 적합한 Websocket 형식의 API Gateway도 제공하고 있다. 인증(Authentication) 및 인가(Authorization)에서의 API Gateway 1. 인증과 인가 간단하게 다시 되집어보면 아래와 같다. 인증 : 유저의 정보를 확인, 유..</div></div><div class="bookmark-href"><img src="https://saysimple.tistory.com/favicon.ico" class="icon bookmark-icon"/>https://saysimple.tistory.com/161</div></div><img src="https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FccYa3P%2FbtsFRjSBc5U%2FXOsjq2V4YKf9xNt5lnrLuK%2Fimg.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="5b6f1aca-12e5-4b07-8f00-c7bb3bad7829" class="toggle"><li><details open=""><summary>Kafka IDC 이중화</summary><p id="5f42ee43-3c72-4aef-bb0b-c1c0473f615f" class="">Kafka Connect와 Offset Sync는 여러 IDC에 걸쳐 고가용성 Kafka 클러스터를 구성하는 데 매우 효과적인 도구입니다. 이를 통해 데이터 손실 없이 안정적으로 데이터를 복제하고, 장애 발생 시 신속하게 복구할 수 있습니다. 적절한 구성과 관리 도구를 사용하여 네트워크 지연 및 보안 문제를 해결하면, 대규모 분산 시스템에서의 안정성과 가용성을 향상시킬 수 있습니다</p><figure id="cecdef34-6af0-4537-862c-b9302bca8b02" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.35.23.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.35.23.png"/></a></figure><figure id="3bb8afc2-b533-4053-8189-14f1478b4d22" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.36.16.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.36.16.png"/></a></figure><figure id="7316066b-e64e-4b6c-a612-121283342ab8" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.37.35.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.37.35.png"/></a></figure><figure id="f1d65914-9dcd-4063-8e97-47eb7515e7f7" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.38.16.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.38.16.png"/></a></figure></details></li></ul><ul id="13f408dd-ad5f-440e-bb54-14233ef85c0d" class="toggle"><li><details open=""><summary>Kafka 개요</summary><p id="69c7761c-600f-4166-8d38-877b09ed8856" class="">메시지 지향 미들웨어(Message Oriented Middleward: MOM)은 비동기 메시지를 사용하는 각각의 응용프로그램 사이의 데이터 송수신을 의미하고, 이를 구현한 시스템을 메시지 큐(Message Queue: MQ)라고 합니다.</p><h3 id="ca7a121c-c6fe-46a3-b551-d0d39f9fd0db" class=""><strong>메시지큐를 왜 사용할까?</strong></h3><p id="ffebfdc1-6aff-4757-a04e-208e94dc4059" class="">메시지 큐를 사용하면 발신자와 수신자가 서로를 직접 알 필요 없으므로 <strong>느슨한 결합(decoupling)</strong>을 만들어낼 수 있다. 발신자, 수신자 서로가 서로에게 의존하지 않으므로, 각자는 <strong>독립적으로 확장(scalable)</strong>될 수 있다. N:1:M 의 형태로 발신자, 수신자 사이에 메시지 큐가 메시지를 중개하기 때문이다.</p><p id="18c28122-5d49-41bd-9210-7c75eec59c66" class="">또한 수신자 서비스가 당장 장애 상황이더라도 발행된 메시지는 모두 메시지 큐에 남아있으므로 결국 발신자가 발생한 모든 메시지는 소비자 서비스에게 전달된다는 <strong>보장성(guarantees)</strong>를 갖는다. 이러한 여러 특성으로 메시지 큐는 여러 마이크로 서비스가 서로 협력하는 MSA 환경에서 빛을 발한다.</p><p id="1126e2a4-bc86-406f-9cd3-b62256f7f453" class="">메시지 큐를 사용하면 <strong>비동기 통신(asynchronous)</strong>을 구현할 수 있다. A 서비스와 B 서비스가 통신을 한다고 가정해보자. A가 B를 HTTP 통신을 통해 request 한다면, A는 B로부터 동기적으로 response를 기다릴 것이다. 반면 A가 메시지를 메시지 큐에 발행하고, B가 그 메시지를 가져가는 방식으로 통신한다면 비동기적으로 통신이 이루어질 수 있다. 이런 특성으로 메시지 큐는 이미지 프로세싱과 같이 <strong>굉장히 무거운 작업을 요청</strong>하거나, 혹은 이벤트 드리븐 아키텍처에서 <strong>이벤트가 발생했음을 알리기 위한 용도</strong>로 사용하기 적합하다.</p><p id="7384f35b-679b-4ff3-9dee-c98d06d099ca" class="">
</p><p id="c7b5b251-3881-453d-8795-18bf6ddb98fd" class="">많이 사용하는 오픈소스 MQ로는 <span style="border-bottom:0.05em solid">RabbitMQ, ActiveMQ, RedisQueue</span>등이 있습니다.</p><p id="a21b591d-ca6a-4721-9b46-e745f81061dc" class="">Kafka는 <strong>이벤트 스트리밍 플랫픔</strong>으로서, 여러가지 작업을 할 수 있고 MQ처럼 <strong>메시지 브로커 역할</strong>을 할 수 있도록 구현하여 사용할 수도 있으며 기존 범용 메시지브로커들과 비교했을 때 아래와 같은 특징이 있습니다.</p><ul id="c9b03aff-03a6-415f-9e81-6d912208f225" class="bulleted-list"><li style="list-style-type:disc">대용량의 실시간 로그 처리에 특화되어 있어 TPS가 우수하다.</li></ul><ul id="37d9343e-f5b9-4431-8004-40cfacb1b634" class="bulleted-list"><li style="list-style-type:disc">분산 처리에 효과적으로 설계되어 병렬처리와 확장(Scaleout), 고가용성(HA)에 용이하다.</li></ul><ul id="58f175c7-e454-49c1-97b4-8207713bf9e2" class="bulleted-list"><li style="list-style-type:disc">발행/구독(Publish-Subscribe) 모델 (Push-Pull 구조)<ul id="8a6e9493-b8bb-4b26-a42d-1328532c018a" class="bulleted-list"><li style="list-style-type:circle">메시지를 받기를 원하는 컨슈머가 해당 <strong>토픽(topic)</strong>을 구독함으로써 메시지를 읽어오는 구조</li></ul><ul id="82c18cc1-865e-4f8b-8b4b-d629efdef2f7" class="bulleted-list"><li style="list-style-type:circle">기존에 퍼블리셔나 브로커 중심적인 브로커 메시지와 다릴 똑똑한 컨슈머 중심</li></ul><ul id="d8dd085a-9d85-49a7-b3b2-f92550d0e86f" class="bulleted-list"><li style="list-style-type:circle">브로커의 역할이 줄어들기 때문에 좋은 성능을 기대할 수 있게 됨</li></ul></li></ul><ul id="f62e0ec1-8660-4c72-bda0-6738bc26ad25" class="bulleted-list"><li style="list-style-type:disc"><strong>파일 시스템에 메시지를 저장</strong>함으로써 영속성(durability)가 보장됨.<ul id="40305ae5-c6c5-46e1-a6a7-8c4e0af44a18" class="bulleted-list"><li style="list-style-type:circle">장애시 데이터 유실 복구 가능</li></ul><ul id="62588476-f542-4d0a-8dce-d17e86b98dda" class="bulleted-list"><li style="list-style-type:circle">메시지가 많이 쌓여도 성능이 크게 저하되지 않음</li></ul><ul id="bf3eceae-2f1f-4df7-a7bc-30eb7c989e0c" class="bulleted-list"><li style="list-style-type:circle">대규모 처리를 위한 batch 작업 용이</li></ul><p id="53dda5a6-ddc0-4b7a-b083-c496f8318d5c" class="">
</p></li></ul><p id="cb4feafa-dc4c-4311-8e2d-2d448972f4ca" class=""><strong><a href="https://hyunseo-fullstackdiary.tistory.com/418#%EC%A-%BC%EC%-A%--%--%EA%B-%-C%EB%--%--%--%EB%B-%-F%--%EC%-A%A-%EC%--%B-">주요 개념 및 용어</a></strong></p><figure id="72a74356-4b54-4270-98e4-e5c42ac136f9" class="image"><a href="https://blog.kakaocdn.net/dn/bsNeKp/btsrBPEcm0Z/UVhAcA6fVIqxV5fGt9sI2K/img.png"><img style="width:700px" src="https://blog.kakaocdn.net/dn/bsNeKp/btsrBPEcm0Z/UVhAcA6fVIqxV5fGt9sI2K/img.png"/></a></figure><ul id="8a336a9c-c846-4395-84a7-0cfaad1135e3" class="bulleted-list"><li style="list-style-type:disc"><strong>KafkaCluster</strong>: 카프카 브로커들의 모임. Kafka는 확장성과 고가용성을 위해서 broker들이 클러스터로 구성됩니다.</li></ul><ul id="2568d0cd-e253-4fc7-8b38-4a59173a994d" class="bulleted-list"><li style="list-style-type:disc"><strong>Broker:</strong> 각각의 카프카 서버</li></ul><ul id="05da0717-031b-4c5d-a137-bfb9809f2e38" class="bulleted-list"><li style="list-style-type:disc"><strong>ZooKeeper:</strong> 카프카 클로스터 정보 및 분산처리 관리 등 메타데이터 저장. 카프카를 띄우기 위해 반드시 실행되어야 합니다.</li></ul><ul id="ddd8772f-a922-46a0-9398-560227454d29" class="bulleted-list"><li style="list-style-type:disc"><strong>Producer:</strong> 메시지(이벤트)를 발행하여 생산하는 주체</li></ul><ul id="13d34348-11d6-46e5-99f1-2a6e756b7801" class="bulleted-list"><li style="list-style-type:disc"><strong>Consumer:</strong> 메시지(이벤트)를 구독하여 소비하는 주체</li></ul><p id="a837dd97-df57-4eaf-84ed-a775308bc6a8" class="">
</p><p id="f6f09446-bc4d-41cb-859d-3fa613780ce5" class=""><strong><a href="https://hyunseo-fullstackdiary.tistory.com/418#%ED%--%A-%ED%--%BD%-C%--%ED%-C%-C%ED%-B%B-%EC%--%--%-C%--%EC%--%A-%ED%--%--%EC%--%-B">토픽, 파티션, 오프셋</a></strong></p><figure id="a3d8edf8-1ac8-45ba-a124-371318037f87" class="image"><a href="https://blog.kakaocdn.net/dn/dkyqS4/btsrvZnKqma/tRzxVI5PFfqDldT122ONIK/img.png"><img style="width:700px" src="https://blog.kakaocdn.net/dn/dkyqS4/btsrvZnKqma/tRzxVI5PFfqDldT122ONIK/img.png"/></a></figure><p id="c9e33420-71b3-4769-8735-2e0516137984" class="">카프카에 저장되는 메시지는 <strong><span style="border-bottom:0.05em solid">topic</span></strong>으로 분류, topic은 여러개의 <strong><span style="border-bottom:0.05em solid">partition</span></strong>으로 나누어집니다.</p><ul id="66be2ebc-739f-4838-bd38-4f637070bdbd" class="bulleted-list"><li style="list-style-type:disc"><strong>Topic:</strong> 메시지를 구분하는 단위<ul id="7d487da7-ff8b-4ed1-8c9c-49b11ff9d562" class="bulleted-list"><li style="list-style-type:circle">파일시스템의 폴더, 메일함과 유사함 ex)주문용 토픽, 결제용 토픽 등</li></ul></li></ul><ul id="403db10d-40de-43d1-9b12-5db29bf76779" class="bulleted-list"><li style="list-style-type:disc"><strong>Partition:</strong> 메시지를 저장하는 물리적인 파일<ul id="fa7abed9-fffb-4d05-9237-3dcde839af74" class="bulleted-list"><li style="list-style-type:circle">한 개의 토픽은 한 개 이상의 파티션으로 구성됨.</li></ul><ul id="c762e6ec-d588-4900-bc62-d2aa6de40fda" class="bulleted-list"><li style="list-style-type:circle">파티션은 메시지 추가만 가능한 파일(append-only)</li></ul></li></ul><ul id="157355ba-9a19-4217-a28a-6e89d44a2a56" class="bulleted-list"><li style="list-style-type:disc"><strong>offset:</strong> 파티션내 각 메시지의 저장된 상대적 위치</li></ul><ul id="d30918e2-3159-464b-ab5b-e38b07e6d0a6" class="bulleted-list"><li style="list-style-type:disc">프로듀서가 넣은 메시지는 파티션의 맨 뒤에 추가 (Queue)</li></ul><ul id="4ead9a7f-91d2-4fa1-9bab-ab7183e0b221" class="bulleted-list"><li style="list-style-type:disc">컨슈머는 오프셋 기주으로 마지막 커밋 시점부터 메시지를 순서대로 읽어서 처리함</li></ul><ul id="023f3620-af5e-482b-81d0-57d6ae874268" class="bulleted-list"><li style="list-style-type:disc">파티션의 메시지 파일은 처리 후에도 계쏙 저장되어 있으며 설정에 따라 일정시간 뒤에 삭제됨.</li></ul><p id="b4fbb938-82b3-4c87-bb01-111de915372d" class="">
</p></details></li></ul><ul id="3f1052b5-fd3e-41da-b7f9-5cc6139f513a" class="toggle"><li><details open=""><summary>kafka 데이터 신뢰성 보장</summary><p id="292fb381-31f4-41ac-bec7-8b51b0b44ac2" class="">Apache Kafka를 활용한 이벤트 기반 아키텍처는 마이크로서비스, 데이터 스트리밍, 실시간 분석 등 다양한 분야에서 광범위하게 사용되고 있습니다. Kafka는 분산 스트리밍 플랫폼으로서 대용량 데이터의 실시간 처리를 위해 설계되었습니다. 이 아키텍처는 시스템의 유연성, 확장성, 가용성을 향상시키는 데 중요한 역할을 합니다.</p><p id="e4b363a7-1975-4ad4-a2ef-d0dfda46ff5b" class="">다음은 Kafka를 활용한 이벤트 기반 아키텍처 구축 방법을 상세하게 설명한 내용입니다.</p><h2 id="b6faf85a-ca7b-46ad-a42c-d7abd3522c57" class="">1. 이벤트 기반 아키텍처의 개념</h2><h3 id="5acc13f2-a43b-488a-a11c-83743338cd14" class="">1.1 정의</h3><p id="a190c874-75eb-4b97-b61d-739c69291a02" class="">이벤트 기반 아키텍처는 시스템 내의 모든 상태 변경을 이벤트로 간주하고, 이러한 이벤트를 발행하여 다른 서비스가 이를 구독하고 처리할 수 있도록 하는 아키텍처 스타일입니다. 이벤트는 시스템에서 발생하는 중요한 상태 변경이나 액션을 나타내며, 이를 통해 시스템 간의 통합과 확장성을 쉽게 구현할 수 있습니다.</p><h3 id="d8ae6957-758b-44e8-b4f7-b5fd0f3473da" class="">1.2 장점</h3><ul id="ace20bbb-a3c6-4220-9049-1ebd1a9f50d9" class="bulleted-list"><li style="list-style-type:disc"><strong>확장성</strong>: 이벤트를 통해 시스템을 쉽게 확장할 수 있으며, 서비스 간의 의존성을 줄일 수 있습니다.</li></ul><ul id="77c53e87-1e85-44ea-8606-15f104fcd6ce" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 처리</strong>: 이벤트가 발생하는 즉시 처리가 가능하므로 실시간 데이터 처리에 유리합니다.</li></ul><ul id="32935200-b6ab-46e5-975d-5ff522484bf7" class="bulleted-list"><li style="list-style-type:disc"><strong>유연성</strong>: 새로운 서비스나 기능을 추가할 때 기존 시스템에 최소한의 영향을 미칩니다.</li></ul><ul id="500d9fda-cbd1-443d-a265-2600d92b0e8c" class="bulleted-list"><li style="list-style-type:disc"><strong>모듈성</strong>: 서비스 간의 결합도가 낮아져 유지 보수와 관리가 용이합니다.</li></ul><h2 id="a297b31b-edb5-449a-a338-9c194f0ee2e0" class="">2. Apache Kafka의 역할</h2><h3 id="02404ebb-9c2f-47fe-bdac-26d4221ef6bb" class="">2.1 Kafka의 개념</h3><p id="c311bcab-0557-4ede-843d-452c7cf6591e" class="">Apache Kafka는 분산 스트리밍 플랫폼으로, 주로 다음과 같은 목적으로 사용됩니다.</p><ul id="e01183fd-9a03-4055-b4d5-4fbce2660163" class="bulleted-list"><li style="list-style-type:disc"><strong>이벤트 스트리밍</strong>: 실시간 데이터 스트리밍 및 이벤트 처리.</li></ul><ul id="9ef937a2-3eee-4731-967b-8b5c88370ad2" class="bulleted-list"><li style="list-style-type:disc"><strong>메시지 큐</strong>: 시스템 간의 메시지 교환 및 통합.</li></ul><ul id="0c598d30-24e5-4a2a-b221-01eae8dd037f" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 파이프라인</strong>: 대용량 데이터의 처리 및 이동.</li></ul><h3 id="f86a6e39-99eb-4112-ba95-22e211061431" class="">2.2 Kafka의 구성 요소</h3><ul id="b228e5ec-e565-426b-a004-8f78040a987f" class="bulleted-list"><li style="list-style-type:disc"><strong>Producer</strong>: 이벤트나 메시지를 생성하여 Kafka에 발행하는 역할을 합니다.</li></ul><ul id="58cabc6b-5d47-4e46-af4c-d2ab6822b2f8" class="bulleted-list"><li style="list-style-type:disc"><strong>Consumer</strong>: Kafka로부터 이벤트나 메시지를 구독하여 처리하는 역할을 합니다.</li></ul><ul id="f24627dd-c8fd-427d-9e72-9adc47c07367" class="bulleted-list"><li style="list-style-type:disc"><strong>Broker</strong>: 이벤트나 메시지를 저장하고 관리하는 Kafka의 서버입니다.</li></ul><ul id="c8d33eb3-f0a2-4cc4-bc6d-e386f49ee2e6" class="bulleted-list"><li style="list-style-type:disc"><strong>Topic</strong>: 이벤트나 메시지를 카테고리별로 분류하여 저장하는 논리적 단위입니다.</li></ul><ul id="ee255e97-2272-4f1a-a679-5d645053cd70" class="bulleted-list"><li style="list-style-type:disc"><strong>Partition</strong>: 하나의 Topic을 여러 분할된 파티션으로 구성하여 확장성과 고가용성을 제공합니다.</li></ul><ul id="e46ab521-3591-44f0-9c5b-6aea07cc5c68" class="bulleted-list"><li style="list-style-type:disc"><strong>Consumer Group</strong>: 여러 Consumer가 하나의 그룹을 이루어 Topic의 파티션을 병렬로 처리할 수 있도록 합니다.</li></ul><h2 id="7c3532e0-6126-40fa-abf6-916cf2b448c3" class="">3. Kafka를 활용한 이벤트 기반 아키텍처 구축 방법</h2><h3 id="6bfc81aa-d742-4b23-91fb-d7973780d2d9" class="">3.1 시스템 요구사항 분석</h3><p id="b2557b54-676c-4fa5-9f40-25d2b98680b5" class="">Kafka를 활용한 이벤트 기반 아키텍처를 구축하기 전에 시스템의 요구사항을 분석해야 합니다. 다음과 같은 질문을 고려합니다.</p><ul id="db3aff67-65c8-4d8a-9063-6b5f2922343c" class="bulleted-list"><li style="list-style-type:disc">어떤 종류의 이벤트가 발생하는가?</li></ul><ul id="720c7981-8d1f-4c3d-aa50-6752d33f5866" class="bulleted-list"><li style="list-style-type:disc">이벤트의 생산자(Producer)와 소비자(Consumer)는 누구인가?</li></ul><ul id="b44f38dc-b763-4c84-8103-ae34b40c97a4" class="bulleted-list"><li style="list-style-type:disc">이벤트의 처리 우선순위와 시점은 어떻게 되는가?</li></ul><ul id="88b38221-ec66-4eb2-8bff-4fd79c898294" class="bulleted-list"><li style="list-style-type:disc">이벤트의 일관성과 신뢰성은 어떻게 보장할 것인가?</li></ul><ul id="7d798c60-c3cd-4240-96ed-66f1856dbb83" class="bulleted-list"><li style="list-style-type:disc">시스템의 확장성과 가용성 요구사항은 무엇인가?</li></ul><h3 id="be41f0b6-86dc-4979-8046-7238ddf989e9" class="">3.2 Kafka 클러스터 설정</h3><h3 id="d095d29a-a3da-4d0f-8f26-257645e89f34" class="">Kafka 브로커 설치 및 구성</h3><ol type="1" id="5283c944-8efe-42b6-b829-94ee6815159f" class="numbered-list" start="1"><li><strong>다운로드 및 설치</strong>: Apache Kafka의 최신 버전을 다운로드하여 설치합니다.</li></ol><ol type="1" id="ad049481-9e4c-43fd-8a38-69796359019d" class="numbered-list" start="2"><li><strong>구성 파일 편집</strong>: <code>server.properties</code> 파일을 편집하여 Kafka 브로커의 설정을 구성합니다.<ul id="6664d40b-4d4f-48f0-a3aa-ea423b246e44" class="bulleted-list"><li style="list-style-type:disc"><code>broker.id</code>: 브로커의 고유 ID를 설정합니다.</li></ul><ul id="52795a91-a2f4-4c87-bdad-89eac5f22025" class="bulleted-list"><li style="list-style-type:disc"><code>zookeeper.connect</code>: Kafka와 Zookeeper 간의 연결 설정을 지정합니다.</li></ul><ul id="dd662e2c-8edf-4151-88e8-158bfaa92607" class="bulleted-list"><li style="list-style-type:disc"><code>log.dirs</code>: Kafka 로그 파일의 저장 경로를 지정합니다.</li></ul></li></ol><ol type="1" id="ae92e7d2-aee2-43ce-aabd-b64bc4deae3f" class="numbered-list" start="3"><li><strong>브로커 시작</strong>: Kafka 브로커를 시작합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="123c5145-7a7f-49c3-944c-3f877e873676" class="code"><code class="language-Shell" style="white-space:pre-wrap;word-break:break-all">bash코드 복사
bin/kafka-server-start.sh config/server.properties</code></pre></li></ol><h3 id="708fde6e-30af-46dc-a9df-4111795450a8" class="">Zookeeper 설치 및 구성</h3><p id="55479a88-19b0-4eab-bb7c-2f8282f51741" class="">Kafka는 분산 시스템의 조정 서비스를 위해 Zookeeper를 사용합니다.</p><ol type="1" id="245c213a-99d6-4064-872b-e62a232394e4" class="numbered-list" start="1"><li><strong>다운로드 및 설치</strong>: Apache Zookeeper의 최신 버전을 다운로드하여 설치합니다.</li></ol><ol type="1" id="378a69f4-5a5a-4668-a1ba-e1f6b90998ee" class="numbered-list" start="2"><li><strong>구성 파일 편집</strong>: <code>zoo.cfg</code> 파일을 편집하여 Zookeeper의 설정을 구성합니다.<ul id="0443a210-70f7-4144-ae5c-96760ed7f55f" class="bulleted-list"><li style="list-style-type:disc"><code>tickTime</code>: Zookeeper의 기본 시간 단위를 설정합니다.</li></ul><ul id="815d1b2b-2f3e-4909-8630-84c1a5275f8d" class="bulleted-list"><li style="list-style-type:disc"><code>dataDir</code>: Zookeeper 데이터의 저장 경로를 지정합니다.</li></ul><ul id="118ba2b4-f782-4eb3-ad1f-56799e47a760" class="bulleted-list"><li style="list-style-type:disc"><code>clientPort</code>: 클라이언트가 연결할 포트를 지정합니다.</li></ul></li></ol><ol type="1" id="4f266325-e5e1-47f7-9931-d01f9b05ee16" class="numbered-list" start="3"><li><strong>Zookeeper 시작</strong>: Zookeeper 서비스를 시작합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="990019cb-c134-4390-a714-7090635b0971" class="code"><code class="language-Shell" style="white-space:pre-wrap;word-break:break-all">bash코드 복사
bin/zkServer.sh start</code></pre></li></ol><h3 id="dbd2be34-be61-455a-8472-08ca236156a5" class="">3.3 이벤트 주제(Topic) 설계</h3><p id="bdb248a9-5293-4bf1-8d4c-9013048b7114" class="">이벤트를 카테고리별로 분류하기 위해 적절한 Topic을 설계해야 합니다.</p><ol type="1" id="d8e27a9b-ca51-4370-9c97-c4d97982438b" class="numbered-list" start="1"><li><strong>Topic 생성</strong>: 필요에 따라 다양한 Topic을 생성합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="eb0804be-0b6d-4f57-b388-41e78cea1c5f" class="code"><code class="language-Shell" style="white-space:pre-wrap;word-break:break-all">bash코드 복사
bin/kafka-topics.sh --create --topic my_topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 2</code></pre></li></ol><ol type="1" id="f56cab0c-0fb7-449d-b1b5-5d4795421c2e" class="numbered-list" start="2"><li><strong>파티셔닝 전략</strong>: 각 Topic의 파티션 수를 결정합니다. 파티션 수는 시스템의 부하 및 확장성 요구사항에 따라 조정할 수 있습니다.</li></ol><ol type="1" id="2ef98cdd-eb18-491b-a0a5-2daf3aa719d8" class="numbered-list" start="3"><li><strong>복제 전략</strong>: Topic의 복제 수를 결정하여 고가용성을 확보합니다.</li></ol><h3 id="960abf81-f307-4941-a0a1-38af9ad75dcc" class="">3.4 Producer 개발</h3><p id="3e4cff34-3e03-40e3-b7b5-464bb28a5bed" class="">Producer는 이벤트를 생성하고 Kafka Topic에 발행하는 역할을 합니다.</p><ol type="1" id="72f11648-e1ea-4b69-8cd3-673aa2bce4c5" class="numbered-list" start="1"><li><strong>Kafka Producer API 사용</strong>: Kafka에서 제공하는 Producer API를 사용하여 Producer를 개발합니다.</li></ol><ol type="1" id="03846403-bb94-489d-8b82-3392ca4ca46b" class="numbered-list" start="2"><li><strong>이벤트 생성 및 발행</strong>: 이벤트를 생성하여 Kafka Topic에 발행합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="49dfe74b-18fb-4373-93c1-a292bf8f1a36" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 
Properties props = new Properties();
props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
producer.send(new ProducerRecord&lt;&gt;(&quot;my_topic&quot;, &quot;key&quot;, &quot;value&quot;));
producer.close();</code></pre></li></ol><ol type="1" id="7e382369-4fd7-42d2-ba2e-54df1706a48a" class="numbered-list" start="3"><li><strong>발행 전략</strong>: 이벤트의 중요도에 따라 동기(Synchronous) 또는 비동기(Asynchronous) 방식으로 이벤트를 발행합니다.</li></ol><h3 id="3d5ec46d-56d5-4698-a441-a26acf2f64f0" class="">3.5 Consumer 개발</h3><p id="fa82efa8-a9a3-462e-8465-fba63ea5ca54" class="">Consumer는 Kafka로부터 이벤트를 구독하고 처리하는 역할을 합니다.</p><ol type="1" id="383fc4d5-9b6d-4138-8de7-07985d3e7855" class="numbered-list" start="1"><li><strong>Kafka Consumer API 사용</strong>: Kafka에서 제공하는 Consumer API를 사용하여 Consumer를 개발합니다.</li></ol><ol type="1" id="1a691cfa-36b1-4cf0-ab02-307ae303f5bb" class="numbered-list" start="2"><li><strong>이벤트 구독 및 처리</strong>: Kafka Topic으로부터 이벤트를 구독하여 처리합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="ec942447-51ed-4e2f-9be6-2f107352b41c" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
Properties props = new Properties();
props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
props.put(&quot;group.id&quot;, &quot;my_group&quot;);
props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);

Consumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
consumer.subscribe(Collections.singletonList(&quot;my_topic&quot;));

while (true) {
    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord&lt;String, String&gt; record : records) {
        System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());
    }
}
consumer.close();</code></pre></li></ol><ol type="1" id="34ecf8e8-cdc4-4787-99b3-fe0c373e7bf9" class="numbered-list" start="3"><li><strong>컨슈머 그룹 관리</strong>: 여러 Consumer가 하나의 컨슈머 그룹을 이루어 Topic의 파티션을 병렬로 처리할 수 있도록 구성합니다.</li></ol><h3 id="a8b1f498-ffa9-4832-b5fa-f1ee71f47d5d" class="">3.6 데이터 일관성과 신뢰성 보장</h3><h3 id="d4891401-69cb-4186-858f-6c25cc00dfa5" class="">이벤트 일관성 보장</h3><ul id="fb3acad1-993c-40ac-bb4d-2cfd99338d52" class="bulleted-list"><li style="list-style-type:disc"><strong>트랜잭션 지원</strong>: Kafka는 트랜잭션을 지원하여 Producer와 Consumer 간의 데이터 일관성을 보장합니다.</li></ul><ul id="2c196c77-3d5f-46fb-8d91-dd650c3786e1" class="bulleted-list"><li style="list-style-type:disc"><strong>Idempotent Producer</strong>: 동일한 메시지가 여러 번 발행되어도 시스템의 상태가 변하지 않도록 보장합니다.</li></ul><h3 id="bc8fdc32-d83e-40e9-b766-2b37391eea5e" class="">이벤트 신뢰성 보장</h3><ul id="87a62558-f061-4bc1-8c29-da8705aee286" class="bulleted-list"><li style="list-style-type:disc"><strong>오프셋 관리</strong>: Consumer는 Kafka로부터 이벤트를 처리한 후, 해당 이벤트의 오프셋을 커밋하여 데이터의 신뢰성을 보장합니다.</li></ul><ul id="9d4ef0ee-7328-458a-9b74-6565a098add3" class="bulleted-list"><li style="list-style-type:disc"><strong>재시도 메커니즘</strong>: 이벤트 처리에 실패한 경우, 재시도 메커니즘을 구현하여 신뢰성을 보장합니다.</li></ul><h3 id="44065ec9-250a-4759-9317-8b9cb4eb1f3a" class="">3.7 모니터링 및 관리</h3><p id="2ab07039-afde-428e-afbf-c86ae7e494e1" class="">Kafka 클러스터와 이벤트 기반 아키텍처의 상태를 모니터링하고 관리하는 것이 중요합니다.</p><ol type="1" id="69bc5c84-eda2-4b50-8b46-85f151e6fa6f" class="numbered-list" start="1"><li><strong>Kafka 클러스터 모니터링</strong>: Kafka의 상태, 브로커, Topic, 파티션 등을 모니터링합니다. Prometheus, Grafana, Kafka Manager 등의 도구를 사용할 수 있습니다.</li></ol><ol type="1" id="7653fec2-d794-4ec3-939a-55d113f67383" class="numbered-list" start="2"><li><strong>애플리케이션 모니터링</strong>: Producer와 Consumer의 상태, 이벤트 처리량, 오류 등을 모니터링합니다. Jaeger, Zipkin, Elastic Stack 등의 도구를 사용할 수 있습니다.</li></ol><ol type="1" id="34934844-a696-4cce-89f3-e827d5329e24" class="numbered-list" start="3"><li><strong>경보 및 알림 시스템 구축</strong>: 이상 징후나 오류가 발생할 경우, 즉시 알림을 받을 수 있도록 경보 및 알림 시스템을 구축합니다.</li></ol><h3 id="da0380b7-e30c-4041-84a1-78f79cc7ffd8" class="">3.8 확장 및 최적화</h3><p id="eb570a43-84b9-4ae3-8906-3da756314739" class="">Kafka를 활용한 이벤트 기반 아키텍처는 확장성과 최적화를 통해 시스템의 성능을 향상시킬 수 있습니다</p><p id="e149d0f2-a69f-443b-bba7-e9425f55b7b5" class="">
</p><p id="c7dcdcf8-93a2-4442-8700-76a859747aa4" class="">Kafka에서 데이터 일관성과 신뢰성을 보장하기 위해서는 다양한 기법과 구성 요소가 필요합니다. Kafka는 분산 스트리밍 플랫폼으로서 높은 처리량과 빠른 데이터 전송을 목표로 설계되었지만, 동시에 데이터의 정확성과 신뢰성을 보장하기 위한 기능을 제공합니다. 다음은 Kafka에서 데이터 일관성과 신뢰성을 보장하는 주요 방법들을 자세히 설명한 내용입니다.</p><h2 id="fe4c1d6c-b58f-4372-b38f-dd50310c220b" class="">1. 데이터 일관성 보장</h2><h3 id="50977590-86ea-4f8c-96d7-fcc587c4f67a" class="">1.1 트랜잭션 지원 (Transactions)</h3><p id="21ba7b02-25ed-4bbd-b4db-a3185da43af3" class="">Kafka는 트랜잭션을 지원하여 Producer와 Consumer 간의 데이터 일관성을 보장합니다. 이를 통해 한 번에 여러 Topic이나 파티션에 데이터를 쓰는 작업이 완전하거나 전혀 적용되지 않도록 할 수 있습니다. 트랜잭션 지원을 통해 &quot;모든 이벤트를 처리하거나, 하나도 처리하지 않는&quot; 원자성을 보장합니다.</p><h3 id="ae4ef49c-99b8-4e31-a6cc-9952d82f6f5c" class="">트랜잭션 설정 및 사용 방법</h3><ol type="1" id="f0893f0a-dac8-448b-a6a3-e8559509f223" class="numbered-list" start="1"><li><strong>Producer 트랜잭션 설정</strong>: 트랜잭션을 사용하려면 트랜잭션 ID를 지정하여 KafkaProducer를 생성해야 합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="d0bca954-05f8-494c-bd55-0c072aa4c8db" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
Properties props = new Properties();
props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
props.put(&quot;transactional.id&quot;, &quot;my-transactional-id&quot;);
Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</code></pre></li></ol><ol type="1" id="ea9509f1-a8a1-469c-805d-c914c14efe91" class="numbered-list" start="2"><li><strong>트랜잭션 시작, 커밋, 중단</strong>: 트랜잭션을 시작하고 데이터를 전송한 후, 커밋하거나 중단할 수 있습니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="62aefcf4-b806-4c9e-9185-c6d2227a66b0" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
producer.initTransactions(); // 트랜잭션 초기화
try {
    producer.beginTransaction(); // 트랜잭션 시작
    producer.send(new ProducerRecord&lt;&gt;(&quot;my_topic&quot;, &quot;key&quot;, &quot;value&quot;));
    producer.commitTransaction(); // 트랜잭션 커밋
} catch (Exception e) {
    producer.abortTransaction(); // 트랜잭션 중단
}</code></pre></li></ol><h3 id="70d4b96a-b5c6-4939-95cf-38fb20dfbac3" class="">1.2 Idempotent Producer</h3><p id="28cbccd7-20d8-417d-b16c-60d031032f15" class="">Kafka는 멱등성(Idempotent)을 지원하는 프로듀서를 통해 동일한 메시지가 여러 번 발행되더라도 시스템 상태가 변하지 않도록 보장합니다. 이는 네트워크 오류나 프로듀서 오류로 인해 중복 메시지가 발생하는 경우에 유용합니다.</p><h3 id="b6471120-0990-4e5c-af33-2631182414a1" class="">Idempotent Producer 설정</h3><ol type="1" id="5629111c-cee5-44e8-8aad-78b1edc25b55" class="numbered-list" start="1"><li><strong>멱등성 프로듀서 설정</strong>: 멱등성을 위해 프로듀서 설정에서 <code>enable.idempotence</code>를 <code>true</code>로 설정합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="ec6ef7f7-5a93-483f-b181-bb85e1fdf610" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
Properties props = new Properties();
props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
props.put(&quot;enable.idempotence&quot;, &quot;true&quot;);
Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</code></pre></li></ol><h3 id="3a8d2de5-dbf4-40c0-a23c-a9ebd05180ec" class="">1.3 오프셋 관리 (Offset Management)</h3><p id="f11d7981-84bc-4e95-b532-0c8a1483f786" class="">Kafka의 Consumer는 메시지를 처리한 후, 해당 메시지의 오프셋을 커밋하여 데이터의 일관성을 유지합니다. 오프셋 관리는 크게 두 가지 방식으로 이루어집니다.</p><ol type="1" id="edc577d5-72b3-4136-bbf7-0acd5098d54c" class="numbered-list" start="1"><li><strong>자동 커밋 (Auto-commit)</strong>: <code>enable.auto.commit</code>을 <code>true</code>로 설정하여 Kafka가 주기적으로 오프셋을 자동으로 커밋하도록 할 수 있습니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="24e0263d-1025-4e9d-af3e-762e3198f316" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
Properties props = new Properties();
props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);
props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); // 1초마다 자동 커밋</code></pre></li></ol><ol type="1" id="1c281370-07b9-44bf-b20d-667036152535" class="numbered-list" start="2"><li><strong>수동 커밋 (Manual commit)</strong>: <code>enable.auto.commit</code>을 <code>false</code>로 설정하고, 필요할 때마다 오프셋을 수동으로 커밋할 수 있습니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="28272585-a9de-44e1-bea6-004bb63bbef4" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
Properties props = new Properties();
props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);
Consumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
// 메시지 처리 후 수동 커밋
consumer.commitSync();</code></pre></li></ol><h3 id="5365d6b2-bbdb-4aa4-9e13-9d854236726d" class="">1.4 Exactly-once Semantics (EoS)</h3><p id="940d3094-f1bd-4223-9a8d-f4d6ef12e2b4" class="">Kafka는 트랜잭션 및 멱등성을 통해 정확히 한 번의 처리(Exactly-once)를 보장합니다. 이는 프로듀서에서 이벤트를 전송하고, 컨슈머가 해당 이벤트를 한 번만 처리하도록 하는 것을 의미합니다.</p><ol type="1" id="1ef0aa11-f8c6-4a83-8a7a-548704ec3337" class="numbered-list" start="1"><li><strong>Exactly-once 프로듀서 설정</strong>: 멱등성 프로듀서와 트랜잭션을 결합하여 EoS를 구현합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="d11a5ff0-519d-4483-be33-31e98e9b44cd" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
Properties props = new Properties();
props.put(&quot;enable.idempotence&quot;, &quot;true&quot;);
props.put(&quot;transactional.id&quot;, &quot;my-transactional-id&quot;);
Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</code></pre></li></ol><ol type="1" id="d65dc8e6-939a-47f0-8a22-a880cdb2ea47" class="numbered-list" start="2"><li><strong>Exactly-once 컨슈머 설정</strong>: 컨슈머는 트랜잭션 컨텍스트 내에서 오프셋을 커밋하도록 합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1a8a0417-a224-472a-881f-eb0d5f2ea056" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
// 컨슈머가 트랜잭션을 사용하도록 설정
consumer.commitTransaction();</code></pre></li></ol><h2 id="d8962da2-f391-4bd3-b355-dc44b13ed64f" class="">2. 데이터 신뢰성 보장</h2><h3 id="bc880c35-d39c-4867-afd6-2bf46fef9b50" class="">2.1 데이터 복제 (Data Replication)</h3><p id="bfa817ea-018f-4060-ba38-52bd66398fa3" class="">Kafka는 각 Topic을 여러 파티션으로 구성하고, 각 파티션은 다시 여러 개의 복제본(Replica)을 가집니다. 이러한 복제 메커니즘을 통해 데이터의 신뢰성을 보장합니다.</p><ol type="1" id="84cb2666-f028-4573-a7ea-20d0b33f98cd" class="numbered-list" start="1"><li><strong>복제 팩터 설정</strong>: Topic을 생성할 때 복제 팩터를 지정하여 데이터의 복제본을 생성합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="149154e7-0b97-4813-bf09-51fbaa058223" class="code"><code class="language-Shell" style="white-space:pre-wrap;word-break:break-all">bash코드 복사
bin/kafka-topics.sh --create --topic my_topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 2</code></pre></li></ol><ol type="1" id="bb53d377-0076-464a-8f62-6fe28bfa9569" class="numbered-list" start="2"><li><strong>복제본의 동기화 상태 관리</strong>: Kafka는 리더(Leader)와 팔로워(Follower) 복제본의 동기화 상태를 지속적으로 관리하여 데이터의 가용성과 일관성을 유지합니다.</li></ol><h3 id="3129e47d-7e24-48a3-8e5c-6bbdf2166a22" class="">2.2 데이터 무결성 검사 (Data Integrity Check)</h3><p id="2962426c-6f70-4156-94b5-86a265e74d5d" class="">Kafka는 데이터 전송 중에 발생할 수 있는 오류를 감지하고 방지하기 위해 메시지 무결성 검사를 수행합니다. 메시지는 전송 시 CRC32를 사용하여 체크섬을 계산하고, 수신 시 이를 검증합니다.</p><ol type="1" id="a304c05d-8e63-401e-8b0b-62a853df24cb" class="numbered-list" start="1"><li><strong>메시지 무결성 검사 설정</strong>: 기본적으로 Kafka는 메시지 무결성 검사를 수행하지만, 필요에 따라 설정을 변경할 수 있습니다.</li></ol><h3 id="998e96ae-d589-4199-9dac-24e3e1515372" class="">2.3 오류 처리 및 재시도 메커니즘 (Error Handling and Retry Mechanisms)</h3><p id="13449d7d-d9d6-46c2-8581-e32554c92373" class="">Kafka는 프로듀서와 컨슈머에서 발생하는 오류를 처리하고, 필요한 경우 재시도 메커니즘을 제공합니다.</p><ol type="1" id="9211e042-674d-47b2-827a-db900602d4f3" class="numbered-list" start="1"><li><strong>프로듀서 재시도 설정</strong>: 프로듀서는 메시지 전송 실패 시 재시도하도록 설정할 수 있습니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="6887bd36-4cbe-426f-862a-db28cbca44f3" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
Properties props = new Properties();
props.put(&quot;retries&quot;, 3); // 3회 재시도
props.put(&quot;retry.backoff.ms&quot;, 100); // 100ms 대기 후 재시도
Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</code></pre></li></ol><ol type="1" id="941f8aa6-0517-40a3-a41f-f7e481cbf65b" class="numbered-list" start="2"><li><strong>컨슈머 재시도 설정</strong>: 컨슈머는 메시지 처리 실패 시 재시도할 수 있으며, 이러한 재시도 로직은 애플리케이션 코드에서 구현해야 합니다.</li></ol><h3 id="21c02761-6180-49a9-8f28-bc90d86d1266" class="">2.4 메시지 순서 보장 (Message Ordering Guarantee)</h3><p id="20f43c96-8ce2-4548-976f-4f7a53e53259" class="">Kafka는 각 파티션 내에서 메시지의 순서를 보장합니다. 따라서 특정 파티션에만 메시지를 전송하면, 해당 파티션 내에서는 메시지의 순서가 유지됩니다.</p><ol type="1" id="3afefe3b-e75b-47fe-87a2-2665ac746d6b" class="numbered-list" start="1"><li><strong>파티셔닝 전략 설정</strong>: 메시지의 순서를 유지하기 위해 동일한 키를 가진 메시지를 동일한 파티션에 전송하도록 파티셔닝 전략을 설정합니다.<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="2a7e1643-396b-4961-a213-ab21ffb987d6" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
producer.send(new ProducerRecord&lt;&gt;(&quot;my_topic&quot;, &quot;key&quot;, &quot;value&quot;));</code></pre></li></ol><ol type="1" id="248486e7-e7b4-4697-9df4-16afbfe6f813" class="numbered-list" start="2"><li><strong>컨슈머 오프셋 관리</strong>: 컨슈머는 메시지를 처리한 후, 해당 메시지의 오프셋을 커밋하여 순서를 보장합니다.</li></ol><h2 id="c35ea4f7-1268-41e7-9c2e-be6bdaa295a1" class="">3. Kafka의 구성 및 운영상의 고려사항</h2><h3 id="a8f48cbd-6bd6-4d0b-81a2-77de4e6e48f6" class="">3.1 클러스터 설정 및 관리</h3><p id="9f8046f6-87ab-487c-a5ce-2a733efb7398" class="">Kafka 클러스터의 설정 및 관리 방식은 데이터의 일관성과 신뢰성을 보장하는 데 중요한 역할을 합니다.</p><ol type="1" id="18b202a1-12c1-4557-ac85-5e9022a7f7b8" class="numbered-list" start="1"><li><strong>다중 브로커 구성</strong>: 다중 브로커를 구성하여 데이터의 고가용성과 신뢰성을 확보합니다.</li></ol><ol type="1" id="8bd26b7f-77fd-47fc-9083-911ffdadbb43" class="numbered-list" start="2"><li><strong>ZooKeeper 관리</strong>: Kafka 클러스터의 상태 및 메타데이터 관리를 위해 ZooKeeper를 적절하게 구성하고 관리합니다.</li></ol><ol type="1" id="14b60ee1-81b9-4011-90bf-509ba7c5c17c" class="numbered-list" start="3"><li><strong>브로커 모니터링</strong>: 브로커의 상태, 파티션, 복제본 등을 지속적으로 모니터링하여 문제를 조기에 감지하고 해결합니다.</li></ol><h3 id="9b6a886b-4a90-4e3c-b5f9-d719c22f379b" class="">3.2 애플리케이션 개발 시 고려사항</h3><p id="37dc74dd-dc0e-4b96-8bb2-cf37c836130d" class="">Kafka를 사용하는 애플리케이션을 개발할 때, 다음과 같은 고려사항을 통해 데이터의 일관성과 신뢰성을 강화할 수 있습니다.</p><ol type="1" id="a09c512d-8799-455f-9198-d59789c163f2" class="numbered-list" start="1"><li><strong>오프셋 커밋 전략</strong>: 자동 커밋과 수동 커밋의 장단점을 고려하여 적절한 오프셋 커밋 전략을 선택합니다.</li></ol><ol type="1" id="8cb7c9e6-1ba5-4437-83bd-51f60877da2d" class="numbered-list" start="2"><li><strong>에러 핸들링 로직 구현</strong>: 메시지 처리 중 발생하는 오류를 적절히 처리하고, 필요한 경우 재시도 메커니즘을 구현합니다.</li></ol><ol type="1" id="c0f29f1a-04c2-4ac2-8277-a6687931a475" class="numbered-list" start="3"><li><strong>로그 및 모니터링 시스템 구축</strong>: 애플리케이션의 로그 및 모니터링 시스템을 구축하여 문제를 조기에 감지하고 대응할 수 있도록 합니다.</li></ol><hr id="32711703-0d2f-430c-8eed-aad14c6c8971"/><p id="00643432-a430-4651-9272-8a1e43423eaa" class="">이상으로 Kafka에서 데이터 일관성과 신뢰성을 보장하는 다양한 방법을 살펴보았습니다. 이러한 방법들을 적절히 활용함으로써 Kafka 기반의 시스템에서 데이터의 정확성과 신뢰성을 확보할 수 있습니다.</p><p id="009cce7e-bb03-4924-8fe2-3d1c6fc82fa4" class="">
</p></details></li></ul><ul id="db88c960-3a7b-4deb-ae31-16bf1b0131cf" class="toggle"><li><details open=""><summary>kafka 기반 이벤트 분석 시스템 설계</summary><p id="e262ef08-d4b7-4554-96c1-e163cee60d23" class="">Kafka 기반의 이벤트 스트림을 활용한 데이터 분석 시스템은 다양한 데이터 소스에서 발생하는 이벤트를 실시간으로 수집하고 처리하여 분석하는 시스템입니다. 이 시스템은 데이터 수집, 처리, 저장, 분석 등의 단계로 구성되며, 각 단계에서 Kafka가 중요한 역할을 수행합니다. 다음은 Kafka 기반의 데이터 분석 시스템을 설계하고, 각 구성 요소의 역할을 설명한 내용입니다.</p><h2 id="9512d268-af34-4d4c-9604-0dc56eeedb77" class="">1. 데이터 분석 시스템의 설계</h2><p id="6b105a43-67dd-4d33-b9d0-a8e73cf2353c" class="">Kafka 기반의 이벤트 스트림을 활용한 데이터 분석 시스템은 다음과 같은 단계로 구성됩니다.</p><ol type="1" id="25d9c30f-624f-47fd-94eb-02ea40754cb0" class="numbered-list" start="1"><li><strong>데이터 수집(Producer)</strong></li></ol><ol type="1" id="8057bd06-05d8-4da8-b76c-aecdd508c75d" class="numbered-list" start="2"><li><strong>데이터 스트리밍 및 처리(Kafka Broker, Stream Processor)</strong></li></ol><ol type="1" id="0724f8ea-fc1f-46e0-b6c6-6c16a6625417" class="numbered-list" start="3"><li><strong>데이터 저장(Storage)</strong></li></ol><ol type="1" id="e231a3b0-2d10-40b0-8331-2a33530b6edf" class="numbered-list" start="4"><li><strong>데이터 분석 및 시각화(Analysis, Visualization)</strong></li></ol><p id="1804c285-ef66-47dc-87de-068dad134f12" class="">각 단계별로 구성 요소와 역할을 자세히 살펴보겠습니다.</p><h2 id="1356f99e-be8b-4c29-bd6f-049ba09eb097" class="">2. 구성 요소와 역할</h2><h3 id="42ebb55a-5039-44c8-b2e6-1fb0e6b0b9e7" class="">2.1 데이터 수집 (Producer)</h3><p id="fcaf5abb-cf6a-4cb9-a4d4-3e6caa66d9b9" class=""><strong>Producer</strong>는 다양한 데이터 소스에서 발생하는 이벤트를 수집하여 Kafka로 전송하는 역할을 합니다. 이 단계에서는 다음과 같은 작업이 수행됩니다.</p><ul id="dc836052-08ca-4142-84ec-ad084383b51b" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 소스 연결</strong>: 웹 애플리케이션, IoT 기기, 로그 파일, 데이터베이스 등 다양한 소스에서 데이터를 수집합니다.</li></ul><ul id="64b0e27a-f837-4b9c-8bca-9cdc1e718dee" class="bulleted-list"><li style="list-style-type:disc"><strong>이벤트 생성</strong>: 수집된 데이터를 기반으로 이벤트를 생성합니다. 이벤트는 일반적으로 JSON, Avro, Protobuf 등의 포맷으로 표현됩니다.</li></ul><ul id="86c9d283-7f85-47bc-ad27-c06e061f1e69" class="bulleted-list"><li style="list-style-type:disc"><strong>이벤트 발행</strong>: 생성된 이벤트를 Kafka의 특정 Topic으로 발행합니다.</li></ul><h3 id="924edaf4-f14d-4eb9-9f89-e00bc1e5170b" class="">Producer 구성 및 예제</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="0765dc27-77b1-4271-b36c-a6961ae160d9" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
Properties props = new Properties();
props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
producer.send(new ProducerRecord&lt;&gt;(&quot;sensor_data&quot;, &quot;sensor_id&quot;, &quot;{\&quot;temperature\&quot;: 25.3, \&quot;humidity\&quot;: 60}&quot;));
producer.close();</code></pre><h3 id="fc52527a-a6f3-4543-99d4-c161e7582a65" class="">2.2 데이터 스트리밍 및 처리 (Kafka Broker, Stream Processor)</h3><p id="d8d2c653-b18a-44ba-ab0f-bb3a6d0d65c6" class=""><strong>Kafka Broker</strong>와 <strong>Stream Processor</strong>는 이벤트 스트림을 관리하고 실시간으로 처리하는 역할을 합니다.</p><h3 id="25d40633-dea3-48f1-8428-d51ba93498fd" class="">Kafka Broker</h3><ul id="45428010-c67d-425d-a642-f51b22337753" class="bulleted-list"><li style="list-style-type:disc"><strong>이벤트 저장</strong>: Producer로부터 수신한 이벤트를 지정된 Topic에 저장합니다.</li></ul><ul id="8fc0f91e-4485-4eed-8456-625778dc79f1" class="bulleted-list"><li style="list-style-type:disc"><strong>이벤트 전달</strong>: 저장된 이벤트를 Consumer에게 전달합니다.</li></ul><ul id="7ce03ea3-290c-4d88-8b1c-e4ef0b6e5927" class="bulleted-list"><li style="list-style-type:disc"><strong>파티셔닝 및 복제</strong>: Topic을 여러 파티션으로 나누어 데이터를 분산 저장하고, 복제본을 관리하여 데이터의 가용성과 신뢰성을 확보합니다.</li></ul><h3 id="bb3c35dc-eb32-4ace-8d24-9c7fee57c754" class="">Stream Processor</h3><ul id="4205ae1b-5559-4513-a7ce-fe9e9940a3c1" class="bulleted-list"><li style="list-style-type:disc"><strong>이벤트 필터링 및 변환</strong>: 이벤트 스트림을 필터링하거나 변환하여 필요한 데이터만 추출합니다.</li></ul><ul id="62984db2-843c-415f-9e56-873bdddaa3cd" class="bulleted-list"><li style="list-style-type:disc"><strong>상태 저장 및 집계</strong>: 이벤트의 상태를 저장하고 집계 작업을 수행합니다.</li></ul><ul id="a986634f-783c-417e-83d7-293140ec81c8" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 윈도잉</strong>: 시간 기반 또는 카운트 기반의 윈도잉을 통해 데이터를 그룹화하여 처리합니다.</li></ul><h3 id="a56ab3ff-4086-4157-ae02-19f165b2a259" class="">Stream Processor 구성 및 예제 (Kafka Streams)</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="d8209771-a740-478a-a724-6166b3d8816e" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
Properties props = new Properties();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;stream-processor&quot;);
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);
props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

StreamsBuilder builder = new StreamsBuilder();
KStream&lt;String, String&gt; sourceStream = builder.stream(&quot;sensor_data&quot;);
KStream&lt;String, String&gt; filteredStream = sourceStream.filter((key, value) -&gt; {
    // 예시: 온도가 30도 이상인 데이터만 필터링
    JsonObject jsonObject = new Gson().fromJson(value, JsonObject.class);
    return jsonObject.get(&quot;temperature&quot;).getAsDouble() &gt; 30;
});
filteredStream.to(&quot;high_temp_data&quot;);

KafkaStreams streams = new KafkaStreams(builder.build(), props);
streams.start();</code></pre><h3 id="791d7860-8137-4781-a869-e385058164c0" class="">2.3 데이터 저장 (Storage)</h3><p id="91167af4-07f7-4b30-b1fd-9a4410db610c" class=""><strong>Storage</strong>는 실시간으로 처리된 이벤트를 영구적으로 저장하는 역할을 합니다. 데이터 저장소는 일반적으로 다음과 같은 유형으로 구성됩니다.</p><ul id="098f3c61-7598-4640-a089-771ecc2c5d98" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 웨어하우스</strong>: 대량의 구조화된 데이터를 저장하고 분석하기 위한 중앙 저장소입니다. 예시로 Amazon Redshift, Snowflake, Google BigQuery 등이 있습니다.</li></ul><ul id="24fa8557-c37f-46a8-9665-11b5a22a0a65" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 레이크</strong>: 구조화, 비구조화 데이터를 모두 저장할 수 있는 중앙 저장소입니다. 예시로 AWS S3, Azure Data Lake, Google Cloud Storage 등이 있습니다.</li></ul><ul id="30bff7f0-88e4-4b3d-8da5-f685eea4e829" class="bulleted-list"><li style="list-style-type:disc"><strong>NoSQL 데이터베이스</strong>: 실시간 데이터 저장 및 조회를 위해 사용되는 비관계형 데이터베이스입니다. 예시로 Apache Cassandra, MongoDB, Elasticsearch 등이 있습니다.</li></ul><h3 id="19092f6a-b5c5-41d5-a5e0-0ed924b59003" class="">데이터 저장 구성 및 예제 (Elasticsearch)</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="45b4e97a-47c7-4062-8cd3-b91682031da3" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">java코드 복사
// Elasticsearch 클라이언트 설정
RestHighLevelClient client = new RestHighLevelClient(
    RestClient.builder(new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;)));

// Kafka에서 데이터 읽어오기
Consumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
consumer.subscribe(Collections.singletonList(&quot;high_temp_data&quot;));

while (true) {
    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord&lt;String, String&gt; record : records) {
        // Elasticsearch에 데이터 저장
        IndexRequest request = new IndexRequest(&quot;sensor_index&quot;).id(record.key()).source(record.value(), XContentType.JSON);
        client.index(request, RequestOptions.DEFAULT);
    }
}</code></pre><h3 id="99dfb9bb-5601-498b-8224-8401d93312da" class="">2.4 데이터 분석 및 시각화 (Analysis, Visualization)</h3><p id="d56ed6a9-b553-44d0-9ce2-acdf78ff993f" class=""><strong>Analysis</strong>와 <strong>Visualization</strong> 단계에서는 저장된 데이터를 기반으로 분석을 수행하고, 그 결과를 시각화하여 제공합니다.</p><h3 id="7fe59b48-d275-4e2c-936d-e001c40c3e4b" class="">데이터 분석</h3><ul id="2e6e4fc5-e5be-4143-be0f-a888be95c343" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 분석</strong>: Kafka Streams, Apache Flink, Apache Spark 등의 스트리밍 프레임워크를 활용하여 실시간 분석을 수행합니다.</li></ul><ul id="d6e30172-33e8-4189-a113-bc8ee35aabfb" class="bulleted-list"><li style="list-style-type:disc"><strong>배치 분석</strong>: 저장된 데이터를 대상으로 Hadoop, Apache Spark 등의 배치 처리 프레임워크를 활용하여 분석을 수행합니다.</li></ul><ul id="87f31c86-e734-4d39-8154-3dfd07947bda" class="bulleted-list"><li style="list-style-type:disc"><strong>머신러닝 및 AI</strong>: 분석 결과를 기반으로 머신러닝 모델을 학습시키고, 예측 및 인사이트를 도출합니다.</li></ul><h3 id="54f6d038-e3a7-40e1-8c39-d55e1714ce7b" class="">데이터 시각화</h3><ul id="c5541f4e-47a7-4e2a-b86c-3a6afbec84a4" class="bulleted-list"><li style="list-style-type:disc"><strong>대시보드 구축</strong>: Grafana, Kibana, Tableau 등의 시각화 도구를 활용하여 대시보드를 구축하고, 실시간 및 과거 데이터를 시각화합니다.</li></ul><ul id="75580389-dc77-4c77-ae68-42cd13a2556e" class="bulleted-list"><li style="list-style-type:disc"><strong>알림 및 경보 시스템</strong>: 분석 결과에 따라 알림 및 경보 시스템을 구축하여, 이상 징후나 이벤트를 실시간으로 감지하고 대응합니다.</li></ul><h3 id="6ac55007-ebf6-47c3-84e9-6374ed305b96" class="">데이터 시각화 예제 (Grafana)</h3><h2 id="b2f5e28e-4b27-46e5-bf70-d3eaef253758" class="">3. 전체 아키텍처 다이어그램</h2><p id="3c19affa-de6c-4009-a937-31c9d669761f" class="">다음은 Kafka 기반의 이벤트 스트림을 활용한 데이터 분석 시스템의 전체 아키텍처 다이어그램입니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="ce4d5405-c533-43bb-bd8c-1cafd634c23c" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
+--------------+       +--------------+       +--------------+       +--------------+
|              |       |              |       |              |       |              |
| Data Sources | ----&gt; |   Producers  | ----&gt; |  Kafka Broker| ----&gt; |   Consumers  |
|              |       |              |       |              |       |              |
+--------------+       +--------------+       +--------------+       +--------------+
                                               |      |       \            |
                                               |      |        \           |
                                               v      v         v          v
                                        +-----------------+  +-----------------+
                                        | Stream Processor|  |    Storage      |
                                        +-----------------+  +-----------------+
                                                     |              |
                                                     v              v
                                            +------------------------------+
                                            |      Analysis &amp; Visualization |
                                            +------------------------------+

</code></pre><h2 id="356f7bd7-4aca-475b-9553-ad94307d0654" class="">4. Kafka 기반 데이터 분석 시스템의 장점</h2><ul id="27071c03-9507-47a5-925c-5b608ebcfdad" class="bulleted-list"><li style="list-style-type:disc"><strong>확장성</strong>: Kafka의 분산 아키텍처를 활용하여 대규모 데이터의 실시간 처리가 가능합니다.</li></ul><ul id="a11cacba-316b-4e74-8de3-299fd3094eab" class="bulleted-list"><li style="list-style-type:disc"><strong>유연성</strong>: 다양한 데이터 소스와의 통합이 용이하며, 분석 요구 사항에 따라 시스템을 쉽게 확장 및 변경할 수 있습니다.</li></ul><ul id="43339c0f-5214-4219-a102-6dcb379e517d" class="bulleted-list"><li style="list-style-type:disc"><strong>신뢰성</strong>: Kafka의 데이터 복제 및 오류 처리 메커니즘을 통해 데이터의 신뢰성을 보장합니다.</li></ul><ul id="7f0de844-aa29-4489-a620-102d6bf5f5d1" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 처리</strong>: 스트리밍 데이터의 실시간 처리를 통해 빠른 의사 결정을 지원합니다.</li></ul><h2 id="568082c3-39c7-4736-9b7a-64b9c41bbfbd" class="">5. Kafka 기반 데이터 분석 시스템의 고려사항</h2><ul id="9c4e83d0-ab1b-4d7c-ad84-1bf64b66abbc" class="bulleted-list"><li style="list-style-type:disc"><strong>시스템 복잡성</strong>: Kafka를 포함한 분산 시스템의 복잡성을 이해하고 관리해야 합니다.</li></ul><ul id="f07a0ebb-7a23-4a9a-9bc7-731b5889893a" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 일관성</strong>: 분산된 환경에서 데이터의 일관성을 유지하기 위한 전략이 필요합니다.</li></ul><ul id="23882c46-c76a-4d30-bcc2-312327c4374d" class="bulleted-list"><li style="list-style-type:disc"><strong>보안 및 프라이버시</strong>: 데이터의 보안과 프라이버시를 보장하기 위한 대책이 필요합니다.</li></ul><ul id="e670296b-b608-4862-95e7-69581df8ccdc" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링 및 관리</strong>: 시스템의 상태를 지속적으로 모니터링하고 관리하여 안정적인 운영을 유지해야 합니다.</li></ul><hr id="e51c218e-4362-40c0-acb2-1ef6352e8e2b"/><p id="9322d6d6-ca43-4422-ba94-319560104609" class="">이상으로 Kafka 기반의 이벤트 스트림을 활용한 데이터 분석 시스템의 설계와 구성 요소의 역할에 대해 설명했습니다. 이 시스템은 실시간 데이터 처리와 분석을 통해 다양한 비즈니스 인사이트를 도출하는 데 효과적으로 활용될 수 있습니다.</p><p id="e3b7c993-2914-4d44-8cfa-57be93057050" class="">
</p></details></li></ul><ul id="50d6cff4-1208-4c75-be2e-3fd7a399362e" class="toggle"><li><details open=""><summary>kafka streams 실시간 데이터 처리/분석 사례</summary><p id="903872b5-44fe-4d3b-a927-cd7c684ae8d5" class="">Kafka Streams는 실시간 데이터 처리와 분석을 위한 강력한 플랫폼으로, 다양한 산업과 애플리케이션에서 활용되고 있습니다. 특히 금융 거래 모니터링, 사기 탐지, 실시간 추천 시스템 등과 같은 분야에서 Kafka Streams의 특성을 활용하여 실시간으로 대규모 데이터를 처리하고 분석하는 데 사용됩니다. 아래에는 Kafka Streams의 구체적인 활용 사례들을 소개합니다.</p><hr id="b5b6ba55-1a00-452d-9592-5353bde101b7"/><h3 id="33a7443f-8b02-40c5-9c99-7c0d02bca3a6" class="">1. 금융 거래 모니터링</h3><h3 id="6ea00845-951d-46a0-bbd5-039dfb78593c" class="">1.1 실시간 거래 추적 및 분석</h3><ul id="74365531-d5e7-4635-ad15-3fe7911acb2f" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 금융기관은 Kafka Streams를 사용하여 수백만 건의 거래를 실시간으로 모니터링하고 분석합니다. 이를 통해 거래 내역을 실시간으로 추적하여, 불규칙한 패턴을 식별하고 거래를 자동으로 차단할 수 있습니다.</li></ul><ul id="3305f2c0-2e9a-4e16-a42e-2c34d82701d2" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: 각 거래 이벤트를 Kafka 토픽에 전송하고, Kafka Streams를 사용하여 이 데이터를 처리합니다. 스트림 프로세싱을 통해 거래 금액, 빈도, 거래 상대방 등 다양한 조건을 실시간으로 분석하여 이상 거래를 감지합니다.</li></ul><h3 id="0461aa29-c450-43f4-8dd3-595610c39592" class="">1.2 규제 준수 및 보고</h3><ul id="c42917b6-7649-4490-8c21-a852983661ae" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 금융기관은 규제 기관의 요구 사항을 충족하기 위해 모든 거래를 실시간으로 모니터링하고 기록해야 합니다.</li></ul><ul id="d84fd58a-cec6-4a64-8ff0-0dbb08279fbc" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams는 거래 데이터 스트림을 처리하여 규제 보고를 위한 필요한 데이터를 추출하고, 필요한 시점에 규제 기관에 보고할 수 있도록 합니다.</li></ul><h3 id="5f37dddf-b0c6-45f6-bd5f-11649ea88560" class="">2. 사기 탐지</h3><h3 id="4cc67ce8-26a0-4150-8c72-a877dc8af79c" class="">2.1 실시간 사기 탐지</h3><ul id="5c4a1579-b7da-4130-88e7-be4af1d3a536" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 온라인 뱅킹 및 전자 상거래 사이트는 실시간으로 사기성 거래를 탐지하고 차단해야 합니다.</li></ul><ul id="a1a22a19-942a-4e15-b5a6-7b53c789958e" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams를 사용하여 트랜잭션 패턴을 분석하고, 머신 러닝 모델과 연계하여 사기 가능성이 있는 트랜잭션을 식별합니다. 식별된 트랜잭션은 즉시 차단되거나 추가 검증을 위해 대기 상태로 전환됩니다.</li></ul><h3 id="06e27d78-bf59-437f-96d5-7e778fab9e7f" class="">2.2 사용자 행동 분석</h3><ul id="5fe255f2-02ad-47cc-be6d-1fa661370424" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 사용자 로그인 패턴, 구매 행동, 지불 방식 등을 분석하여 비정상적인 패턴을 식별합니다.</li></ul><ul id="b045ebde-3ed2-4f44-932b-5774be09514b" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams는 사용자의 행동 데이터를 실시간으로 처리하여 비정상적인 활동을 탐지하고, 사전 정의된 기준에 따라 경고를 발생시킵니다.</li></ul><h3 id="2294094f-03e2-4af7-a28e-9ed76914b9a8" class="">3. 실시간 추천 시스템</h3><h3 id="a5dd80ab-8859-4ad9-874a-425e0e2a2b88" class="">3.1 e-커머스 추천 시스템</h3><ul id="1ae4cf64-a8d2-4266-ab76-79650fa86b02" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 전자 상거래 플랫폼은 고객에게 실시간으로 개인화된 제품 추천을 제공합니다.</li></ul><ul id="fb90b00b-57ef-43b1-b07b-89b3bb31aa1a" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams는 고객의 과거 구매 기록, 검색 내역, 현재 웹 사이트 탐색 활동 등의 데이터를 분석하여 관련 제품을 추천합니다. 이러한 실시간 분석을 통해 고객의 참여와 전환율을 높일 수 있습니다.</li></ul><h3 id="1a67bb5a-9047-43b5-9f94-36cefb74dc53" class="">3.2 콘텐츠 스트리밍 추천</h3><ul id="4004e33a-89c1-4d23-b4c9-6cdb2ddee6bb" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 스트리밍 서비스는 사용자에게 맞춤형 콘텐츠를 실시간으로 추천합니다.</li></ul><ul id="c74a4932-5059-4682-8519-3a08326a2772" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams를 사용하여 사용자의 시청 기록, 선호도, 현재 시청 중인 콘텐츠 등을 실시간으로 분석하여 관련 동영상, 음악, 또는 기타 콘텐츠를 추천합니다.</li></ul><h3 id="915291ce-8025-4958-8d75-00c0776ed81d" class="">4. IoT 데이터 처리</h3><h3 id="f39c715a-de42-465a-b9de-562ee221b984" class="">4.1 실시간 센서 데이터 모니터링</h3><ul id="769819fd-764d-43e4-a000-c4355a87e9a2" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 제조업에서는 생산 라인의 IoT 센서 데이터를 실시간으로 모니터링하고 분석하여 장비의 이상 상태를 탐지합니다.</li></ul><ul id="2bfaebea-5a6c-460a-b5ca-be6593d1f48d" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams는 IoT 센서에서 발생하는 데이터를 수집하고, 실시간으로 처리하여 이상 상태를 조기에 감지하고 경고를 생성합니다.</li></ul><h3 id="d424a348-d5fa-4d2e-ab4c-0e26a3bdb0f2" class="">4.2 스마트 시티 관리</h3><ul id="02be4d7e-fdce-4dab-93df-8da3abc8a09d" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 스마트 시티 프로젝트에서는 교통량, 에너지 사용량, 대기질 등 다양한 데이터를 실시간으로 모니터링합니다.</li></ul><ul id="1b0bd130-bd2c-4eac-bfcf-405b8af2bb06" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams를 통해 이러한 데이터를 실시간으로 수집하고 분석하여 도시 관리 효율성을 높이고, 응답 시간을 개선합니다.</li></ul><h3 id="17868dd2-6c75-4aff-a3fa-d378649444d1" class="">5. 소셜 미디어 분석</h3><h3 id="f20c0086-88bd-4952-8a76-57309c964203" class="">5.1 실시간 트렌드 분석</h3><ul id="382fa4bc-b38d-44ec-990d-6e49f4942a95" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 소셜 미디어 플랫폼은 실시간으로 유저들의 게시글, 댓글, 좋아요 등의 데이터를 분석하여 트렌드와 인기 주제를 파악합니다.</li></ul><ul id="ba3f1069-9101-4e54-ba7c-6266c36bb1aa" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams는 소셜 미디어 이벤트 스트림을 처리하여 해시태그 사용 빈도, 특정 키워드의 언급량 등을 실시간으로 계산합니다.</li></ul><h3 id="af9a75ce-18ec-4323-982c-db60c29d86d4" class="">5.2 사용자 감정 분석</h3><ul id="e803c9c1-4eb4-4539-ba0b-33fa3219e267" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 기업들은 고객의 피드백, 리뷰, 댓글 등을 분석하여 실시간으로 고객의 감정을 파악하고, 이에 대응하는 전략을 수립합니다.</li></ul><ul id="b2ae50ba-112d-4c92-a8a7-8ec2866f988a" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams는 자연어 처리(NLP)와 결합하여 실시간으로 텍스트 데이터를 분석하고, 사용자 감정을 긍정, 부정, 중립 등으로 분류합니다.</li></ul><h3 id="6b373a33-5416-4149-a35c-3dc153f736c5" class="">6. 통신 네트워크 모니터링</h3><h3 id="da0621fe-952e-4252-a0cc-1f059b2864ae" class="">6.1 실시간 네트워크 트래픽 분석</h3><ul id="eaf2a6de-7aa9-4d9f-9434-021782c25eca" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 통신사는 네트워크 트래픽을 실시간으로 모니터링하여 네트워크 혼잡을 방지하고, 서비스 품질을 유지합니다.</li></ul><ul id="361e9050-138f-4b23-ba4e-be9632a12c95" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams는 네트워크 트래픽 데이터를 처리하여 실시간으로 트래픽 패턴을 분석하고, 잠재적인 문제를 감지하여 조치를 취합니다.</li></ul><h3 id="2238694c-aeb4-4091-8718-932e853e016a" class="">6.2 장애 예측 및 예방</h3><ul id="21e4375b-2697-47bb-b9dc-0752818b8e88" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 사례</strong>: 통신사는 네트워크 장비의 로그와 성능 데이터를 실시간으로 분석하여 잠재적인 장애를 예측하고 예방합니다.</li></ul><ul id="103c9dc5-0c35-4caf-a54b-0bc3981b770e" class="bulleted-list"><li style="list-style-type:disc"><strong>구현 방법</strong>: Kafka Streams는 머신 러닝 모델과 통합하여 실시간으로 데이터를 처리하고, 이상 패턴을 감지하여 사전에 경고를 발행합니다.</li></ul><hr id="1a55fb1d-8643-4699-8bc1-dbd7a4ded981"/><h3 id="c1369a6f-241c-4761-808e-3f9cb070d186" class="">결론</h3><p id="2df93482-ae8f-4476-a656-d543fda8c982" class="">Kafka Streams는 다양한 분야에서 실시간으로 데이터를 처리하고 분석하는 데 사용될 수 있으며, 금융, 소매, IoT, 소셜 미디어, 통신 등 다양한 산업에서 사용됩니다. 이를 통해 데이터의 실시간 분석과 처리 능력을 활용하여 비즈니스 가치를 극대화할 수 있습니다. 이러한 사례들을 통해 Kafka Streams의 활용 범위와 가능성을 파악할 수 있으며, 각 산업과 응용 분야에 맞게 커스터마이징하여 적용할 수 있습니다.</p><p id="28f910f8-0d5e-4347-95b3-aecf864852b2" class="">
</p></details></li></ul><ul id="a2b232e9-fbbd-4e31-913c-dc5990530dd7" class="toggle"><li><details open=""><summary>kafka streams + Machine Learning 기반 통신 장애 예측</summary><h3 id="10ab8a58-e764-4eb7-adfe-30136fcd464c" class="">통신사의 네트워크 장비 장애 예측 및 예방 시스템 설계</h3><p id="2bd88a3d-f54a-4bfc-85b3-d630f73d5b49" class="">통신사에서 네트워크 장비의 로그와 성능 데이터를 실시간으로 분석하여 잠재적인 장애를 예측하고 예방하는 시스템은 Kafka Streams와 머신러닝 기술을 결합하여 설계할 수 있습니다. 이 시스템은 다음과 같은 구성 요소와 아키텍처를 포함합니다.</p><hr id="babd15fc-5873-414c-b3c0-62a55c430205"/><h3 id="c8cb1601-9652-4847-b7e0-53f6bfcbd1a9" class="">1. 시스템 구성 요소</h3><h3 id="2c732da3-0b07-4b9a-8dae-2444609689d7" class="">1.1 데이터 소스</h3><ul id="044b5a9a-0121-410d-9a71-d10683941d73" class="bulleted-list"><li style="list-style-type:disc"><strong>네트워크 장비</strong>: 라우터, 스위치, 방화벽 등의 장비에서 로그와 성능 데이터를 생성합니다.</li></ul><ul id="eaa9f8d6-dcae-4abb-b016-5e9cff1cb584" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 수집 에이전트</strong>: 장비에서 데이터를 수집하여 Kafka 클러스터로 전송합니다.</li></ul><h3 id="196c9ffd-1ac4-4341-8b81-3314a003ed5d" class="">1.2 데이터 파이프라인</h3><ul id="9bb08e25-40c7-48f7-ab41-7a4835fbf106" class="bulleted-list"><li style="list-style-type:disc"><strong>Kafka 클러스터</strong>: 다양한 소스로부터 들어오는 데이터를 수집, 저장, 분산합니다.<ul id="70745f78-9f59-462e-9b4d-26f31afb64ca" class="bulleted-list"><li style="list-style-type:circle"><strong>Raw Logs Topic</strong>: 원시 로그 데이터를 저장하는 토픽.</li></ul><ul id="05cd38e0-b69e-461e-9547-a63784fd31e7" class="bulleted-list"><li style="list-style-type:circle"><strong>Metrics Topic</strong>: 성능 지표 데이터를 저장하는 토픽.</li></ul></li></ul><h3 id="000f0c94-d577-4943-8eb2-530bff121585" class="">1.3 데이터 처리 및 분석</h3><ul id="1eba2efd-bf40-4921-8b23-3ea0f5ff309a" class="bulleted-list"><li style="list-style-type:disc"><strong>Kafka Streams 애플리케이션</strong>: 실시간 데이터 스트림을 처리하고, 머신러닝 모델을 적용하여 이상 징후를 탐지합니다.<ul id="194e19bb-9845-4d68-8828-e0e4a2c474f4" class="bulleted-list"><li style="list-style-type:circle"><strong>로그 파서(Stream 1)</strong>: 원시 로그를 구조화된 형식으로 변환하고 필요한 데이터를 추출합니다.</li></ul><ul id="16b29141-4f6e-41ec-b2ba-129a6db9256b" class="bulleted-list"><li style="list-style-type:circle"><strong>성능 지표 분석기(Stream 2)</strong>: 성능 데이터를 분석하여 패턴을 식별하고 이상치를 감지합니다.</li></ul><ul id="a8319573-9d41-493b-a6af-26799b739e3f" class="bulleted-list"><li style="list-style-type:circle"><strong>이상 탐지 및 예측(Stream 3)</strong>: 로그와 성능 데이터를 결합하여 머신러닝 모델로 이상 탐지 및 장애 예측을 수행합니다.</li></ul></li></ul><h3 id="7e98a89f-3088-4b2b-82c2-d0b86a059a66" class="">1.4 머신러닝</h3><ul id="d0c8249e-7c14-4175-935e-fb04e450422f" class="bulleted-list"><li style="list-style-type:disc"><strong>모델 학습 및 배포 플랫폼</strong>: 실시간 분석에 사용될 머신러닝 모델을 학습, 평가, 배포하는 플랫폼입니다.<ul id="eb61f066-3ded-46e7-b1b9-885036a59029" class="bulleted-list"><li style="list-style-type:circle"><strong>모델 학습 파이프라인</strong>: 과거의 로그와 성능 데이터를 사용하여 모델을 학습합니다.</li></ul><ul id="cbcfd555-29bd-48fa-a40a-2fd12a97eeb0" class="bulleted-list"><li style="list-style-type:circle"><strong>모델 배포</strong>: 학습된 모델을 Kafka Streams 애플리케이션에 배포합니다.</li></ul></li></ul><h3 id="0b72213e-90af-4bc2-81d4-88bf8e4e8c94" class="">1.5 알림 및 대응 시스템</h3><ul id="7c210350-5396-4996-9c04-125864a6453c" class="bulleted-list"><li style="list-style-type:disc"><strong>경고 및 알림 시스템</strong>: 예측된 이상 상황이나 잠재적 장애에 대해 실시간으로 경고를 발행합니다.</li></ul><ul id="7a7ff2e0-8bd4-4fb3-b267-998809c796fc" class="bulleted-list"><li style="list-style-type:disc"><strong>자동 대응 시스템</strong>: 경고에 따라 자동으로 대응 작업을 수행하거나, 담당자에게 조치를 권고합니다.</li></ul><h3 id="fbd3e916-143a-41d2-9faf-ea38aec2b6b5" class="">1.6 대시보드 및 모니터링</h3><ul id="e4cb5a2f-6b6a-487e-bd06-7169e6f5716f" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 대시보드</strong>: 시스템의 현재 상태, 성능 지표, 이상 징후 등을 시각화합니다.</li></ul><ul id="6c455595-4d22-4f00-abff-e8a4b67ad6fa" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링 시스템</strong>: 시스템의 가용성과 성능을 모니터링하고, 장애 발생 시 문제를 추적합니다.</li></ul><hr id="d6f41241-835d-4437-94a5-2b2b09c3f293"/><h3 id="8bf5bef5-c656-4ea1-ad44-7560c1cbea69" class="">2. 소프트웨어 아키텍처</h3><h3 id="727dcd5c-24b6-4ef4-a055-7d86e44bde41" class="">2.1 데이터 수집</h3><ol type="1" id="c24265a0-c776-4b79-adcb-a2943074a4ad" class="numbered-list" start="1"><li><strong>데이터 수집 에이전트</strong>: 네트워크 장비에서 로그와 성능 지표 데이터를 수집하여 Kafka 클러스터에 전송합니다. 에이전트는 다양한 형식의 데이터를 수집할 수 있도록 구성되어 있습니다.<ul id="a0b58810-20cf-4c7e-aa48-9531191b0ccb" class="bulleted-list"><li style="list-style-type:disc">로그 데이터는 <code>Raw Logs Topic</code>에 저장됩니다.</li></ul><ul id="890762e9-e787-4c82-8581-0712c4207b00" class="bulleted-list"><li style="list-style-type:disc">성능 지표 데이터는 <code>Metrics Topic</code>에 저장됩니다.</li></ul></li></ol><h3 id="7642e2a1-8b65-4dda-b567-eb7d76c1e569" class="">2.2 데이터 처리 및 분석</h3><ol type="1" id="49b655a5-7093-46b0-9e2d-b091fb43a5b6" class="numbered-list" start="1"><li><strong>Kafka Streams 애플리케이션</strong>: Kafka Streams를 사용하여 데이터 스트림을 처리합니다.<ul id="91ebc9ed-c750-42ee-8641-8cddf251ee64" class="bulleted-list"><li style="list-style-type:disc"><strong>로그 파서(Stream 1)</strong>: <code>Raw Logs Topic</code>에서 데이터를 읽어 필요한 정보를 추출하고, 구조화된 형식으로 변환합니다. 변환된 데이터는 <code>Parsed Logs Topic</code>에 저장됩니다.</li></ul><ul id="b09ac3f9-b927-4057-9724-3fb28efa2a43" class="bulleted-list"><li style="list-style-type:disc"><strong>성능 지표 분석기(Stream 2)</strong>: <code>Metrics Topic</code>에서 데이터를 읽어 지표를 분석하고, 이상치를 탐지합니다. 분석 결과는 <code>Analyzed Metrics Topic</code>에 저장됩니다.</li></ul><ul id="30575f02-2cd3-4dfc-a365-c181745a8037" class="bulleted-list"><li style="list-style-type:disc"><strong>이상 탐지 및 예측(Stream 3)</strong>: <code>Parsed Logs Topic</code>과 <code>Analyzed Metrics Topic</code>에서 데이터를 읽어 머신러닝 모델을 사용하여 이상 탐지 및 장애 예측을 수행합니다. 결과는 <code>Anomaly Detection Topic</code>에 저장됩니다.</li></ul></li></ol><h3 id="4f9840ce-3ca0-4cf9-b97d-bcee5b37c4b0" class="">2.3 머신러닝 모델 적용</h3><ol type="1" id="d5e02b39-ef70-4213-b6ec-43db32d319ca" class="numbered-list" start="1"><li><strong>머신러닝 모델</strong>: 머신러닝 모델은 이상 탐지 및 장애 예측에 사용됩니다.<ul id="59fbd7a3-2333-4646-bdb8-ee49205f6508" class="bulleted-list"><li style="list-style-type:disc">모델은 과거의 로그와 성능 지표 데이터를 사용하여 학습됩니다.</li></ul><ul id="7a203c17-9f24-4110-952f-2b29da255d39" class="bulleted-list"><li style="list-style-type:disc">학습된 모델은 Kafka Streams 애플리케이션 내에서 사용됩니다.</li></ul><ul id="149606cb-5e46-4111-99a6-733f8b8325e3" class="bulleted-list"><li style="list-style-type:disc">모델은 새로운 데이터에 대해 실시간으로 예측을 수행합니다.</li></ul></li></ol><h3 id="49d20f64-a1ac-47d1-b049-035d93fc9f23" class="">2.4 알림 및 대응</h3><ol type="1" id="26f50cf5-ff51-4cb2-abc2-ca5f77fd134e" class="numbered-list" start="1"><li><strong>경고 및 알림 시스템</strong>: <code>Anomaly Detection Topic</code>에서 데이터를 읽어 이상 상황이나 장애가 예측될 경우, 경고를 발행합니다.<ul id="1bda4b22-e1ff-4c91-8d98-5af56172e263" class="bulleted-list"><li style="list-style-type:disc">경고는 이메일, SMS, Slack 등 다양한 채널로 전달될 수 있습니다.</li></ul><ul id="4743269d-5aed-485c-a16d-bdc7f01b7022" class="bulleted-list"><li style="list-style-type:disc">경고는 자동 대응 시스템으로 전달되어, 필요 시 자동으로 대응 작업을 수행합니다.</li></ul></li></ol><h3 id="da934bc9-1c2b-4852-82ea-f87f2edb95d3" class="">2.5 대시보드 및 모니터링</h3><ol type="1" id="1ca1185d-eaaf-4cd1-8c67-050748345b5e" class="numbered-list" start="1"><li><strong>실시간 대시보드</strong>: 모든 토픽의 데이터를 읽어 시각화하고, 시스템의 현재 상태를 표시합니다.<ul id="3853de60-1a4b-4c2a-b0fd-88f5b7b37a6e" class="bulleted-list"><li style="list-style-type:disc">대시보드는 경영진, 운영자, 엔지니어 등 다양한 사용자에게 필요한 정보를 제공합니다.</li></ul><ul id="40e231e2-2802-4439-a514-e88b34236b95" class="bulleted-list"><li style="list-style-type:disc">대시보드는 이상 상황을 실시간으로 모니터링하고, 경고가 발생할 경우 이를 표시합니다.</li></ul></li></ol><hr id="dcd3d8d0-e670-4c93-8a32-5a6a21d70bab"/><h3 id="8b2e1fb5-de72-444a-8e41-a85e2970997f" class="">3. 트래픽 흐름도 예시</h3><ol type="1" id="6e03488e-2c25-48fd-a798-c168a89676d4" class="numbered-list" start="1"><li><strong>데이터 수집</strong>: 네트워크 장비의 로그와 성능 지표 데이터가 Kafka 클러스터에 전송됩니다.</li></ol><ol type="1" id="913f27ff-8e4d-43e1-8d1e-eaf07a507095" class="numbered-list" start="2"><li><strong>Kafka Streams 애플리케이션</strong>은 데이터를 읽고, 로그 파서, 성능 지표 분석기, 이상 탐지 및 예측 프로세스를 통해 데이터를 처리합니다.</li></ol><ol type="1" id="5a85f71b-a607-4cbf-96a7-6987fc1a6c05" class="numbered-list" start="3"><li><strong>머신러닝 모델</strong>은 처리된 데이터를 사용하여 이상 상황을 예측하고, 결과를 Kafka 클러스터에 저장합니다.</li></ol><ol type="1" id="78eb72f5-4f58-46a8-80cf-45ace66efc33" class="numbered-list" start="4"><li><strong>경고 및 알림 시스템</strong>은 예측된 이상 상황에 대해 경고를 발행하고, 자동 대응 시스템은 필요 시 대응 작업을 수행합니다.</li></ol><ol type="1" id="eebccc65-8382-4f55-b1a3-5fbb5afd90bb" class="numbered-list" start="5"><li><strong>실시간 대시보드</strong>는 모든 데이터를 시각화하여 사용자가 시스템의 상태를 실시간으로 모니터링할 수 있도록 합니다.</li></ol><hr id="8f1a3543-91fc-4681-b199-24bf69746082"/><h3 id="a39547ee-8011-4551-9838-28c01c6c4b6d" class="">4. 결론</h3><p id="10609b21-0f37-497a-a115-ce0ef3ea5716" class="">Kafka Streams와 머신러닝을 결합한 이 시스템은 네트워크 장비의 로그와 성능 데이터를 실시간으로 분석하여 잠재적인 장애를 예측하고 예방합니다. 이를 통해 통신사는 네트워크 가용성과 안정성을 높일 수 있으며, 빠른 문제 해결과 운영 효율성을 개선할 수 있습니다. 이 시스템은 대규모 트래픽을 처리할 수 있도록 확장 가능하며, 다양한 장비와 데이터 소스를 지원하도록 설계되었습니다.</p><p id="1ed3a4cc-090a-80d1-b391-ec13ace31f11" class="">
</p></details></li></ul><ul id="4f9b084e-e332-47e0-81fc-caafeb68094d" class="toggle"><li><details open=""><summary>Kafka streams를 활용한 실시간 이상 로그인 감지 시스템 도입</summary><ul id="c21e62b1-f7a3-4247-a350-8f3d4ef21309" class="bulleted-list"><li style="list-style-type:disc">RDB를 조회하는 배치를 개발하는 모델<ul id="a4c17c6e-a7a0-4c73-a28f-6d7152191af2" class="bulleted-list"><li style="list-style-type:circle">하지만 RDB에 직접 조회하고 집계하는 방식은 부하와 실시간 처리의 보장이 어려워 제외</li></ul><figure id="1c4838fc-866a-4c5d-b433-66a7a2bbfb6c" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%204.png"><img style="width:576px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%204.png"/></a></figure></li></ul><ul id="99fd6f3a-1644-4464-993d-1afe62b5088c" class="bulleted-list"><li style="list-style-type:disc">Kafka Streams는 JVM 기반 언어인 Java, Kotlin 등에서 사용 가능한 라이브러리를 지원</li></ul><figure id="2188ff64-9bec-411c-ad4c-605c1efe4c6c" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%205.png"><img style="width:480px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%205.png"/></a></figure><figure id="3a70fa76-d465-49ea-964c-4513d62f3f2c" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%206.png"><img style="width:672px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%206.png"/></a></figure><ul id="7ef9befd-afdf-4219-a79b-ab10ae02a8cf" class="bulleted-list"><li style="list-style-type:disc">이상 로그인 감지<ul id="2e19b7cf-d166-448e-8847-d329c0022ab1" class="bulleted-list"><li style="list-style-type:circle">로그인 시 발생하는 로그성 정보(성공, 실패 등)를 Kafka를 이용하여 후처리로 데이터베이스에 저장</li></ul><ul id="66663fed-3a01-4782-a2f7-f79caf277b41" class="bulleted-list"><li style="list-style-type:circle">이 과정에서 Kafka 브로커로 보내진 메시지의 토픽 변경을 감지하기 위해 Kafka Streams의 Consumer 기능 활용</li></ul><ul id="442265e3-b593-4920-95a8-4091401027da" class="bulleted-list"><li style="list-style-type:circle">Kafka Streams에서는 이러한 토픽 변경을 감지하여 패턴 분석 및 후처리를 위한 데이터 가공 작업을 수행하고, 결과를 이상 로그인 감지 토픽에 발행</li></ul><ul id="ef0b4e24-6a8a-4c58-9a4c-be5bfd0c5267" class="bulleted-list"><li style="list-style-type:circle">이에 대한 후속 조치는 Consumer가 이상 로그인 감지 토픽을 구독하면서 슬랙 메시지 발행, 이력 저장 등을 역할을 수행</li></ul><figure id="1fd473bd-0ab9-4e78-b545-2165d785005f" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%207.png"><img style="width:886.4061889648438px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%207.png"/></a></figure></li></ul></details></li></ul><ul id="d9d9cc99-daf3-40e5-9dcf-e2b9b91cc3ab" class="toggle"><li><details open=""><summary>kafka streams + spark 분석 시스템</summary><p id="40c083a7-4050-42c2-b84e-b830e8413cc1" class="">Kafka Streams와 Apache Spark를 함께 활용한 데이터 분석 시스템은 실시간 스트리밍 데이터 처리와 배치 데이터 처리를 모두 지원하는 강력한 아키텍처입니다. 두 기술의 장점을 결합하여 데이터를 실시간으로 처리, 분석하고, 복잡한 데이터 분석 및 머신러닝 작업을 수행할 수 있습니다. 아래에서는 Kafka Streams와 Spark를 함께 활용한 데이터 분석 시스템의 구성과 활용 예시를 설명합니다.</p><h2 id="a44a356b-d319-4de9-93e9-fa911d252445" class="">1. 시스템 구성</h2><h3 id="75ae25d0-9c42-4dcf-aa3c-1236f244fc58" class="">1.1 아키텍처 개요</h3><h3 id="310c2381-c2c1-4a20-9f10-0b38c8ecdf32" class="">1.2 주요 구성 요소</h3><h3 id="46f4ccec-68f5-40d9-a147-84f75186f27c" class="">Kafka</h3><ul id="0e7d262e-df2c-4812-b98b-dc2e76d81e1f" class="bulleted-list"><li style="list-style-type:disc"><strong>Kafka 클러스터</strong>: 실시간 데이터 스트리밍의 중심. 데이터를 토픽 단위로 수집, 저장, 분산합니다.<ul id="61a9ab00-302c-4712-a1eb-b271892edcc6" class="bulleted-list"><li style="list-style-type:circle"><strong>Source Topic</strong>: 원시 데이터를 수집하는 토픽.</li></ul><ul id="f232a6df-330f-4484-aa6a-81cdba91843b" class="bulleted-list"><li style="list-style-type:circle"><strong>Processed Topic</strong>: Kafka Streams에서 처리된 데이터를 저장하는 토픽.</li></ul><ul id="830826af-3ce9-477c-a10e-69a598db66b6" class="bulleted-list"><li style="list-style-type:circle"><strong>Analytics Topic</strong>: Spark에서 분석한 결과를 저장하는 토픽.</li></ul></li></ul><h3 id="731dfc9a-a4b3-40d9-a760-387ec611d322" class="">Kafka Streams</h3><ul id="9e6ab3bd-06bd-4499-b2ad-74bd2f057446" class="bulleted-list"><li style="list-style-type:disc"><strong>Stream Processing</strong>: 실시간으로 데이터를 처리하고, 필요한 변환 및 필터링 작업을 수행합니다.<ul id="e108e718-21f1-446b-9583-a22491f98b29" class="bulleted-list"><li style="list-style-type:circle"><strong>Filter</strong>: 원시 데이터에서 유의미한 이벤트를 필터링합니다.</li></ul><ul id="188ae3d8-3989-4023-8f17-a2b6ee803f7c" class="bulleted-list"><li style="list-style-type:circle"><strong>Transform</strong>: 데이터를 구조화하고, 필요한 형식으로 변환합니다.</li></ul><ul id="7ceeaf24-7e0c-40b0-a36d-1c1883f74eb9" class="bulleted-list"><li style="list-style-type:circle"><strong>Aggregation</strong>: 데이터의 집계 및 통계를 생성합니다.</li></ul></li></ul><h3 id="1583d4fe-2f7b-4173-9e39-55b7543a1127" class="">Apache Spark</h3><ul id="a1c72fb9-f516-4d4f-951f-29577d6dcbdc" class="bulleted-list"><li style="list-style-type:disc"><strong>Batch and Stream Processing</strong>: Kafka Streams에서 처리된 데이터를 기반으로 복잡한 분석 작업과 머신러닝 모델을 적용합니다.<ul id="218eee5d-b012-4206-abce-4290b964459f" class="bulleted-list"><li style="list-style-type:circle"><strong>Spark Streaming</strong>: Kafka에서 스트림 데이터를 읽고, 추가적인 실시간 분석을 수행합니다.</li></ul><ul id="148dfc8e-c28e-4c54-b400-0acdfb7c5282" class="bulleted-list"><li style="list-style-type:circle"><strong>Spark SQL</strong>: 데이터를 쿼리하고, 분석 결과를 추출합니다.</li></ul><ul id="45cb6727-e8c2-4cb9-9621-8c468eb9ad3c" class="bulleted-list"><li style="list-style-type:circle"><strong>Spark MLlib</strong>: 머신러닝 모델을 학습하고 적용합니다.</li></ul></li></ul><h3 id="b7193f34-0cfe-4571-beda-53a5638426b7" class="">Data Storage</h3><ul id="8bbdd4b5-bd40-4d8a-9a44-2207f34845dc" class="bulleted-list"><li style="list-style-type:disc"><strong>HDFS/S3/NoSQL</strong>: Spark에서 처리된 데이터를 저장하고, 장기 보관을 위해 사용합니다.</li></ul><h3 id="d14b11c2-82be-454b-a371-430c1c3e8b6e" class="">Monitoring and Alerting</h3><ul id="d4a46c39-fc25-4ada-b148-9eba76e2adb6" class="bulleted-list"><li style="list-style-type:disc"><strong>Prometheus/Grafana</strong>: 시스템의 상태와 성능을 모니터링하고, 이상 상황에 대한 경고를 발행합니다.</li></ul><h3 id="595c2465-6b7f-4930-a448-1e854eb8ed84" class="">1.3 데이터 흐름</h3><ol type="1" id="839cbdbf-2ddf-4007-9c6d-8614e77e9314" class="numbered-list" start="1"><li><strong>데이터 수집</strong>: IoT 디바이스, 웹 로그, 금융 거래 등 다양한 소스에서 원시 데이터를 Kafka의 <code>Source Topic</code>에 수집합니다.</li></ol><ol type="1" id="59379701-c56f-4fcc-b17e-eccd8ca2837c" class="numbered-list" start="2"><li><strong>실시간 처리 (Kafka Streams)</strong>: Kafka Streams 애플리케이션이 <code>Source Topic</code>에서 데이터를 읽어 필터링, 변환, 집계 등의 처리를 수행하고, 결과를 <code>Processed Topic</code>에 저장합니다.</li></ol><ol type="1" id="f1ed8ba1-1a54-4d86-b568-a6a8f71f352c" class="numbered-list" start="3"><li><strong>실시간 분석 및 배치 처리 (Spark)</strong>:<ul id="5f45135b-82f2-43a4-8eda-772bc7979cea" class="bulleted-list"><li style="list-style-type:disc">Spark Streaming이 <code>Processed Topic</code>에서 데이터를 읽어 추가적인 실시간 분석을 수행합니다.</li></ul><ul id="599512b4-4561-4d1e-939b-b5eeafc2494f" class="bulleted-list"><li style="list-style-type:disc">Spark SQL 및 MLlib을 사용하여 복잡한 배치 처리, 데이터 분석, 머신러닝 모델 적용을 수행하고, 결과를 <code>Analytics Topic</code>에 저장합니다.</li></ul></li></ol><ol type="1" id="32e559f7-557e-4a88-8ce1-b68869ff73fe" class="numbered-list" start="4"><li><strong>데이터 저장 및 시각화</strong>:<ul id="45b4cb06-8815-4e2f-a9be-5900a91c1419" class="bulleted-list"><li style="list-style-type:disc">분석 결과는 HDFS, S3 또는 NoSQL 데이터베이스에 저장됩니다.</li></ul><ul id="df78abda-a68f-4d51-8efc-831064b72dca" class="bulleted-list"><li style="list-style-type:disc">Grafana와 같은 시각화 도구를 통해 데이터를 시각화하고, 사용자에게 유용한 정보를 제공합니다.</li></ul></li></ol><h2 id="fb5f0454-7970-4ec4-a260-1782425f21ca" class="">2. 활용 예시</h2><h3 id="cf07efc4-66e6-4854-9cdf-996dc3868f67" class="">2.1 금융 거래 모니터링 및 사기 탐지</h3><h3 id="6593bedf-3c73-4aa6-bfe8-8c2881305d22" class="">시나리오</h3><ul id="51c74800-bea9-46b9-9f7e-769242aad6a7" class="bulleted-list"><li style="list-style-type:disc">금융기관은 수백만 건의 거래를 실시간으로 모니터링하고 분석하여, 이상 거래를 탐지하고, 사기 가능성이 있는 거래를 식별합니다.</li></ul><h3 id="42092fc7-9753-4d87-b34f-6cb6b4a3890c" class="">구성 및 활용</h3><ol type="1" id="5239601d-10d5-4c25-940d-26a142398b02" class="numbered-list" start="1"><li><strong>데이터 수집</strong>: 각 거래는 Kafka의 <code>Source Topic</code>에 이벤트로 수집됩니다.</li></ol><ol type="1" id="20129122-4a52-442e-be94-a97d77c26d86" class="numbered-list" start="2"><li><strong>Kafka Streams 처리</strong>: 거래 데이터를 필터링하고, 각 거래의 금액, 빈도, 위치 등의 속성을 분석합니다.</li></ol><ol type="1" id="5dff9c5e-b141-4cb4-b1d9-415ac411264a" class="numbered-list" start="3"><li><strong>Spark 분석</strong>:<ul id="4352ad55-0790-41cd-ac9f-41f04367d18a" class="bulleted-list"><li style="list-style-type:disc">Spark Streaming이 Kafka Streams에서 처리된 데이터를 기반으로 더 복잡한 이상 패턴 분석을 수행합니다.</li></ul><ul id="d1f269c6-fcbe-4c0b-9d8d-d0f8848acf4f" class="bulleted-list"><li style="list-style-type:disc">Spark MLlib를 사용하여 사기 탐지 머신러닝 모델을 학습하고, 이를 실시간 거래 데이터에 적용합니다.</li></ul></li></ol><ol type="1" id="130a7548-b188-4492-98af-524422251fe7" class="numbered-list" start="4"><li><strong>결과 저장 및 경고</strong>: 사기로 식별된 거래는 <code>Analytics Topic</code>에 저장되고, 즉시 관련 부서에 경고가 발송됩니다.</li></ol><h3 id="525e682f-e813-4c32-8ec2-29cf0a5e497a" class="">2.2 e-커머스 실시간 추천 시스템</h3><h3 id="70548448-be5f-4792-b376-f559ea147fbd" class="">시나리오</h3><ul id="3074dae0-ac51-41e2-8345-b07af43eb4cd" class="bulleted-list"><li style="list-style-type:disc">전자 상거래 플랫폼은 고객의 실시간 웹 탐색 및 구매 행동을 기반으로 개인화된 제품 추천을 제공합니다.</li></ul><h3 id="3ce03cfd-243e-4d33-b0e8-325718bcb49c" class="">구성 및 활용</h3><ol type="1" id="01d34260-ec12-44bd-8d21-2fb04ca2352d" class="numbered-list" start="1"><li><strong>데이터 수집</strong>: 고객의 웹 탐색 및 구매 이벤트는 Kafka의 <code>Source Topic</code>에 기록됩니다.</li></ol><ol type="1" id="8011fddf-e231-4fec-a775-6dd6d90cda5b" class="numbered-list" start="2"><li><strong>Kafka Streams 처리</strong>: 실시간으로 고객의 현재 탐색 상태 및 구매 기록을 분석합니다.</li></ol><ol type="1" id="938063e1-39a2-43dd-9fd1-a61c5598888e" class="numbered-list" start="3"><li><strong>Spark 분석</strong>:<ul id="c7f39227-f96f-44d7-b2c8-8b9458a335fa" class="bulleted-list"><li style="list-style-type:disc">Spark SQL을 사용하여 과거의 구매 데이터와 현재의 웹 탐색 데이터를 조합하여 고객의 선호도를 분석합니다.</li></ul><ul id="9e9f635a-765e-4ada-bb12-60c0449d9a36" class="bulleted-list"><li style="list-style-type:disc">Spark MLlib를 사용하여 협업 필터링 모델을 학습하고, 실시간으로 고객에게 추천 제품을 제공합니다.</li></ul></li></ol><ol type="1" id="b470f1a6-0683-4c5a-a8e4-3b40a0fada41" class="numbered-list" start="4"><li><strong>추천 시스템</strong>: 분석 결과는 <code>Analytics Topic</code>에 저장되고, 웹 애플리케이션은 이를 기반으로 고객에게 맞춤형 추천을 표시합니다.</li></ol><h3 id="11223591-6500-46dd-9411-7b4d4681fb70" class="">2.3 IoT 장비 모니터링 및 이상 감지</h3><h3 id="b0465487-0cf6-4694-b7fb-b49a7e0ca593" class="">시나리오</h3><ul id="21080cc6-bcb9-452f-b06f-e34662cf74d3" class="bulleted-list"><li style="list-style-type:disc">제조업에서는 생산 라인의 IoT 장비에서 수집된 데이터를 실시간으로 모니터링하고, 장비의 이상 상태를 감지하여 조기 경고를 제공합니다.</li></ul><h3 id="4c5f65fd-a49e-4b4b-8bbb-21388696bfcd" class="">구성 및 활용</h3><ol type="1" id="1f36a5b1-0109-41cc-9976-1ec6a977dfd8" class="numbered-list" start="1"><li><strong>데이터 수집</strong>: IoT 장비에서 생성된 데이터는 Kafka의 <code>Source Topic</code>에 수집됩니다.</li></ol><ol type="1" id="d5353626-85a6-4806-b7c3-a005729d38af" class="numbered-list" start="2"><li><strong>Kafka Streams 처리</strong>: 장비 데이터에서 이상 패턴을 필터링하고, 구조화된 형식으로 변환합니다.</li></ol><ol type="1" id="854e7374-b01d-4c03-a87c-e1cdc6813c8a" class="numbered-list" start="3"><li><strong>Spark 분석</strong>:<ul id="3f9ccf48-e9ca-44d7-b1d6-da06a02e6325" class="bulleted-list"><li style="list-style-type:disc">Spark Streaming을 사용하여 장비 데이터의 실시간 분석을 수행합니다.</li></ul><ul id="e9f5a477-c56a-45e6-97ba-eb7ead2e7418" class="bulleted-list"><li style="list-style-type:disc">Spark MLlib를 사용하여 이상 감지 모델을 적용하여 장비의 이상 상태를 예측합니다.</li></ul></li></ol><ol type="1" id="f5d3532f-92aa-4ef6-be7d-27126f660916" class="numbered-list" start="4"><li><strong>결과 저장 및 경고</strong>: 이상 상태로 식별된 장비는 <code>Analytics Topic</code>에 저장되고, 즉시 기술팀에 경고가 발송됩니다.</li></ol><h3 id="db59bea4-69f2-44d5-93e1-f611913395e7" class="">2.4 소셜 미디어 감정 분석</h3><h3 id="eb3409c9-abbc-4a51-a2cb-e6e9878fda19" class="">시나리오</h3><ul id="e59b82b4-9c4b-4820-8a43-8c3a9748df46" class="bulleted-list"><li style="list-style-type:disc">기업은 고객의 소셜 미디어 활동을 분석하여 브랜드에 대한 감정을 파악하고, 마케팅 전략을 조정합니다.</li></ul><h3 id="aa8db256-ed7d-4c4d-a486-a3065b8296dd" class="">구성 및 활용</h3><ol type="1" id="adb25435-41bd-42b3-b3fa-4ec0bab6f679" class="numbered-list" start="1"><li><strong>데이터 수집</strong>: 트위터, 페이스북 등의 소셜 미디어 플랫폼에서 수집된 데이터는 Kafka의 <code>Source Topic</code>에 저장됩니다.</li></ol><ol type="1" id="670684b0-5a40-493b-92ca-b1d60e020b02" class="numbered-list" start="2"><li><strong>Kafka Streams 처리</strong>: 텍스트 데이터에서 불필요한 정보를 제거하고, 필요한 속성을 추출합니다.</li></ol><ol type="1" id="76cb3fe0-cd99-4dc4-bf3d-438145cb3fb9" class="numbered-list" start="3"><li><strong>Spark 분석</strong>:<ul id="ac6bd94e-8d4d-4102-a20d-60ce078d71d6" class="bulleted-list"><li style="list-style-type:disc">Spark SQL을 사용하여 텍스트 데이터를 분석하고, 키워드 빈도를 계산합니다.</li></ul><ul id="6f190b32-7114-4ee0-9654-c61d20295a42" class="bulleted-list"><li style="list-style-type:disc">Spark MLlib를 사용하여 감정 분석 모델을 학습하고, 실시간으로 소셜 미디어 텍스트 데이터에 적용합니다.</li></ul></li></ol><ol type="1" id="428b4cda-a396-425d-8cdc-233274cd1fb4" class="numbered-list" start="4"><li><strong>결과 저장 및 경고</strong>: 분석된 감정 데이터는 <code>Analytics Topic</code>에 저장되고, 마케팅 팀에 보고됩니다.</li></ol><hr id="9cb6fb45-f8b7-4401-9ce0-cda30c397c29"/><h2 id="16261ec0-c4f9-46b9-92d5-7501a9662710" class="">3. 장점 및 고려사항</h2><h3 id="9b9bfe78-f01f-4d86-9943-a9e88f54edb7" class="">3.1 장점</h3><ul id="dc833a3b-bb45-45ba-b46d-b2a06285de9b" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 처리와 배치 처리의 조합</strong>: Kafka Streams는 실시간 데이터 처리를, Spark는 배치 처리와 복잡한 분석 작업을 수행하여 두 기술의 장점을 모두 활용할 수 있습니다.</li></ul><ul id="93cd61a0-a955-412f-bc43-dd6033275587" class="bulleted-list"><li style="list-style-type:disc"><strong>확장성</strong>: Kafka와 Spark 모두 높은 확장성을 가지고 있어, 대규모 데이터를 효율적으로 처리할 수 있습니다.</li></ul><ul id="688f4a09-45f9-48f4-a006-12a22f0de387" class="bulleted-list"><li style="list-style-type:disc"><strong>유연성</strong>: 다양한 데이터 소스와 분석 요구 사항에 대응할 수 있는 유연한 아키텍처를 제공합니다.</li></ul><h3 id="9ef7ce81-9cd6-46c6-8b9c-82f6b16c78c9" class="">3.2 고려사항</h3><ul id="b308d0ff-14bb-4631-81c3-09a3788c58f0" class="bulleted-list"><li style="list-style-type:disc"><strong>복잡성</strong>: 두 가지 기술을 함께 사용하면 시스템의 복잡도가 증가할 수 있으며, 운영 및 유지 관리에 추가적인 노력이 필요합니다.</li></ul><ul id="4e0c5a44-d80e-4516-a810-9bbb488c42e8" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 일관성</strong>: 실시간 처리와 배치 처리 간의 데이터 일관성을 유지하기 위한 추가적인 설계와 구현이 필요합니다.</li></ul><ul id="f511b4b6-7a02-4682-80bc-2e904fa3d647" class="bulleted-list"><li style="list-style-type:disc"><strong>자원 관리</strong>: Kafka와 Spark 모두 높은 자원 요구 사항을 가지므로, 적절한 자원 할당과 관리가 필요합니다.</li></ul><hr id="bde38eae-b3b9-4170-b781-be3aa5e6609e"/><p id="e74a75f4-44e0-4762-ac3c-a7b9d327260e" class="">Kafka Streams와 Spark를 함께 활용한 데이터 분석 시스템은 실시간성과 복잡한 분석 작업을 모두 만족시킬 수 있는 유연하고 강력한 솔루션입니다. 이를 통해 다양한 산업에서 실시간 데이터 처리 및 분석의 요구 사항을 충족할 수 있습니다.</p></details></li></ul><p id="2cc6da5e-fcb6-4284-a833-4bab0e8ebfd8" class="">
</p><ul id="b7e00097-c3b1-4fc8-b360-1089cde93bfc" class="toggle"><li><details open=""><summary>신뢰성 있는 카프카 애플리케이션을 만드는 3가지 방법</summary><ul id="7f060254-ee41-4e16-88c7-8de194a184ee" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.youtube.com/watch?v=7_VdIFH6M6Q">https://www.youtube.com/watch?v=7_VdIFH6M6Q</a></li></ul><ul id="f76fb5e4-3ea8-4b21-a231-f05081827a62" class="bulleted-list"><li style="list-style-type:disc">메시지 전달 신뢰성 확보 중요<figure id="59885d9a-0779-4f4d-8d49-2a1eb2547aab" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.36.48.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.36.48.png"/></a></figure><figure id="e619d492-9a7c-4694-a6ad-d4df14435dd5" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.37.28.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.37.28.png"/></a></figure></li></ul><ul id="2800bc02-9611-416c-8508-d11e587a908c" class="bulleted-list"><li style="list-style-type:disc">아치 카프카 <figure id="78adf655-b918-4ea4-9a98-cb775f202e68" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.38.27.png"><img style="width:480.397705078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.38.27.png"/></a></figure></li></ul><ul id="054196e4-8973-49c5-a49f-2d0e0c050c09" class="bulleted-list"><li style="list-style-type:disc">프듀서의 메시지 전달 신뢰도<figure id="f183e4e6-c1b3-43d9-916b-62f92908535f" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.40.08.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.40.08.png"/></a></figure><figure id="820f74e4-3edb-4f89-aa6e-3851c8e72649" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.41.12.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.41.12.png"/></a></figure><figure id="f4f98cc7-b677-472b-8d11-6d4aca264f57" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.42.28.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.42.28.png"/></a></figure></li></ul><ul id="2dee563d-343d-464b-be6a-3344b3bb402a" class="bulleted-list"><li style="list-style-type:disc">토픽 to 토픽의 메시지 전달<figure id="a9656944-aebc-4011-8341-9109e4d7037e" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.43.35.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.43.35.png"/></a></figure><figure id="346a9cdb-ec68-48d9-a706-97b6b01635a2" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.43.48.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.43.48.png"/></a></figure><figure id="60d7f57a-9edf-43c8-953a-7d5f6bfcec73" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.44.46.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.44.46.png"/></a></figure><figure id="7c03fa85-cd0e-4438-be91-dadd73d599ac" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.46.32.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.46.32.png"/></a></figure></li></ul><ul id="1d223534-2bad-4da5-b9d2-4b3f57325a26" class="bulleted-list"><li style="list-style-type:disc">컨슈머의 중복 적재 방지<figure id="bbafe0ac-3073-443e-b667-c04f4c1295ff" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.48.00.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.48.00.png"/></a></figure><figure id="760e96e6-984e-4a85-85a5-60bceabe1ef2" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.49.10.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.49.10.png"/></a></figure><figure id="2b4a7c51-ff6c-4b15-ac7b-e481d9317e70" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.49.50.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.49.50.png"/></a></figure><figure id="6c46253d-edf9-4b66-82ea-b9c3bf45b494" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.50.35.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.50.35.png"/></a></figure></li></ul><ul id="742e3d07-07e9-4a38-93d1-b87bcbb491fc" class="bulleted-list"><li style="list-style-type:disc">3가지 방법 정리<figure id="c69c0658-ba84-42d2-bc91-fe3948cb0c38" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.51.13.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.51.13.png"/></a></figure></li></ul><ul id="62b48b8c-f773-4c65-a2e9-60aa3c2181b2" class="bulleted-list"><li style="list-style-type:disc">내부 활용 사례<figure id="5e7ec6db-a993-4829-aa51-73d342503872" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.52.04.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.52.04.png"/></a></figure><figure id="9308612e-14f6-47ef-848e-822424e5d9b8" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.52.28.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.52.28.png"/></a></figure><figure id="d414cda3-4957-49cf-8b9c-80c1fab5ce14" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.52.42.png"><img style="width:452.428955078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-29_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_9.52.42.png"/></a></figure><p id="760690d4-eca1-4edb-bc6e-227edceb6289" class="">
</p></li></ul></details></li></ul><ul id="0a565c18-6552-4007-9315-cda43859c7ea" class="toggle"><li><details open=""><summary>kafka 에서 데이터 신뢰성 보장 문제/해결</summary><p id="163464b4-276d-49ac-82a5-16f5351c85c6" class="">카프카(Kafka) 어플리케이션 개발에서 신뢰성 있는 데이터 처리를 위해서는 여러 문제점과 해결 방안을 고려해야 합니다. 다음은 카프카를 사용하면서 발생할 수 있는 문제점과 각각의 해결 방안에 대한 설명입니다.</p><h2 id="4bfae154-596a-4617-9001-9a054fa11fe0" class="">1. 데이터 손실</h2><h3 id="79e1ea0e-fe4d-4588-bebb-47292b27161d" class="">문제점</h3><ul id="e5824aaa-d75c-4997-8090-46dfdd362959" class="bulleted-list"><li style="list-style-type:disc"><strong>프로듀서에서의 데이터 손실</strong>: 프로듀서에서 브로커로 데이터를 전송하는 중에 문제가 발생하여 메시지가 유실될 수 있습니다.</li></ul><ul id="f31cad44-ae8d-437e-a742-396c91dd6c93" class="bulleted-list"><li style="list-style-type:disc"><strong>브로커에서의 데이터 손실</strong>: 브로커 노드 실패 시, 해당 노드에 저장된 데이터가 손실될 수 있습니다.</li></ul><ul id="8657f4ca-e721-447b-a6b7-6ffdbadd1a60" class="bulleted-list"><li style="list-style-type:disc"><strong>컨슈머에서의 데이터 손실</strong>: 컨슈머가 메시지를 처리하기 전에 실패하면 메시지가 다시 처리되지 않고 유실될 수 있습니다.</li></ul><h3 id="0657affe-f5e2-4d45-ae68-8d35b3cd3586" class="">해결 방안</h3><ul id="352f74b2-ffd7-421c-b992-091183eda637" class="bulleted-list"><li style="list-style-type:disc"><strong>ACK 설정</strong>: 프로듀서 설정에서 <code>acks=all</code> 옵션을 사용하여 모든 리플리카에 기록될 때까지 기다리도록 설정합니다.</li></ul><ul id="4e0b141a-6207-410b-9b20-fd102871e8ca" class="bulleted-list"><li style="list-style-type:disc"><strong>ISR(In-Sync Replica) 사용</strong>: 카프카는 리더-팔로워 구조를 사용합니다. ISR을 이용하면 모든 리플리카가 동기화될 때까지 메시지를 커밋하지 않아 데이터 손실을 최소화할 수 있습니다.</li></ul><ul id="7d19d01e-9748-4559-90fb-8ce693b573b4" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 복제(factor 설정)</strong>: 토픽 생성 시 복제 팩터(replication factor)를 2 이상으로 설정하여 데이터 유실 시 다른 노드에서 복구할 수 있도록 합니다.</li></ul><ul id="2d55f569-77e6-4c37-bb59-90f7c3ee870e" class="bulleted-list"><li style="list-style-type:disc"><strong>Idempotent Producer 사용</strong>: 동일한 메시지를 여러 번 전송해도 동일한 결과를 얻을 수 있도록 설정하여 프로듀서의 중복 전송 문제를 해결합니다.</li></ul><ul id="73428de7-3b80-4324-b837-ac9aba98e060" class="bulleted-list"><li style="list-style-type:disc"><strong>컨슈머 오프셋 관리</strong>: 컨슈머 그룹에서 오프셋 커밋을 자동으로 하지 않고 수동 커밋을 사용하여 데이터 처리 완료 시점에 오프셋을 기록합니다.</li></ul><h2 id="fe6cb7d0-5b69-41be-91fe-e2667a732e7d" class="">2. 메시지 순서 보장</h2><h3 id="7ddccd97-5719-4996-9b84-50743186aada" class="">문제점</h3><ul id="f7a22b57-4219-4c04-87fc-f761135a361c" class="bulleted-list"><li style="list-style-type:disc"><strong>메시지 순서 불일치</strong>: 프로듀서가 동일한 파티션에 동시에 여러 메시지를 보낼 경우 순서가 바뀔 수 있습니다.</li></ul><h3 id="c34a4569-af38-481f-92f3-b3c51d77e131" class="">해결 방안</h3><ul id="c618bc1a-e1b1-48bc-8ce6-708f3cbe5a6a" class="bulleted-list"><li style="list-style-type:disc"><strong>파티션 키 사용</strong>: 동일한 파티션 키를 가진 메시지들은 같은 파티션에 저장되므로 순서를 보장할 수 있습니다.</li></ul><ul id="14d0638f-bd2d-4bf8-8d2d-835d8abcc6a8" class="bulleted-list"><li style="list-style-type:disc"><strong>프로듀서 측에서의 순서 보장 설정</strong>: 프로듀서 설정에서 <code>max.in.flight.requests.per.connection=1</code>로 설정하면 순서가 보장됩니다.</li></ul><h2 id="e396d399-8b66-4e73-892d-02882214d209" class="">3. 중복 메시지 처리</h2><h3 id="edb42c8c-2be2-443a-af66-4008ab84973b" class="">문제점</h3><ul id="32753079-7576-46f2-8f56-07a213b413f8" class="bulleted-list"><li style="list-style-type:disc"><strong>프로듀서 또는 컨슈머의 재시도로 인한 중복 메시지 발생</strong>: 메시지 전송이 실패하거나 처리 중 오류가 발생했을 때 재시도할 경우 중복 메시지가 발생할 수 있습니다.</li></ul><h3 id="d720a350-3a35-4969-b916-7ef625ae0404" class="">해결 방안</h3><ul id="3bc31d0e-d337-477e-b420-4227892e9a86" class="bulleted-list"><li style="list-style-type:disc"><strong>Idempotent Producer 사용</strong>: 프로듀서에서 메시지를 중복 전송하더라도 동일한 결과를 보장할 수 있는 설정을 사용합니다.</li></ul><ul id="81671b8e-868d-47d5-808a-8b231a5f3b2d" class="bulleted-list"><li style="list-style-type:disc"><strong>중복 제거 로직 구현</strong>: <span style="border-bottom:0.05em solid">컨슈머 측에서 메시지 키를 기반으로 중복 여부를 판단하여 처리하는 로직을 구현</span>합니다.</li></ul><h2 id="a6ad74d5-7675-4f86-abca-3747ec5c2b0b" class="">4. 데이터 일관성 문제</h2><h3 id="2510b1d2-9288-4ddf-801d-c3fa732fa884" class="">문제점</h3><ul id="35e4f8ec-be79-4cfe-952f-233d1e6ace82" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 불일치</strong>: 분산 환경에서 여러 컨슈머가 동시에 데이터를 처리할 때 일관성이 보장되지 않을 수 있습니다.</li></ul><h3 id="5e1b3992-60a4-4264-9636-c9622d080be9" class="">해결 방안</h3><ul id="32bd4526-284f-4e94-8a1f-2d26610f9886" class="bulleted-list"><li style="list-style-type:disc"><strong>트랜잭션 사용</strong>: <span style="border-bottom:0.05em solid">카프카에서 제공하는 트랜잭션 기능을 사용하여 프로듀서와 컨슈머 간의 데이터 일관성을 보장</span>합니다.</li></ul><ul id="0c010c14-8ab1-42d4-84af-4515d59a44b0" class="bulleted-list"><li style="list-style-type:disc"><strong>분산 락 사용</strong>: 여러 <span style="border-bottom:0.05em solid">컨슈머가 동일한 데이터에 접근할 때 분산 락을 사용하여 일관성을 유지</span>합니다.</li></ul><h2 id="c9aac373-6c3f-4dfb-b414-f3b18d78c70a" class="">5. 스케일링 문제</h2><h3 id="361bec6c-351e-4639-9f51-df84690a5a74" class="">문제점</h3><ul id="bd0bd205-2f0a-4ed7-b335-ed7cae6d67ce" class="bulleted-list"><li style="list-style-type:disc"><strong>브로커 및 클러스터의 확장성</strong>: 데이터 양이 많아지거나 클러스터에 더 많은 프로듀서와 컨슈머가 추가될 때 성능 저하가 발생할 수 있습니다.</li></ul><h3 id="f2b4a622-55dc-4e22-949c-be3ddaa0c19c" class="">해결 방안</h3><ul id="b9af86a5-033c-431e-b2d1-34699931179e" class="bulleted-list"><li style="list-style-type:disc"><strong>파티션 확장</strong>: 토픽의 파티션 수를 늘려 병렬 처리를 향상시킵니다.</li></ul><ul id="1957df91-7ae2-48ce-ac49-74a5330973a4" class="bulleted-list"><li style="list-style-type:disc"><strong>클러스터 리밸런싱</strong>: 카프카의 리밸런싱 기능을 사용하여 클러스터 내에서 데이터의 균형을 맞춥니다.</li></ul><ul id="16f0e48e-de2f-4e99-9505-2c2b9df33b19" class="bulleted-list"><li style="list-style-type:disc"><strong>리소스 모니터링 및 확장</strong>: 클러스터의 성능을 모니터링하고 필요에 따라 리소스를 확장합니다.</li></ul><h2 id="6b5eb8b5-0571-45ed-ac99-1e3303a96130" class="">6. 장애 조치(Failover) 및 복구</h2><h3 id="e00dddcd-0b93-40a9-af54-93bd1b6abc03" class="">문제점</h3><ul id="dbee50b8-3cfb-4d3d-a3ad-f4961d103d2c" class="bulleted-list"><li style="list-style-type:disc"><strong>브로커 장애</strong>: 브로커가 장애를 겪을 경우 데이터 처리에 지연이 발생하거나 데이터가 손실될 수 있습니다.</li></ul><ul id="13343ce2-74fb-4da3-b022-788db00153b1" class="bulleted-list"><li style="list-style-type:disc"><strong>컨슈머 장애</strong>: 컨슈머가 중단되면 데이터 처리가 중단될 수 있습니다.</li></ul><h3 id="36eb45e7-71bc-46b7-b550-b02a44434007" class="">해결 방안</h3><ul id="6a62ece2-0a00-464a-a3a9-9cdbf42a1381" class="bulleted-list"><li style="list-style-type:disc"><strong>멀티 브로커 설정</strong>: 여러 브로커를 설정하여 한 브로커가 장애가 발생하더라도 다른 브로커가 작동하도록 합니다.</li></ul><ul id="4fcb4eb5-d823-450c-9975-f12973e7cc58" class="bulleted-list"><li style="list-style-type:disc"><strong>컨슈머 그룹 사용</strong>: 컨슈머를 그룹으로 구성하여 한 컨슈머가 중단되더라도 다른 컨슈머가 데이터를 처리할 수 있도록 합니다.</li></ul><ul id="1ba7bdad-ee07-4000-a87d-c0bd4ded3d06" class="bulleted-list"><li style="list-style-type:disc"><strong>자동 복구 설정</strong>: 브로커 및 컨슈머에 대해 자동 재시작 및 복구를 설정합니다.</li></ul><h2 id="9e7e7d49-59c0-420c-b4e6-63e27dd8cd98" class="">7. 데이터 처리 지연</h2><h3 id="16d58db5-8407-412c-95de-5c7bfc6cb76c" class="">문제점</h3><ul id="f2c893e4-9fb2-4ebf-9932-d419449dea2c" class="bulleted-list"><li style="list-style-type:disc"><strong>네트워크 지연</strong>: 네트워크 문제로 인해 데이터 처리가 지연될 수 있습니다.</li></ul><ul id="5a152f29-c80e-4930-9588-fcc2418aaf1a" class="bulleted-list"><li style="list-style-type:disc"><strong>브로커의 과부하</strong>: 브로커에 과도한 데이터가 몰리면 처리 속도가 느려질 수 있습니다.</li></ul><h3 id="028d4807-e6e5-4713-a80c-5196db5d6c81" class="">해결 방안</h3><ul id="1d31f2ef-bbc7-4e75-b05b-95aeb56af52a" class="bulleted-list"><li style="list-style-type:disc"><strong>네트워크 최적화</strong>: 네트워크 대역폭을 최적화하고 데이터 전송 경로를 최적화하여 지연을 최소화합니다.</li></ul><ul id="ef37ef75-b6f7-4932-8a18-d1f6551ab488" class="bulleted-list"><li style="list-style-type:disc"><strong>로드 밸런싱</strong>: 브로커와 컨슈머 간의 부하를 분산하여 성능을 최적화합니다.</li></ul><ul id="31d6416d-53dd-4789-9c7f-3309a70cbb47" class="bulleted-list"><li style="list-style-type:disc"><strong>캐싱 사용</strong>: 필요한 경우 데이터 처리 전에 캐싱을 사용하여 처리 속도를 높입니다.</li></ul><h2 id="1a0c5f2e-59de-4dba-85cd-1d8e502cef7e" class="">8. 운영 및 모니터링 문제</h2><h3 id="9a30ebcb-2e8c-4800-a836-1264e3e06a0b" class="">문제점</h3><ul id="f145c299-8a67-403c-87e1-9f0893ab15bd" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링 부족</strong>: 카프카 클러스터의 상태를 제대로 모니터링하지 않으면 문제가 발생할 때 신속하게 대응하기 어렵습니다.</li></ul><ul id="ba342cb4-9932-4b6b-b28f-49cd18868d7f" class="bulleted-list"><li style="list-style-type:disc"><strong>운영 복잡성</strong>: 대규모 카프카 클러스터를 운영할 때 복잡도가 증가합니다.</li></ul><h3 id="c33c071c-9a50-4a1e-bba5-933430dcaa9d" class="">해결 방안</h3><ul id="91f43a2b-8965-43f7-a49d-b92bee979b8f" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링 툴 사용</strong>: Grafana, Prometheus, JMX 등을 사용하여 카프카 클러스터의 상태를 모니터링합니다.</li></ul><ul id="0741b62f-3a1e-4954-88b8-16d5d6b63af1" class="bulleted-list"><li style="list-style-type:disc"><strong>알림 시스템 구축</strong>: 장애나 성능 저하가 발생했을 때 즉각적으로 알림을 받을 수 있도록 설정합니다.</li></ul><ul id="6ba49ce0-86a4-4ba6-ba43-836c18972c65" class="bulleted-list"><li style="list-style-type:disc"><strong>자동화된 운영 절차</strong>: 스크립트와 자동화 도구를 사용하여 운영 작업을 간소화합니다.</li></ul><p id="b56bb909-98e7-43f9-9311-c6da1de2f4a9" class="">위에서 언급한 문제점과 해결 방안을 고려하여 카프카 어플리케이션을 개발하고 운영하면 데이터 처리의 신뢰성을 높이고 안정적인 시스템을 구축할 수 있습니다.</p></details></li></ul><ul id="8098de3f-be87-4b9d-9dd2-f4fae8202fff" class="toggle"><li><details open=""><summary>배민 - 회원시스템 이벤트기반 아키텍처 구축하기</summary><figure id="8d2dcfec-a2e6-4b97-b3e2-4233f8a5a742"><a href="https://techblog.woowahan.com/7835/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">회원시스템 이벤트기반 아키텍처 구축하기 | 우아한형제들 기술블로그</div><div class="bookmark-description">배달의민족의 주문수는 J 커브를 그리는 빠른 속도로 성장했고, 주문수가 커지면서 자연스럽게 트래픽 또한 매우 커졌습니다.</div></div><div class="bookmark-href"><img src="https://techblog.woowahan.com/wp-content/uploads/2020/08/favicon.ico" class="icon bookmark-icon"/>https://techblog.woowahan.com/7835/</div></div><img src="https://techblog.woowahan.com/wp-content/uploads/2022/04/회원시스템-이벤트기반-아키텍처-구축하기.jpg" class="bookmark-image"/></a></figure></details></li></ul><p id="f120de05-cb3e-4830-8e2a-eb98e1d4d78f" class="">
</p><p id="ae5ed8fb-697d-4689-8950-e9f5988bb589" class="">DB</p><ul id="92b528f0-ce69-4006-897f-8f011613f7e3" class="toggle"><li><details open=""><summary>ERD - MarketGola 프로젝트</summary><ul id="725b26ad-212f-45d6-93f2-5783590405df" class="bulleted-list"><li style="list-style-type:disc">‘유저’, ‘상품’, ‘후기’ 등이 개체이고 ‘주문 기록’, ‘결제 기록’ 등이 사건<ul id="834ac777-3ea8-44d8-86c1-371127b2b90b" class="bulleted-list"><li style="list-style-type:circle">&#x27;유연성&#x27;이 &#x27;성능&#x27;보다 우선순위가 높기 때문에 유저 테이블 또한 인조키를 기본키로 하기로 결정하였습니다.</li></ul></li></ul><figure id="42fc1329-af26-4d17-bcbe-7eacc85ed1a4" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2014.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2014.png"/></a></figure><ul id="1621c8c6-0b9c-4cba-9580-ef6f3cc6c194" class="bulleted-list"><li style="list-style-type:disc">사진을 가진 후기<ul id="3c899cdf-f9d6-4056-8b09-5f5b1a2be138" class="bulleted-list"><li style="list-style-type:circle">다중 값 필드와 다중 부분 필드는 그 안에 데이터를 수정, 삭제, 정렬, 그룹화하기가 어렵기 때문에 피하는 것이 좋습니다.</li></ul><figure id="1142f2bd-8a21-473d-97ad-b389230a7732" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2015.png"><img style="width:397.99713134765625px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2015.png"/></a></figure></li></ul><ul id="449ec725-0872-457c-a908-6f75ae4a79ba" class="bulleted-list"><li style="list-style-type:disc">절대적으로 최소한의 중복 데이터만 포함한다<figure id="93a2fff3-3624-4e21-a147-2c515dd775de" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2016.png"><img style="width:452.99713134765625px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2016.png"/></a></figure></li></ul><ul id="4cfa11ad-e97c-4351-8bcb-82f4a9f4b241" class="bulleted-list"><li style="list-style-type:disc">다대다 관계 풀어주기<figure id="e8ac555e-dd1e-4f3e-bd0e-58e1d9e05052" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2017.png"><img style="width:690.4260864257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2017.png"/></a></figure></li></ul><ul id="a3cfa064-0cce-42bf-8a3b-351fab057b7c" class="bulleted-list"><li style="list-style-type:disc">전시용 상품 구성<figure id="1403a339-258f-4b8a-8d7f-9658e3af5455" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2018.png"><img style="width:279.9875183105469px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2018.png"/></a></figure></li></ul><ul id="54a2fe37-433d-4696-91ab-552a859df4cb" class="bulleted-list"><li style="list-style-type:disc">적립금 관리<figure id="a183b7fb-8297-43f1-a06b-06ac012258c6" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2019.png"><img style="width:690.4260864257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2019.png"/></a></figure></li></ul><ul id="7f7a0db5-a8ff-47b3-a261-77585227b6f7" class="bulleted-list"><li style="list-style-type:disc">부분 환불<figure id="3223f010-3589-4a46-88de-7267a02e8c00" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2020.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2020.png"/></a></figure></li></ul><ul id="68d4c411-6b8a-40b7-aef8-67e63b40d22d" class="bulleted-list"><li style="list-style-type:disc">할인율<figure id="7df941d3-ddc9-40fa-99a7-d8b8862c5e35" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2021.png"><img style="width:700.9942626953125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2021.png"/></a></figure></li></ul><p id="6029a1f7-fe2e-461c-baa1-6e8d92410d9c" class="">
</p><p id="24dfdf4b-2f1d-4bc7-8575-2f7e7d23aa57" class="">최종 ERD</p><figure id="e378aa36-d913-4c78-9474-f9637da3cb00" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2022.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2022.png"/></a></figure><figure id="1acc3e08-1359-4bbd-8828-67f3758ebe22"><a href="https://velog.io/@sontulip/how-to-db-design" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">DB 설계는 어떻게 해야 할까?</div><div class="bookmark-description">도대체 어떻게 설계해야 할까? 😂</div></div><div class="bookmark-href"><img src="https://static.velog.io/favicons/apple-icon-152x152.png" class="icon bookmark-icon"/>https://velog.io/@sontulip/how-to-db-design</div></div><img src="https://velog.velcdn.com/images/sontulip/post/209631a1-7a9c-42ad-a808-25eb5e20e061/image.png" class="bookmark-image"/></a></figure><p id="f20ae533-b4d6-4e0b-9b28-5eef1bfa3548" class="">
</p></details></li></ul><ul id="a8b59c1b-2f03-4d4a-84ae-6447f1ba40a8" class="toggle"><li><details open=""><summary>Toss - 캐시 문제 해결 가이드 - DB 과부하 방지 실전 팁</summary><p id="511e8b92-9eea-4e08-ae4d-ae034d46c3f4" class="">데이터베이스는 시스템을 확장하기 어려워요. 주로 샤딩과 복제를 통해 어렵게 확장해야 하는데다가, 이 과정에서 일관성, 가용성, 분할 내성 셋을 모두 만족시킬 수 없다는 점이 널리 알려져 있죠(<a href="https://www.ibm.com/kr-ko/topics/cap-theorem">CAP 이론</a>). 그래서 데이터베이스를 확장할 때는 신중해야 돼요.</p><p id="60ac16b7-8dc2-4393-b7f5-df2c53a29584" class="">가급적 데이터베이스의 부하를 최소화하여 확장 필요성을 줄이는 것이 바람직한데요. 이를 위한 기본적인 접근법은 데이터베이스 조회 이전에 캐시를 먼저 확인하는 것입니다. 높은 캐시 히트율을 유지하면 데이터베이스 확장 없이도 상당한 트래픽을 처리할 수 있어요.</p><p id="dca70cfe-ff90-4fa0-b540-14b7140825ab" class=""><a href="https://redis.com/">Redis</a>나 <a href="https://memcached.org/">Memcached</a>와 같은 인메모리 저장소로 캐시 시스템을 많이 구축합니다. 사용하기 쉬운 데다가 응답 속도가 빠르기 때문인데요. 특히 Redis는 온라인에서 다양한 활용 사례를 쉽게 찾을 수 있어서 안정적인 운영이 가능하기도 하고요.</p><p id="f7833479-6596-40cc-a8a4-a3064366a004" class="">하지만 대용량 트래픽 환경에서 캐시를 사용하려면 몇 가지 주의해야 할 상황이 있어요. 이 글은 캐시를 사용해도 데이터베이스 부하로 인해 서비스 장애가 발생할 수 있는 위험 상황들을 설명하고 이를 예방하는 방법을 소개해요.</p><h1 id="c0a08d28-831a-489e-8151-676b4cd1aacb" class=""><strong>1. 캐시 쇄도(Cache Stampede)</strong></h1><figure id="065d7e93-81b4-40b7-a400-ad49961f9417" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/602e6ce1-f3e2-4c57-a11f-12877df1d0e3/mermaid-diagram-2024-01-30-143704-fotor-20240130144531.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/602e6ce1-f3e2-4c57-a11f-12877df1d0e3/mermaid-diagram-2024-01-30-143704-fotor-20240130144531.png"/></a></figure><p id="9c93688f-7725-4469-a2ea-d1cf6be1ebc5" class="">캐시 미스가 동시에 많이 발생하면 데이터베이스에 부담이 가중돼요. &#x27;캐시 쇄도&#x27;라고 부르는 상황인데, 캐시가 전부 정확히 같은 시간에 만료되도록 구현하면 자주 발생하고요.</p><p id="7187cb03-42bf-45d8-bfa9-93750345b6fd" class="">예를 들어, 매일 자정에 캐시를 갱신한다고 생각해 볼게요. 갱신 시간에 맞춰 캐시가 일제히 만료되도록 설계하는 것은 구현하기 쉬운 데다가 최신 정보를 바로 제공할 수 있다는 이점이 있어요. 하지만 이런 캐시 만료 전략은 캐시가 만료되는 자정마다 데이터베이스로 트래픽이 집중되어 서비스 장애가 발생할 위험도 있어요.</p><h1 id="ac5a5a1c-ddc0-4168-a7f3-2919c48c4afd" class=""><strong>해결안: 지터(Jitter)</strong></h1><p id="6156f0f5-c386-4245-8655-349d101f400b" class="">캐시 만료 시간을 무작위로 조금 지연시키면, 캐시 쇄도 상황에서도 데이터베이스의 부하를 균등하게 분산시킬 수 있어요.</p><p id="c40f3472-1f0a-4e09-9434-aa375e119ce4" class="">전자공학에서 사용되는 &#x27;지터(Jitter)&#x27; 개념을 활용하는 건데요. 지터는 전자 신호를 읽는 과정에서 발생하는 짧은 지연 시간을 의미해요. 우리는 지터처럼 짧은 시간을 캐시 만료 시간에 더해서 부하를 분산시킬 수 있어요. 예를 들어 0~10초 사이의 무작위 지연 시간을 추가하면, 데이터베이스의 부담이 10초에 걸쳐 분산되는 것이죠.</p><p id="e9ad6536-3e1d-4207-b199-af3bb134daf6" class="">서비스마다 허용할 수 있는 지연 시간은 다르기 때문에, 서비스에 적절한 최대 지터 시간을 설정해야 돼요. 지터가 길어질수록 사용자는 더 오래된 정보를 볼 수 있으므로, 지터가 과도하게 추가되지 않도록 주의해야 합니다.</p><h1 id="67d79531-715d-46c7-af8b-175c4c6eed91" class=""><strong>2. 캐시 관통(Cache Penetration)</strong></h1><figure id="f45382cc-3736-442a-9cda-48301e082c29" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/fec7efa1-8724-4aa3-8343-d8cb91c08e57/mermaid-diagram-2024-01-30-143731-fotor-20240130144845.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/fec7efa1-8724-4aa3-8343-d8cb91c08e57/mermaid-diagram-2024-01-30-143731-fotor-20240130144845.png"/></a></figure><p id="18aa4001-91d1-461f-b07f-9f08b9f5b5ed" class="">보통 캐시에서 <code>null</code> 값이 반환되면 자연스럽게 데이터베이스를 조회해서 캐시를 채워요. 그런데 데이터베이스에도 해당 값이 없어서 <code>null</code>을 반환받았을 때는 캐시를 채우지 않도록 구현하는 경우가 흔해요. 데이터베이스로부터 반환받은 &#x27;값이 없다&#x27;라는 정보를 캐싱하지 않으면 어떤 위험이 있을까요?</p><p id="221a13ff-4b1b-4fd3-9f03-df51c08bd332" class="">데이터베이스에서 읽었는데도 캐싱 되지 않는 상황을 &#x27;캐시 관통&#x27;이라고 합니다. 캐시 관통이 빈번하다면, 데이터베이스에 불필요한 조회 요청이 자주 발생해요. 따라서 데이터가 없다는 사실도 캐싱해야 불필요한 데이터베이스 부하를 줄일 수 있어요.</p><h1 id="56400283-7904-4f2e-8ac8-f1b9bb9ed424" class=""><strong>해결안: 널 오브젝트 패턴(Null Object Pattern)</strong></h1><p id="75a04668-00b8-440d-aaff-14846d740e46" class="">‘값이 없음’을 캐싱함으로써 데이터베이스의 트래픽을 줄이려면 <a href="https://en.wikipedia.org/wiki/Bloom_filter">블룸 필터</a>를 사용하는 것도 좋은 방법입니다. 블룸 필터를 사용하면 확률적으로 캐시 관통을 방지해요. 하지만 블룸 필터의 정합성이 깨진다면, 블룸 필터를 복구하기 위해 모든 캐시를 읽어야 해서 운영이 어려워요.</p><p id="24d8abfa-645c-4f7a-bd67-796e48afd576" class=""><a href="https://en.wikipedia.org/wiki/Null_object_pattern">널 오브젝트 패턴</a>을 사용해서 ‘값이 없음’을 캐싱하는 방법이 운영하기 더 쉬워요. 객체 타입은 부재를 뜻하는 객체를 선언하여 사용하면 되지만, 원시 타입은 이 객체를 대체할 특정 값을 지정해야 돼요. 예를 들어, 양수만 존재하는 정수 타입의 데이터를 캐시할 때는 음수인 정수의 최솟값으로 &#x27;값이 없음&#x27;을 나타내기로 애플리케이션에서 약속할 수 있어요.</p><h1 id="ba435ee5-997f-4339-a781-3d8a316fe46c" class=""><strong>3. 캐시 시스템 장애</strong></h1><figure id="7322adb6-2e7d-409c-9ad8-286b8c41c1b4" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/9258d260-2708-49b0-bbfa-93d8baea3373/mermaid-diagram-2024-01-30-143754-fotor-2024013014509.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/9258d260-2708-49b0-bbfa-93d8baea3373/mermaid-diagram-2024-01-30-143754-fotor-2024013014509.png"/></a></figure><p id="c7d04ae2-bb78-437e-be95-ba268db8f7c0" class="">평이한 트래픽 상황에서는 캐시 시스템에 장애가 발생하더라도 데이터베이스로 트래픽을 보내면 서비스를 정상 운영할 수 있어요. 하지만 트래픽이 큰 상황이라면 캐시 시스템이 복구될 때까지 데이터베이스에 과부하가 걸릴 위험이 있어요.</p><p id="82b2fb0d-644c-4894-9992-8236e34edfba" class="">데이터베이스가 모든 트래픽을 감당할 수 있다고 낙관하는 것은 위험한 생각이에요. 데이터베이스가 한계를 넘는 트래픽을 받으면, 캐시와 무관한 기능조차 정상적으로 작동하지 못할 수 있어요. 따라서 데이터베이스가 감당할 수 있는 범위의 트래픽을 유지하도록 계획을 세워야 합니다.</p><h1 id="f94f688f-759f-4ff1-91bf-bcb9fff7ff6c" class=""><strong>해결안: 대체 작동(Failover)</strong></h1><p id="619fd40a-f072-46fa-94ee-69573d890990" class="">캐시 시스템 결함에 의한 장애를 최소화하기 위해서는 핵심 기능을 정의할 필요가 있어요. 캐시 시스템이 망가졌다면 반드시 동작해야 되는 핵심 기능을 제외하고, 편의를 위한 부가 기능은 일시적으로 운영을 중단하는 게 낫습니다. 캐시 시스템이 복구되는 동안 데이터베이스가 핵심 기능으로 트래픽을 처리할 수 있고, 부가 기능은 사용자에게 대체 UI를 제공하거나 양해를 구하는 게 현실적인 대응 방법입니다.</p><p id="01983c0c-e3a2-47fb-ac4e-83c51b7ce3a9" class="">캐시 코드를 공통화 하다보면 기능의 중요도를 따지지 않고, 데이터베이스로 fallback하는 코드를 작성하기 쉬워요. 데이터베이스 부하를 감안하더라도 꼭 동작해야할 기능인지 개발자가 미리 고민할 필요가 있습니다.</p><h1 id="1eea94bd-c3c9-4f40-8c98-ffea3857664e" class=""><strong>4. 핫(Hotkey) 만료</strong></h1><figure id="a448a973-80c8-4a31-ab71-1e30c08515d2" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/78dca86e-7f8c-402b-a04a-0b9a00644ce3/mermaid-diagram-2024-01-30-143802-fotor-20240130145049.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/78dca86e-7f8c-402b-a04a-0b9a00644ce3/mermaid-diagram-2024-01-30-143802-fotor-20240130145049.png"/></a></figure><p id="9ada1e20-3b18-4026-9630-52c6a85f6663" class="">많은 요청이 집중되는 키를 &#x27;핫키&#x27;라고 하는데요. 핫키가 만료되는 순간, 여러 요청이 동시에 데이터베이스를 불필요하게 반복해서 조회할 수 있어요. 가능하다면 캐시의 만료 기한을 없애거나, 백그라운드에서 주기적으로 새 값을 적용해서 캐시가 만료되지 않게 하는 것이 좋습니다. 하지만 핫키가 때에 따라 바뀌는 환경에서는 더 이상 핫키가 아닌 데이터로 인해 캐시 저장소 공간이 낭비될 수 있어요.</p><h1 id="d19e691c-14f4-4a6e-942b-bf25e5146c60" class=""><strong>해결안: 분산 락(Distributed Lock)</strong></h1><p id="c3bb8436-5eca-47b6-92d6-330222bbe332" class="">분산 락을 사용하면 공간 낭비 없이 불필요한 데이터베이스 중복 조회를 방지할 수 있어요. 멀티 스레드 프로그래밍에서 공유 자원 다룰 때 락을 사용하는 것과 비슷한 원리인데요. 캐시를 애플리케이션 서버 간의 공유 자원으로 볼 수 있습니다. 캐시 미스가 발생했을 때 락을 설정하고 캐싱한 후에 락을 해제함으로써, 단 한 번의 쓰기 작업만 허용할 수 있고요.</p><p id="17d34270-58d5-4f0c-9083-7016a74dd138" class="">Redis를 사용하고 있다면 분산 락을 적용하기 굉장히 쉬워요. Redis의 싱글 스레드 특징을 활용한 <a href="https://redis.io/docs/manual/patterns/distributed-locks/">레드락</a> 알고리즘 덕분인데요. 다양한 프로그래밍 언어를 지원하는 레드락 구현 라이브러리들이 존재해요. 이 라이브러리들을 사용하면 분산 환경에서도 공유 자원을 효과적으로 관리할 수 있어요. Redis 없이도 분산 락을 구현할 방법은 다양하므로, 핫키 만료 상황에서 분산 락을 이용하면 캐시 히트율을 유지할 수 있습니다.</p><h1 id="1a33a9c4-c916-41dd-a30c-9efd3cfe729a" class=""><strong>정리</strong></h1><p id="0ad4068d-86ed-42bc-b7fa-371433e504fa" class="">이 글에서는 데이터베이스 부하 방지를 위한 캐시 시스템의 도전과제들을 다뤘으며, 이에 대한 몇 가지 해결책을 모색해 봤어요. 모든 상황에 완벽하게 적용될 수는 없겠지만, 적어도 일부 문제를 해결하거나 완화하는 데는 도움 되길 바랍니다.</p><p id="047a9ce1-fe5a-454c-a5e4-ca45c7af39bf" class="">데이터베이스와 캐시 시스템의 상호작용은 예측하기 어려워요. 그래서 제시된 아이디어를 실제로 적용할 때는 더 다양한 요소들을 고려해야 합니다. 모든 환경에서 효과적이지는 않지만 이런 아이디어들이 캐시로 인한 문제들을 인식하고, 해결 방안을 고려하는 데 시작점이 되기를 바래요.</p><figure id="3203884b-23f7-4d07-b3ae-bfb4b3f235a9"><a href="https://toss.tech/article/25301" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">캐시 문제 해결 가이드 - DB 과부하 방지 실전 팁</div><div class="bookmark-description">대용량 트래픽 환경에서 캐시를 사용할 때 주의해야할 위험 상황과 예방법을 소개합니다.</div></div><div class="bookmark-href"><img src="https://static.toss.im/tds/favicon/favicon-196x196.png" class="icon bookmark-icon"/>https://toss.tech/article/25301</div></div><img src="https://static.toss.im/assets/payments/contents/app-thumb.jpg" class="bookmark-image"/></a></figure></details></li></ul><ul id="b749815b-dc1f-450d-900e-99e81d210cda" class="toggle"><li><details open=""><summary>대용량 트래픽 환경에서 캐시 고려사항</summary><p id="2172c749-e692-4589-8b5a-d8dbe7df9d02" class="">대용량 트래픽 환경에서 캐시를 사용하면 데이터베이스의 부하를 줄이고 성능을 개선할 수 있지만, 캐시를 적절히 관리하지 않으면 여전히 데이터베이스에 과부하가 발생하거나 서비스 장애를 일으킬 수 있습니다. 캐시를 사용 시 고려해야 할 주요 사항과 데이터베이스 부하로 인한 서비스 장애를 예방하는 방안을 설명하겠습니다.</p><h2 id="d1cc430f-f38a-4a40-bb51-10ba63e071f7" class="">1. 캐시 사용 시 고려해야 할 사항</h2><h3 id="e22515bb-6090-4e70-8a5a-476012b8996a" class="">1.1 캐시 설계 및 전략</h3><ul id="3bfe3f46-70c3-4316-9cf5-f8228a73efa9" class="bulleted-list"><li style="list-style-type:disc"><strong>캐시 만료 정책 (Expiration Policy)</strong>: 캐시된 데이터가 유효한 시간 동안만 저장되도록 하여 오래된 데이터가 남지 않도록 합니다. 예를 들어, TTL(Time-To-Live) 설정을 통해 데이터의 생명 주기를 정의합니다.</li></ul><ul id="a95f3604-6633-4d23-a096-1e06080bdb8b" class="bulleted-list"><li style="list-style-type:disc"><strong>캐시 무효화 (Cache Invalidation)</strong>: 데이터베이스의 데이터가 업데이트되면 캐시된 데이터도 무효화되어야 합니다. 이를 통해 데이터의 일관성을 유지합니다. 캐시 무효화 전략으로는 쓰기-through, 쓰기-around, 쓰기-behind 등이 있습니다.</li></ul><ul id="a5fd9b02-bd8d-4413-9774-02190cd7d87a" class="bulleted-list"><li style="list-style-type:disc"><strong>캐시 일관성 (Cache Consistency)</strong>: 캐시와 데이터베이스 간의 데이터 일관성을 유지하기 위한 방법을 결정합니다. 예를 들어, 데이터베이스에 대한 변경 사항이 있을 때 캐시를 갱신하거나 무효화합니다.</li></ul><ul id="12c4d82a-c164-485e-a8ea-35829389d986" class="bulleted-list"><li style="list-style-type:disc"><strong>캐시 적중률 (Cache Hit Ratio)</strong>: 캐시 적중률을 모니터링하여 캐시의 효율성을 분석하고, 필요 시 캐시 용량을 조정합니다.</li></ul><h3 id="e966b99a-48c6-408a-a125-6cb12d1f8c3a" class="">1.2 캐시 용량 관리</h3><ul id="ee5dcf48-8998-46ac-b073-b4137d792251" class="bulleted-list"><li style="list-style-type:disc"><strong>용량 계획</strong>: 캐시 용량을 예측하고, 트래픽의 증가에 대비하여 적절한 캐시 크기를 설정합니다.</li></ul><ul id="7090a835-6735-43eb-b6f5-50e09d79ca9f" class="bulleted-list"><li style="list-style-type:disc"><strong>자동 확장</strong>: 캐시 클러스터가 자동으로 확장될 수 있는 기능을 활용하여 트래픽 급증에 대비합니다.</li></ul><ul id="a2f65b58-0018-4157-9eb9-130b98d1eda6" class="bulleted-list"><li style="list-style-type:disc"><strong>LRU (Least Recently Used) 정책</strong>: 자주 사용되지 않는 데이터를 제거하여 최신 데이터를 유지합니다.</li></ul><h3 id="fad25383-a028-4992-a369-8eb5cca62f9c" class="">1.3 캐시 데이터의 복원력</h3><ul id="86652433-8d76-40eb-8b76-cde97ebeeb7f" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 백업</strong>: 캐시 데이터의 중요한 정보는 정기적으로 백업하여 데이터 손실을 방지합니다.</li></ul><ul id="3f46a38c-aeef-4394-86a7-a7f9c1df2295" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 재생성</strong>: 캐시 서버가 재시작되거나 장애가 발생했을 때, 데이터베이스에서 캐시 데이터를 재생성할 수 있도록 설계합니다.</li></ul><h3 id="8a100c41-7688-42d4-8b87-fe1573e675c5" class="">1.4 캐시 장애 대응</h3><ul id="9c3d7e7f-45ba-4afe-8ac6-668b21bfd72a" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링 및 알림</strong>: 캐시 서버의 상태를 모니터링하고, 장애 발생 시 즉시 알림을 받습니다.</li></ul><ul id="53394bbe-3142-4830-87ad-d189d3201a39" class="bulleted-list"><li style="list-style-type:disc"><strong>다중 캐시 인스턴스</strong>: 캐시 서버의 고가용성을 보장하기 위해 다중 캐시 인스턴스를 운영하고, 장애 조치(failover) 기능을 설정합니다.</li></ul><h2 id="234e7f2b-711f-4959-a8c9-dd3c92efb657" class="">2. 데이터베이스 부하로 인한 서비스 장애 위험과 해결 방안</h2><h3 id="84083847-13b0-4c5e-8ce6-d2cc812e8f91" class="">2.1 위험 상황</h3><ol type="1" id="ffdd30e0-645a-493e-a955-d71c766b4b28" class="numbered-list" start="1"><li><strong>캐시 미스 (Cache Miss)</strong>: 캐시된 데이터가 없는 경우, 데이터베이스에 직접 요청이 전달되며 데이터베이스 부하가 증가할 수 있습니다. 캐시 미스가 빈번하게 발생하면 데이터베이스에 과부하가 발생할 수 있습니다.</li></ol><ol type="1" id="c5fca931-e95c-4b6e-9c86-dcd58527cfe4" class="numbered-list" start="2"><li><strong>캐시 무효화 지연</strong>: 데이터베이스의 변경 사항이 캐시에 즉시 반영되지 않으면 캐시와 데이터베이스 간의 데이터 불일치가 발생할 수 있습니다.</li></ol><ol type="1" id="de1858c5-5168-4965-83cb-25280507c948" class="numbered-list" start="3"><li><strong>캐시 오염 (Cache Poisoning)</strong>: 잘못된 데이터가 캐시에 저장되면, 이 데이터가 여러 요청에 사용되어 데이터베이스와 캐시 간의 불일치를 초래할 수 있습니다.</li></ol><ol type="1" id="06f22aa6-0dbc-491d-a97e-eb91e376dafe" class="numbered-list" start="4"><li><strong>캐시 장애</strong>: 캐시 서버가 장애를 일으키면 모든 트래픽이 데이터베이스로 우회하게 되어 데이터베이스에 과부하가 발생할 수 있습니다.</li></ol><h3 id="f1e40df3-cda2-49cd-9319-81c74dc7bed0" class="">2.2 해결 방안</h3><h3 id="bbcc43d0-1a62-4e0d-91d7-5352b0811449" class="">1. 캐시 미스 관리</h3><ul id="496c5fb4-393e-462b-ad8b-cd32adb7fff7" class="bulleted-list"><li style="list-style-type:disc"><strong>적절한 캐시 크기</strong>: 캐시 크기를 충분히 설정하여 캐시 미스를 줄입니다.</li></ul><ul id="bfa1a5c2-ffba-469e-87d3-461ba9a0dc92" class="bulleted-list"><li style="list-style-type:disc"><strong>캐시 프리페칭 (Pre-fetching)</strong>: 데이터베이스의 예상 쿼리에 대한 결과를 사전에 캐시에 로드하여 캐시 미스를 줄입니다.</li></ul><ul id="c65101a8-3f66-4b03-9bf4-3a042dfbc9db" class="bulleted-list"><li style="list-style-type:disc"><strong>쿼리 최적화</strong>: 데이터베이스 쿼리를 최적화하여 캐시 미스 시에도 데이터베이스의 부하를 최소화합니다.</li></ul><h3 id="b4a3d275-03bd-47bc-bae9-a237c9f24eaf" class="">2. 캐시 무효화 및 일관성</h3><ul id="8186ec29-0d4a-4815-8a1f-a034a8b0ba66" class="bulleted-list"><li style="list-style-type:disc"><strong>자동 무효화</strong>: 캐시가 데이터베이스의 변경 사항을 자동으로 반영하도록 설정합니다. 예를 들어, 데이터베이스의 트랜잭션과 연동하여 캐시를 무효화하는 방법을 사용합니다.</li></ul><ul id="3f294e74-2103-40d2-b468-1c8a17443e96" class="bulleted-list"><li style="list-style-type:disc"><strong>트랜잭션 관리</strong>: 데이터베이스의 트랜잭션이 완료된 후 캐시를 업데이트하거나 무효화하여 일관성을 유지합니다.</li></ul><h3 id="f92825f7-487f-49fb-9393-041fa9b7eead" class="">3. 캐시 오염 방지</h3><ul id="7912b81a-8585-40ba-ab3c-51afb65530ce" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 유효성 검사</strong>: 캐시된 데이터의 유효성을 정기적으로 검사하여 잘못된 데이터가 캐시에 저장되지 않도록 합니다.</li></ul><ul id="996209e5-0e85-48e8-8976-03b9852f006e" class="bulleted-list"><li style="list-style-type:disc"><strong>일관성 검사</strong>: 데이터베이스와 캐시 간의 데이터 일관성을 검사하고, 필요한 경우 캐시를 갱신합니다.</li></ul><h3 id="77d838f6-f425-4e19-a825-75e800a6f284" class="">4. 캐시 장애 대응</h3><ul id="4ffbed41-092f-4eb0-8370-6ee5fa1bc197" class="bulleted-list"><li style="list-style-type:disc"><strong>다중 캐시 인스턴스</strong>: 캐시 서버를 클러스터링하여 단일 장애점(Single Point of Failure)을 방지합니다. 각 캐시 인스턴스는 서로 복제되어 장애 발생 시 자동으로 대체합니다.</li></ul><ul id="4cd72883-454d-4968-ab38-6db09c9fd337" class="bulleted-list"><li style="list-style-type:disc"><strong>장애 조치(failover) 설정</strong>: 캐시 서버가 장애를 일으킬 경우 자동으로 다른 캐시 서버로 장애 조치를 설정합니다.</li></ul><ul id="0d71c4e2-788a-483b-9ef6-18d30b80b902" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링 및 자동 복구</strong>: 캐시 서버의 상태를 모니터링하고, 장애 발생 시 자동으로 복구할 수 있는 시스템을 구성합니다.</li></ul><h3 id="7202cdfe-b8c4-4834-a9c2-4316d79d271c" class="">5. 데이터베이스 부하 분산</h3><ul id="ea4652e1-5492-4f02-9550-684f9942e9f9" class="bulleted-list"><li style="list-style-type:disc"><strong>읽기/쓰기 분리</strong>: 읽기 작업과 쓰기 작업을 분리하여 데이터베이스의 부하를 줄입니다. 읽기 작업은 읽기 전용 복제본으로 처리합니다.</li></ul><ul id="538ea580-9de8-4a93-9732-56710de06970" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터베이스 샤딩 (Sharding)</strong>: 데이터베이스를 샤딩하여 데이터의 분산 저장을 통해 부하를 분산시킵니다.</li></ul><ul id="782acf5d-4eb6-45eb-99e9-fbf95bddd86b" class="bulleted-list"><li style="list-style-type:disc"><strong>부하 분산</strong>: 데이터베이스 클러스터링 및 부하 분산 기술을 사용하여 데이터베이스의 부하를 여러 서버에 분산시킵니다.</li></ul><p id="8a733d32-98ae-44d2-bcd1-9febf792d3d5" class="">이러한 고려사항과 해결 방안을 통해 대용량 트래픽 환경에서 캐시를 효율적으로 사용하고, 데이터베이스의 부하를 줄이며 서비스의 안정성을 유지할 수 있습니다.</p><p id="a53d3831-fad9-400f-a5f1-22123307dc16" class="">
</p></details></li></ul><ul id="97bded81-bc03-4780-aba9-9017dd11fd85" class="toggle"><li><details open=""><summary>Toss - 우리는 어떻게 해외주식 서비스 안정화를 이뤘는가</summary><h1 id="b916b38f-3dcd-4f0f-9468-b9dbf532cf28" class=""><strong>토스증권 해외주식 서비스 소개 ✌️</strong></h1><p id="e25b3004-8c5e-414f-be67-4ed7a50de80a" class="">안녕하세요, 토스증권 Server Developer 김광훈입니다. 제가 근무하고 있는 해외주식 플랫폼 팀은 미국 주식을  중심으로 해외 주식 원장을 담당하고 있어요. 원장이란 증권 서비스에서 가장 주요한 영역 중 하나이며, 금융거래를 기록하는 장부를 말해요. 저희 팀에서는 고객의 주문, 자산, 권리 그리고 종목 정보 관리와 환전까지 해외주식 서비스 제공에 필요한 모든 거래와 정보들을 원장에 기록하는 개발과 운영을 하고 있어요.</p><p id="4409a98d-2aab-445f-b392-860d92528c6d" class="">이번 글에서는 저희 팀이 외부 브로커와 통신하고 있는 해외 주식 서비스를 안전하게 운영하기 위해 고민했던 내용을 공유하려고 합니다.</p><h1 id="812a2e6d-3e2c-4b6b-bbf8-97620648fb16" class=""><strong>토스증권 미국 주식 매매 아키텍처</strong></h1><figure id="4e676af6-b11b-43f6-b702-429acf726415" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/b8e9f2f8-09a6-483f-ae3c-f7027a974c97/inner-0711-6.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/b8e9f2f8-09a6-483f-ae3c-f7027a974c97/inner-0711-6.png"/></a></figure><p id="0f932db8-761e-4df4-8bd8-6885459a5b73" class="">먼저, 미국 주식 매매 아키텍처를 같이 살펴볼게요. 사용자가 토스증권에서 매매 요청을 하면 현지 브로커로 요청을 보내고 브로커는 현지 미국 거래소에서 매매를 체결하고 응답을 보내는 구조입니다. 브로커라는 용어가 생소할 수 있는데요, 이름 그대로 주식 매매를 현지에서 처리를 해주는 역할을 하는 회사에요. 미국에서 직구를 할 때 중간에 상품을 현지에서 구매하고 한국으로 배송해주는 대행사와 비슷한 것이죠.</p><p id="7486df41-c92e-4bcf-a5fb-3f46b69aa378" class="">브로커와 통신은 HTTP, FIX 두 가지 프로토콜을 사용하고 있어요. 메인으로는 FIX 프로토콜을 사용하고 있고, 브로커 요구사항에 따라 HTTP 를 부분적으로 사용하여 요청 보내고 있어요. 요청에 대한 응답은 최종적으로 Kafka나 SQS와 같은 큐를 사용하여 비동기로 처리하고 있어요.</p><p id="3d748e52-1d9b-4336-811a-b5bb33a36928" class=""><strong>FIX 프로토콜은 금융 서비스에서 사용하는 통신 프로토콜이에요. FIX 프로토콜은 HTTP 와 비교하면 장단점이 명확하여 엔지니어링 적으로 고민할 요소가 많다고 생각해요. 그래서 기회가 된다면 나중에 좀 더 자세히 다룰 예정입니다. 다만, 이번 글 주제와는 거리가 있어서 이 정도만 설명하고 넘어갈게요.</strong></p><h1 id="e92c095f-a07d-462d-9e72-ab43b6328027" class=""><strong>문제 원인 파악 😢</strong></h1><p id="d3878ca1-e125-4e50-9e7b-1730b665c0d8" class="">그럼 이제 토스증권에서 브로커와 통신하는 과정에서 어떤 문제가 왜 일어났는지 설명드릴게요. 아래 그림은 브로커 이슈로 문제가 된 상황 당시의 핀포인트 그래프입니다. 그래프를 보면 브로커 응답 시간이 조금씩 지연이 발생하였고, 지연된 주문들은 계속 대기하면서 쌓이게 되고 결국에는 5000ms 이상 응답이 걸리게 되면서 이슈가 발생한 것을 볼 수 있어요.</p><figure id="3763301a-56ef-4c13-8279-b9fbbb173b50" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/27a627cc-3bb3-4581-8f59-c72ebd5ed2c9/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/27a627cc-3bb3-4581-8f59-c72ebd5ed2c9/Untitled.png"/></a></figure><p id="6eedcb51-38a8-473a-a007-127d2fe3e4d1" class="">문제의 원인은 크게 두 가지였어요.</p><p id="3da29ea8-4ac9-494c-8f11-10a6faf5fe0f" class="">먼저 정규장 시작에 크게 뛰는 트래픽이었는데요. 아래 그래프는 주문 API 호출 건 수를 시간대별로 나타내고 있어요. 미국의 정규장 시작(22시30분)부터 호출 건 수가 급격히 증가하는 것을 볼 수 있어요. 해외주식 서비스 특성상 정규장 초반에 트래픽이 급격히 증가하고 최소 두 시간 정도는 지속돼요.<strong> TPS 를 정규장 시간과 아닌 시간을 비교해보면 20배 이상 차이가 나기에, 대부분의 운영 이슈는 정규장 오픈 초반에 발생할 수밖에 없어요.</strong></p><figure id="0ce6f6fe-8d6c-48a7-96c2-9d09c5d1db6b" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/e43ed8f4-ba32-491e-a322-f05d0e1b3912/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/e43ed8f4-ba32-491e-a322-f05d0e1b3912/Untitled.png"/></a></figure><p id="aa682b71-14d7-4104-82ce-4d0a7250033c" class="">토스증권 사용자가 늘어나는 것도 문제의 원인이었어요.해외주식 주문 증가 추세를 보기 위해 주문 접수 API 요청을 월 별로 집계를 해보았어요. 아래 그래프를 보면 계속 주문 수는 증가하고 있는 추세를 볼 수 있어요. 오픈 초기 주문 요청량 대비 현재 요청량을 비교해보면 약 30배 넘게 증가한 것을 볼 수 있었습니다.</p><p id="28f6ed9c-a340-47b5-b7f0-5027d1e2547b" class="">서비스가 오픈하고 폭발적인 성장을 하게 되었고, 동시에 브로커도 함께 처리해야 하는 주문도 증가했어요. 그로 인하여 보이지 않았던 이슈들이 점차 수면 위로 올라왔고, 크고 작은 이슈들을 겪게 되었습니다.</p><figure id="78bcc7cf-2c7a-4a5e-944e-b32794c9d7c3" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/34907e55-1439-4402-a582-fa31f8e43993/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/34907e55-1439-4402-a582-fa31f8e43993/Untitled.png"/></a></figure><p id="5c285fac-e4fe-46d2-88b4-c1e91993a75a" class="">브로커와 통신 과정에서 이슈를 겪고 나서 팀에서는 통신 구간에 엔지니어링을 시작을 했고, 가장 먼저 브로커가 수용할 수 있는 최대 TPS 이상 보내지 않도록 트래픽 제어를 했어요. 트래픽을 조절해서 보냈음에도 브로커 측에서 발생한 문제를 <strong>빠르게 감지하고 다른 브로커로 주문 요청을 보낼 수 있는 시스템</strong>을 만들어야 했어요. 시스템을 어떻게 만들었는지 설명드릴게요.</p><h1 id="8043b043-5c02-4fa7-80a9-4e7872be0196" class=""><strong>1. 트래픽 제어</strong></h1><figure id="fda42994-b5e5-4166-9270-240526904ceb" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/4d4ef9eb-7dd2-4fed-bbe8-b0227183cb31/inner-0711-5.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/4d4ef9eb-7dd2-4fed-bbe8-b0227183cb31/inner-0711-5.png"/></a></figure><p id="e4f4e4b3-792c-4a58-b3da-cbe086a3016a" class="">주식을 예약 주문해보신 경험이 있나요? 해외 주식도 예약 주문을 받는데요. 토스증권은 예약 주문을 들고 있다가, 실제 주문 요청은 정규장이 시작된 뒤에 배치로 보내고 있어요. 정규장 시작 후 대략 100만 건 이상의 예약 주문을 브로커로 보내게 되는데, 한 번에 보내면 브로커에 부하를 줄 수 있어요.</p><p id="70548dc9-669c-4968-9d4e-bd1cecfdaf55" class="">그래서 브로커로 보내는 주문 요청 TPS를 제어를 할 필요가 생겼고, 이미 잘 만들어져 있는 <a href="https://github.com/resilience4j/resilience4j">resilience4j</a>를 사용하여 간단하게 문제를 해결했어요. resilience4j 는 fault tolerance(내결함성)의 목적으로 나왔기 때문에 서킷 브레이커, 트래픽 제어, 재시도 등 분산 시스템 안정성과 탄력성을 높이기 위한 기능들을 지원해요.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="92c0739f-03bf-4d08-9ea8-c95bd2495f52" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">123456789101112131415161718192021class BatchJob {    lateinit var rateLimiter: RateLimiter        companion object {        private const val JOB_CODE = &quot;TradePreparedOrderExecutorJob&quot;    }        fun run(context: RunContext): BatchResponse {        val tps = arguments[2].toInt()        rateLimiter = RateLimiterCreator.of(		        limitRefreshPeriod = Duration.ofSeconds(1), 		        limitForPeriod = tps, 		        name = JOB_CODE	      )	      	      rateLimiter.executeRunnable {            preparedOrderBrokerRequestFacade.sendOrder()        }    }}</code></pre><p id="ffe4b65e-677d-4666-9785-0420e7ecb0be" class="">위 코드는 예약 주문 배치 코드 예시입니다. 파라미터로 TPS를 받고, <code>rateLimiter</code> 객체를 입력받은 TPS로 객체 생성을 하고, runnable로 주문 요청하는 파라미터를 넘기면 TPS 파라미터 수만큼 요청을 제한해서 할 수 있어요.</p><p id="175017f0-5e54-4511-9c76-38ad8137f7bb" class=""><code>12345678910111213141516171819202122object RateLimiterCreator {    private val DEFAULT_TIMEOUT_DURATION = Duration.ofSeconds(5) // resilience4j 기본 설정    fun of(        limitRefreshPeriod: Duration,        limitForPeriod: Int,        name: String,        timeoutDuration: Duration = DEFAULT_TIMEOUT_DURATION,    ): RateLimiter {        val config = RateLimiterConfig.custom()            .limitRefreshPeriod(limitRefreshPeriod)            .limitForPeriod(limitForPeriod)            .timeoutDuration(timeoutDuration)            .build()        val registry = RateLimiterRegistry.of(config)        val rateLimiter = registry.rateLimiter(name)        return rateLimiter    }}</code></p><p id="d619651f-21b4-4e8b-9dae-b15d7c258e30" class="">위 코드는 <code>RateLimiterConfig</code> 를 생성하는 코드예요.</p><p id="55659b94-907f-4552-866d-8b0b63d47b3d" class="">설정값들을 yml 파일로 관리할 수 있지만, 배치잡 파라미터로 TPS를 제어하고 배치를 실행할 때 TPS를 결정하고 싶어 코드로 관리하는 선택을 했어요. 아래 이미지에 보이듯이 간단하게 파라미터만 넘기면 배치에서 브로커로 요청하는 TPS를 결정할 수 있어요.</p><figure id="56a56c21-b375-411e-be5a-5d38c54e7ea7" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/8bc12ff4-00f3-4477-8c57-ab89272077a8/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/8bc12ff4-00f3-4477-8c57-ab89272077a8/Untitled.png"/></a></figure><h1 id="bf772cd8-6217-4105-9119-951a51a1b36b" class=""><strong>2. 빠른 이상 탐지 및 브로커 전환</strong></h1><p id="2d98ac9b-304a-4e2a-8574-64b6869854d6" class="">미국 주식 장 운영 시간 특성상 브로커 이는 주로 새벽에 발생하고, 사람이 수동으로 대응을 하기에는 한계가 있었어요. 수동으로 브로커 이슈를 감지하기 위해서는 사람이 24시간 대기를 해야 하고, 담당자가 문제가 발생했는지아닌지 판단을 하는 순간에 피해 규모는 점점 더 커질 수 있어요.</p><p id="d5d234c1-2d3a-4cf1-a7d2-e5d291fef70d" class="">그래서 메인 브로커 이슈가 감지되면 미리 정해둔 룰에 의해 시스템이 감지하고 서브 브로커로 주문을 보낼 수 있는 이상 감지 시스템을 만들게 되었어요.</p><figure id="e85aa1ca-69d1-48b0-b260-bef2f9f96dc4" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/f5964494-30b0-4b80-8fac-71488f468ab9/inner-0711-4.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/f5964494-30b0-4b80-8fac-71488f468ab9/inner-0711-4.png"/></a></figure><p id="207279fa-9ac0-4848-aad8-9284d3894971" class="">위 그림은 설계 당시 요구사항이에요. 요구사항을 토대로 팀에서는 브로커 이상 감지되면 결과를 이벤트로 발행하고 이벤트를 구독한 시스템에서 자율적으로 대응할 수 있는 시스템을 만들었어요. 이상 감지 시스템도 역시 잘 만들어진 Grafana, kibana 등의 모니터링 도구를 사용하여 쉽게 구축을 할 수 있었어요.</p><p id="05462a56-3a48-442e-8606-3d4ce3e3f06b" class="">각 모니터링 도구는 설정한 룰에 매칭이 되면 이상 감지 시스템 API를 호출해서 정보를 제공하는 방식으로 설계했어요. 이후에 이상 감지 시스템은 Kafka 이벤트를 발행하고 각 토픽을 구독하고 있는 시스템에 이슈 상황을 전파를 할 수 있어요. 결국에 하나의 토픽을 여러 시스템이 구독하고 있는 구조이다 보니 자연스럽게 규격화된 JSON 구조를 여러 시스템이 사용할 수 있어요.</p><p id="71d06537-efad-423b-bb46-6362e0b76f5b" class="">이번 글에서는 Grafana로 어떻게 이상 감지 시스템을 구축 했는지 더 자세히 설명드릴게요. Grafana를 사용한 이유는 로그보다는 시스템 메트릭으로 조건 지정을 하고 싶었고, 이슈를 대응할 때 그래프 시각화 정보도 중요하다고 생각했기 때문이에요.</p><p id="fad88aed-1c60-4ea3-b816-253aced6deab" class="">이제 Grafana 설정을 어떻게 했는지 간단히 살펴봐요. Grafana 버전에 따라 세팅 설정 상이할 수 있어요. 이번 글에서는 v10.4.1 기준으로 작성했어요.</p><h1 id="b7a5f463-9a4b-45b0-8b35-fa2cab1a1c08" class=""><strong>Notification policy</strong></h1><p id="0cd99664-bcef-4444-af6e-006adc5b44b8" class="">먼저 웹훅 세팅을 위해 Notification policy를 먼저 살펴볼게요. 원하는 이름을 설정과 Contact point 설정이 필요해요. Contact point로 알림을 어떻게 보낼지도 설정할 수 있어요.</p><p id="939ec4c1-8bd2-4656-b681-ce99b441f017" class="">설정한 Contact point를 살펴보면, Intergration을 Webhook 으로 설정하고 URL 탭에 이상 감지 시스템 API 를  작성을 하면 돼요.</p><figure id="f8b52034-36d5-42ad-9072-a18709234f9e" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/a65555c1-851e-436e-802f-9a1724b8fbd1/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/a65555c1-851e-436e-802f-9a1724b8fbd1/Untitled.png"/></a></figure><h1 id="8970720a-b10a-45f2-ac05-a1d2e2600e28" class=""><strong>Alert rule</strong></h1><p id="4a296e5e-2404-4a51-a78d-ce131624c3b2" class="">여기까지 Notification policy 생성하는 방법에 대하여 간단하게 알아봤어요. 이제 Alert rule 을 생성하고 생성한 rule 에 Notification policy 를 붙여주면 끝이에요.</p><p id="56eb223c-ea25-4913-8787-6cbe2dc811a9" class="">Alert rule 설정하는 것을 살펴보면 쿼리는 1분 동안 API 요청이 실패한 개수를 카운트하도록 했어요. 그리고 alert 조건으로 위 쿼리로 수집된 에러 API 개수가 100 개가 넘으면 발생하도록 설정했어요.</p><figure id="b0186c7e-96e0-4f91-b5e9-1264168f6f1d" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/b74486df-d379-435e-bf58-2e850e224a71/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/b74486df-d379-435e-bf58-2e850e224a71/Untitled.png"/></a></figure><p id="a925388f-98da-4eb1-b91b-a1ab4104937a" class="">이제 alert 조건 만족이 얼마나 지속이 될 때, 알림을 트리거할지 설정해주세요. Evaluation interval 과 pending period를 설정할 수 있어요. Evaluation interval는 위에서 작성한 쿼리 결과를 어느 주기로 체크할지 설정할 수 있고, pending period는 위에서 classic condition으로 작성한 조건이 만족하고 어느 기간 동안 만족하면 alert 을 발생시킬지 설정하는 값이에요.</p><p id="6458c38b-9dbd-4050-81db-e3d6f02bd084" class="">예를 들어 evaluation interval를 30초 그리고 pending period를 3분으로 설정을 했다면, 30초 주기로 쿼리 결과를 체크하고 만약 classic condition을 만족했다면, 만족한 시점 이후로 3분 동안 지속이 된다면 alert 을 발생하게 돼요.</p><figure id="f8bb80df-6bfc-4e72-9bb9-465a2d49927d" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/fbffa8d5-80e4-4381-9b9e-61183440d990/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/fbffa8d5-80e4-4381-9b9e-61183440d990/Untitled.png"/></a></figure><p id="13ff3ad5-b409-4d3b-86ea-54ded61913b9" class="">아래 Enum 코드는 alert이 발생했을 때, 이상 감지 시스템에서 제공하는 상태 타입이에요.</p><p id="229fa3f6-b5ff-466f-88f5-a122d591e5e4" class=""><code>12345enum class SystemStatus {    HEALTHY,    // 시스템이 정상    CAUTION,    // 시스템에 문제가 있을 수도 있음. 알아서 판단    CRITICAL    // 시스템 down}</code></p><p id="18c15208-ca03-45ed-a2df-33842e42904a" class="">이상 감지 시스템에서는 모니터링 도구로부터 API 호출을 받고 전달받은 데이터를 기반으로 위 세 가지 타입 중 하나를 택하여 Kafka 이벤트를 발행하게 돼요.</p><p id="c7dd69bb-44ea-47d1-9132-e9264b199dfe" class=""><code>12345678910111213141516171819202122232425262728293031323334@Componentclass BrokerFailOverConsumer(    private val brokerFailoverService: BrokerFailoverService,    private val slackSender: SlackSender,) {    private val log = KotlinLogging.logger { }    @KafkaListener(        topics = [&quot;topicName&quot;],        clientIdPrefix = &quot;appName&quot;,        containerFactory = &quot;falioverContainerFactory&quot;    )    fun consume(record: ConsumerRecord&lt;String, String&gt;) {        val json = record.value()        log.info { &quot;system-status-event consume: $json&quot; }        val message = JsonUtil.fromJson(record.value(), SystemStatusRecord::class.java)                when (message.status) {            SystemStatus.CRITICAL -&gt; {                slackSender.sendCriticalSlackMessage(message)                brokerFailoverService.failover()            }            SystemStatus.CAUTION -&gt; {                log.info { &quot;브로커 상태 알림 수신: BrokerType=${message.type}, status=${message.status}&quot; }            }            SystemStatus.HEALTHY -&gt; {                when (message.prevStatus) {                    SystemStatus.CRITICAL -&gt; slackSender.sendReturnHealthySlackMessage(message, message.prevStatus!!)                    else -&gt; log.info { &quot;브로커 상태 알림 수신: BrokerType=${message.type}, status=${message.status}&quot; }                }            }        }    }</code></p><p id="196e93af-013e-4152-add7-82b1ce00db23" class="">위 코드는 이상 감지 시스템에서 발행한 Kafka 이벤트를 구독하고 CRITICAL 상황이면 브로커 failover 시키는 코드에요. 비즈니스 목적에 맞게 CRITICAL 이 아닌 경우에는 별도 대응을 하지 않고 로그 정도만 찍었습니다.</p><p id="ad7db321-10d9-42a2-9cc9-6642f99df905" class="">두 가지 케이스에 대하여 아래처럼 메신저 알림을 발송하고 있어요. 모든 임직원이 사용하는 메신저를 사용해서 담당자를 멘션해서 즉각 알림을 보낼 수 있어요.</p><ol type="1" id="7c256cb4-507f-40dc-943f-96fb11b65b91" class="numbered-list" start="1"><li>브로커 상태가 <code>CRITICAL</code> 인 경우</li></ol><ol type="1" id="3bd16456-a8c3-4056-ab80-7f063af3bf5a" class="numbered-list" start="2"><li>브로커 상태가 <code>HEALTHY</code> 이지만 이전 상태가 <code>CRITICAL</code> 인 경우<figure id="e60a8edd-3215-40c2-9775-f2bd24b43d8d" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/69f063d4-cf08-45e0-af96-94609581be5b/IMG_9699.jpg"><img src="https://static.toss.im/ipd-tcs/toss_core/live/69f063d4-cf08-45e0-af96-94609581be5b/IMG_9699.jpg"/></a></figure></li></ol><h1 id="70a591c0-2bd8-4ae1-9fa9-173a05fceec3" class=""><strong>3. 증권 원장에 MongoDB 도입</strong></h1><p id="84d95181-dcbf-400c-9840-01ee2388ca58" class="">마지막으로 서비스가 성장하면서 데이터 사이즈도 같이 증가를 했어요. 따라서 데이터 관리를 어떻게 할지에 대한 고민거리도 같이 생겼어요. 단순한 조회 API가 500ms 이상 응답이 늦는 빈도가 증가하였고, 그중에 몇몇 API는 1000ms 이상 튀는 요청이 존재했어요.</p><p id="f5f78b93-2db6-4fed-9390-f7b18e93f25e" class="">테이블에 데이터가 크지 않았을 때는 문제가 되지 않았지만 데이터 사이즈가 증가하면서 비효율적인 쿼리들이 성능에 병목이 되었습니다.</p><figure id="c400bd63-c8a6-486f-8fc1-9b19ac429e95" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/94d91a48-f3a1-4348-bc21-a4f62aa87afe/inner-0711-8-2.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/94d91a48-f3a1-4348-bc21-a4f62aa87afe/inner-0711-8-2.png"/></a></figure><p id="1aac748f-2037-4945-a477-bd3b459c4a84" class="">따라서 여러 테이블들을 aggregate 한 테이블이 필요했어요. 데이터 저장소로 Oracle, MySQL 과 같은 RDB 혹은 MongoDB 사이에 많은 고민을 했어요. MongoDB를 후보군에 넣은 이유는 Oracle과 같은 RDB는 파티션 키가 없으면 모든 파티션을 검색하기 때문에 파티션 키가 필요하지만, <strong>MongoDB는 샤드 키가 없어도 어느 정도 준수한 성능 보장이 되기 때문이에요.</strong></p><figure id="61237479-3294-46a2-89a4-77902501c350" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/7fe37cdd-690c-4da9-abc2-2add3b32620d/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/7fe37cdd-690c-4da9-abc2-2add3b32620d/Untitled.png"/></a></figure><p id="179d1af0-b233-47fa-bd24-15e6ca0c48eb" class="">MongoDB는 샤드 키가 없이 쿼리를 날려도 모든 노드로 브로드캐스트 요청을 보내 해당 쿼리를 수행하고 mongos(라우터)에서 결과를 조합해서 변환해줘요. <strong>즉, 모든 노드에서 병렬처리를 하기 때문에 적절한 인덱스만 구성이 되면 어느 정도 준수한 성능이 보장이 돼요.</strong></p><p id="8ce6cf06-2111-4fb5-9bf1-c3e125bdfff0" class="">파티션 키를 고민한 이유는 데이터가 증가하면서 Oracle DB에 있는 주요 테이블에 파티션 키를 잡을 필요성이 생겼기 때문이에요.</p><figure id="f1bde6f8-a780-4b4d-ae16-f3e758b4c877" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/c6a94b8c-8ba1-4bdc-bf6c-8a2150a35c45/inner-0711-7.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/c6a94b8c-8ba1-4bdc-bf6c-8a2150a35c45/inner-0711-7.png"/></a></figure><p id="8aaddbd5-c835-493e-b08d-147d15e08c35" class="">사내 Oracle DBA(DataBase Administrator)로부터 데이터가 많은 주요 원장 테이블에 파티션 전환을 해야한다는 이야기를 들었어요. 여기서 개발자와 DBA 사이에 파티션 키로 뭐로 잡을지에 대한 의견이 달랐어요.</p><p id="5fa661bd-8448-46d5-be8a-13d13948df32" class="">개발자 입장에서는 증권의 모든 고객 요청은 계좌번호 조건을 찍고 조회하는 특성이 있기 때문에 계좌번호를 파티션 키로 잡고 싶은 니즈가 있었어요. 반면에 DBA 입장에서는 성능 향상도 중요하지만 디스크 저장도 같이 고려한다면 날짜를 파티션 키로 잡는 게 유리하기 때문에 날짜 단위로 파티션 키를 잡는 것을 권장했어요.</p><p id="c491d00e-99ed-474e-8559-8d2b30c2457b" class="">디스크 저장을 고려해야 하는 이유는 다른 DB에 비해 Oracle DB는 상대적으로 확장에 불리하기 때문에 디스크 관리도 같이 고민을 해주면 좋기 때문이에요. 날짜를 파티션 키로 잡게 되면 상대적으로 조회 빈도가 낮은 과거 데이터를 압축하기에 유리하기 때문에 압효율이 높아지고 디스크에 저장하는 데이터 사이즈를 많이 줄일 수 있어요.</p><p id="d15eb488-0f7a-478d-ac1e-7a1f307de59d" class=""><strong>결국 고민 끝에 팀에서는 MongoDB를 도입하기로 선택했어요.</strong></p><p id="21c006bd-f1b1-4fad-ac47-750af10a192a" class="">원천 데이터를 저장하는 Oracle DB는 날짜로 파티션 키를 잡아 장비 운영 효율을 높이고, 비즈니스 목적으로 계좌 단위로 조회를 하는 데이터는 MongoDB로 조회를 함으로써 상황에 맞게 적절하게 모두 대응을 할 수 있다는 점이 팀 상황에 매우 필요하다고 생각했어요. 그리고 성능도 준수하게 보장이 되고, 샤드 확장도 상대적으로 자유로우니 운영 비용도 크지 않다고 생각했습니다.</p><p id="a128f24f-2167-4881-b9fd-51a0a2213a6b" class="">이제 Oracle DB에서 MongoDB로 어떻게 데이터 마이그레이션했는지 살펴볼게요.</p><figure id="45ca678d-f95d-4191-8643-63cb03fe312b" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/584f0f53-ab8e-4cc1-bd64-2ec7ccfa3979/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/584f0f53-ab8e-4cc1-bd64-2ec7ccfa3979/Untitled.png"/></a></figure><p id="725c0dd5-0064-4e45-88ae-ef6052991a64" class="">위 그림은 데이터 마이그레이션 플로우에요. 문제가 된 Oracle 쿼리는 성능이 좋지 않았기 때문에, 빠른 배치 처리를 위해 Hadoop 기반 병렬처리 쿼리 엔진인 Impala에서 원본 데이터 조회를 했어요. Impala는 이미 사내에서 데이터 웨어하우스로 사용 중이기 때문에 별도 환경 구축 없이 빠르게 사용할 수 있었습니다.</p><figure id="c1a2c5bb-d58c-4d69-be3a-65eeb53a5c6c" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/8bbbbf30-2cff-469e-a111-647e2d78115d/Untitled.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/8bbbbf30-2cff-469e-a111-647e2d78115d/Untitled.png"/></a></figure><p id="1db30536-9520-46f8-b91f-99c8b6e5653c" class="">마이그레이션 이후 발생하는 데이터는 최대한 지연 없이 원본 데이터와 정합을 유지하기 위해 Kafka를 사용해서 실시간으로 데이터를 저장했어요. Kafka 이벤트 또한 이미 발행하고 있었기 때문에 MongoDB 데이터 저장하는 코드만 확장해서 빠르게 개발할 수 있었습니다.</p><h1 id="8f813769-48a7-4551-9169-18bb1e3aaa00" class=""><strong>마무리 🙇‍♂️</strong></h1><p id="f3b8b517-7508-4d5d-ae1c-023c4d149daf" class="">해외주식 서비스가 성장하는 과정 속에 발생한 문제들을 해결한 방법을 소개드렸는데요. 저 당시 팀에서는 언제 브로커 이슈가 발생할지 예상할 수 없기 때문에, 매우 빠르고 효율적으로 개발을 해야 했어요. 글에서 소개한 트래픽 제어, failover, 데이터 관리 등 간단하고 필수적인 기능들이지만 팀에서는 어떤 관점으로 문제를 인식했고 어떻게 지혜롭게 문제를 해결했는지 공유하고 싶었어요.</p><p id="66b52166-40ca-488e-97cf-ee04b2a536a5" class="">이번 글에서 최종적으로 전달하고 싶은 메시지는 <strong>먼저 문제의 핵심을 파악하고 이를 적정 수준의 엔지니어링을 통해 해결하는 것이 중요하다는 것이에요.</strong> 오버엔지니어링 없이 기존에 이미 잘 구현된 제품을 사용하여 문제를 빠르게 해결하고, 절약한 시간을 중요한 비즈니스 개발에 집중할 수 있었고, 이는 저희 팀이 빠르게 성장할 수 있는 비결이라고 생각해요.</p><p id="0e8a31b4-d2ca-4392-becf-426f7d4f3512" class="">
</p></details></li></ul><ul id="0314d52d-d438-4c52-91ec-13e3c8f8f852" class="toggle"><li><details open=""><summary>올리브영 재고 API 에서의 Resilience4j 도입 배경</summary><h3 id="6cc717e2-637b-406c-bb5d-8d96024d7936" class=""><strong>올리브영 재고 API 에서의 Resilience4j 도입 배경</strong></h3><figure id="43044e2e-ddc7-4e60-9731-c3bbce8e7985" class="image"><a href="https://oliveyoung.tech/static/856f38726631d238f4a16d4924b90abf/3bd3e/flow.png"><img style="width:700px" src="https://oliveyoung.tech/static/856f38726631d238f4a16d4924b90abf/3bd3e/flow.png"/></a></figure><p id="15536b94-2403-43ef-bf34-3f5de4c2d55c" class="">올리브영의 통합 재고 API 조회 프로세스 플로우는 위와 같습니다.</p><p id="30242358-d3bf-4694-a1a0-c628002093b9" class="">AWS memoryDB(Redis) 조회 후</p><p id="dbbc346e-d63a-48ff-a1fd-242d866524c0" class="">Hit 일 경우 조회 결과를 Return 합니다.</p><p id="1ea14641-0b23-43a2-990f-22052e78a70c" class="">Miss 일 경우 Oracle RDB를 조회하여 결과를 Redis 에 저장 후 조회 결과를 Return 합니다.</p><p id="e06af157-dc20-4458-abf2-596be9cdd40f" class=""><strong>1. CircuitBreaker 미적용</strong></p><figure id="d57fb388-adb1-4971-b165-602f25642652" class="image"><a href="https://oliveyoung.tech/static/ecda4054826b372ba6b8b2f6df0d7b03/3bd3e/flow_without_cb.png"><img style="width:700px" src="https://oliveyoung.tech/static/ecda4054826b372ba6b8b2f6df0d7b03/3bd3e/flow_without_cb.png"/></a></figure><p id="8576c522-2463-4791-9f2c-3d94a1964d15" class="">Redis 서버와 통신이 불가하여 예외가 발생할 경우</p><p id="e1819b84-55ee-45cf-b22d-53df82496dd7" class="">서버는 Redis 액션(조회/저장) 요청마다</p><p id="c4e96c81-8cb1-4a5c-8dcf-6e4b7ee0372e" class=""><em><strong>(redis connection wait timeout 시간 * redis connection retry 횟수)</strong></em> 만큼 시간을 낭비하고 그만큼 latency 는 증가하게 됩니다.</p><p id="232c8185-9121-4bd2-9335-4f0e2950d6be" class="">유저는 늘어난 latency 만큼 의미 없는 대기를 하게 됩니다.</p><p id="3a4254e9-901f-4243-93bb-22b8c824a6c2" class=""><strong>2. CircuitBreaker 적용</strong></p><figure id="27c62e2f-a170-4810-8688-e2912e7d8ffe" class="image"><a href="https://oliveyoung.tech/static/e94277327a29cde122979f9f665abb47/f47bd/flow_with_cb.png"><img style="width:700px" src="https://oliveyoung.tech/static/e94277327a29cde122979f9f665abb47/f47bd/flow_with_cb.png"/></a></figure><p id="da01558a-d674-4239-b0db-9f622b5e0c57" class="">Redis 서버와 통신이 불가하다고 판단된 경우(Circuit 이 Open state 인 경우)</p><p id="2636d768-c4bc-410e-9757-64f94b905722" class="">서버는 Redis 액션 없이 Oracle RDB 로 <strong>바로</strong> failover 처리되어 결과를 Return 하게 됩니다.</p><p id="5dcfc9e3-ff16-4e43-9177-95fbb92e5dc6" class="">Redis 서버에 장애가 있어도 유저는 더 이상 무의미한 대기를 하지 않아도 됩니다.</p><h3 id="ecc992a1-8a1e-47f1-b3f0-f364e9da31ff" class=""><strong>올리브영 재고 API 에서의 CircuitBreaker + Retry 적용</strong></h3><p id="14f99a22-48f4-41d9-964a-e549103e6bf6" class=""><strong>Gradle</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1b2324fe-285a-4254-8cfc-4fdc73546e41" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">implementation(&quot;org.springframework.cloud:spring-cloud-starter-circuitbreaker-resilience4j:2.1.6&quot;)
implementation(&quot;org.springframework.boot:spring-boot-starter-actuator&quot;)</code></pre><p id="2e1325e9-f113-43e8-b7b0-3ff49a35b13a" class="">CircuitBreaker, Retry 모듈만 사용할 예정이지만 간편하게 starter를 사용했습니다.</p><p id="a42ce8ba-5474-4f10-bc91-49b761491c96" class="">AOP 기반에서 동작하므로 aop 에 대한 dependency 는 필요하나,</p><p id="911fced4-3746-41ec-8798-93d6f0ad9cca" class="">보통 aop 는 다른 jar 를 통해 runtime 시에 주입되는 경우가 많으므로 프로젝트 dependency 를 확인하여 주입이 되지 않는 경우 추가가 필요합니다.</p><p id="4ec972a4-62c0-4349-9116-87b25eba8735" class="">actuator는 circuitbreaker 상태를 쉽게 확인할 수 있도록 health check 기능을 제공합니다.</p><p id="c1972f90-f727-40f9-a4aa-5125f844629c" class=""><strong>application yml 파일</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="bf360f7d-10c1-456d-aedb-406eeb56c05d" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">resilience4j:
  circuitbreaker:
    failure-rate-threshold: 10   # 실패 10% 이상 시 서킷 오픈
    slow-call-duration-threshold: 500   # 500ms 이상 소요 시 실패로 간주
    slow-call-rate-threshold: 10   # slowCallDurationThreshold 초과 비율이 10% 이상 시 서킷 오픈
    wait-duration-in-open-state: 30000   # OPEN -&gt; HALF-OPEN 전환 전 기다리는 시간
    minimum-number-of-calls: 50   # 집계에 필요한 최소 호출 수
    sliding-window-size: 100   # 서킷 CLOSE 상태에서 N회 호출 도달 시 failureRateThreshold 실패 비율 계산
    permitted-number-of-calls-in-half-open-state: 30   # HALFOPEN -&gt; CLOSE or OPEN 판단하기 위해 호출 횟수
  retry:
    wait-duration: 100   # 재시도 사이 간격
    max-attempts: 2   # 재시도 횟수(최초 호출 포함)</code></pre><p id="39642ce7-4a66-412c-b778-a09f3e43ae07" class=""><strong>ConfigurationProperties 사용하여 Property 관리</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8ce8047b-6872-457d-b232-e17b1d0a544b" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Configuration
@ConfigurationProperties(prefix = &quot;resilience4j.circuitbreaker&quot;)
class CircuitBreakerProperty {
   var failureRateThreshold: Float = Float.MIN_VALUE
   var slowCallDurationThreshold: Long = Long.MIN_VALUE
   var slowCallRateThreshold: Float = Float.MIN_VALUE
   var waitDurationInOpenState: Long = Long.MIN_VALUE
   var minimumNumberOfCalls: Int = Int.MIN_VALUE
   var slidingWindowSize: Int = Int.MIN_VALUE
   var permittedNumberOfCallsInHalfOpenState: Int = Int.MIN_VALUE
}</code></pre><p id="99dae732-396b-4afa-b3eb-c9fd5c753310" class=""><strong>CircuitBreaker Bean 선언</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="c53bd801-875a-4a66-84e9-4f0b99652b06" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Configuration
class CircuitBreakerProvider(
    val circuitBreakerProperty: CircuitBreakerProperty
) {
    companion object {
        const val CIRCUIT_REDIS: String = &quot;CB_REDIS&quot;
    }

    @Bean
    fun circuitBreakerRegistry(): CircuitBreakerRegistry {
        return CircuitBreakerRegistry.ofDefaults()
    }

    @Bean
    fun redisCircuitBreaker(circuitBreakerRegistry: CircuitBreakerRegistry): CircuitBreaker {
        return circuitBreakerRegistry.circuitBreaker(
            CIRCUIT_REDIS, CircuitBreakerConfig.custom()
                .failureRateThreshold(circuitBreakerProperty.failureRateThreshold)
                .slowCallDurationThreshold(Duration.ofMillis(circuitBreakerProperty.slowCallDurationThreshold))
                .slowCallRateThreshold(circuitBreakerProperty.slowCallRateThreshold)
                .waitDurationInOpenState(Duration.ofMillis(circuitBreakerProperty.waitDurationInOpenState))
                .minimumNumberOfCalls(circuitBreakerProperty.minimumNumberOfCalls)
                .slidingWindowSize(circuitBreakerProperty.slidingWindowSize)
                .ignoreExceptions(StockManageException::class.java)   // 화이트리스트로 서킷 오픈 기준 관리
                .permittedNumberOfCallsInHalfOpenState(circuitBreakerProperty.permittedNumberOfCallsInHalfOpenState)
                .build()
        )
    }
}</code></pre><h2 id="8530dedf-8277-478b-a381-347f0e50a265" class=""><strong>CircuitBreaker 모니터링</strong></h2><p id="61d64b83-4732-4f39-896c-e18403bdf2ca" class="">하기와 같이 actuator 설정을 할 경우 <code>/api/actuator/health</code> 를 호출하여 circuitbreaker 의 상태를 확인 할 수 있습니다.</p><p id="03b0b18b-1bdd-4620-9bfe-9b6343f6d79b" class=""><strong>application yml</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="fb260391-d499-47c8-8da4-2b95e1c45e05" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">management.endpoints.web.base-path=/api/actuator
management.endpoint.health.show-details=always
management.health.circuitbreakers.enabled= true
management.health.retry.enabled= true
resilience4j.circuitbreaker.configs.default.registerHealthIndicator= true</code></pre><p id="0e789805-f309-4212-95a9-4383f43b3793" class=""><code><strong>/api/actuator/health</strong></code><strong> 호출 결과</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1f1969cd-9c47-4926-8133-ca239432b743" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">&quot;circuitBreakers&quot;: {
    &quot;status&quot;: &quot;UP&quot;,
    &quot;details&quot;: {
      &quot;CB_REDIS&quot;: {
        &quot;status&quot;: &quot;UP&quot;,
        &quot;details&quot;: {
          &quot;failureRate&quot;: &quot;-1.0%&quot;,
          &quot;failureRateThreshold&quot;: &quot;10.0%&quot;,
          &quot;slowCallRate&quot;: &quot;-1.0%&quot;,
          &quot;slowCallRateThreshold&quot;: &quot;100.0%&quot;,
          &quot;bufferedCalls&quot;: 0,
          &quot;slowCalls&quot;: 0,
          &quot;slowFailedCalls&quot;: 0,
          &quot;failedCalls&quot;: 0,
          &quot;notPermittedCalls&quot;: 0,
          &quot;state&quot;: &quot;CLOSED&quot;
        }
      }
    }
  }</code></pre></details></li></ul><ul id="c9035b27-726f-4bf4-adbc-659650301d6d" class="toggle"><li><details open=""><summary>Transactional Outbox Pattern</summary><figure id="bfef2e49-e57d-4898-b21b-7fb1b64814b4" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2023.png"><img style="width:622.3650512695312px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2023.png"/></a></figure><p id="96fa1c81-1e4b-49df-8471-4b5874030474" class="">애플리케이션은 데이터베이스의 outbox 테이블에 메시지 내용을 저장합니다. 다른 애플리케이션이나 프로세스는 outbox 테이블에서 데이터를 읽고 해당 데이터를 사용하여 작업을 수행할 수 있습니다. 실패시 완료될 때까지 다시 시도할 수 있습니다. 따라서 outbox pattern은 적어도 한 번 이상(at-least once) 메시지가 성공적으로 전송되었는지 확인할 수 있습니다.</p><figure id="1005b4f6-dfcc-4ea3-9f15-03a1d7e98e84" class="image"><a href="https://velog.velcdn.com/images/eastperson/post/c67e25eb-6f91-467e-a31e-6b3e3108b4d8/image.png"><img style="width:528px" src="https://velog.velcdn.com/images/eastperson/post/c67e25eb-6f91-467e-a31e-6b3e3108b4d8/image.png"/></a></figure><figure id="33ce5b17-43a1-4c0e-943c-6b9df13f5afb" class="image"><a href="https://velog.velcdn.com/images/eastperson/post/3ff5b14d-f0bf-4dce-bcb3-e8d8c14eddfe/image.png"><img style="width:30px" src="https://velog.velcdn.com/images/eastperson/post/3ff5b14d-f0bf-4dce-bcb3-e8d8c14eddfe/image.png"/></a></figure><p id="624f7b92-76b9-4914-aca3-288f820d0fb9" class=""><a href="https://en.wikipedia.org/wiki/Inbox_and_outbox_pattern">https://en.wikipedia.org/wiki/Inbox_and_outbox_pattern</a></p><p id="9e1ad0df-e185-4081-a11f-40853f87ee5f" class="">여기서 outbox는 ‘보낼 편지함’이라는 뜻이 있습니다. 전송되지 않았거나 전송에 실패한 메시지들이 모여있는 보관함이라는 뜻입니다. 메시지를 보낼 데이터를 저장하는 저장소를 따로 두는 것이죠. 이제는 크리스 리처드슨(Chris Richardson’s)의 <a href="http://microservices.io/">microservices.io</a> 에서 정의하는 아웃박스 패턴을 보겠습니다.</p><figure id="16feaf43-4adc-417b-afc0-b680f27a039b" class="image"><a href="https://velog.velcdn.com/images/eastperson/post/8315f545-08a9-4aec-8739-1f95a2cf2a76/image.png"><img src="https://velog.velcdn.com/images/eastperson/post/8315f545-08a9-4aec-8739-1f95a2cf2a76/image.png"/></a></figure><p id="285a73e0-f91e-4d9b-b46a-7f85746483d7" class="">이 패턴의 구성요소는 다음과 같습니다.</p><ul id="de70f891-12fd-4bba-86bf-1a3c4ed33ea9" class="bulleted-list"><li style="list-style-type:disc">Sender - 메시지를 보내는 서비스</li></ul><ul id="7df74737-74e4-46d3-b04f-9e1bd0ec4767" class="bulleted-list"><li style="list-style-type:disc">Database - 엔티티 및 메시지 outbox를 저장하는 데이터베이스</li></ul><ul id="ce2c2b9e-c684-413a-a73f-b5fd7c5c552e" class="bulleted-list"><li style="list-style-type:disc">Message outbox - 관계형 데이터베이스인 경우 보낼 메시지를 저장하는 테이블. NoSQL의 경우 각 데이터베이스 record(document or item)의 프로퍼티</li></ul><ul id="cbf8db5e-c28f-4637-b422-2cbc3d79bae1" class="bulleted-list"><li style="list-style-type:disc">Message relay - outbox에 저장된 메시지를 메시지 브로커로 보내는 서비스</li></ul><p id="2c9cd221-b25d-4a02-90de-b452ca14fd56" class="">이 패턴에서는 Message Relay라는 별도의 프로세스가 추가됐습니다. outbox 테이블은 임시 메시지 큐 역할을 하며 엔티티 업데이트와 함께 트랜잭션으로 묶입니다. Message Relay는 outbox 테이블에 저장하는 데이터를 비동기적으로 읽어서 메시지를 발행하여 메시지 브로커에게 전달하는 역할을 하게 됩니다. outbox pattern의 Message Relay을 구현하는데는 Polling publisher, Transaction log tailing 두 가지 방식이 있습니다.</p><h1 id="fdd597aa-da3d-419e-950c-7c67d55bb9fa" class="">Outbox Pattern with Kafka Connect</h1><hr id="58c927d6-9202-4843-a1bb-d66097765569"/><p id="f271266c-01e9-4a42-b901-ee275c37d591" class="">Kafka-Connect는 Kafka 브로커 외에 별도의 서비스로 실행됩니다. 아래의 그림에서는 Postgres 데이터 베이스를 사용하였는고 엔티티 업데이트가 발생할 때 oubox 테이블에 레코드를 추가하는 모습입니다. Kafka-Connect 는 런타임시점에서 데이터베이스의 변경사항을 캡쳐하기 위해 Debezium 커넥터가 배포됩니다. Debezium 커넥터는 outbox 테이블에서 데이터베이스 트랜잭션 로그(write ahead log)를 추적하고 사용자 정의 커넥터에 의해 정의된 토픽에 메시지를 발행합니다.</p><figure id="fcd3fc51-42b7-4cbc-8b1e-b118850b7a40" class="image"><a href="https://velog.velcdn.com/images/eastperson/post/aa7d325f-7888-459d-bb0f-23e4a1b86b8c/image.png"><img src="https://velog.velcdn.com/images/eastperson/post/aa7d325f-7888-459d-bb0f-23e4a1b86b8c/image.png"/></a></figure><p id="4be557d0-c03e-45de-b27e-279c9890d219" class=""><a href="https://dzone.com/articles/implementing-the-outbox-pattern">https://dzone.com/articles/implementing-the-outbox-pattern</a></p><p id="b86ec72a-cdd7-461b-84ed-43e986fa6319" class="">이 방법은 적어도 한 번(at-least once) 전달을 보장합니다. 커넥터가 다운되고 시작될 때 동일한 이벤트를 여러 번 게시할 때가 있습니다. 따라서 consumer는 멱등성 상태여야 하며 중복 이벤트가 다시 처리되지 않도록 해야합니다.</p><p id="e6ffeb1f-0b2b-43e3-9a53-791264ebed90" class="">이와같이 로그의 변경된 데이터를 감지하는 작업을 <strong>CDC(Change Data Capture)</strong>라고 합니다. Debezium MySQL Connector는 bonlog를 읽어 INSERT, UPDATE, DELETE 연산에 대한 변경 이벤트를 만들어 Kafka 토픽으로 전송해줍니다. 따라서 DB에서 수행된 모든 이벤트가 안정적으로 수집되고 이벤트 발행시 정확한 순서가 보장됩니다.</p></details></li></ul><ul id="3f947777-bf1f-4b19-bda0-f0fef4bf0cdb" class="toggle"><li><details open=""><summary>CDC 너두 할 수 있어(feat. B2B 알림 서비스에 Kafka CDC 적용하기)</summary><h3 id="faebe043-2379-460f-8373-80eec6b586d2" class=""><strong>B2B 알림 서비스 소개</strong></h3><p id="21f2d560-57dd-41b4-82d3-f078795b01f4" class="">일단 이 이야기의 배경이 되는 B2B 알림 서비스 프로젝트부터 알아야, 왜 CDC를 도입하게 되었는지 이해하기 쉬울 겁니다. 기존 배민 B2C 고객 서비스에서는 ‘알림센터’라는 코어 시스템을 통해 고객에게 알림을 제공하고 있었지만, 사장님에게 발송되는 알림은 플랫폼이 부재한 관계로 카카오 알림톡으로 발송하고 있었습니다.</p><p id="08c0220e-8200-4c8a-aef6-dedfc2df06f5" class="">이에 따라, 사장님에게 전달되는 전체적인 알림 경험을 파악하기 힘들었고, 알림의 중요도와 종류에 관계없이 동일한 채널로 알림톡이 발송되고 있어, 전체적인 알림톡에 대한 반응이 저해될 뿐만 아니라, 알림톡 발송으로 인한 비용적인 문제가 발생하고 있던 상황이었습니다.</p><p id="95105a0e-b9b6-4fc4-890b-e5d7a7bee16d" class="">그래서, 알림센터를 활용해 사장님에게 전달되는 메시지를 내부 서비스를 통해 전달함으로써, 내부 서비스 활용도와 사용자 편의성을 향상하고자 진행한 프로젝트가 바로 B2B 알림 서비스 프로젝트입니다. 그 프로젝트 중 첫 번째 단계로 세일즈 매니저에 대한 알림톡을 알림센터내 웹 푸시 알림으로 전환하는 과정에서 CDC를 도입하게 되었습니다.</p><figure id="a714b5e1-604a-41e5-8a35-f90029385879" class="image"><a href="https://i.imgur.com/roCBjqj.gif"><img src="https://i.imgur.com/roCBjqj.gif"/></a></figure><h3 id="b3a034b4-ba3c-45ee-bc32-ac716f11d3b2" class=""><strong>B2B 알림서비스에 CDC를 도입하게 된 이유</strong></h3><p id="d5587361-a760-47a5-96ce-7e3b2381b6b4" class="">세일즈 매니저에게 발송되는 알림은 다음 경우에 발생합니다.</p><ul id="05975fdc-0099-40db-b96a-4ca58960f42c" class="bulleted-list"><li style="list-style-type:disc">세일즈 매니저 본인이 만든 업무 요청 건의 상태가 변경되는 경우</li></ul><ul id="2cb1fa2f-611c-4eae-94af-dc027e3ad46d" class="bulleted-list"><li style="list-style-type:disc">세일즈 매니저 본인이 해당 가게의 세일즈 매니저로 설정되어 있는 업무 요청 건의 상태가 변경될 때</li></ul><p id="7a729c69-864f-4ee0-b030-a40b97c67b20" class="">기존에는 이러한 요청 건의 상태 변경이 사용자 동작에 의해(요청 반려 버튼을 클릭 등) 발생되는 것이므로 프론트 코드에 알림을 발송하는 코드가 있던 상태였죠.</p><p id="441a0ad9-6c29-4f5d-b4ae-0953ce1b8af9" class="">하지만, 프론트에서 알림을 발생시키는 경우엔 다음과 같은 문제가 있습니다.</p><ul id="ff0120dc-c22a-4230-a992-aeeee79ae85f" class="bulleted-list"><li style="list-style-type:disc">네트워크 문제로 알림 발송 누락</li></ul><ul id="f9daf436-8a8e-49fb-8995-033c7df71e5e" class="bulleted-list"><li style="list-style-type:disc">알림 발송 이후 요청 건의 상태 변경에 실패하면 실제 데이터와 알림이 맞지 않음</li></ul><p id="77b32580-9545-4c60-b61d-cd402278788d" class="">이러한 문제를 해결하고자 알림에 대한 처리를 백엔드에서 할 방법이 필요했습니다. 그래서, 요청 건의 상태가 변경되면 DB에 반영되는 것에 착안하여 변경된 데이터를 감지하는 CDC를 선택하게 된 것이죠. 이런 식으로 CDC는 데이터가 변경되는 시점에 해당 항목을 추적하고, 변경에 대응해야 하는 다른 시스템 및 서비스에 알림을 전송하는 데이터 통합 패턴입니다.</p><h2 id="17da3aa4-e1cc-435e-9e20-74d3ed2a6471" class=""><strong>이제 CDC에 대해서도 한번 알아볼까요?</strong></h2><h3 id="b45fb5ad-59bc-48bd-b0fc-28c1d6eae510" class=""><strong>CDC의 개념과 동작 방식, 그리고 Kafka CDC</strong></h3><p id="3dc6df77-72d7-4bd8-8aec-bfa86e84a2ba" class="">CDC는 Change Data Capture의 약자로, 앞서 말씀드린 것처럼 소스 시스템에서 데이터가 변경된 것을 감지하여, 타깃 시스템이 변경 작업에 대응하는 작업을 수행하도록 하는 프로세스입니다. 여기서 우리 B2B 알림 서비스의 소스 시스템이 바로 DB였던 것이고, 타깃 시스템이 B2B 알림 서비스였던 것이죠. 이렇게 CDC를 사용한다면, 데이터를 사용하는 모든 시스템에서 일관성을 유지할 수 있다는 장점이 있습니다.</p><p id="9550d862-e617-45d0-8d33-fce4d9640358" class="">CDC에서 데이터 변경을 감지하는 방법에는 Pull 방식과 Push 방식이 존재합니다.</p><ul id="a2b02cb6-92bf-462f-bb96-3e7ae9988a3c" class="bulleted-list"><li style="list-style-type:disc">Pull 방식: 타깃 시스템의 주기적인 풀링으로 변경 사항이 있는지 확인하는 방법입니다. 쉽게 구현할 수 있다는 장점이 있지만, 실시간성이 떨어진다는 단점 또한 있습니다.</li></ul><ul id="9cc1d20f-42c3-4fd0-a2fc-7ef3b9eaa5a3" class="bulleted-list"><li style="list-style-type:disc">Push 방식: 소스 시스템이 변경이 발생할때마다 타깃 시스템에 알려주는 방법입니다. Pull 방식에 비해 소스 시스템이 많은 작업을 해야 하고, 타깃 시스템에 문제가 발생한다면 변경 이벤트에 누락이 발생할 수 있지만, 실시간성이 뛰어나다는 장점이 있습니다.</li></ul><p id="c87e58c3-6b0a-4c07-8bf1-17d76ce10746" class="">이런 두 가지 방법 중, Push 방식에서 이벤트 누락의 단점을 메시지큐인 Kafka를 통해 해결하여 CDC 시스템을 만드는 것이 바로 Kafka CDC입니다. B2B 알림서비스에서는 소스 시스템인 DB였는데요, 이 DB로부터 데이터의 변경 이벤트를 감지해서 Kafka 이벤트를 발행해 주는 것이 바로 Debezium MySQL Connector입니다.</p><h3 id="edc81a49-5571-4972-934e-852ccf328626" class=""><strong>Debezium MySQL Connector 주요 특징</strong></h3><p id="a45543c8-441e-4d8a-b24e-ce961127a8e0" class="">Debezium MySQL Connector는 MySQL의 binlog를 읽어 INSERT, UPDATE, DELETE 연산에 대한 변경 이벤트를 만들어 Kafka 토픽으로 이벤트를 전송해줍니다. binlog를 기반으로 데이터를 수집하기 때문에, DB에서 수행된 모든 이벤트가 안정적으로 수집되고, 이벤트 발행 시 정확한 순서가 보장되죠.</p><h2 id="6101c5dd-2267-4572-b7e7-ac33b2408e09" class=""><strong>B2B 알림 서비스에서는 어떻게 Kafka CDC를 활용했는지 알아봅시다</strong></h2><h3 id="c8b3b3cc-254c-4943-92f8-3a121f455a85" class=""><strong>사전 준비</strong></h3><p id="f66def31-99b4-4144-8cc0-bebf53fa7710" class="">일단 Kafka + Kafka Connect + Debezium MySQL Connector가 사용할 수 있는 환경에, 이미 설치되어 있다는 것을 가정하고 진행하겠습니다. 이 과정에서 주의해야 하는 것은 MySQL의 설정입니다. binlog 설정이 제대로 되어 있는지 확인해야 하고, Debezium MySQL Connector가 사용할 DB 계정에 SELECT, RELOAD, SHOW DATABASE, REPLICATION SLAVE, REPLICATION CLIENT 등의 권한이 잘 있나 확인해야 합니다.</p><h3 id="37a843e5-afa1-4c6d-84db-6614b74343ad" class=""><strong>Kafka CDC를 활용한 코드 작성하기</strong></h3><p id="6a2521e2-653f-4e32-8ee5-7514d24a590e" class="">일단 먼저 Kafka를 통해 넘어오는 이벤트 레코드를 변환해야 하는데 Debezium MySQL Connector는 Apache Avro를 지원하고, 이를 사용하려면 스키마 레지스트리를 사용해야 하죠. 스키마 레지스트리에 등록된 스키마를 받기 위해서는, 프로젝트의 gradle에 설정을 추가해두면 편합니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="b3ffb6d8-15b4-4c8b-90b7-86061789fa7b" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">val schemaRegistry = &quot;http://localhost:8081&quot; // 스키마 레지스트리 주소
val downloadInputs = listOf(
    &quot;schema.data-key&quot;,
    &quot;schema.data-value&quot;
)
val avroDestination = &quot;org/main/avro&quot; //avro 스키마가 저장될 프로젝트상의 위치
schemaRegistry {
    url.set(schemaRegistry)
    download {
        // 패턴에 해당하는 서브젝트(스키마)를 다운로드
        downloadInputs.forEach {
            subjectPattern(
                inputPattern = it,
                file = avroDestination
            )
        }
    }
}</code></pre><p id="0827ab0f-640d-4e2e-af51-dae7b40afe7f" class="">받아온 avro 스키마는 대략적으로 다음과 같이 생겼죠.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e4a5cb14-5165-4aea-969b-01d78384a0d0" class="code"><code class="language-JSON" style="white-space:pre-wrap;word-break:break-all">{
    &quot;type&quot;: &quot;record&quot;,
    &quot;name&quot;: &quot;Envelope&quot;,
    &quot;namespace&quot;: &quot;schema.data&quot;,
    &quot;fields&quot;: [
        {
            &quot;name&quot;: &quot;before&quot;,
            &quot;type&quot;: [
                &quot;null&quot;,
                {
                    &quot;type&quot;: &quot;record&quot;,
                    &quot;name&quot;: &quot;Value&quot;,
                    &quot;fields&quot;: [
                        {
                            &quot;name&quot;: &quot;id&quot;,
                            &quot;type&quot;: &quot;long&quot;
                        }
                        // ...
                    ],
                    &quot;connect.name&quot;: &quot;schema.data&quot;
                }
            ],
            &quot;default&quot;: null
        },
        {
            &quot;name&quot;: &quot;after&quot;,
            &quot;type&quot;: [
                &quot;null&quot;,
                &quot;Value&quot;
            ],
            &quot;default&quot;: null
        },
        {
            &quot;name&quot;: &quot;source&quot;,
            &quot;type&quot;: {
                &quot;type&quot;: &quot;record&quot;,
                &quot;name&quot;: &quot;Source&quot;,
                &quot;namespace&quot;: &quot;io.debezium.connector.mysql&quot;,
                &quot;fields&quot;: [
                    {
                        &quot;name&quot;: &quot;version&quot;,
                        &quot;type&quot;: &quot;string&quot;
                    }
                    // ...
                ],
                &quot;connect.name&quot;: &quot;io.debezium.connector.mysql.Source&quot;
            }
        },
        {
            &quot;name&quot;: &quot;op&quot;,
            &quot;type&quot;: &quot;string&quot;
        },
        {
            &quot;name&quot;: &quot;ts_ms&quot;,
            &quot;type&quot;: [
                &quot;null&quot;,
                &quot;long&quot;
            ],
            &quot;default&quot;: null
        },
        {
            &quot;name&quot;: &quot;transaction&quot;,
            &quot;type&quot;: [
                &quot;null&quot;,
                {
                    &quot;type&quot;: &quot;record&quot;,
                    &quot;name&quot;: &quot;ConnectDefault&quot;,
                    &quot;namespace&quot;: &quot;io.confluent.connect.avro&quot;,
                    &quot;fields&quot;: [
                        {
                            &quot;name&quot;: &quot;id&quot;,
                            &quot;type&quot;: &quot;string&quot;
                        },
                        {
                            &quot;name&quot;: &quot;total_order&quot;,
                            &quot;type&quot;: &quot;long&quot;
                        },
                        {
                            &quot;name&quot;: &quot;data_collection_order&quot;,
                            &quot;type&quot;: &quot;long&quot;
                        }
                    ]
                }
            ],
            &quot;default&quot;: null
        }
    ],
    &quot;connect.name&quot;: &quot;schema.Envelope&quot;
}
</code></pre><p id="d681250d-767c-4fdf-8692-37990daf5479" class="">이 상태에서 빌드를 거치고 나면 Envelop 클래스가 생기는데, 이것을 그대로 활용하는 것보단 적절하게 변환해서 사용하는 게 좋습니다. 마침 우리 프로젝트는 Kotlin이었기 때문에 Kotlin의 확장 함수를 이용해서 변환을 쉽게 할 수 있었죠.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="40d898e9-66f6-4ea7-a7e1-afd064be35fd" class="code"><code class="language-Kotlin" style="white-space:pre-wrap;word-break:break-all">fun Envelop.toBefore(): CdcRecord? {
    val before = this.getBefore() ?: return null

    return CdcRecord(
        //...
    )
}</code></pre><p id="a5ae5dde-b5a5-4aba-9b99-6ee4885690e1" class="">자, 클래스도 준비되었으니 이제 클래스를 활용해서 본격적인 작업을 시작하기에 앞서, Kafka CDC도 Kafka를 이용해야 하므로 ConsumerConfig를 설정해줘야 하겠죠?</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="03239b6b-91c7-41b8-9f9b-939954a0b42c" class="code"><code class="language-Kotlin" style="white-space:pre-wrap;word-break:break-all">@Configuration
class CdcConsumerConfig {
    @Bean(CDC_CONTAINER_FACTORY)
    fun cdcListenerContainerFactory(
        properties: CdcConsumerProperties,
        @Value(&quot;\${spring.kafka.bootstrap-servers}&quot;) bootstrapServers: String
    ): KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;String, Envelope&gt;&gt; {
        val factory = ConcurrentKafkaListenerContainerFactory&lt;String, Envelope&gt;()
        factory.consumerFactory = DefaultKafkaConsumerFactory(
            mapOf(
                ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG to bootstrapServers,
                ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG to properties.keyDeserializerClass,
                ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG to properties.valueDeserializerClass,
                ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG to properties.enableAutoCommit,
                ConsumerConfig.MAX_POLL_RECORDS_CONFIG to properties.maxPollRecords,
                ConsumerConfig.AUTO_OFFSET_RESET_CONFIG to properties.autoOffsetReset,
                // Schema Registry, Avro 관련 설정 필수
                KafkaAvroDeserializerConfig.SCHEMA_REGISTRY_URL_CONFIG to properties.schemaRegistryUrl,
                KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG to properties.specificAvroReader,
            )
        )
        // ...
    }
}</code></pre><p id="9413ede1-dc9d-4758-be6d-0ea7a673b033" class="">이벤트를 받아 처리하는 것이니 이벤트 리스너를 만들어야겠죠?</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e4884c6c-9f8f-4b54-885e-8adfde88abe2" class="code"><code class="language-Kotlin" style="white-space:pre-wrap;word-break:break-all">class CdcEventListener(
    private val cdcEventProcessor: List&lt;CdcEventProcessor&gt;,
) {
    private val sinkQueue = Queues.get&lt;List&lt;Envelope&gt;&gt;(4096).get()
    private val sinks = Sinks.many()
        .unicast()
        .onBackpressureBuffer(sinkQueue)
    private lateinit var disposable: Disposable

    @KafkaListener(
        topics = [&quot;\${kafka.cdc.topic}&quot;],
        groupId = &quot;\${kafka.cdc.groupId}&quot;,
        containerFactory = CdcConsumerConfig.CDC_CONTAINER_FACTORY,
    )
    fun listen(
        @Payload payloads: List&lt;Envelope?&gt;,
        @Header(KafkaHeaders.RECEIVED_PARTITION_ID) partition: Int,
        @Header(KafkaHeaders.RECEIVED_TOPIC) topic: String,
        @Header(KafkaHeaders.RECEIVED_TIMESTAMP) ts: Long,
        acknowledgment: Acknowledgment,
    ) {
        // ...
    }
}</code></pre><p id="3a15d667-e6ff-4512-8d57-795a6ef60174" class="">B2B 알림 서비스에서는, CDC 이벤트의 종류에 따라서 다른 알림을 보내야 했었는데요. 이를 위해서 서로 다른 이벤트의 종류를 받을 이벤트 프로세서와, 각 이벤트 내에서 어떤 알림을 보낼지 결정하는 이벤트 핸들러를 구현하였습니다. 예를 들어 어떤 종류(예: 가게 로고 수정, 가게 소개 수정 등)의 요청 건에 대한 이벤트인지는 이벤트 프로세서로 구분하고, 해당 요청 건에 대한 어떤 이벤트인지(예: 요청이 승인됨, 요청이 반려됨 등)는 이벤트 핸들러로 구분해서 알림을 보내는 구조이죠. 그림으로 나타내면 아래와 같습니다.</p><figure id="8cc9c115-d69c-4d17-875e-2fb2cdad2fda" class="image"><a href="https://i.imgur.com/Adw3jzI.png"><img src="https://i.imgur.com/Adw3jzI.png"/></a></figure><p id="dce6a724-33ef-4ed4-8f79-31574b686744" class="">이러한 구조를 반영하려면 이벤트 리스너에 아래와 같이 각 이벤트 프로세서에 이벤트를 전달하는 코드가 추가되어야 합니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="d0b054ea-d2b1-4d2d-8515-617ca55f6ec1" class="code"><code class="language-Kotlin" style="white-space:pre-wrap;word-break:break-all">class CdcEventListener(
    private val cdcEventProcessor: List&lt;CdcEventProcessor&gt;,
) {
    // ...
    @PostConstruct
    protected fun init() {
        disposable = sinks.asFlux()
            // ...
            // 이벤트를 처리 하는 과정에서 doAlarm으로 알림 발송
            .doOnNext(::doAlarm)
            // ...
    }

    private fun doAlarm(CdcRecords: List&lt;Envelope&gt; = emptyList()) {
        Flux.fromIterable(CdcRecords)
            .flatMap {
                Mono.fromCallable {
                    // 각각의 이벤트 프로세서에게 이벤트를 처리 하도록 지시
                    cdcEventProcessor.forEach { processor -&gt;
                        try {
                            processor.process(
                                before = it.toBefore(),
                                after = it.toAfter(),
                            )
                        } catch (e: Exception) {
                            log.warn(&quot;[CdcEventProcessor] occured exception&quot;, e)
                        }
                    }
                }.subscribeOn(Schedulers.boundedElastic())
            }.subscribe()
    }
}
</code></pre><p id="d55f2a19-8a17-412e-9ebd-31a7427c55eb" class="">이제 이벤트를 처리하는 이벤트 프로세서의 차례입니다. 이벤트 프로세서에서는 자신이 전달받은 이벤트에 대해서 처리할 수 있는 이벤트인지 확인한 후, 처리할 수 있는 이벤트의 종류라면 자신이 가지고 있는 이벤트 핸들러들에게 처리를 위임합니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="80528dc6-ac9f-413e-be45-8b267cbd1bb5" class="code"><code class="language-Kotlin" style="white-space:pre-wrap;word-break:break-all">@Service
class NotificationCenterAlarmFacade(
    private val notificationHandlers: List&lt;NotificationHandler&gt;
) : CdcEventProcessor {

    override fun process(before: CdcRecord?, after: CdcRecord?) {
        log.debug(&quot;[알림서비스] process 진입 before = `{}`, after = `{}`&quot;, before, after)

        if (after == null) {
            log.info(&quot;[알림서비스] 데이터 삭제건에 대해서는 알림서비스 발송처리를 하지 않습니다. before: `{}`&quot;, before)
            return
        }

        notificationHandlers.find { it.accept(before = before, after = after) }
            ?.send(record = after)
    }
}
</code></pre><p id="6b38febf-f133-4cfb-8050-6c1d343e61d4" class="">마지막으로, 핸들러는 본인이 처리할 수 있는 이벤트인지 확인하고 알림을 보내는 것으로 B2B 알림 서비스가 동작하게 됩니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="3a72831d-31c3-4277-ae21-0c491fad7e4e" class="code"><code class="language-Kotlin" style="white-space:pre-wrap;word-break:break-all">@Component
class CompleteHandler : NotificationHandler {
    override fun send(record: CdcRecord) {
        // 알림 발송 로직
    }

    override fun accept(before: CdcRecord?, after: CdcRecord?): Boolean {
        // 완료 이벤트에 대한 알림을 발송하는 핸들러이기 때문에, 완료 이벤트인지 확인하는 조건
        if (before == null || after == null ||
            before.status == Complete || after.status != Complete
        ) {
            return false
        }
        log.info(&quot;[알림서비스] 완료 이벤트 감지 `{}`&quot;, after.id)
        return true
    }
}</code></pre><p id="063ca317-8f25-4776-8ec0-eee1eef64508" class="">이제 특정 요청 건들의 상태가 변경되면 자동으로 알림을 받아볼 수 있게 되었습니다!</p><p id="d758dacf-043d-4a73-8fdc-de37418a37a3" class="">그럼 마지막으로 CDC를 사용할 때 무엇을 주의해야 할지 알아보시죠.</p><h2 id="9f2b9c30-42aa-4402-975d-0028d24d1461" class=""><strong>Kafka CDC를 사용할 때 주의할 것</strong></h2><h3 id="0b702b4d-ac97-4f58-b523-774607d4a1dc" class=""><strong>AWS Aurora 환경에서 쓰기 부하가 많은 경우</strong></h3><p id="0d74d8ca-a6f8-41be-a451-063cf6329fcf" class="">Debezium MySQL Connector를 연동하면 binlog dump thread가 Aurora MySQL 클러스터 스토리지의 binlog를 읽는데, 이때 잠시 락을 걸게 됩니다. 그런데, Aurora MySQL 2.10.2 미만의 버전(<a href="https://aws.amazon.com/ko/blogs/database/introducing-binlog-i-o-cache-in-amazon-aurora-mysql-to-improve-binlog-performance/">2.10.2 버전 binlog 부하 개선사항</a>)에서는 아키텍처상 문제로 쓰기 부하가 많은 경우 부하가 심해지게 되는 문제가 있습니다. 만약 binlog dump thread의 부하가 심해지는 경우 INSERT, UPDATE, DELETE, COMMIT 등 DML 관련 레이턴시가 증가하게 되고, 이에 따라 장애가 발생할 수 있게 됩니다.</p><h3 id="0b1a0e47-6315-4420-9549-ecffca8fe4cf" class=""><strong>중복 메시지 발생의 가능성</strong></h3><p id="c7e71641-48eb-4667-98f2-f1002aac4d1f" class="">여러 가지 경우로 Kakfa 메시지는 중복될 수 있습니다. 그렇다면 중복으로 메시지가 발생하는 경우에도 대응해야겠죠. 이건 CDC의 문제가 아니라 이벤트 큐를 사용한다면 누구나 발생할 수 있는 문제이기 때문에 여러 해결 방법이 있고, 저는 Redis Cache를 이용해 이 문제를 해결했습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="d86a4453-34b9-4503-a931-fa454db99e5a" class="code"><code class="language-Kotlin" style="white-space:pre-wrap;word-break:break-all">class CdcEventListener(
    private val cdcEventProcessor: List&lt;CdcEventProcessor&gt;,
) {
    // ...
    @PostConstruct
    protected fun init() {
        disposable = sinks.asFlux()
            // ...
            // 이벤트를 처리 하는 과정에서 doCheckDuplicationPrevent 으로 중복 확인
            .flatMap(::doCheckDuplicationPrevent)
            // ...
    }

    private fun doCheckDuplicationPrevent(cdcRecords: List&lt;Envelope&gt;): Mono&lt;List&lt;Envelope&gt;&gt; {
        return Mono.fromCallable {
            cdcRecords.filter {
                // HashCode를 이용한 RedisKey 생성
                val key = RedisCacheType.DUPLICATION_PREVENT.addPostfix(name = &quot;${it.getAfter().getId()}:${it.hashCode()}&quot;)
                // 해당 Key가 이미 존재하는지 확인
                val existKey = redisTemplate.opsForValue().existKey(
                    key = key
                )
                log.debug(
                    &quot;[CDC][EventEmitterSinks] Check Duplication Prevent. Key = `{}`, Value = `{}`&quot;,
                    key, existKey
                )
                (!existKey)
            }
        }.subscribeOn(Schedulers.boundedElastic())
    }
}
</code></pre><h2 id="c87dcaf8-e888-4148-90b0-76de6185f95f" class=""><strong>마무리</strong></h2><p id="537413ab-37ff-4af2-995c-2a81b812fde7" class="">지금까지 CDC란 무엇인지, Kafka CDC를 활용해 코드는 어떻게 작성하는지, Kafka CDC를 사용할 때 주의할 것은 무엇인지에 대해서 B2B 알림 서비스의 예시를 통해 알아보았습니다.</p><p id="ea63f3ab-8da3-4c4c-9f05-6922a245286f" class="">이 글의 내용을 참고해 여러분의 프로젝트에 CDC를 도입하는 데 도움이 되길 바라며, 추가적으로 Kafka CDC에 더 관심 있는 분은 <a href="https://kafka.apache.org/documentation/#introduction">Apache Kafka 공식 문서</a>와 <a href="https://debezium.io/documentation/reference/stable/connectors/mysql.html">Debezium MySQL Connector 공식 문서</a>를 참고하시기 바랍니다.</p></details></li></ul><ul id="ccee9caf-0d1a-46f9-b370-d8a376d5d8f3" class="toggle"><li><details open=""><summary>고성능 DB 서비스 기술</summary><p id="7aed2977-d4c6-424f-bceb-22ac3f122471" class="">고성능 서비스를 제공하기 위한 데이터베이스 기술은 대규모 데이터 처리, 높은 트랜잭션 속도, 낮은 지연 시간, 그리고 확장성 등을 목표로 합니다. 이러한 요구를 충족하기 위해 다양한 기술과 접근 방법이 존재합니다. 주요한 기술 및 접근법은 다음과 같습니다:</p><ol type="1" id="c06c52ad-2a3a-481c-93ab-deeef869ea98" class="numbered-list" start="1"><li><strong>분산 데이터베이스 시스템 (Distributed Databases):</strong><ul id="a4423dfb-6a5e-47dc-afb1-158f37afd1f7" class="bulleted-list"><li style="list-style-type:disc"><strong>NoSQL 데이터베이스:</strong> NoSQL 데이터베이스는 관계형 데이터베이스(RDBMS)에 비해 유연한 데이터 모델링과 뛰어난 확장성을 제공합니다. 대표적인 예로는 MongoDB, Cassandra, Couchbase, HBase 등이 있습니다.<ul id="bd2a7a1b-0650-4f27-90d5-2f0145ff9a1e" class="bulleted-list"><li style="list-style-type:circle"><strong>MongoDB:</strong> 문서 지향 데이터베이스로, JSON과 유사한 BSON 형식을 사용합니다. 스케일 아웃이 용이하며, 유연한 스키마를 지원합니다.</li></ul><ul id="21dd996c-c5b5-41b2-9ee8-b9aa3e9ef427" class="bulleted-list"><li style="list-style-type:circle"><strong>Cassandra:</strong> 분산형 키-값 스토어로, 높은 가용성과 확장성을 자랑합니다. 특히 쓰기 작업에서 뛰어난 성능을 발휘합니다.</li></ul><ul id="2a9b1189-e558-433d-9996-fe15c1341bcd" class="bulleted-list"><li style="list-style-type:circle"><strong>Couchbase:</strong> 메모리 우선 아키텍처와 JSON 문서 모델을 결합한 데이터베이스로, 실시간 애플리케이션에 적합합니다.</li></ul><ul id="c31f7287-d392-4549-8f2a-0026f41573d8" class="bulleted-list"><li style="list-style-type:circle"><strong>HBase:</strong> Apache Hadoop 생태계의 일부로, 거대한 테이블 구조에서 실시간 읽기/쓰기 성능을 제공합니다.</li></ul></li></ul><ul id="01cb4f70-573b-45ce-b8ac-bba626c5b0a3" class="bulleted-list"><li style="list-style-type:disc"><strong>NewSQL 데이터베이스:</strong> 전통적인 관계형 데이터베이스의 특성을 유지하면서도 NoSQL의 확장성을 제공하는 시스템입니다. 예로는 Google Spanner, CockroachDB, VoltDB 등이 있습니다.</li></ul></li></ol><ol type="1" id="c74af7fd-312f-4be6-beb2-7118d28cb0ec" class="numbered-list" start="2"><li><strong>인메모리 데이터베이스 (In-Memory Databases):</strong><ul id="ee844f4a-676d-4e11-8a72-9a4f45ad9676" class="bulleted-list"><li style="list-style-type:disc">인메모리 데이터베이스는 데이터를 디스크가 아닌 메모리에 저장하여 매우 빠른 읽기 및 쓰기 성능을 제공합니다. 대표적인 예로는 Redis, Memcached, SAP HANA 등이 있습니다.<ul id="8480edcf-102b-4a07-84de-7d54af1056d8" class="bulleted-list"><li style="list-style-type:circle"><strong>Redis:</strong> 키-값 저장소로, 다양한 데이터 구조(리스트, 세트, 해시 등)를 지원하며, 높은 성능의 캐싱 및 세션 관리에 사용됩니다.</li></ul><ul id="2ccc1508-68bb-4eed-9ead-1bbefeadd763" class="bulleted-list"><li style="list-style-type:circle"><strong>Memcached:</strong> 단순한 키-값 캐시 시스템으로, 자주 접근하는 데이터를 메모리에 저장하여 데이터베이스 부하를 줄입니다.</li></ul><ul id="896d997c-9188-44f6-a429-6e04d8b6992b" class="bulleted-list"><li style="list-style-type:circle"><strong>SAP HANA:</strong> 인메모리 관계형 데이터베이스로, 실시간 데이터 처리 및 분석에 적합합니다.</li></ul></li></ul></li></ol><ol type="1" id="df8c1e99-a639-41cc-a762-993375b993a8" class="numbered-list" start="3"><li><strong>샤딩 (Sharding):</strong><ul id="3b8ff7ed-9615-4209-bb74-c156e802d1a8" class="bulleted-list"><li style="list-style-type:disc">샤딩은 데이터를 여러 데이터베이스 서버에 분산 저장하여 성능을 향상시키는 기술입니다. 수평적 확장이 가능하며, 각 샤드는 독립적으로 작동합니다.</li></ul></li></ol><ol type="1" id="8c3c13a5-d576-4fa5-bf15-56500c1052e3" class="numbered-list" start="4"><li><strong>리플리케이션 (Replication):</strong><ul id="c9183d2b-a89a-427c-936c-7b52f00a77a1" class="bulleted-list"><li style="list-style-type:disc">데이터베이스 리플리케이션은 데이터를 여러 복제본에 복제하여 가용성과 읽기 성능을 높이는 기술입니다. 마스터-슬레이브 리플리케이션, 멀티 마스터 리플리케이션 등이 있습니다.<ul id="1851f90e-65c3-4cd7-872a-19463bcbc2ce" class="bulleted-list"><li style="list-style-type:circle"><strong>마스터-슬레이브 리플리케이션:</strong> 하나의 마스터 데이터베이스가 쓰기 작업을 처리하고, 여러 슬레이브 데이터베이스가 읽기 작업을 처리합니다.</li></ul><ul id="a9534a2e-e213-4b3d-a117-d5a4f59a5921" class="bulleted-list"><li style="list-style-type:circle"><strong>멀티 마스터 리플리케이션:</strong> 여러 마스터가 쓰기 작업을 동시에 처리할 수 있어, 확장성과 가용성을 높입니다.</li></ul></li></ul></li></ol><ol type="1" id="04d51466-cee7-4253-b2d5-0a765bef7c91" class="numbered-list" start="5"><li><strong>데이터 캐싱 (Data Caching):</strong><ul id="eaa3de1a-c782-422e-9c5f-89d312b59e98" class="bulleted-list"><li style="list-style-type:disc">자주 사용되는 데이터를 캐시에 저장하여 데이터베이스의 부하를 줄이고 응답 속도를 높이는 기술입니다. 앞서 언급한 Redis와 Memcached가 대표적인 예입니다.</li></ul></li></ol><ol type="1" id="07852dd0-3b8f-488f-b189-bc9e316d72cf" class="numbered-list" start="6"><li><strong>데이터베이스 최적화 (Database Optimization):</strong><ul id="24bbd71b-bdaa-4d49-9813-8e6578a864cd" class="bulleted-list"><li style="list-style-type:disc">인덱싱, 쿼리 최적화, 파티셔닝 등 다양한 최적화 기법을 통해 데이터베이스 성능을 극대화할 수 있습니다.<ul id="ffbca522-670b-4810-adc2-b4ce88c31f68" class="bulleted-list"><li style="list-style-type:circle"><strong>인덱싱:</strong> 적절한 인덱스를 생성하여 검색 성능을 향상시킵니다.</li></ul><ul id="08dcd68a-b2aa-4f9c-9748-340ae06bfc82" class="bulleted-list"><li style="list-style-type:circle"><strong>쿼리 최적화:</strong> 쿼리 작성 방식을 최적화하여 실행 속도를 높입니다.</li></ul><ul id="dce2aed4-b433-499d-b4db-0f204d1c2a1a" class="bulleted-list"><li style="list-style-type:circle"><strong>파티셔닝:</strong> 테이블을 작은 단위로 나누어 관리하여 성능을 개선합니다.</li></ul></li></ul></li></ol><p id="825ffb7f-7e87-449e-a9d3-1bbadc579a12" class="">이와 같은 기술들을 적절히 조합하고 활용하면, 고성능 데이터베이스 시스템을 구축하여 대규모 데이터와 높은 트랜잭션 속도를 효과적으로 처리할 수 있습니다.</p><p id="27909983-2f79-47bc-839b-49240a0e290f" class="">
</p></details></li></ul><ul id="a1516d12-cb53-4eaf-8a64-927b72ba3b08" class="toggle"><li><details open=""><summary>11번가 인턴의 카탈로그 리뷰 API 개선기</summary><p id="0e0a29f7-865d-406c-90b8-3990c4bde9bf" class="">아래 사진은 2022년 그랜드 십일절 당시 카탈로그 리뷰 API로 인해 DB에 부하가 생긴 모습입니다.</p><p id="4bbf536c-fd9b-4362-81f1-93182a2114a8" class="">그랜드 십일절 카탈로그 리뷰로 인한 DB 부하</p><figure id="59242984-7167-4b9e-a543-a7ac9b1b9695" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/grand-11-db.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/grand-11-db.png"/></a></figure><h1 id="0dda8f50-6004-4f0e-93fe-8d9938e65464" class=""><strong>카탈로그 리뷰 API, 너 왜 문제 있어?</strong></h1><p id="55b2dc5b-b5a4-4e40-be39-0c3ef435f6f9" class="">카탈로그 리뷰 API는 어떤 이유로 DB에 부하를 가하는 문제점을 가지고 있을까요?</p><p id="0d99f519-94cd-4bfa-a392-86555bb22120" class="">API의 문제점을 분석하기 이전에 먼저 “카탈로그 리뷰” 에 대해 이해해야 한다고 생각했습니다.</p><p id="8139b8cd-2c9c-4e18-b4de-2ca8b221965c" class="">먼저, <code>카탈로그</code>란 <strong>11번가의 상품들이 고객에게 잘못 노출되는 경우를 없애기 위해 자체적으로 가격 비교를 할 수 있는 정제된 데이터</strong>를 말합니다.</p><p id="f0f1d0a1-ed08-42d0-8b33-6d854c864611" class="">카탈로그와 리뷰 관계 정리</p><figure id="2d542773-bd02-4050-8168-25114b725e5a" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/catalog-and-review.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/catalog-and-review.png"/></a></figure><p id="2f1fff7d-1f17-404e-b374-9f269044139b" class="">카탈로그는 상품과</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e76b6617-dc6f-48af-b67d-a8ff003f5f22" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">1대N</code></pre><p id="b1b89300-e0fa-460e-a887-4686b326bd8d" class="">의 관계를 가집니다. 상품과 리뷰도</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="5e07cbfb-4f32-488a-bcb9-61d406e72981" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">1대N</code></pre><p id="6c4c60db-3785-40da-a6fd-c4d0d1d727ee" class="">의 관계를 가집니다.</p><p id="d1850b2d-d43b-4bc3-b4ec-c39734543de5" class="">따라서, 카탈로그와 리뷰는</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e5154be9-72f5-46be-afb9-ea03a6ea7115" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">1대N^2</code></pre><p id="7c905734-147a-4ef0-a28c-21a352595fc0" class="">관계이기 때문에 제대로 성능이 나올 수 없는 구조입니다.</p><p id="ce59e9f0-5d8b-4263-b06a-e46c8c8f7db9" class="">카탈로그와 리뷰는 각각의 도메인으로 존재하고 데이터양이 매우 많은 시스템이어서 구조적인 개선이 어렵습니다.</p><p id="d3c08f3d-8ba3-4b4e-b3ae-a71a6fe506b9" class="">카탈로그 리뷰 개선 방법</p><figure id="b72bfa71-33dc-4ad1-813f-27bb7ffa661a" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/how-to-improve.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/how-to-improve.png"/></a></figure><p id="940e2801-6cda-4023-8b8f-43fca99587eb" class="">문제점을 개선하기 위해</p><ol type="1" id="8a896f24-8675-492c-ba26-6b20b884f93e" class="numbered-list" start="1"><li>첫 번째로 글로벌 캐시를 도입하고,</li></ol><ol type="1" id="9ab65e41-d0b3-47b6-88c4-200d3b9932a7" class="numbered-list" start="2"><li>두 번째로 호출이 빈번한 카탈로그 캐시의 TTL 만료 전 능동적으로 캐시 최신화 작업을 수행하기로 결정했습니다.</li></ol><h1 id="50d6c1a0-5919-4928-928b-569ce715e1f3" class=""><strong>글로벌 캐시 도입</strong></h1><h1 id="1a56ac03-df4e-49d2-91cb-d85572e43141" class=""><strong>기존 구조 - Only 로컬 캐시</strong></h1><p id="025b3b00-797a-42b3-84f0-f993fdb6afcf" class="">로컬 캐시만 사용중인 기존 구조</p><figure id="37111c9e-b8de-4edf-a75a-da2684e7a2d0" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/only-local-cache.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/only-local-cache.png"/></a></figure><p id="8ba7c32d-7e9c-445e-b4ab-e5e76c15ed2a" class="">카탈로그 리뷰의 쿼리는 top-query이지만 <code>1대N^2</code> 구조로 인해 성능이 좋지 않습니다.</p><p id="9457aa23-3e48-486e-9918-bb440150cef6" class="">따라서, A 상품의 카탈로그 리뷰를 처음 호출 시 Read Timeout이 발생할 수 있습니다.</p><p id="abf5037d-0571-4c78-9495-065eb28dc38c" class="">이를 해결하고자 기존 구조에서는 Caffeine 캐시를 사용하여 로컬 캐싱을 적용하고 있었습니다.</p><p id="7f3e3cba-eddd-494c-bc14-92f4fca59272" class="">로컬 캐시는 속도가 빠르지만 캐시 동기화를 할 수 없다는 단점을 가지고 있어 서버마다 데이터의 차이가 존재할 수 있습니다.</p><p id="67c037bb-1628-4945-a246-556b679e7c20" class="">만약, WAS 3대 중 A 상품에 대한 로컬 캐싱이 1대에만 적용되어 있는 상황이라면 다른 2개의 WAS로 A 상품에 대한 카탈로그 리뷰 호출 시 무거운 쿼리가 실행되는 것입니다.</p><p id="9e6bea87-cf44-4722-bec7-fa7a4817df68" class="">성능이 좋지 않은 쿼리 실행은 쌓이고 쌓여 속도가 더 느려지며 이로인해 카탈로그 리뷰 페이지를 새로고침 시 카탈로그 리뷰가 간헐적으로 노출되지 않는 현상이 존재했습니다.</p><h1 id="12c235d4-c3e7-41ef-aa4d-fbe932325216" class=""><strong>글로벌 캐시 로직 구현</strong></h1><p id="adb5fee5-1c0b-417a-858b-2eecb1cafbdc" class="">Cache Key와 Cache Value</p><figure id="e52e4187-e53a-4b75-9407-b3f3ba849c96" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/catalog-review-list-param.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/catalog-review-list-param.png"/></a></figure><p id="f13244c0-b808-45a8-a88d-dcd558d38e46" class="">카탈로그 리뷰 API는 CatalogReviewListParam이라는 클래스를 argument로 사용하며 카탈로그 리뷰 데이터인 CatalogDetailReviews를 반환합니다.</p><p id="db775c1a-c8ce-4062-803e-e1b85234d935" class="">CatalogReviewListParam에는 여러 필드들이 존재합니다.</p><p id="f7f2f48f-d73c-4595-a068-b784ec186103" class="">각각의 필드들에 의해 카탈로그 리뷰 데이터 결과가 달라지고 카탈로그 리뷰 관련 서비스 코드들이 CatalogReviewListParam 자체를 인자로 많이 사용하고 있어 일부 필드들로 캐시 key로 구성했습니다.</p><p id="5c945bbc-5f43-485b-bc2a-45ca88dd7250" class=""><code>public class CatalogGlobalCache {<br/>    private CatalogReviewListParam cacheKey;<br/>    private CatalogDetailReviews cacheValue;<br/>    <br/>    ...<br/>}<br/></code></p><p id="65c70226-e9ac-4971-b903-a5c3ee2a2a39" class="">이를 토대로 <code>CatalogReviewListParam</code>을 Cache의 Key로, <code>CatalogDetailReviews</code>를 Cache의 Value로 가지는 <code>CatalogGlobalCache</code>를 만들었습니다.</p><p id="e8553205-ff50-4128-8248-d10340fa90fb" class="">로컬 캐시, 글로벌 캐시 모두 사용한 구조</p><figure id="356b1f5b-42da-457a-b3f4-a29267dcc1cf" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/local-and-global-cache.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/local-and-global-cache.png"/></a></figure><p id="c8846f43-0bdd-4dc8-81c0-dbe47a17aeef" class="">기존 로컬 캐시 제거하지 않고, 로컬 캐시와 글로벌 캐시, 2가지 캐시 레이어를 모두 사용했습니다.</p><p id="d554fa4b-83ab-43d2-80c2-0ca61078be00" class="">2가지 캐시 레이어를 사용하기 때문에 캐시 히트율을 높일 수 있습니다.</p><h1 id="59073609-14d6-426f-bd67-5242b10365d4" class=""><strong>글로벌 캐시를 추가한 후 흐름</strong></h1><p id="b3f45472-deec-4ae7-82aa-2063b3c37d10" class="">글로벌 캐시 추가 후 흐름</p><figure id="e692f126-27d9-4384-b5b7-09dc39b216ec" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/global-cache-flow.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/global-cache-flow.png"/></a></figure><p id="c93ee8c2-0b50-490e-ac31-dd185d0b90c3" class="">글로벌 캐시를 추가한 후 카탈로그 리뷰 API의 흐름은 다음과 같습니다.</p><ol type="1" id="a92556d5-9529-41ad-932b-62e3f485e926" class="numbered-list" start="1"><li>로컬 캐시에서 해당 요청에 맞는 데이터를 우선적으로 탐색합니다.</li></ol><ol type="1" id="0157aa94-c81a-4509-b067-e7c3d4e77c9d" class="numbered-list" start="2"><li>만약, 로컬 캐시에 원하는 데이터가 있다면 반환하고, 없다면 글로벌 캐시 로직으로 넘어갑니다.</li></ol><ol type="1" id="4064b75d-332e-48bd-a381-46c0c365e363" class="numbered-list" start="3"><li>글로벌 캐시에서 로컬 캐시로부터 넘어온 요청에 맞는 데이터를 탐색합니다.</li></ol><ol type="1" id="27e49d0d-ac6c-4f9e-91d2-5d7873780404" class="numbered-list" start="4"><li>만약, 글로벌 캐시에 원하는 데이터가 있다면 반환하고, 없다면 데이터 쿼리 로직을 수행합니다.</li></ol><p id="ed7e66e0-8ca1-49be-9d00-c54cba731e6d" class="">추가로, 글로벌 캐시가 도입된 순서도입니다.</p><p id="296d5260-cbf5-480b-9285-a7dbb7c97908" class="">글로벌 캐시가 도입된 순서도</p><figure id="280498ad-41a7-4f6b-9110-4600d74c2a95" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/global-cache-flowchart.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/global-cache-flowchart.png"/></a></figure><h1 id="c03c57f9-a947-4607-862f-586c79a6a27c" class=""><strong>캐시 자동 최신화</strong></h1><p id="07cc9a6a-1c98-4d95-b5e2-db6d29c7cc31" class=""><a href="https://giphy.com/gifs/team-fortress-2-refresh-f5-vTKXchNrmZ6RW">출처</a></p><p id="37d6f391-41a1-43c5-b99c-844a36e91caa" class="">글로벌 캐시를 도입하더라도 첫 호출과 만료된 캐시에 대해서는 개선이 되지 않아 호출이 실패하게 됩니다.</p><p id="f17cba5f-dd38-40c2-849f-45fa7945579f" class=""><strong>호출이 빈번한 카탈로그 리뷰 데이터를 능동적으로 최신화</strong>하여 개선하기로 결정했습니다.</p><p id="b890e01b-6c93-465f-818f-00209ab1b280" class="">호출이 빈번한 카탈로그 리뷰 데이터를 능동적으로 최신화하기 위해서는 호출이 빈번한 카탈로그가 어떤 카탈로그인지 알아야 합니다.</p><p id="c50ef05a-4bc5-4f81-b503-247c12b5fe67" class="">이를 위해 Redis의 Sorted Set을 사용하기로 결정했습니다.</p><p id="7c2595d8-5d3a-4ae5-9d9b-3375088be7e0" class="">Redis의 Sorted Set은 Leaderboard와 같이 순위가 필요한 곳에 사용할 수 있는 자료구조입니다.</p><p id="648bc191-046a-41ef-910e-0c31efdafb6a" class="">카탈로그 리뷰 데이터가 호출될 때마다 Score를 증가시켜 호출 횟수를 기록합니다.</p><p id="f315fe3b-dd24-4efd-b69f-df68ad070bcb" class="">하지만, 호출이 빈번한 카탈로그 정보를 추출하기 위해 Redis의 Sorted Set Score 데이터를 확인해보니 로직의 문제점을 발견했습니다.</p><p id="40f1e2e7-7098-4f6e-bf6c-dc991971acfd" class="">Sorted Set Score가 로컬 캐시에 데이터가 없을 때에만 증가되는 것이었습니다.</p><p id="8b6bf649-caab-42f1-9175-91d725fb8f50" class="">대부분의 데이터가 로컬 캐시에서 히트되어 나가기 때문에 Redis의 Sorted Set Score를 증가시킬 수 없었고 글로벌 캐시로 사용하는 Redis까지 요청이 거의 도착하지 않았습니다.</p><p id="ef270695-036d-48fc-8442-2794a3369552" class="">이렇게 만들어진 Score 정보는 호출이 빈번한 카탈로그를 알아내기 위한 유의미한 정보가 아니라고 판단했습니다.</p><p id="846a5a05-7d00-42ed-822f-286eb47c72e7" class="">따라서, 로컬 캐시와 글로벌 캐시의 순서를 변경하였습니다.</p><p id="d055fd93-2058-4a00-a1ae-787a7d2e50e2" class="">로컬 캐시와 글로벌 캐시의 순서 변경</p><figure id="14996c37-63a3-4fcd-90ab-e09accb9d046" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/modify-cache-sequence.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/modify-cache-sequence.png"/></a></figure><p id="a4e22aa5-0c4a-434f-9828-1d0c6f7e2c12" class="">스위치 배치</p><figure id="2e2e840a-ffba-4391-9e9c-62496fdb9ec6" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/add-switch.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/add-switch.png"/></a></figure><p id="2fe4ba48-89b4-484a-a2cf-09409fc453fd" class="">글로벌 캐시의 순서가 앞으로 조정되면서 혹시 모를 서비스 장애에 대비하여 컨트롤러단에 스위치를 배치했습니다.</p><p id="95da8175-5f94-4b5e-8e26-99db117cca40" class="">스위치를 통해 상용 서비스 도중 문제 발생 시 기존 서비스로 빠르게 롤백할 수 있습니다.</p><p id="84e7c2ed-7f78-4809-ab42-5e1256e3f384" class="">다음은 로컬 캐시와 글로벌 캐시의 위치를 변경한 후의 순서도입니다.</p><p id="6366d9f9-17f6-422b-ab84-ff7e1c84e01d" class="">로컬 캐시와 글로벌 캐시의 순서 변경 후 순서도</p><figure id="6e299974-6299-4c29-9f99-353583776b84" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/after-cache-flowchart.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/after-cache-flowchart.png"/></a></figure><h1 id="42302d1b-1939-471e-bc7f-293e2ae96277" class=""><strong>글로벌 캐시의 단점</strong></h1><p id="b1feaf37-a4f9-4994-b8ea-6057d714ca11" class="">동기와 비동기</p><figure id="b1ceee32-46a1-4fe7-ac9a-da4692d7e6af" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/sync-and-async.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/sync-and-async.png"/></a></figure><p id="4e8dd76a-2760-4f21-b011-d0c93c53e7db" class="">글로벌 캐시에도 네트워크 통신으로 인해 응답속도가 느리다는 단점이 존재합니다.</p><p id="97cbf000-aa71-4727-90c3-5021d2b6b338" class="">카탈로그 리뷰 API의 목적은 <strong>카탈로그 리뷰 데이터를 조회하여 반환하는 것</strong>입니다.</p><p id="f72f0f98-baa9-4aa0-8fc5-2ada09dd5e81" class="">Redis에 데이터를 추가하거나 Sorted Set Score를 올리는 작업이 해당 API 내에서 동기적으로 작업되어야할 필요가 없다는 것이죠.</p><p id="efe94530-c0d8-488d-9508-5209626b1840" class="">따라서, 해당 작업들을 비동기로 전환할 계획을 세웠습니다.</p><h1 id="6bd1a345-0a5b-4328-b316-92a6de89ea80" class=""><strong>동기 or 비동기 무엇이 더 좋을까?</strong></h1><p id="dc651045-c769-4050-9f19-67263a5a9996" class="">비동기로의 전환이 유의미한 개선이 될 수 있을 지 판단하기 위해 테스트를 진행했습니다.</p><ul id="113d53af-4ca2-4fcb-9264-3896d5bc8015" class="bulleted-list"><li style="list-style-type:disc">기존 로컬 캐시를 타는 로직</li></ul><ul id="0e546d79-d681-4dde-84c4-3bdefe12a157" class="bulleted-list"><li style="list-style-type:disc">글로벌 캐시는 먼저 타는 동기 로직</li></ul><ul id="bf4ca10e-a622-4876-9540-76450f7cb7a2" class="bulleted-list"><li style="list-style-type:disc">글로벌 캐시 로직을 먼저 타지만, 일부 작업이 비동기인 로직</li></ul><p id="77a0f22e-cae8-4d6b-b884-53607f077fcc" class="">위와 같이 3가지 경우로 나누어 테스트를 진행했습니다.</p><h3 id="f4a49cc9-dc6b-4a7d-b09e-24b8c6aef630" class=""><strong>Test 1. 로컬 캐시에 데이터가 존재하지 않는 경우</strong></h3><p id="d928818e-66d6-4712-938d-35d8d95d6239" class="">Test 1</p><figure id="2d76eac6-3029-41b7-b36f-a9e166c93d81" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test1.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test1.png"/></a></figure><p id="c960c083-e78b-4a4b-a902-77154a35ef13" class="">1번 테스트는 기존 로컬 캐시를 타는 로직이며, 로컬 캐시에 데이터가 존재하지 않는 경우입니다.</p><ol type="1" id="52cd1276-0a5e-4178-ae78-007d6620edf8" class="numbered-list" start="1"><li>로컬 캐시에서 데이터를 탐색</li></ol><ol type="1" id="1c251522-bc6b-4668-aded-4825159e54af" class="numbered-list" start="2"><li>로컬 캐시에 데이터가 존재하지 않아 데이터를 쿼리</li></ol><ol type="1" id="b8904c15-bf26-4ae4-aa7c-c36db4108dac" class="numbered-list" start="3"><li>쿼리한 데이터를 로컬 캐시에 추가</li></ol><ol type="1" id="bc6fe961-3508-456c-bd62-fb30c96227e7" class="numbered-list" start="4"><li>반환</li></ol><p id="38fbcdb9-43ca-4f07-9acd-e1945c0d30ee" class="">순서로 이루어지고, 36~45ms가 소요되었습니다.</p><h3 id="30837941-d2eb-4187-9651-38c132a7db5a" class=""><strong>Test 2. 로컬 캐시에 데이터가 존재하는 경우</strong></h3><p id="bc835cd6-b2cf-4f90-8460-63c5a48debc0" class="">Test 2</p><figure id="33772bb7-dbaa-44c8-bb36-24ca7de00a57" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test2.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test2.png"/></a></figure><p id="5eed8ed2-db78-4434-82ad-602fd29c4041" class="">2번 테스트는 기존 로컬 캐시를 타는 로직이며, 로컬 캐시에 데이터가 존재하는 경우입니다.</p><ol type="1" id="88870340-5aa8-4703-9575-2c6c1e6c8591" class="numbered-list" start="1"><li>로컬 캐시에서 데이터 탐색</li></ol><ol type="1" id="15f968ba-3356-40e8-950b-75e2da9286da" class="numbered-list" start="2"><li>반환</li></ol><p id="685d29ea-d05c-492b-91ea-483551b5e171" class="">순서로 이루어지고, 6~9ms가 소요되었습니다.</p><h3 id="45b59040-4d45-4d5b-a8f4-7d915c724505" class=""><strong>Test 3. 로컬과 글로벌 캐시 모두 데이터가 존재하지 않는 경우</strong></h3><p id="3ba88a20-9d56-4ffa-bdb8-ee07de5f0f10" class="">Test 3</p><figure id="e8562ad8-5b21-4c46-bebb-b430aa211b22" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test3.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test3.png"/></a></figure><p id="4085156b-6331-409f-8278-07526671bbaf" class="">3번 테스트는 글로벌 캐시를 먼저 타는 동기 로직이며, 로컬 캐시와 글로벌 캐시 모두 데이터가 존재하지 않는 경우입니다.</p><ol type="1" id="7e33c9eb-8a74-4204-a214-0d6a0b829add" class="numbered-list" start="1"><li>글로벌 캐시에서 데이터를 탐색</li></ol><ol type="1" id="c12f9041-0686-492c-ae32-2895887a51e4" class="numbered-list" start="2"><li>글로벌 캐시에 데이터가 존재하지 않아 로컬 캐시에서 데이터를 탐색</li></ol><ol type="1" id="41dd9e3d-42a5-4705-9662-3f0e106b7ccc" class="numbered-list" start="3"><li>로컬 캐시에 데이터가 존재하지 않아 데이터를 쿼리</li></ol><ol type="1" id="9e3fd2ba-4b45-4a25-b9b5-927fa3f3339f" class="numbered-list" start="4"><li>쿼리해온 데이터를 로컬 캐시에 추가</li></ol><ol type="1" id="87be48b5-6dcb-4082-b39a-a18d0e0b8178" class="numbered-list" start="5"><li>쿼리해온 데이터를 글로벌 캐시에 추가</li></ol><ol type="1" id="a6226c9b-1303-42a8-bb17-321c0027613f" class="numbered-list" start="6"><li>Redis Sorted Set Score 증가</li></ol><ol type="1" id="44a36915-1d59-4275-85e4-ca2e604a272e" class="numbered-list" start="7"><li>반환</li></ol><p id="0e7fadc2-c8e9-492f-b498-e6690b3a579a" class="">순서로 이루어지고, 153~175ms가 소요되었습니다.</p><h3 id="a19f705d-6a0c-49b3-8ea2-a4e274d8aed2" class=""><strong>Test 4. 로컬과 글로벌 캐시 모두 데이터가 존재하는 경우</strong></h3><p id="7f08b6ba-2d60-4684-84bb-1171c143fc21" class="">Test 4</p><figure id="613d3dfb-59f5-4bb4-b7c7-a1e92187a646" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test4.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test4.png"/></a></figure><p id="02b3407f-84d8-4eb6-af50-76e33eff27f4" class="">4번 테스트는 글로벌 캐시를 먼저 타는 동기 로직이며, 로컬과 글로벌 캐시에 모두 데이터가 존재하는 경우입니다.</p><ol type="1" id="1123f8b5-6868-4f75-bc1f-4e8c18b9117c" class="numbered-list" start="1"><li>글로벌 캐시에서 데이터를 탐색</li></ol><ol type="1" id="133253a8-1e2b-4e53-aad1-50b037c6c6dc" class="numbered-list" start="2"><li>Redis Sorted Set Score 증가</li></ol><ol type="1" id="fd0a7204-1325-49df-a43c-e1f042b3ea59" class="numbered-list" start="3"><li>반환</li></ol><p id="898d03c0-242b-4662-90e1-1c239c0e1c87" class="">순서로 이루어지고, 30~37ms가 소요되었습니다.</p><h3 id="0c7ae4d9-f763-42b5-a0d0-4837ac8af30c" class=""><strong>Test 5. 로컬과 글로벌 캐시 모두 데이터가 존재하지 않는 경우</strong></h3><p id="31ed6dc9-8d61-41ac-96a4-7d8ed4a1245e" class="">Test 5</p><figure id="6a55dcbe-6e1a-4c69-8fa8-179e37d27ea2" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test5.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test5.png"/></a></figure><p id="3209a7e8-b5a6-45dd-8de3-6518a1623f45" class="">글로벌 캐시를 먼저 타지만, 일부 작업이 비동기인 로직입니다.</p><p id="c5c38029-ff76-4a4b-bca7-30437ecc8fba" class="">5번 테스트는 로컬과 글로벌 캐시 모두 데이터가 존재하지 않는 경우입니다.</p><p id="d39a3ee3-e630-4f8a-95b6-0078fbd23165" class="">3번 테스트와 조건은 동일하지만, 글로벌 캐시에 데이터를 추가하는 작업과 Sorted Set Score를 증가시키는 작업을 비동기로 처리합니다.</p><ol type="1" id="46191f5b-ad8c-41d4-b714-55cd21a44bfe" class="numbered-list" start="1"><li>글로벌 캐시에서 데이터를 탐색</li></ol><ol type="1" id="3c97eac6-321a-4270-95bc-241b61e577e9" class="numbered-list" start="2"><li>글로벌 캐시에 데이터가 존재하지 않아 로컬 캐시에서 데이터를 탐색</li></ol><ol type="1" id="849b9203-f057-451f-a4b4-1c0b482ecb75" class="numbered-list" start="3"><li>로컬 캐시에 데이터가 존재하지 않아 데이터를 쿼리</li></ol><ol type="1" id="250bbfe0-b884-4a57-9cf7-87392a979037" class="numbered-list" start="4"><li>쿼리해온 데이터를 로컬 캐시에 추가</li></ol><ol type="1" id="5ace946c-8182-45d6-9b33-d9fa7ab152b0" class="numbered-list" start="5"><li>쿼리해온 데이터를 글로벌 캐시에 비동기로 추가</li></ol><ol type="1" id="747144d8-ccaa-4b89-9a48-450dcf4295fa" class="numbered-list" start="6"><li>Redis Sorted Set Score를 비동기로 증가</li></ol><ol type="1" id="35648885-7831-46f2-b187-1d012e90fe35" class="numbered-list" start="7"><li>반환</li></ol><p id="f20122e3-9ed2-413d-9da2-67998d1f52c5" class="">순서로 이루어지며, 50~75ms가 소요되었습니다.</p><h3 id="bda70dd2-7d41-4adb-8499-f14e460c60ef" class=""><strong>Test 6. 로컬과 글로벌 캐시 모두 데이터가 존재하는 경우</strong></h3><p id="ec7353e2-6d37-4b26-a9b7-984ea50e340d" class="">Test 6</p><figure id="b04a8771-433b-49f3-85ce-461cf85a7eb8" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test6.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test6.png"/></a></figure><p id="73d45502-ac33-452b-ab72-efe66150ff78" class="">6번 테스트는 로컬과 글로벌 캐시 모두 데이터가 존재하는 경우입니다.</p><p id="07e139b9-001f-4e03-8806-1fc58ae3ec6b" class="">글로벌 캐시에서 데이터를 찾고 Redis Sorted Set Score 증가 작업을 비동기로 처리하고 데이터를 반환합니다.</p><ol type="1" id="b92bdc4a-a5f7-4b78-b0fd-841b67b4b9c8" class="numbered-list" start="1"><li>글로벌 캐시에서 데이터를 탐색</li></ol><ol type="1" id="acf26a6a-4e7b-4642-9d75-3e26c6c75d46" class="numbered-list" start="2"><li>Redis Sorted Set Score를 비동기로 증가</li></ol><ol type="1" id="7e71275e-4a6e-4e71-993b-f0842c8edef3" class="numbered-list" start="3"><li>반환</li></ol><p id="054fad7a-3562-4519-8feb-9bafd66b9fc9" class="">순서로 이루어지며, 16~21ms가 소요되었습니다.</p><h3 id="93984a90-fb97-47dd-85b2-307dee2816a2" class=""><strong>테스트 결과</strong></h3><p id="8fda1cdc-1805-48ba-82ed-fa0bf0fbe078" class="">테스트 케이스 정리 및 결과입니다.</p><blockquote id="7fb5ec7b-f0c8-48fe-98fa-33aa017eaf85" class="">기존 로컬 캐시를 타는 구조<ul id="93bf1ff4-e3da-46e4-aa01-c4226838c26b" class="bulleted-list"><li style="list-style-type:disc">T1 : 로컬 캐시에 데이터가 없는 경우</li></ul><ul id="59a2c8d0-77bb-4ef4-8d33-29a0d383f801" class="bulleted-list"><li style="list-style-type:disc">T2 : 로컬 캐시에 데이터가 있는 경우</li></ul><p id="16aa6133-9d55-4ac1-8193-6cc89a94bb07" class=""><strong>글로벌 캐시 데이터 X -&gt; 로컬 캐시 데이터 X -&gt; 데이터 쿼리</strong></p><ul id="e0c701b2-dc7c-47f6-a000-0644606e8c31" class="bulleted-list"><li style="list-style-type:disc">T3 : 로컬 &amp; 글로벌 캐시 모두 데이터가 없는 경우</li></ul><ul id="a789d011-03ed-4d5b-a98c-94eceffd2dfa" class="bulleted-list"><li style="list-style-type:disc">T4 : 로컬 &amp; 글로벌 캐시 모두 데이터가 있는 경우</li></ul><p id="a3d227d5-6833-4e62-95d2-b5b0094169bb" class=""><strong>데이터 반환과 관계없는 작업들은 모두 비동기 전환</strong></p><ul id="a3c12dc9-c17a-4314-a6b4-dcbbd62930dd" class="bulleted-list"><li style="list-style-type:disc">T5 : 로컬 &amp; 글로벌 캐시 모두 데이터가 없는 경우</li></ul><ul id="ef5e9027-d80a-43f6-9620-e0592465ca8d" class="bulleted-list"><li style="list-style-type:disc">T6 : 로컬 &amp; 글로벌 캐시 모두 데이터가 없는 경우</li></ul></blockquote><p id="f037fdcb-724e-4bd9-b1f1-4ad2b80befe0" class="">테스트 결과</p><figure id="02f65f27-5188-49b9-a9f0-1b9489a7d741" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test-result.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/test-result.png"/></a></figure><p id="7b145cd4-e93c-4db7-a364-c4c074f6835e" class="">로컬과 글로벌 캐시 모두 데이터가 없는 경우에는 동기에서 비동기로 일부 작업을 전환하면서 응답시간이 <strong>61% 감소</strong>했습니다.</p><p id="dbe57aa4-509e-446a-bfc2-2534ed5428f2" class="">모두 데이터가 있는 경우에는 응답시간이 <strong>44% 감소</strong>한 것을 알 수 있었습니다.</p><p id="acddde81-21f4-478f-86b6-d1f44a909ec5" class="">일부 작업을 비동기로 전환하여 글로벌 캐시의 단점인 느린 응답속도를 개선했습니다.</p><h1 id="4582d86a-73f3-4b8a-b312-36aa0d8bd452" class=""><strong>글로벌 캐시 도입으로 카탈로그 리뷰 API 개선 결과</strong></h1><p id="f2c8431b-917e-40d0-b4e8-a7eacc9e9b3f" class="">개선 결과</p><figure id="ad46e427-95ba-40d9-949f-7bb0b03c1ad6" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/improvement-result.gif"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/improvement-result.gif"/></a></figure><p id="d5ddc61a-b237-4a1b-bb62-fd43a41bfbcd" class="">카탈로그 리뷰 페이지를 새로고침 시 데이터가 간헐적으로 나오지 않았던 현상을 해결하고 카탈로그 리뷰를 빠르게 보여주고 있습니다.</p><p id="48c344e3-f569-4407-9d00-e4dc2d08c6e3" class="">사용자들이 느낄 수 있는 부정적인 경험을 개선하고, 150개로 제한하고 있던 카탈로그 리뷰 개수 또한 더 늘릴 수도 있게 되었습니다.</p><p id="e2b5ff8e-67fe-45d4-bb87-dfd02aff3a8e" class="">카탈로그 리뷰 API 개선 이전과 이후의 히트맵 트랜잭션 사진입니다.</p><p id="6b076980-7a04-42a2-9046-ad818f62f15f" class="">개선 후 히트맵 트랜잭션 사진</p><figure id="d2b76cbe-9151-4b0d-8812-365fc4909f96" class="image"><a href="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/after-improvement-heatmap-transaction.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-07-19-improve-catalog-review-api/after-improvement-heatmap-transaction.png"/></a></figure><p id="fcafe54e-86e0-4d0e-8195-73ad678d72de" class="">카탈로그 리뷰 API 개선 후로 에러가 줄어든 것을 확인할 수 있습니다.</p><p id="9206fa9c-3f5f-465b-b16c-8080a59787e6" class="">글로벌 캐시 도입과 호출 빈도가 높은 카탈로그 리뷰 데이터 자동 최신화로 로컬 캐시의 만료로 발생하는 무거운 쿼리의 실행빈도가 WAS 인스턴스 수에 비례하여 감소했습니다.</p><p id="e248efb8-0a01-4a9d-9498-00a1b12e8424" class="">그로인해, DB 역시 부하가 감소한 것을 알 수 있습니다.</p><h1 id="e039b931-8686-470d-b0da-0d905fa6ed6e" class=""><strong>되돌아보며</strong></h1><p id="6933ec6c-ac23-4431-a072-df7c70b9ddea" class="">인턴 기간동안 Cache와 Redis에 대해 고민하고 공부해가며 진행했습니다.</p><p id="7f048825-3a3e-4b9c-ae60-8d204ff9d720" class="">인턴으로 진행하는 과제가 실제 상용에 배포되어 고객들에게 서비스된다는 점이 저에겐 설렘과 두려움 모두를 느끼게 해주었습니다.</p><p id="bb4cffce-9272-481d-8d53-4dda9434e591" class="">그래서 제가 생각한 방법들과 코드에 대해 더 많이 고민했던 것 같습니다.</p><p id="4233d0e1-04b4-4e69-934d-dd8cc261bebe" class="">인턴에게 상용 배포를 경험하게 해주신 저희 PDP개발팀분들에게 정말 감사합니다.</p><h1 id="9a3342f4-790e-4f60-b5b2-01e2d0b16b3d" class=""><strong>앞으로</strong></h1><p id="937e9cd2-fe4a-4734-aa18-d8805eaba49d" class="">인턴 당시에는 정말 열심히 진행하였지만 경험을 정리하면서 돌아보니 아쉬움이 남아있습니다.</p><p id="c42fd6aa-ad74-4f40-a5ee-bfc1c9bea28e" class="">글로벌 캐시가 로컬 캐시보다 앞 단에서 처리하기 때문에 로컬 캐시가 잘 사용되지 않는 구조이기 때문입니다.</p><p id="49732086-2ad8-4818-ade7-9aa6df6e1938" class="">당시에는 Redis Sorted Set을 사용하기 위해 이런 결정을 했지만, Spring에 존재하는 CompositeCacheManager 등을 모티브하여 Cache 자체를 구현하여 두 개의 Cache Layer를 활용하는 방법도 있는데 말이죠.</p><p id="8826fb03-7d81-4c8b-b55f-beb56a63ce24" class="">스스로 진행한 과제에서 이런 아쉬움을 뒤에 남겨두지 않기 위해 Multi-layer Cache 자체를 구현하여 상품 상세에 적용하고 있습니다.</p><p id="20efda9e-e01b-4eb5-beb9-476772da4e10" class="">Multi-layer Cache를 직접 구현하며 느낀 경험도 추후에 공유할 수 있도록 노력하겠습니다.</p><figure id="587fea1b-c20f-4e69-931a-7f796226df65"><a href="https://11st-tech.github.io/2023/07/19/improve-catalog-review-api/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">11번가 인턴의 카탈로그 리뷰 API 개선기 | 11번가 TechBlog — 11번가 기술블로그</div><div class="bookmark-description">안녕하세요. 11번가 PDP개발팀 신치용입니다. 작년 11월 중순부터 5주가량 진행된 인턴 기간동안 과제를 진행하면서 느낀 경험을 담은 글입니다. 많이 부족하지만 짧은 인턴 기간 동안 진행한 과제라는 점을 고려해주시면서 읽어주시면 감사하겠습니다! 😄 목차 인턴 과제 카탈로그 리뷰 API, 너 왜 문제 있어? 글로벌 캐시 도입 기존 구조 - Only 로컬 캐시 글로벌 캐시 로직 구현 글로벌 캐시를 추가한 후 흐름 캐시 자동 최신화 글로벌 캐시의 단점 동기 or 비동기 무엇이 더 좋을까? Test 1. 로컬 캐시에 데이터가...</div></div><div class="bookmark-href"><img src="https://11st-tech.github.io/assets/apple-touch-icon.png" class="icon bookmark-icon"/>https://11st-tech.github.io/2023/07/19/improve-catalog-review-api/</div></div><img src="https://11st-tech.github.io/assets/images/og_image.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="6a562fa6-6bd0-4a24-925b-6164f170aa73" class="toggle"><li><details open=""><summary>11번가 CDC 개발기</summary><h1 id="de27820d-dbb9-4706-a7e3-4917926cce4c" class=""><strong>What is Change Data Capture ?</strong></h1><p id="ac6742d0-d87d-4429-b898-bd08c3ef2538" class="">Database의 <code>데이터에 대한 변경 사항</code>을 식별 및 캡처한 다음 이러한 변경 사항을 <code>실시간</code>으로 Down Stream 또는 System에 <code>전달</code>하는 Process 를 나타냅니다.</p><ul id="3e6a479a-1076-42f5-9fb4-ece9eacb088d" class="bulleted-list"><li style="list-style-type:disc">Source Database의 Transaction에서 모든 변경 대상을 캡쳐해서 실시간으로 데이터를 동기화 합니다</li></ul><ul id="6f30f233-d888-460f-8c35-4339b902845f" class="bulleted-list"><li style="list-style-type:disc">안정적인 데이터 복제 및 Down Time 없는 마이그레이션을 제공합니다.</li></ul><ul id="34bdf3a5-3f25-4f35-bceb-0d9d13b795e4" class="bulleted-list"><li style="list-style-type:disc">최신 클라우드 아키텍처에 적합하며, 실시간 데이터를 이동하기 때문에 실시간 분석 및 Data Science 도 지원합니다</li></ul><p id="be468773-1547-45ed-b78c-db25de0acf13" class="">목표는 <code>Oracle에서 제공하는 CDC 솔루션인 OGG(Oracle Golden Gate)</code>를 사용하지 않고 <code>쿠폰 DB의 변경 사항이 생길 경우 메인 DB에 변경 사항을 반영</code>해주는 것이었습니다.</p><p id="796583f9-4361-4cb7-9163-eb0c60d0ac98" class="">OGG를 사용하지 않으려 한 이유는, 현재 거대한 데이터베이스 중심인 메인 DB에 더 이상의 부하를 주지 않으려고 한 것이 컸습니다. 또한 과제 당시 <code>MSA 설계</code>와 <code>Kafka</code> 기술 스택의 경험 및 활용하길 원해서 해당 스택으로 개발을 진행하고, 클라우드 아키텍처에 적합하기에 <code>AWS</code> 기반으로 개발하였습니다.</p><p id="8955f5a3-4e0e-4946-bb9e-b2f34c9bcf94" class="">그때까지만 해도 자신감에 차있던 나</p><h1 id="4f50c75d-ca97-4ef8-a089-678d5fb6b402" class=""><strong>Q. 데이터 전송,, 혹시,, 너,, 뭐,, 돼,,?</strong></h1><p id="852284d2-d2eb-4a88-9437-5576228783a2" class="">A. 응. 나 뭐 돼..</p><p id="fda74afa-6fe0-49a1-9339-c824ed402684" class="">쉬울거라 생각하진 않았지만, 막상 시작하니 정말 설계부터 쉽지 않았습니다. 초기에 필요한 기능은 다음과 같았습니다.</p><ul id="2af1c8cf-a87b-4ced-b303-1bf912711332" class="bulleted-list"><li style="list-style-type:disc">CDC 기능을 개발해 OGG를 대체할 것.<ul id="ab7f2b65-34f6-41f2-94da-f542cddd708a" class="bulleted-list"><li style="list-style-type:circle">변경 데이터를 <code>실시간 반영</code> 해야한다.</li></ul><ul id="8879a10c-df4a-4abd-a22e-6ccf4eed5dc0" class="bulleted-list"><li style="list-style-type:circle"><code>순서 보장</code>이 필요함.</li></ul></li></ul><ul id="7d40cb5f-7c08-4e0e-b870-366fbee65762" class="bulleted-list"><li style="list-style-type:disc">데이터 동기화에 대한 <code>로깅</code> 및 <code>모니터링</code> 개발.</li></ul><p id="a71369d0-a87e-4822-932d-683a775b4175" class="">이후 요구사항의 구체화, 오버엔지니어링의 지양 등으로 필요한 기능이 변경되게 됩니다.</p><h1 id="497901df-2589-4cb7-b261-9c9f6b99b5a5" class=""><strong>뭐부터 해야할지..</strong></h1><p id="0836d06a-564d-4855-901d-afce1628cecb" class="">데이터를 전송하는 방법에는 <code>Infra Level</code>에서의 전송과 <code>Application Level</code>에서의 전송이 있다고 판단 했습니다. 이 중 좀 더 유연하고 확장성 있는 구조를 위해 <code>Application Level</code>에서 CDC를 구현하기로 결정했습니다.</p><p id="cb5dfdc6-76cf-4e6e-a986-c31cf9d5c28b" class="">이후 요구사항을 바탕으로 적용해야할 사내 시스템에 대해 파악해보았습니다.</p><p id="06a7c478-1c22-4206-b81d-b4d956d4b740" class="">현재 11번가에는 <code>Vine</code> 이라는 이름의 API Server가 있습니다. 그 중 쿠폰 도메인에 대한 API Server가 존재합니다. 11번가에서는 내부적으로 끊임없이 레거시를 개선하고 있습니다. 그의 일환으로 레거시 프로젝트의 로직을 API Server로 이관하는 작업도 진행 중입니다.</p><p id="e76d9a39-5566-405f-9446-2e65b01a4133" class="">해당 작업이 완료되었다는 가정하에, 모든 로직이 API Server에 모여있음을 가정한다면, 해당 API Server에 전송 로직을 구현하는 것이 좋을 것이란 판단이 들었습니다.</p><h1 id="74f0e166-66d8-41d7-b78b-4b7b2254038d" class=""><strong>설계 과정</strong></h1><h1 id="4709362f-146a-479b-a2bd-26465359ec6e" class=""><strong>Why Kafka ?!</strong></h1><figure id="cc297090-a6b9-4048-91d1-3bb74ec03cc8" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/Untitled.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/Untitled.png"/></a></figure><p id="eef1bedc-9c54-468a-92fe-6e616eb22776" class="">설계의 가장 큰 목적은 Oracle에 의존적이며 부하가 많이 발생하는 OGG를 대체하는 것입니다. OGG와 같이 대용량 데이터를 <code>거의 실시간(Near Real-time)</code> 으로 반영하기 위해서는 <code>Batch System</code> 이 아닌 <code>Reactive System</code> 이 필요합니다. 따라서 시스템 간 느슨한 연결이 필요하며, 이에 <code>Message Queue</code>를 사용하기로 했습니다. <code>Message Queue</code> 중 사내 인프라가 이미 갖춰져 있으며, 대용량 처리에 적합한 <code>Apache Kafka</code>를 선택했습니다.</p><p id="7c5e5966-c6fd-4dfa-a47c-a8a153324129" class=""><strong>Kafka의 특징은 다음과 같습니다.</strong></p><ul id="a3ecc64a-af52-4c16-b7a5-78cd12db59c4" class="bulleted-list"><li style="list-style-type:disc"><code>데이터의 종류</code>별로 <code>Topic</code>을 생성할 수 있습니다.</li></ul><ul id="59ea6990-b422-48ea-9fc1-73fa49ee34f9" class="bulleted-list"><li style="list-style-type:disc">하나의 Topic에 <code>여러 개의 Partition</code>을 설정해 대량의 데이터를 <code>분산 처리</code>할 수 있습니다.</li></ul><ul id="afa6eb85-08b9-4ef0-bc61-49dafe948ebe" class="bulleted-list"><li style="list-style-type:disc">하나의 데이터를 <code>여러 App이 Consume</code> 할 수 있습니다.<ul id="cef0425d-3cc9-4faa-9c75-cb8ad9ddd2b7" class="bulleted-list"><li style="list-style-type:circle">일반적인 Queue와 다르게 데이터를 File System에 저장하며</li></ul><ul id="55637a01-d804-4338-b42f-2a32035faf3e" class="bulleted-list"><li style="list-style-type:circle">그래서 <code>각 Consumer마다 다른 Offset으로 데이터를 처리</code>할 수 있습니다.</li></ul><ul id="14c9d695-de0f-43f2-a44d-d8968485695a" class="bulleted-list"><li style="list-style-type:circle">이를 이용해 한가지의 데이터를 동시에 <code>여러 방법으로 이용</code>할 수 있습니다.</li></ul></li></ul><ul id="f80c24d5-36f0-4e59-97e5-53e4a462d983" class="bulleted-list"><li style="list-style-type:disc">Topic 간에 <code>Stream</code>을 제공합니다.<ul id="9ff7cd91-50b3-4414-b196-c3875013b430" class="bulleted-list"><li style="list-style-type:circle">필요하다면 <code>데이터를 실시간 변환</code>해 Topic 간 주고 받을 수 있습니다.</li></ul><ul id="4eb1c247-da5a-4444-8674-5eb275f79034" class="bulleted-list"><li style="list-style-type:circle">하나의 데이터에 대해 App 마다 필요한 형식이 다르다면 Kafka Streams를 이용해 데이터를 실시간으로 변경해 전송할 수 있습니다.</li></ul></li></ul><h1 id="2575ce21-b754-49ee-8ff3-8370e6153d04" class=""><strong>Flow 설계</strong></h1><p id="e5da1b7a-b943-4a8d-a515-5112838c8887" class="">전체적인 데이터의 흐름은 다음과 같습니다.</p><p id="fbb69497-cbe4-4074-b706-83364603322a" class="">쿠폰 DB에 대한 로직이 있는 Vine Server에서 출발한 <code>변경된 데이터</code>가 Producer Server → Kafka → Consumer 를 거쳐 메인 DB에 Access 하는 Server에 도착해 <code>변경사항을 저장</code>합니다.</p><p id="e348cfb6-0e09-4d03-8d80-3bb4d002c0b0" class="">좀 더 구체적으로 말씀드리자면,</p><p id="d44b9a27-fc83-460a-91e5-e6fa086cd80b" class="">Vine API를 사용하고 있는 곳에서 Vine API를 호출해 로직이 수행될 때 쿠폰 DB에 데이터가 저장되고, 동시에 Producer에게 Message를 Producing 합니다. 그리고 Kafka를 거쳐서 Consumer는 메인 DB와 연결된 Server에 Consume한 데이터를 보내고, 다 전달된 변경된 데이터는 그대로 메인 DB에 저장됩니다.</p><p id="38e82dcb-8bb2-4387-a0c9-d7918eb7baef" class="">참 쉽죠 ? By Uncle Bob 🎨</p><figure id="45b548a5-0726-490a-b1db-09696d329c42" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/01-3.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/01-3.png"/></a></figure><h1 id="c267db60-1d7e-467b-9ae9-78fd080e2e57" class=""><strong>기술 스택</strong></h1><p id="d958e649-48ad-44e4-a8f2-cdeb410f88be" class="">기술 스택은 다음과 같습니다</p><ul id="91786017-e744-463f-87fb-05bbec153ddd" class="bulleted-list"><li style="list-style-type:disc">Java 11 → Java 8<ul id="3f51bf6e-f182-40a9-b788-38edb074800b" class="bulleted-list"><li style="list-style-type:circle">기존 Vine과의 Java Version을 맞추기 위해 변경</li></ul></li></ul><ul id="012ba7fe-1a0d-454f-97ea-709d3981747a" class="bulleted-list"><li style="list-style-type:disc">Oracle Database<ul id="160608db-2cb4-4776-b292-10fd3a598eed" class="bulleted-list"><li style="list-style-type:circle">Oracle → Oracle 이전</li></ul><ul id="7e0587c7-1e77-4def-a086-bea0feb46333" class="bulleted-list"><li style="list-style-type:circle">Oracle → 다른 DB 이전도 가능하지만 기존 DB가 모두 Oracle임</li></ul></li></ul><ul id="04d42b95-02cd-4528-8227-616a87fa1211" class="bulleted-list"><li style="list-style-type:disc">MyBatis</li></ul><ul id="2908a9b5-46bf-4558-87f5-38a5c2542eb0" class="bulleted-list"><li style="list-style-type:disc">Gradle v6.8.3</li></ul><ul id="4854f59b-d3f5-4d56-b251-4a1b70648415" class="bulleted-list"><li style="list-style-type:disc">On-Premise</li></ul><ul id="7a9759bf-973f-45bc-8828-9452565e7291" class="bulleted-list"><li style="list-style-type:disc">AWS EC2</li></ul><ul id="bf120bdb-cb02-4102-aeaa-120aa67433c4" class="bulleted-list"><li style="list-style-type:disc">Kafka<ul id="b1078b3e-ff31-47dd-94e0-6017ea0cde02" class="bulleted-list"><li style="list-style-type:circle">spring-kafka version v2.6.0</li></ul><ul id="1f74b78a-06dd-4b77-a2cf-ef96ffda7866" class="bulleted-list"><li style="list-style-type:circle">AWS MSK<ul id="04c90683-f31f-4d11-9918-97eaacd707c4" class="bulleted-list"><li style="list-style-type:square">당시 MSK가 spring-kafka 2.6.1 와 호환</li></ul><ul id="26a23786-13ed-47ba-9ae7-93a6fe2682e5" class="bulleted-list"><li style="list-style-type:square">Spring Boot Version에 따라 2.6.0 or 2.6.2로 설정이 가능함</li></ul></li></ul></li></ul><ul id="4666ea9b-184b-4a77-9d54-391faa67f20e" class="bulleted-list"><li style="list-style-type:disc">SpringBoot 2.6.x → 2.3.12.RELEASE<ul id="70eb7820-af08-498f-9d0e-7e47f88fe32e" class="bulleted-list"><li style="list-style-type:circle">SpringBoot에 내장된 spring-kafka Version 수정을 위해 변경</li></ul></li></ul><ul id="a09565f5-0227-432d-a0ec-958c717d7f07" class="bulleted-list"><li style="list-style-type:disc">Schema Registry<ul id="797e3454-05c8-4121-b6ad-a98670a19177" class="bulleted-list"><li style="list-style-type:circle">Avro</li></ul><ul id="554de5ac-3dee-4040-ae72-7be341a27b81" class="bulleted-list"><li style="list-style-type:circle">AWS Glue</li></ul></li></ul><ul id="1c2d511a-1ba5-4c56-8f6e-c6ed3512184a" class="bulleted-list"><li style="list-style-type:disc">Nexus<ul id="20a7ea8d-c452-40a6-a17e-07b10e8624d8" class="bulleted-list"><li style="list-style-type:circle">Avro Schema Data 의 upload → import 위해 사용</li></ul></li></ul><ul id="f423f8cc-c984-4e4b-9843-868c4fe9be98" class="bulleted-list"><li style="list-style-type:disc">OOP, Clean Code, Test..</li></ul><h1 id="fb6904fd-bb92-4642-8b1d-1a1cbcecab8c" class=""><strong>Sync ? Blocking ? Async ? Non-Blocking?</strong></h1><p id="331be62f-ddd6-48dc-ac62-6775e007352e" class="">판단을 위해 참고한 것들은 다음과 같습니다. 🤔</p><ul id="52b85fbe-375e-4b77-aa12-a7ae6a8ceb92" class="bulleted-list"><li style="list-style-type:disc"><code>Spring MVC</code>의 경우 DeferredResult 등 의 사용으로 <code>Async</code>를 지원합니다 <a href="https://spring.io/blog/2012/05/07/spring-mvc-3-2-preview-introducing-servlet-3-async-support">링크</a><ul id="86087439-801a-4416-a46e-8c63ad3991e4" class="bulleted-list"><li style="list-style-type:circle">Spring MVC의 경우 Blocking이 기본이며, Servlet 3.1 이후부터 Non-block과 Async를 지원하더라도 WebFlux에 비해 성능이 떨어집니다.</li></ul></li></ul><ul id="213683d3-f16a-43d9-9cc2-f2d2d48f742f" class="bulleted-list"><li style="list-style-type:disc"><code>Spring WebFlux</code>는 기본적으로 <code>Netty</code>를 사용합니다. <code>Tomcat</code>도 사용할 수 있으나 동작되는 방식이 같지 않습니다. <a href="https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html#webflux-server-choice">링크</a><ul id="2c0b0df0-a1cd-477c-9a73-c7b02578d7fd" class="bulleted-list"><li style="list-style-type:circle">WebFlux를 사용하며 Tomcat을 사용하는 경우, Servlet 3.1 이후의 Non-Blocking 방식을 사용하지만, MVC 자체에 <code>Blocking</code>의 가능성이 있어 <code>큰 Thread Pool</code>을 생성합니다.</li></ul><ul id="34ba2bad-192a-4d7c-9653-58efba66ed54" class="bulleted-list"><li style="list-style-type:circle">WebFlux의 기본 서버인 Netty는 Blocking의 가능성이 없어 <code>작은 크기의 고정 Thread Pool(Event Loop)</code>을 생성합니다.</li></ul><ul id="97e89ce8-f56f-494d-aebc-d27ca9954451" class="bulleted-list"><li style="list-style-type:circle">따라서 Tomcat을 사용한다면, Non-block이며 Async를 지원은 하지만 완전한 Non-block, Async에 비해 성능이 떨어집니다.</li></ul><ul id="650a09f6-a5c3-4961-926e-3ec354796cfd" class="bulleted-list"><li style="list-style-type:circle">또한 아키텍처에 Reactive한 Non-block 방식이 꼭 필요한지 고려해 봐야합니다.</li></ul><ul id="c0e8afdf-147e-4ce2-9abc-e1226cfd3c7e" class="bulleted-list"><li style="list-style-type:circle">흐름 중 한 곳이라도 Block이 존재한다면 Non-block 방식은 무의미합니다.</li></ul></li></ul><ul id="303bfde8-d232-4272-8506-bf1fb5ddd4e2" class="bulleted-list"><li style="list-style-type:disc">참고한 링크들 📚<ul id="1e623e2a-b95d-40b0-83d9-effc62389a46" class="bulleted-list"><li style="list-style-type:circle">Async, Reactive, Web Flux<ul id="2a2793fb-b4db-4048-9c24-9dea482a859f" class="bulleted-list"><li style="list-style-type:square"><a href="https://www.youtube.com/watch?v=5KttCnoWLhs&amp;list=PLdHtZnJh1KdZ6NDO9zc9hF4tONDLTSEUV&amp;index=3">스프링캠프 : 프로세스와 스레드, NIO 그리고 리액티브 스트림 (Reactive Stream)</a></li></ul><ul id="3185fdc5-c88d-4055-91ee-bc999c920d23" class="bulleted-list"><li style="list-style-type:square"><a href="https://www.youtube.com/watch?v=HKlUvCv9hvA">스프링캠프 : Async &amp; Spring</a></li></ul><ul id="bb2eedf7-87ca-4e9a-acf0-0a8019108352" class="bulleted-list"><li style="list-style-type:square"><a href="https://www.youtube.com/watch?v=2E_1yb8iLKk&amp;list=PLdHtZnJh1KdZ6NDO9zc9hF4tONDLTSEUV&amp;index=4">스프링캠프 : Spring Web Flux</a></li></ul><ul id="ba1f6cda-5974-4c5a-b00a-399108665136" class="bulleted-list"><li style="list-style-type:square"><a href="https://www.youtube.com/watch?v=UIrwrW5A2co&amp;list=PLdHtZnJh1KdZ6NDO9zc9hF4tONDLTSEUV&amp;index=13">스프링캠프 : Reactive Spring ( Spring 5 &amp; Reactor )</a></li></ul><ul id="827a51b2-fced-4c2f-a4f1-0569b9467582" class="bulleted-list"><li style="list-style-type:square"><a href="https://www.youtube.com/watch?v=0zVwXszDk88&amp;list=PLdHtZnJh1KdZ6NDO9zc9hF4tONDLTSEUV&amp;index=16">스프링캠프 : Reactive Programming with RxJava</a></li></ul></li></ul><ul id="d91ce729-2d1a-43bf-9960-3824e59ff82c" class="bulleted-list"><li style="list-style-type:circle">Feign client<ul id="301900df-4797-4906-bac3-5040fcff6a6a" class="bulleted-list"><li style="list-style-type:square"><a href="https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html">spring-cloud-feign</a></li></ul><ul id="bb1ff3ab-b091-4f1d-ab81-f739e3e1b8c7" class="bulleted-list"><li style="list-style-type:square"><a href="https://github.com/OpenFeign/feign/issues/361">OpenFeign - No Non-blocking I/O support</a></li></ul></li></ul></li></ul><h3 id="9cd362e6-4b92-4c40-8e00-c6dc0fee7e48" class=""><strong>First Flow ) Vine → Producer 호출</strong></h3><p id="070cad89-5d52-4505-826c-3d2fee688741" class="">Vine에서 Producer를 호출할 때는 <code>동기(Sync)</code>로 호출합니다.</p><p id="b7f71af8-0f1c-4965-96ae-2e38ff23001a" class="">기본적으로 Vine 서버들은 Servlet 기반의 서버들입니다. WebFlux가 아닌 Servlet 기반의 Spring도 <code>비동기(Async)</code> 를 지원하여, 호출 방식에 대해 고민했습니다. 하지만 Producer의 작업이 오래 걸리지 않는 <em>단순히 데이터를 받아 전달하는 것</em>이고, 내부에서 Kafka를 이용해 데이터를 전송하기에 <em>앞단에서 부터 비동기 처리를 할 필요가 없다는 판단</em>이 들었습니다. 따라서 비동기가 꼭 필요한 상황이 아니며, 당시 사내에서 사용하는 Vine Platform이 당시 Feign Client만 지원해 동기 전송이 기본인 점을 고려해, Async를 사용하는 모험을 하기보다 Sync 방식의 전송을 선택했습니다.</p><h3 id="41221085-ff08-4625-9773-2e32a68c1e3f" class=""><strong>Second Flow ) Consumer → Another Vine</strong></h3><p id="60495389-a32f-4c91-a476-fc8e1b9849fc" class="">Another Vine 은 메인 DB에 Access 하는 Server 입니다. 자세한 사항에 대해서는 추후 설명하겠습니다.</p><p id="f0234bc4-d12b-4f6f-adba-1bc1b601586f" class="">Kafka → Consumer는 기본적으로 <code>비동기(Async)</code>로 동작합니다.</p><p id="de3d6760-5ca9-472c-a4c6-c8a8640f09ad" class="">현재 구조에서 Consumer는 On-Premise가 아닌 <code>Cloud</code> 기반이기에 트래픽 부스팅이 예상되는 경우 서버를 쉽게 증설할 수 있습니다. 또한 중간의 MSK가 대용량 트래픽을 적절히 조절해 주기에 이 부분에 대한 이슈는 크게 없을 것으로 보입니다. 다만 트래픽이 몰려 Consumer의 처리 시간이 지연된다면 Topic 내부의 Partition <code>Lag</code>이 증가하게 됩니다. Consumer Lag을 모니터링해 수동으로 데이터의 정합성을 맞추어 주어야 합니다.</p><h1 id="ac790ac2-28b7-4040-ad04-6097f92d2241" class=""><strong>Producer와 Consumer의 분리</strong></h1><p id="b5654b49-1a94-474f-bbab-47ee1fa5e568" class="">Producer와 Consumer를 굳이 분리한 이유는,</p><p id="4dfc0d8d-5cb5-4d26-84d7-3a803ae4536e" class="">비지니스 로직과 전송부가 <code>강결합</code>되어 있는 것보다는 분리되어 있는 것이 추후 <code>확장성</code>에 도움이 될 것이란 판단이 들었기 때문입니다. 해당 프로그램은 현재는 단순 CDC 프로그램으로 구상하였지만, 추후 Kafka의 데이터를 다양한 방식으로 이용할 수 있기에 Producer, Consumer는 분리하는 것이 맞다는 판단이 들었습니다.</p><h1 id="4e92c466-33ab-4a04-b68c-4f4ca38c1d5c" class=""><strong>Source Server와 Target Server</strong></h1><p id="52b55afc-4c85-48b1-845f-42b952086410" class="">그리고 <code>메인 DB를 Access 하는 App</code>은 <code>전송 부분의 Vine 서버</code>와 동일한 App을 사용했습니다.</p><p id="24922a5b-5dee-49ee-88a4-2f3b8f314f1d" class="">아... 그러니까..</p><p id="b8359261-f5df-4832-b414-9042fcf62d6a" class="">현재 개발의 목적은 <code>쿠폰 DB</code>에 저장되는 데이터를 <code>그대로~ 빠르게~</code> 옮겨서 <code>메인 DB</code>에 저장하는 것입니다.</p><p id="41a1cdad-8727-4d27-89cb-24259b75844f" class=""><code>쿠폰 DB와 매칭되는 Source Server에 있는 도메인 Code</code>들을 <code>메인 DB에 Access 하는 Target Server의 App</code>에 그대로 <code>복사</code>해서 서버를 구현한다면, 중복 코드로 인해 개발자의 <code>관리포인트</code>가 더 늘어나게 됩니다. 따라서 쿠폰 DB에 연결된 App에서 메인 DB를 연결하는 코드를 작성한 뒤, 같은 Code를 각기 다른 서버에 다른 이름으로 띄워 사용해, Source Server와 Target Server에서 <code>도메인 Code를 동일하게 사용하기</code>로 결정했습니다.</p><p id="d7324188-c299-4ef8-ad58-a53c32c30751" class="">A 서버의 Domain 코드를 “복사”해서 B 서버의 App을 따로 구현하는 경우</p><figure id="d5942605-d7c3-4b34-85c3-053fa2cbdc08" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/02-case1.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/02-case1.png"/></a></figure><p id="5ba92b26-078b-4e57-95c8-aec09a98fdf9" class="">A 서버의 코드로 B 서버에서 사용하는 경우</p><figure id="9c334f95-4eab-4cf3-bc9a-e19c40812cc0" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/02-case2-2.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/02-case2-2.png"/></a></figure><p id="eb30a7c4-d5ba-4374-b9dc-c2bf64e90bee" class="">쿠폰, 메인 DB Connection이 <code>Source Server</code>와 <code>Target Server</code>에 둘 다 유지된다는 단점이 있지만, 이 방식의 장점은, 두 서버에서 도메인 Code를 같이 사용해 중복 코드와 관리 포인트를 줄일 수 있다는 점입니다. 그리고 쿠폰 DB와 메인 DB에 대한 <code>Persistence Level의 Test Code</code>를 짤 수 있습니다. 쿠폰 DB에 INSERT 한 뒤 SELECT 한 Origin 값과, 전송된 Avro 데이터로 메인 DB에 INSERT 한 뒤 SELECT 한 값이 동일한지 Test Code로 확인할 수 있습니다.</p><h1 id="9862d116-5c6e-4b26-9b25-ad535f98c1ee" class=""><strong>코드 중복을 어떻게 줄여요 ?</strong></h1><p id="daa008c3-8d48-4854-9903-d1261d1f0902" class="">코드 중복이 많았던 초기 설계</p><figure id="b5643696-bb63-4f05-b759-2a5323c20fa7" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/03-case1-2.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/03-case1-2.png"/></a></figure><p id="bc391b5b-4f1a-4d73-9442-93d985f552c1" class="">초기 설계는 다음과 같았습니다.</p><p id="aac978bc-80fb-4617-a931-d25339aae3fd" class=""><code>이벤트의 Parameter 데이터</code>를 전송하고 Source와 Target Server에서 동일한 데이터로 동일한 쿼리를 수행했습니다.</p><p id="9c713db7-885e-46ec-8375-01b2a797e205" class="">Target Server에서는 <code>메인 DB 설정을 따로</code> 해야해서 같은 프로젝트지만 Source Server의 <code>기존 Mapper를 복사</code>해 와 기존 쿼리를 그대로 이용하는 방식으로 개발했습니다. Source 서버에서 이벤트가 발생할 때( = 쿼리문이 실행될 때), 해당 데이터를 Target 서버에 보내고, Target 서버에서는 <code>Source Server에서 복사해 온 동일한 쿼리</code>를 수행 하도록 했습니다. 따라서 기존 쿼리에 변경 사항이 있다면 복사한 쿼리에도 반영해 주어야 합니다. 이 부분도 코드의 중복으로 쿼리 변경시 관리할 포인트가 추가되었습니다. 그리고 단순한 쿼리보다 복잡한 쿼리가 많았고, Code Level에서의 로직보다 쿼리 내에서 로직이 많아서 <code>변경할 데이터</code>를 받아서 <code>복잡한 쿼리를 똑같이 실행</code>하는게 <code>비효율적</code>이란 판단에 방식을 수정했습니다.</p><p id="e09d6ac9-6a37-4852-8bd9-2d6924aceb95" class="">또한, Source와 Target에는 Domain 코드가 존재하지만, Producer와 Consumer에서 Domain 코드가 없어서 추가로 <code>코드 중복</code>이 발생하게 됩니다.</p><p id="12f2d683-29d5-4d8c-bd0a-9546c1765627" class="">이때 <code>Avro Schema</code>의 도입을 생각하게 됩니다.</p><h1 id="39f48943-1f00-4ec3-b916-413555191bec" class=""><strong>Schema Registry 란게 있다면서요?</strong></h1><p id="7f4779be-71c5-4972-b760-8aaf8c57b837" class="">아~ 그게 있었지!</p><h3 id="496c950c-a2ef-407e-ab23-a5aac97df141" class=""><strong>What is Schema Registry ?</strong></h3><figure id="7d441843-5b03-4183-9f08-760013dc35eb" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/R1280x0-2.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/R1280x0-2.png"/></a></figure><ul id="b30fa913-a6f9-43c8-8843-a56a8c0c7eb2" class="bulleted-list"><li style="list-style-type:disc">Kafka 사용시 Producer는 어떤 Consumer가 메세지를 가져가는지, Consumer는 어떤 Producer가 메세지를 보냈는지 모릅니다.<ul id="11144ef5-1d77-4173-bcd2-28a7e96cd4e5" class="bulleted-list"><li style="list-style-type:circle">따라서 메세지의 송/수신자의 <code>결합도</code>를 낮춥니다.</li></ul></li></ul><ul id="03531ee0-9cfe-4b6e-a93f-ff5964f2776e" class="bulleted-list"><li style="list-style-type:disc">하지만 메세지를 <code>Serialize/Deserialize</code> 하는 구조로 되어 있어 내부적으로 데이터에 대한 결합도가 남아 있게 됩니다.<ul id="b2a793b8-5ca1-405e-aa7b-1d4f2ec63b17" class="bulleted-list"><li style="list-style-type:circle">ex) Producer가 v1 메세지를 보내다가 v2 메세지를 보내면 Consumer가 수신하지 못합니다.</li></ul></li></ul><ul id="e8cd6138-123a-4c6c-8e98-6eab7a07e8e9" class="bulleted-list"><li style="list-style-type:disc">Schema Registry는 Kafka 외부에 구성 되어 클라이언트와 통신합니다.</li></ul><ul id="a467c3ab-f211-44f0-9a66-e91d10483caf" class="bulleted-list"><li style="list-style-type:disc">Topic 별 메세지 Key, Value의 <code>Schema Version을 관리</code>하고, <code>Schema 호환성 규칙을 강제</code>하며, <code>Schema 조회</code>가 가능합니다.</li></ul><ul id="bd942421-dfe2-4710-93dc-939a56ae6c11" class="bulleted-list"><li style="list-style-type:disc">즉, 외부에서 메세지 변경사항에 대해 Versioning을 관리하여 Kafka App 간의 Data Schema 의존성을 낮출 수 있습니다.</li></ul><ul id="aa6d819f-c3f3-4706-a42f-525e91ce171b" class="bulleted-list"><li style="list-style-type:disc">스키마 호환성은 Backward, Forward, Full, None으로 구성됩니다.<ul id="a383baba-e786-4d30-aaf1-6b08ac67befa" class="bulleted-list"><li style="list-style-type:circle">Backward :<ul id="305ad425-390e-4b60-b7a6-c586c4b71703" class="bulleted-list"><li style="list-style-type:square">현재 및 이전 버전의 스키마에도 호환됨</li></ul><ul id="331276e6-5345-4a06-b597-d0f6c688e9e5" class="bulleted-list"><li style="list-style-type:square">필드 삭제 또는 기본 값이 있는 필드 추가 인 경우</li></ul></li></ul><ul id="cc9f5018-dcb2-459b-8244-1fa390b67f15" class="bulleted-list"><li style="list-style-type:circle">Forward :<ul id="2c7279de-6538-4335-9e36-ef437ad9fcf1" class="bulleted-list"><li style="list-style-type:square">현재 및 이후 버전의 스키마에도 호환됨</li></ul><ul id="d9101e04-363e-4cc5-9089-ec41dc1c68df" class="bulleted-list"><li style="list-style-type:square">필드 추가 또는 기본 값이 있는 필드 삭제</li></ul></li></ul><ul id="0542ffa8-47d5-47ca-a055-2130f6b24814" class="bulleted-list"><li style="list-style-type:circle">Full :<ul id="156efd61-d729-4306-a857-a154c4b8ca98" class="bulleted-list"><li style="list-style-type:square">앞 뒤 버전의 스키마에 호환됨</li></ul><ul id="3d36af8d-ed04-4ea7-a458-703eb912fdca" class="bulleted-list"><li style="list-style-type:square">기본 값이 있는 필드 추가 또는 삭제</li></ul></li></ul><ul id="50dbe425-1a13-4911-a0a2-281e628eec64" class="bulleted-list"><li style="list-style-type:circle">None : 스키마 호환성 체크하지 않음</li></ul></li></ul><ul id="deb80e76-6c8f-4ec9-82dc-bb0ba4ee9d9d" class="bulleted-list"><li style="list-style-type:disc">스키마 호환성을 체크한다면 필드에 <code>기본값</code>은 필수로 지정해야합니다.</li></ul><ul id="4491b6da-6640-4940-8b9d-e202ae347481" class="bulleted-list"><li style="list-style-type:disc">일반적으로 Avro 방식을 사용합니다.<ul id="d6c873c7-956f-497b-bdcd-8a8433b670fd" class="bulleted-list"><li style="list-style-type:circle">Avro 명세를 지켜서 Data를 생성해야합니다.</li></ul></li></ul><ul id="e3f0b660-e5a0-4511-b0d9-1c32f2dacd77" class="bulleted-list"><li style="list-style-type:disc">Schema Registry는 스키마 생성, 조회, 관리에 대한 HTTP API를 제공합니다, 클라이언트들은 이 API를 활용해 스키마를 관리할 수 있습니다.</li></ul><p id="be69e1ef-408f-45d1-97cb-73c0f788e613" class="">Avro Schema를 적용한 뒤 변경한 설계는 다음과 같았습니다.</p><p id="9f290bd0-5c92-468d-9757-a471267a15fa" class="">코드 중복을 제거한 변경한 설계</p><figure id="7f70cacf-7507-449b-98ff-a938ba40cece" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/03-case2.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/03-case2.png"/></a></figure><p id="ae799e82-d6ea-4651-a23d-9c37f8d0661b" class="">Source 서버에서 쿼리문을 수행한 뒤, 그 <code>결과물의 데이터</code>를 전송했습니다.</p><p id="3ecbf994-0cbf-4abf-b80c-9f810026d0de" class="">그리고 이벤트 단위가 아닌 <code>테이블 단위</code>로 Avro 객체를 생성하고, Target Server가 Source Server와 동일한 쿼리를 실행하는 것이 아닌 Create, Update, Delete 로직만 수행하도록 했습니다.</p><p id="2cc78f08-d291-4948-b310-573b60c6b811" class="">즉 Source에서 어떤 쿼리를 실행하든 Target Server는 CUD만 수행합니다. 이로써 쿼리 코드 중복을 줄였습니다.</p><p id="1f4a53fc-a401-491a-868c-83dba0807bab" class="">그리고 Avro Schema를 적용하여 Producer와 Consumer에서도 중복적인 Domain 코드를 작성하지 않고 Domain 코드를 사용할 수 있게 되었습니다.</p><h3 id="8a7af3bd-b198-436d-9029-76361319cf44" class=""><strong>Persistence Level의 Test Code</strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="93b6c813-6bcb-48d6-84f3-f78355d98901" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Test // Persistence Test를 위해 @SpringBootTest 사용
public void updateCouponStateTest() {
    // given
    final CouponParameter couponParameter = this.createCouponParameterWithRequiredValuesSet();

    // couponDao는 Source Server, mainDao는 target Server에서 사용
    // COUPON insert 후 select 한 값으로
    Coupon coupon = couponDao.insertCouponState(couponParameter);

    // MAIN 저장 위해 Avro Object 변환 후 MAIN insert
    final CouponAvro couponAvro = SchemaUtil.pojoToAvroObject(coupon, CouponAvro.newBuilder().build());
    mainDao.insertCoupon(couponAvro);

    // 데이터 변경 후 update
    final String editedData = &quot;EDIT&quot;;
    coupon.edit(editedData);
    Coupon editedCoupon = couponDao.updateCouponState(coupon);
    final CouponAvro editedCouponAvro = SchemaUtil.pojoToAvroObject(editedCoupon, CouponAvro.newBuilder().build());

    // when
    mainDao.updateCoupon(editedCouponAvro); 
    // Source 는 Specific Query 를 실행했지만 Target 은 Common Update Query 사용 

    // then
    final Coupon expected = couponDao.getCoupon(editedCoupon.getCouponNo());
    final Coupon actual = mainDao.getCoupon(editedCoupon.getCouponNo());
    // 같은 PK로 조회

    assertThat(expected).equals(actual);
}</code></pre><p id="5d74973b-4073-4dda-84dc-85df199c0876" class="">쿠폰 DB의 DAO에 INSERT 및 UPDATE 한 뒤 SELECT한 결과를 데이터가 같은 Avro 객체로 변환해 INSERT 및 UPDATE를 시행하고 결과값을 비교합니다</p><p id="586be14e-2489-46be-b4c8-eb22227c0606" class="">Schema Registry 적용 후 message를 전송하면 Domain 코드가 Avro 객체로 변환되어 Request/Response가 가능합니다. 테스트를 위해 수동으로 Avro 객체를 생성하기 위해 아래의 방식을 이용했습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="f6ba3db6-7420-4de6-b2d9-3d1320f43575" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">import org.apache.avro.Schema;
import org.apache.avro.generic.GenericData;
import org.apache.avro.reflect.ReflectData;

public class SchemaUtil {
    /**
    * Domain Object를 Avro Object로 변환
    *
    * Domain Object를 Avro Object의 필드에 해당하는 값만 변환함.
    * Domain Object가 Table Column과 온전히 일치하지 않지만
    * Avro Object는 Table Column과 일치하기 때문에
    * Avro Object 기준으로 필드를 세팅함.
    *
    * @param originDomainObject 변환할 Domain Object
    * @param targetAvroObject 변환될 Avro Object
    * @param &lt;T&gt; Domain과 mapping 되는 Avro Object({TABLE_NAME}Avro)
    * @return Avro Object
    */
    public static &lt;T&gt; T pojoToAvroObject(Object originDomainObject, T targetAvroObject) {
        final GenericData.Record record = mapObjectToRecord(originDomainObject);
        return mapRecordToObject(record, targetAvroObject);
    }

    static GenericData.Record mapObjectToRecord(Object targetObject) {
        Assert.notNull(targetObject, &quot;targetObject must not be null&quot;);

        final Schema schema = ReflectData.get().getSchema(targetObject.getClass());
        final GenericData.Record record = new GenericData.Record(schema);
        schema.getFields()
              .forEach(r -&gt; record
                  .put(r.name(), PropertyAccessorFactory
                      .forDirectFieldAccess(targetObject)
                      .getPropertyValue(r.name()))
              );
        return record;
    }

    static &lt;T&gt; T mapRecordToObject(GenericData.Record record, T targetObject) {
        Assert.notNull(record, &quot;record must not be null&quot;);
        Assert.notNull(targetObject, &quot;targetObject must not be null&quot;);

        final Set&lt;String&gt; fieldSet = extractFieldsOfTargetObject(targetObject);

        record.getSchema()
              .getFields()
              .forEach(d -&gt;{
                  if(!fieldSet.contains(d.name())) { // 각 fields의 교집합만 추출
                      return;
                  }
                  PropertyAccessorFactory.forDirectFieldAccess(targetObject)
                                         .setPropertyValue(d.name(),
                                                           record.get(d.name()) == null ?
                                                               record.get(d.name()) :
                                                               record.get(d.name()).toString()
                                         );
              });
        return targetObject;
    }

    private static &lt;T&gt; Set&lt;String&gt; extractFieldsOfTargetObject(T targetObject) {
        final Field[] fields = targetObject.getClass().getDeclaredFields();
        return Arrays.stream(fields)
                     .map(Field::getName)
                     .collect(Collectors.toSet());
    }
}</code></pre><p id="cd55fad5-b017-402b-9967-8fdda955a9f4" class="">테스트를 위해 Domain Code를 바탕으로 <code>동일한 데이터를 가진 Avro 객체</code>를 만들기 위해 작성한 코드 입니다.</p><p id="00463293-50ba-45c7-a782-8250e65c648b" class="">기존 Domain Code들의 경우 DB Table의 Column과 완전히 일치하지 않았고, Avro 객체는 Default로 추가되는 Schema 정보를 가진 Private Field들이 있습니다. 그래서 Avro Schema를 DB Table과 일치하게 만들고 해당 스키마로 Avro 객체를 생성하도록 했습니다. 데이터는 테이블 기준으로 생성한 Schema의 Field들에 기존 Domain의 Field 값을 적용한 뒤, Avro Schema 객체의 고유 Field가 합쳐서 전송됩니다.</p><p id="bb1ae666-6492-46d8-add8-5c51f2e47209" class="">예를 들면 Table A에 a,b,c의 Column이 존재할 때 Domain A 코드에는 a, b의 Field만 존재합니다. 이때 Table A의 Column 기준으로 (a,b,c) Avro Schema를 작성 후 Avro 객체로 변환한다면 a,b,c,SCHEMA$ 등의 필드로 생성됩니다.</p><p id="d623193d-09cd-405b-bbc1-b9b8e1a0e0d1" class="">따라서 테스트를 위해 Avro 객체를 생성한 뒤 Domain Code와 Avro의 field가 일치하면 Avro 객체에 값을 추가합니다. 즉, 두 객체의 교집합에 해당하는 field에 값을 추가해 반환합니다.</p><h1 id="f81b89e7-b7ae-453e-a02a-be0879026e7d" class=""><strong>전송되는 데이터는 어떻게 보장할까.</strong></h1><p id="f2e590e7-37e7-4713-9431-ff2d2c60186a" class="">자네.. 전송 되는 데이터를.. 모두 믿을 수 있는가 ?</p><p id="d081d58d-245f-4bd7-9398-983098a0213c" class="">이때쯤 이런 의문이 듭니다. 아무런 문제 없이 데이터가 모두 <code>정확히 전송</code>이 될 수 있을까 ?</p><h1 id="937a702e-4032-46be-ab72-360a3c3a96e6" class=""><strong>중복 전송</strong></h1><h3 id="c434dbdb-6333-433d-bbd5-e7c6f5790252" class=""><strong>API 멱등성과 데이터의 순서 보장</strong></h3><p id="8ad8d367-4fc5-4d4a-b28b-82d3e91eb1d1" class="">멱등성이란 ? 연산을 <code>여러번</code> 적용해도 <code>한 번</code> 수행한 것과 <code>동일한 결과</code>가 나오는 것을 의미합니다.</p><ul id="9576b224-5708-4731-957e-272cc4b89a0c" class="bulleted-list"><li style="list-style-type:disc">Client의 데이터를 받고 수신을 보낼 때 네트워크 장애 등으로 응답을 보내지 못한 경우, Client 측에서 데이터의 재전송이 이루어질 수 있습니다. 이 경우 Source와 Target의 데이터 정합성이 맞지 않을 수 있습니다.</li></ul><ul id="c3a6635d-b204-4c50-b376-8cae4d7dde51" class="bulleted-list"><li style="list-style-type:disc">DB의 Create가 실행된다면 한번 실행되어 생성된 데이터는 그 다음에 중복으로 Create가 실행되어도 Database의 PK Error 때문에 다시 생성되지 않습니다. Delete도 마찬가지로 여러 번의 Delete가 수행되어도 한 번의 삭제만 이루어집니다. 하지만 여러 개를 수정하는 Update의 경우 여러 번을 실행할 때, 조건과 상태값에 따라 결과가 달라질 수 있습니다. 즉 항상 같은 결과를 갖지 못합니다.</li></ul><ul id="c74f98c5-b2e7-4b4f-b98d-9797cbe767b4" class="bulleted-list"><li style="list-style-type:disc">1개의 로직에 대해 Create, Update, Delete의 순서가 섞여 전송된다면 그 로직은 멱등하지 않습니다.</li></ul><h3 id="a6567a44-196c-4c05-bdf4-703573a5bf54" class=""><strong>Exactly once (enable.idempotence = true)</strong></h3><p id="4922766b-b185-45e8-bf67-d9b2b37caf8e" class="">Kafka에는 <code>정확히 한번 전송</code>을 보장하는 옵션이 있습니다. <a href="https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/">링크</a></p><ul id="266307e7-eda1-449a-8d5c-0e932cf0fc61" class="bulleted-list"><li style="list-style-type:disc">해당 옵션 사용시 <code>Producer→Broker→Topic</code> 간의 멱등성이 보장됩니다. 대신 특정 설정이 종속적입니다.</li></ul><ul id="c5c13426-2c75-463a-ad7a-99d65d8a120e" class="bulleted-list"><li style="list-style-type:disc">또 해당 옵션은 Session 단위에서 유효한 기능으로 Producer App이 재시작하는 경우 멱등성이 보장되지 않습니다.</li></ul><p id="18d7549c-6813-4e63-9ab8-ae5c69ebc0c7" class="">결과적으로 현재 구조에서 종단 간의 멱등성을 보장하지 못하고, 옵션의 제약이 생기며, 실제 적용해보았을 때 Producer의 성능이 크게 떨어져서 해당 옵션은 사용하지 않고 다른 방식으로 풀었습니다.</p><h3 id="98981299-d0e1-466b-ac65-efec744f5a3d" class=""><strong>PK Error</strong></h3><p id="716577f7-5cb1-4019-992f-7f37a27fdf96" class="">따로 멱등성 보장을 위한 장치를 하지 않고, 변경된 데이터를 전송할 때 <code>PK 정보</code>를 포함해 전송하여 중복된 데이터 발생 시 DB PK Error로 종단 간 멱등성을 보장할 수 있습니다.</p><p id="a77208c4-c27a-429e-91c1-a611ebc03bfd" class="">이 방식은 구현이 간단하며 서버 구축 및 운영 리소스를 적게 사용한다는 장점이 있습니다. 다만, 완전한 종단간 멱등성 보장을 위해서는 <code>데이터의 순서</code>가 보장되어야 합니다.</p><h3 id="0392a22a-3fa8-44fd-9430-deac0c4379b4" class=""><strong>Topic 설계</strong></h3><ul id="9739b19c-43ea-4562-a519-010300deda6d" class="bulleted-list"><li style="list-style-type:disc">데이터의 순서 보장</li></ul><figure id="5c8b6d7e-83ad-48eb-adba-1fa8cd640aff" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/04.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/04.png"/></a></figure><p id="4d9df861-cb69-4ab2-a388-9cfc0a2299d8" class="">데이터는 일반적으로 Sequential 하게 흘러가기에 순서를 유지해야 합니다. 순서가 뒤바뀌면 데이터 정합성이 맞지 않을 우려가 있습니다.</p><p id="2965a403-5669-4643-9f88-3f7b0d24dfcc" class="">이를 보장하기 위해, Origin Data의 PK를 Kafka Message Key로 사용해 Kafka의 Topic에 Partitioning 합니다. Kafka는 Partition 내에서 순서가 유지되므로 각 Partition 별로 순서가 유지됩니다. PK를 Key로 이용하는 경우 Key 값이 단순해서 Hash가 중복되더라도 같은 종류의 message가 같은 Partition으로 Partitioning 되므로 같은 데이터에 대해서 데이터 로직의 순서를 유지할 수 있습니다.</p><figure id="59633b18-7183-449f-b3b5-66e91dccb777" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/05.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/05.png"/></a></figure><p id="5808867e-aa38-45d9-9b58-45d9f11f6454" class="">또한 1개의 Partition에 대해서 1개의 Consumer(같은 Consumer group 내에서)가 처리합니다. 따라서 이 경우 동시성 처리는 Kafka의 Partitoin 개수에 따라 결정됩니다.</p><p id="2b93800a-2513-40ea-984b-068e9b2ecb75" class="">이 방식의 단점은, Concurrency 성능이 partition에 의존적이며, Partition이 증가할수록 Kafka Broker, 서비스의 Heap Memory 등에 영향을 줍니다. 그리고 Partition에 대응되어 Consumer의 수가 늘어난다면, Consumer 수가 늘어날수록 Consumer Rebalancing 시간도 증가합니다.</p><ul id="957dae81-c547-45b8-91d1-bf93f0a7db0a" class="bulleted-list"><li style="list-style-type:disc"><strong>Consumer의 Multi Threading 와 Concurrency 성능</strong></li></ul><p id="48844a85-273c-4b9d-a15c-b3545df40064" class="">Kafka가 대용량 데이터 처리에 특화되어 있지만, 멀티 스레딩 처리를 하지 않으면 Concurrency 성능이 Partition의 갯수로 제한됩니다.</p><p id="579ce6c1-81ff-47f1-a1a4-c1fe464cb59b" class="">Partition 개수로만 Concurrency 성능이 조절된다면 Partition 개수의 변화가 있어야 하는데, 성능 조절을 위해 Partition 변경시 Key 와 Partition의 Mapping이 변경되는 Partition Rebalancing이 발생합니다. 또한 Partition은 <em>비싼</em>자원에 속해 갯수 증가를 신중히 고민해야 합니다. <a href="https://www.confluent.io/ko-kr/blog/how-choose-number-topics-partitions-kafka-cluster/">링크</a></p><p id="8e796a18-0826-47af-9c1e-d8ce358f01ba" class="">또, Partition에 대응되는 Consumer 수가 증가할 수록 Consumer Rebalance 시간이 증가합니다.</p><p id="34dbf14a-bd32-4e87-a346-f0ec0524868f" class="">따라서 Concurrency 성능을 위해서는 Partition은 고정해두고 Thread의 갯수로 Concrrency 성능을 조정하는 것이 좋습니다. <a href="https://www.confluent.io/ko-kr/blog/kafka-consumer-multi-threaded-messaging/">링크</a></p><p id="d5784b8e-e02f-48d1-bf63-7a28b7e93b70" class="">이 방식의 단점은 데이터의 순서가 보장되지 않는다는 점입니다.</p><ul id="0dd9653f-7045-4da3-91f9-b89caa2b4f97" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터의 순서 보장 vs Concurrency 성능</strong></li></ul><p id="f8817bd7-6ff9-4a26-bd7f-f6159421f8e6" class="">No Silver Bullet. 세상에 완벽한 해결책은 없습니다. 데이터의 순서 보장을 하며 Concurrency 성능을 어느정도 포기하고 파티션 및 장비 증설로 성능을 커버하거나, 데이터의 순서 보장을 포기하고 전송 성능을 극대화하는 두 가지 선택지가 남았습니다.</p><p id="dcae2b45-e234-4837-884e-5ed582553382" class="">팀원들과 논의 끝에 해당 데이터는 약간의 딜레이가 있게 Sync 되어도 문제는 없을 것 같지만, 데이터에 정합성은 중요하다는 결론이 나와서 전자의 방식을 선택했습니다.</p><ul id="ef3c889a-f411-4543-9bd2-33658c4f0f90" class="bulleted-list"><li style="list-style-type:disc"><strong>그밖에 Topic 설계에 고려한 것들</strong></li></ul><p id="048efb8c-6d01-4ff8-ba4e-eead9accc709" class="">보통 하나의 Database에서는 여러 Table들이 존재합니다. Table 단위로 데이터를 전송한다면, Table 갯수만큼 Topic을 생성해야할까요 ?</p><p id="092b8617-24a7-4b67-ba4d-50f0c90f79a6" class="">Confluent에 관련 글이 있습니다. <a href="https://www.confluent.io/blog/put-several-event-types-kafka-topic/">링크</a> . 간단히 요약하면 다음과 같습니다.</p><ol type="1" id="759abc59-a512-4e88-83cb-2e23c4facebd" class="numbered-list" start="1"><li>Topic 설계시 가장 중요한 것은, 순서를 유지해야하는 것은 동일 topic에 두며 동일한 파티션 키를 사용하는 것</li></ol><ol type="1" id="7d1b5024-03d8-43ee-9432-5368118c4cc0" class="numbered-list" start="2"><li>한 entity가 다른 entity에 종속되어 있는 경우나 함께 자주 필요한 경우 동일한 topic에 배치하는 것이 좋음.</li></ol><ol type="1" id="e8f5ee9c-b63d-44a1-8f3c-95218bbcc504" class="numbered-list" start="3"><li>특정 entity가 다른 entity보다 훨씬 높은 이벤트 비율을 갖는 경우 쓰기 처리량이 낮은 entity만 원하는 consumer를 위해 topic을 분리하는 것이 좋음 (처리량이 낮은 entity가 처리량 높은 entity의 영향을 덜 받기 위한)</li></ol><h1 id="4ca3653e-412a-43af-a614-d0aae07ba17d" class=""><strong>전송 실패</strong></h1><p id="4bea9c82-a349-4100-8476-92b00060dbb5" class="">전송 실패할 경우의 여러 Case에 대해서 고민해본 내용입니다.</p><ul id="0605333e-2fb5-4f29-a08f-76976dd4070f" class="bulleted-list"><li style="list-style-type:disc">Kafka Broker</li></ul><p id="b7b406f5-d8ee-45e4-99d7-532b8cb30510" class="">Kafka 장애는 일어날 일이 거의 드물고, 발생했을 시 데이터 유실은 불가피합니다. 따라서 아예 별개의 모니터링 및 로그 적재가 필요합니다.</p><ul id="72e29b0d-7fdf-4522-84a6-d127f8f7938b" class="bulleted-list"><li style="list-style-type:disc">Consumer</li></ul><p id="c6700b8c-c17d-4bac-a4b5-d693197e196b" class="">카프카 Consumer의 장애로 전송 실패가 일어나는 경우에 일반적으로 Kafka에서 사용하는 Retry 로직을 사용하는 경우 Data의 순서 보장이 되지 않습니다. 따라서 다른 방식의 해결법이 필요합니다.</p><h3 id="12aadfaa-e85f-4477-9bd0-71d670775e9a" class=""><strong>돌고 돌아 Batch 로…</strong></h3><p id="2bd0ac59-bfbb-4529-b0b5-94c934d333aa" class="">현재 솔루션에서 가장 중요한 것은 데이터 정합성입니다. 따라서 가장 간단하면서 정확한 방법인 Batch로 정합성을 맞추기로 결정했습니다. 두 테이블간 잘못된 데이터를 확인하고 Origin Table을 기준으로 데이터를 보정하고 Slack 알림을 보냈습니다. 대부분의 데이터는 Kafka를 통해 전송하고, 잔여 데이터를 Batch로 처리하는 것이기에 Batch 로 데이터를 보정해도 문제가 없었습니다.</p><h1 id="9bcf40bc-c24f-475a-90f5-af2b174527b5" class=""><strong>Transaction</strong></h1><p id="0292c347-41cc-4ba3-a9c5-cc36fdb26c01" class="">메세지 전송의 트랜잭션을 보장하기 위한 것은 여러 방식이 있습니다.</p><ul id="a87e0288-8954-49e9-bd26-47c62b75f126" class="bulleted-list"><li style="list-style-type:disc">Outbox Pattren <a href="https://microservices.io/patterns/data/transactional-outbox.html">링크</a></li></ul><p id="1a19ad70-1c52-471c-b7fa-4efa752eb345" class="">로컬에 전송용 테이블을 따로 두고, Origin 테이블과 전송용 테이블에 Data를 동시에 Access하고 Commit 되면 그때 카프카 브로커에 전송하는 방식입니다. 따라서 DB 트랜잭션이 커밋된 이후에만 메세지가 전송되도록 보장할 수 있습니다. 그리고 App에서 보낸 순서대로 Produce 할 수 있습니다.</p><ul id="cb53aeaf-1f63-468a-9341-cda2e277bc03" class="bulleted-list"><li style="list-style-type:disc">Saga Pattern 을 이용한 분산 트랜잭션 <a href="https://microservices.io/patterns/data/saga.html">링크</a></li></ul><p id="3aca7664-bd95-4d91-878b-752dda5e543c" class="">마이크로서비스 끼리 이벤트를 주고 받다 특정 서비스에서 작업이 실패하는 경우, 이전까지 완료된 작업들에 대해서 보상 이벤트를 보내 분산환경에서 원자성을 보장하는 패턴입니다. SAGA 패턴의 핵심은 트랜잭션의 관리 주체가 DB가 아닌 APP에 있다는 것입니다.</p><p id="a1012313-be78-4872-82ee-491f7799c6d5" class="">예를 들어 A - B App에서 DB가 MS로 연결되어 있다면 A 성공 후 B가 실패하는 경우 B에서 A를 향해 트랜잭션 실패 이벤트를 발행합니다. 그걸 받은 A는 트랜잭션 롤백을 합니다.</p><ul id="0831cfc8-760d-49bc-88ed-42901d4913d0" class="bulleted-list"><li style="list-style-type:disc">Saga Pattern은 Choreography와 Orchestration 두가지 종류가 존재합니다<ul id="40e46f0e-d5df-4f72-9d12-17568ccae132" class="bulleted-list"><li style="list-style-type:circle">Choreography는 이벤트를 순차적으로 받은 뒤 성공한 마지막 App에서 완료 트랜잭션을 보냅니다. 구성하기 편하지만, 트랜잭션의 현재 상태를 알기 어렵습니다.</li></ul><ul id="ba18b00f-3881-4457-bd10-619d9f69e468" class="bulleted-list"><li style="list-style-type:circle">Orchestration은 중간에 Orchestration하는 Saga Instance가 별도로 존재해 트랜잭션 내의 App들은 모두 Saga를 거쳐가도록합니다. 인프라 구현은 복잡해지지만 트랜잭션 현재 상태를 쉽게 알고 롤백하기 쉽습니다.</li></ul></li></ul><p id="5ef8fa7a-e74b-4297-bb7b-e9a2bef87a56" class="">이 방식들을 선택하지 않은 이유는, 해당 솔루션이 사용되는 곳에서 데이터 저장과 메세지 전송에 대한 원자적인 트랜잭션을 보장하지 않아도 되었기 때문입니다.</p><p id="bb536519-b7ba-4ed8-b22a-d56b9b3aba73" class="">보다 <em>정확한 요구 사항</em>은 아래와 같습니다.</p><ul id="9a4db007-b376-4ccd-b581-8b9c36bf7b3f" class="bulleted-list"><li style="list-style-type:disc">데이터가 전송된다면 정확한 데이터가 들어갈 것.</li></ul><ul id="3a7d1c55-b96b-4612-9ac0-da10d9b971e7" class="bulleted-list"><li style="list-style-type:disc">실패한다면 아예 실패할 것.</li></ul><ul id="34212e79-f540-44c5-9acc-75f1e22e5b70" class="bulleted-list"><li style="list-style-type:disc">메세지 전송의 실패가 Origin 로직에 영향을 주지 말 것</li></ul><p id="3596e8b6-15a6-422b-bbe5-c32847076bb7" class="">즉, Transaction을 분리해 개발하는 것이 필요했습니다. 그리고 보정용 Batch를 따로 개발했기에 전송에 실패한 소수의 데이터들은 Batch 를 통해 보정이 맞춰져 별개의 데이터 유실을 걱정하지 않았습니다.</p><h1 id="eba00407-e00c-4ff9-8b5d-1de6309c7fcf" class=""><strong>Logging &amp; Monitoring</strong></h1><ul id="072caa72-5b6d-4139-b18a-b030f01501b3" class="bulleted-list"><li style="list-style-type:disc">로깅 및 모니터링에 대해서도 고민이 많았지만, 구현하지 않았기에 짧게 줄입니다. 로깅과 모니터링은 <em>어떠한 상황</em>에서<em>도</em> 안정성이 보장이 되어야 합니다. 이에 본 목적을 위한 Application 설계보다 과한 엔지니어링을 해야합니다. 이에 목적에 비해 <code>오버 엔지니어링</code>이라는 판단이 들어 관련 사항은 폐기했습니다.</li></ul><ul id="67aa0020-1f42-4a2e-a342-555eb151e3f1" class="bulleted-list"><li style="list-style-type:disc">결과적으로 데이터 정합성을 맞추기 위한 Batch에서 데이터 정합성이 맞지 않을 시 Slack 알람을 하고 있어, Batch가 모니터링의 역할을 어느 정도 수행하게 되었습니다.</li></ul><h1 id="10540714-f15d-431f-a916-159f1c3b1495" class=""><strong>개발하며 겪은 시행 착오</strong></h1><p id="63cb9f6f-0242-4f00-a1ac-68b9f4a857d4" class="">개발하다보니 문제점이 있었습니다. 일반적으로 <code>spring-kafka</code>에서는 <code>KafkaTemplate</code>을 이용해 Producing 합니다. 그리고 <code>Schema Registry (AWS Glue)</code>의 경우 KafkaTemplate별로 Schema를 지정할 수 있었습니다. 현재 구조는 Schema Registry는 DB Table 단위로 나누어져 있고, Topic은 도메인 기준으로 나누어져 있었습니다. 즉, 1개의 Topic에 여러 Schema를 적용하는 상황이었습니다.</p><p id="b7d75ba0-7e59-40b8-b26b-7c1eb9f1452e" class="">1개 TOPIC이 여러 SCHEMA를 받을 수 있어야..</p><figure id="e9ab0a4d-05fe-4740-b4bc-bbad0827ce33" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/07.png"><img style="width:300px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/07.png"/></a></figure><p id="cc8f69e0-2117-4ffc-b67d-230ab1f3759b" class="">일반적으로 1개의 KafkaTemplete에 1개의 Schema 를 등록하는 것이 기본이라 KafkaTemplate에는 1개의 Schema 설정이 가능합니다. 이에 좀 더 찾아보니 <code>&lt;Schema subject name strategy&gt;</code> 와 관련된 내용이 있었습니다. <a href="https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#sr-schemas-subject-name-strategy">링크</a></p><p id="181944b8-faf0-40e0-bcf3-0eb8f8ff9c7c" class="">Default는 <code>TopicNameStrategy</code> 로 Topic name에서 Subject name이 파생됩니다. TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy 세가지 옵션 중 <code>TopicRecordNameStrategy</code>의 경우 Topic 또는 Record Name에서 Subject name이 파생되며, 논리적으로 관련된 이벤트를 그룹화하는 방법이며, Subject 하에 <em>여러 데이터 구조</em>를 가질 수 있는 옵션입니다.</p><p id="28dbd436-355e-48aa-a699-7dbc249a124e" class="">관련 자료를 찾아보면 주로 “동일한 Topic에 여러 Event를 보내는 경우” <a href="https://www.confluent.io/blog/multiple-event-types-in-the-same-kafka-topic/?_ga=2.243682880.498060886.1652521610-605140293.1646630868">링크</a> 가 나오지만 이는 서로 다른 이벤트들을 그룹화해 하나의 토픽에 보내는 것으로 현재 제 구조에는 부적합했습니다.</p><p id="e0ebd3f1-cc38-44ad-ad28-824184bd2358" class="">Schema a + b + c ⇒ Topic A</p><figure id="b80fb98f-b362-4364-b261-c659b1c844d5" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/08.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/08.png"/></a></figure><p id="07bdc94e-022a-4d53-b092-d93c31287c4f" class="">현재 필요한 구조 ) Schema a ⇒ Topic A, Schema b ⇒ Topic A, Schema c ⇒ Topic A</p><figure id="6f107576-bf0f-4b77-95d7-961f9663352e" class="image"><a href="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/09.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2022-05-16-junior-developer-first-msa-design-and-development/09.png"/></a></figure><p id="17b0746d-3519-4386-bc4f-98c1fef0f8ac" class="">또한 자료를 찾아봐도 주로 Schema Registry에 관련 자료일 뿐 Spring-kafka에서 어떻게 적용해야하는지에 대한 자료는 거의 없었습니다. 이에 고민을 하다 아래와 같이 코드를 적용했습니다.</p><ul id="913709f1-4e1f-4ff5-a45c-2a2e6df3dce9" class="bulleted-list"><li style="list-style-type:disc">Producer yml</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="af7e2e0a-3658-4929-b3a0-f08d34c24675" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all"># TopicRecordNameStrategy 적용 

spring:
  kafka:
    properties:
      key.subject.name.strategy: io.confluent.kafka.serializers.subject.TopicRecordNameStrategy 
      value.subject.name.strategy: io.confluent.kafka.serializers.subject.TopicRecordNameStrategy</code></pre><ul id="3d6ff753-d038-4894-bc41-e9b90a44b9d2" class="bulleted-list"><li style="list-style-type:disc">Producer config</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="3d55641e-e9a0-407a-bb1b-7f95c9c9c96f" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Configuration
public class CouponProducerConfig {
		
    // 각 Schema 별로 KafkaTemplate을 설정
    @Bean
    public KafkaTemplate&lt;?, ?&gt; couponKafkaTemplate(ProducerListener&lt;Object, Object&gt; kafkaProducerListener, 
                                                   ObjectProvider&lt;RecordMessageConverter&gt; messageConverter) {
        Map&lt;String, Object&gt; defaultProperties = pf.getConfigurationProperties();
        LinkedHashMap&lt;String, Object&gt; props = new LinkedHashMap&lt;&gt;(defaultProperties);
        props.put(AWSSchemaRegistryConstants.SCHEMA_NAME, CouponSchema.Coupon.getName()); // enum으로 Schema 정보 관리 
        props.put(AWSSchemaRegistryConstants.DESCRIPTION, CouponSchema.Coupon.getDescription());
        return createKafkaTemplate(kafkaProducerListener, messageConverter, props);
    } 

    @Bean
    public KafkaTemplate&lt;?, ?&gt; couponHistoryKafkaTemplate(ProducerListener&lt;Object, Object&gt; kafkaProducerListener,
                                                          ObjectProvider&lt;RecordMessageConverter&gt; messageConverter) {
        Map&lt;String, Object&gt; defaultProperties = pf.getConfigurationProperties();
        LinkedHashMap&lt;String, Object&gt; props = new LinkedHashMap&lt;&gt;(defaultProperties);
        props.put(AWSSchemaRegistryConstants.SCHEMA_NAME, CouponSchema.CouponHistory.getName());
        props.put(AWSSchemaRegistryConstants.DESCRIPTION, CouponSchema.CouponHistory.getDescription());
        return createKafkaTemplate(kafkaProducerListener, messageConverter, props);
    }

    ...

    private KafkaTemplate&lt;Object, Object&gt; createKafkaTemplate(ProducerListener&lt;Object, Object&gt; kafkaProducerListener,
                                                              ObjectProvider&lt;RecordMessageConverter&gt; messageConverter,
                                                              LinkedHashMap&lt;String, Object&gt; props) {
        KafkaTemplate&lt;Object, Object&gt; kafkaTemplate = new KafkaTemplate&lt;&gt;(new DefaultKafkaProducerFactory&lt;&gt;(props));
        kafkaTemplate.setProducerListener(kafkaProducerListener);
        messageConverter.ifUnique(kafkaTemplate::setMessageConverter);
        return kafkaTemplate;
    }
}</code></pre><ul id="ff2d6581-b900-4f9b-bb6a-f42a500beb53" class="bulleted-list"><li style="list-style-type:disc">Producer send</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="dc5ccaa6-9c32-4c0b-b81c-7e71494ab879" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Component
public class SyncCouponClient {

    private static final String TOPIC_NAME = &quot;coupon-topic&quot;;

    private final KafkaTemplate&lt;Object, Object&gt; couponKafkaTemplate;
    private final KafkaTemplate&lt;Object, Object&gt; couponHistoryKafkaTemplate;

    public SyncCouponClient(@Qualifier(&quot;couponKafkaTemplate&quot;) KafkaTemplate&lt;Object, Object&gt; couponKafkaTemplate
                            , @Qualifier(&quot;couponHistoryKafkaTemplate&quot;) KafkaTemplate&lt;Object, Object&gt; couponHistoryKafkaTemplate) {
        this.couponKafkaTemplate = couponKafkaTemplate;
        this.couponHistoryKafkaTemplate = couponHistoryKafkaTemplate;
    }

    // Schema 마다 다른 KafkaTemplate 사용 
    public void produceForCouponAvro(SendType sendType, long pk, String query, CouponAvro receivedData) {
        log.debug(&quot;produceForCouponAvro: sendType: {}, pk: {}, query: {}, receivedDate: {}&quot;, sendType, pk, query, receivedData);
        receivedData.put(&quot;sendType&quot;, sendType);
        receivedData.put(&quot;query&quot;, query);
        couponKafkaTemplate.send(new ProducerRecord&lt;&gt;(TOPIC_NAME, pk, receivedData));
    }

    public void produceForCouponHistoryAvro(SendType sendType, long pk, String query, CouponHistoryAvro receivedData) {
        log.debug(&quot;produceForCouponHistoryAvro: sendType: {}, pk: {}, query: {}, receivedDate: {}&quot;, sendType, pk, query, receivedData);
        receivedData.put(&quot;sendType&quot;, sendType);
        receivedData.put(&quot;query&quot;, query);
        couponHistoryKafkaTemplate.send(new ProducerRecord&lt;&gt;(TOPIC_NAME, pk, receivedData));
    }

}</code></pre><ul id="3d87e5e1-cade-4c4a-9f32-8ee52611701f" class="bulleted-list"><li style="list-style-type:disc">Consumer consume</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="17bcee6d-9b55-4751-a79c-d1b48b771143" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">@Service
@KafkaListener(topics = {&quot;coupon-topic&quot;}, groupId = &quot;coupon-group&quot;, containerGroup = &quot;coupon-group&quot;, containerFactory = &quot;couponListenerContainerFactory&quot;)
@RequiredArgsConstructor
public class DownloadCouponConsumerService {

    @NonNull
    private final CupnSyncAdapter cupnSyncAdapter;

    @KafkaHandler
    public void listenToCouponAvro(@Payload CouponAvro receivedData,
                                   ConsumerRecord&lt;Long, CouponAvro&gt; record) {
        log.debug(&quot;listenToCouponAvro: sendType: {}, pk: {}, partition: {}, query: {}&quot;, receivedData.getSendType(), record.key(), record.partition(), receivedData.getQuery());
        log.debug(&quot;received coupon-topic receivedData : {}&quot;, receivedData);

        cupnSyncAdapter.sendCoupon(receivedData);
    }

    @KafkaHandler
    public void listenToCouponHistoryAvro(@Payload CouponHistoryAvro receivedData,
                                          ConsumerRecord&lt;Long, CouponHistoryAvro&gt; record) {
        log.debug(&quot;listenToMtDwldCupnCrtfAvro: sendType: {}, pk: {}, partition: {}, query: {}&quot;, receivedData.getSendType(), record.key(), record.partition(), receivedData.getQuery());
        log.debug(&quot;received coupon-topic receivedData : {}&quot;, receivedData);

        cupnSyncAdapter.sendCouponHistory(receivedData);
    }
	
    ...
}</code></pre><p id="69982c01-c293-4e22-bbd3-4a3484c407bf" class=""><code>@KafkaListener</code> 내에 <code>topics</code> 지정 후 <code>@KafkaHandler</code> 의 <code>@Payload</code> 를 이용하면 객체의 타입별로 구분해 Consume 할 수 있습니다.</p><h1 id="3eac73cf-773d-47ec-8f65-77c7acb44492" class=""><strong>과정을 진행하며 느낀점</strong></h1><ul id="a6b2b955-a43d-4832-a4de-7d0098550fd3" class="bulleted-list"><li style="list-style-type:disc">컴퓨터 공학은 추상적인 것을 구체화 하는 과정이며, 구체화를 하기 위해서는 많이 정보들이 필요합니다. 하지만 추상적인 정보만 수집하면 안됩니다. 당장 아는 만큼이라도 만들어야 합니다. 정보 수집만 할 수록 더 어렵게 느껴질 수 있습니다.</li></ul><ul id="8e703035-5ac2-44ed-9e97-4c55f98d11a2" class="bulleted-list"><li style="list-style-type:disc">아무 것도 없는 상황에서 개발을 해야한다면, Google, 사내 Wiki, Conference 영상, 관련 기술 모임, 팀장님 팀원들부터 다른 팀 분들 그리고 <em>사돈의 팔촌까지</em> 온갖 인적 자원 등을 적극적으로 활용해야합니다. 개인적으로는 “카프카 한국 사용자 모임”의 질의 응답도 꽤 도움이 되었습니다.</li></ul><ul id="28735f62-19d8-40fb-915d-08b60a693a94" class="bulleted-list"><li style="list-style-type:disc">오버엔지니어링을 경계해야합니다. Avro를 적용함으로써 좀 더 안정적이고, 앞으로 데이터를 활용한다면 해당 플랫폼의 확장성이 좋겠지만, 다시 생각해보면 현재는 데이터를 활용할 계획이 없고, DB Table의 field 추가는 자주 일어나지 않으며, 이미 Batch로 잘못된 잔여 데이터의 정합성을 맞춘다면, 현재의 요구 사항에서는 Avro까지는 필요 없을 수도 있겠다는 생각이 듭니다.</li></ul><ul id="252dacd7-9726-443d-aec0-95a9ed102ccd" class="bulleted-list"><li style="list-style-type:disc">명확한 요구 사항의 중요성을 알았습니다. 기존의 잘 몰랐을 때는 <em>(사실 지금도 잘 모릅니다.)</em> 데이터의 순서도 유지되면서 성능도 좋은 <code>우주최강플랫폼</code>을 생각했으나 그 둘은 공존할 수 없었습니다. <em>(우주최강개발자는 가능할지도..)</em> 결국 여러 번의 토의 끝에 데이터의 순서대로 동기화해 데이터의 정합성을 우선시하기로 했습니다.</li></ul><ul id="b08abda5-73f9-4f01-89b5-f586650d4e6d" class="bulleted-list"><li style="list-style-type:disc">작은 프로토 타입을 빠르게 먼저 만드는 것이 중요하다는 생각이 들었습니다. 위와 같은 여러 번의 요구사항의 수정으로 이미 개발한 코드의 수정도 잦았습니다. 작은 프로토 타입을 빠르게 만들었다면 나 혼자 아는 로직에 대해 팀원들에게 좀 더 쉽게 의견을 구할 수 있지 않았을까 생각이 듭니다. 결과적으로 동기화 대상이 꽤 많았는데 절반 이상의 개발이 이루어진 것도 설계가 변경되서 3번을 엎고 다시 개발하는 과정을 거쳤습니다.</li></ul><ul id="34fa6a9b-c316-4380-b9e1-1aa259deb332" class="bulleted-list"><li style="list-style-type:disc">따라서 설계 변경은 신중하게 해야겠지만 퀵하게 해야합니다. <em>늦었다 생각할 때가 늦었습니다..</em> 하지만 더 늦기 전에 바꿔야 합니다..</li></ul><ul id="56401be7-fc25-4833-af4c-e567e6107fb9" class="bulleted-list"><li style="list-style-type:disc">너무 완벽하려고 제 능력보다 너무 어렵게 생각했습니다. 가장 중요한 것은 Make it work. 고 수준이 아니어도 우선 돌아가게 만드는 것이 중요합니다.</li></ul><ul id="30cc3d4a-b0e7-415c-a478-4882b2ca39eb" class="bulleted-list"><li style="list-style-type:disc">No Silver Bullet. 은총알은 없습니다. 명확한 요구 사항에 맞는 프로그램만 있을 뿐 완벽한 약점 없는 프로그램은 없습니다.</li></ul><figure id="7ca5a62c-9e4d-4f86-b21b-399b188955ca"><a href="https://11st-tech.github.io/2022/05/16/junior-developer-first-msa-design-and-development/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">11번가 주니어 개발자의 첫 MSA 설계 및 개발기 | 11번가 TechBlog — 11번가 기술블로그</div><div class="bookmark-description">안녕하세요. 11번가 주문개발팀 개발자 고다경입니다. 입사 후 파일럿 프로젝트를 진행한 것을 Product로 전환하는 과정을 담았습니다. 많이 부족한 글이지만 신입~주니어의 글이라 생각해주시고 읽어주시기 바랍니다 🙏 목차 그래서 무엇을 했나요 ? What is Change Data Capture ? Q. 데이터 전송,, 혹시,, 너,, 뭐,, 돼,,? 뭐부터 해야할지.. 설계 과정 Why Kafka ?! Flow 설계 기술 스택 Sync ? Blocking ? Async ? Non-Blocking? First Flow ) Vine → Producer 호출 Second Flow ) Consumer → Another Vine Producer와...</div></div><div class="bookmark-href"><img src="https://11st-tech.github.io/assets/apple-touch-icon.png" class="icon bookmark-icon"/>https://11st-tech.github.io/2022/05/16/junior-developer-first-msa-design-and-development/</div></div><img src="https://11st-tech.github.io/assets/images/og_image.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="37a9951b-e79a-4a57-82d4-b3895dab1459" class="toggle"><li><details open=""><summary>Kafka - Schema Registry</summary><p id="e74e8cca-7b04-4112-9833-a1201a1e9d39" class="">Schema Registry는 데이터 구조(스키마)를 중앙에서 관리하고 여러 마이크로서비스에서 이를 일관되게 사용하도록 도와주는 도구입니다. 특히 마이크로서비스 아키텍처(MSA)에서 공통 코드 관리에 중요한 역할을 합니다. 구체적으로 어떻게 활용될 수 있는지 살펴보겠습니다.</p><h3 id="e90a46f1-7fc9-4133-8e3d-902c48275d1a" class="">1. <strong>스키마 중앙 관리</strong></h3><ul id="e39451a7-8518-4328-ab6b-0b76e9e07356" class="bulleted-list"><li style="list-style-type:disc"><strong>중앙 집중화된 스키마 관리</strong>: Schema Registry는 Avro, Protobuf, JSON Schema와 같은 데이터 구조를 중앙에서 관리합니다. 이를 통해 모든 마이크로서비스가 공통된 데이터 구조를 사용할 수 있습니다. 스키마 변경이 필요할 때도 Schema Registry를 통해 일관되게 관리하고 배포할 수 있습니다.</li></ul><h3 id="df01bc2c-a65f-4148-8790-7a7f5785200a" class="">2. <strong>호환성 보장</strong></h3><ul id="ffeb7571-03f3-4e99-aaad-6e58cd5adfd7" class="bulleted-list"><li style="list-style-type:disc"><strong>스키마 호환성 체크</strong>: Schema Registry는 새로운 스키마 버전을 등록할 때 이전 버전과의 호환성을 자동으로 검사합니다. 이를 통해 마이크로서비스 간의 데이터 통신에서 예상치 못한 오류를 방지할 수 있으며, 서비스 간의 연동이 원활하게 이루어질 수 있도록 보장합니다.</li></ul><ul id="31769eb2-7b4d-48b1-97dd-36503a190ec8" class="bulleted-list"><li style="list-style-type:disc"><strong>Backward/Forward Compatibility</strong>: 스키마 버전 관리와 호환성 체크를 통해 기존의 마이크로서비스들이 새로운 스키마 변경에 대응할 수 있도록 지원합니다. 이는 서비스의 독립 배포성을 유지하면서도 공통 코드를 일관되게 사용할 수 있게 해줍니다.</li></ul><h3 id="a4010462-1357-4472-a5af-ad07c3f4766e" class="">3. <strong>중복 코드 감소</strong></h3><ul id="de9b2770-b73a-408e-8a95-c9a2b44317de" class="bulleted-list"><li style="list-style-type:disc"><strong>공통 데이터 모델 사용</strong>: 여러 마이크로서비스가 동일한 데이터 모델을 필요로 할 때, Schema Registry를 통해 이 모델을 정의하고 재사용할 수 있습니다. 이를 통해 중복되는 데이터 구조 정의를 피하고, 모든 서비스가 공통된 모델을 사용하게 되어 유지보수성과 일관성이 높아집니다.</li></ul><h3 id="530943b8-20c3-4e42-b332-74284c479738" class="">4. <strong>API 계약 관리</strong></h3><ul id="95ac1a29-f10c-4774-a7a9-c7f5d6b0ba63" class="bulleted-list"><li style="list-style-type:disc"><strong>계약 기반 개발</strong>: 마이크로서비스 간의 통신에 사용되는 메시지나 API의 계약(Contract)을 Schema Registry에 등록하여 관리할 수 있습니다. 이를 통해 각 서비스는 공통된 계약을 기반으로 상호작용하게 되고, 중복된 코드 작성 없이 공통된 규격을 준수할 수 있습니다.</li></ul><ul id="7c45f28f-d902-4d11-8ea7-551aa7c8172f" class="bulleted-list"><li style="list-style-type:disc"><strong>버전 관리 및 추적</strong>: 스키마의 버전이 변경될 때마다 이를 기록하고 추적할 수 있습니다. 이를 통해 공통 데이터 구조의 진화를 관리하며, 마이크로서비스의 업데이트 시 기존 서비스를 손쉽게 유지할 수 있습니다.</li></ul><h3 id="fb88cc83-ec0b-410b-aaa6-8ff9b4017b2e" class="">5. <strong>코드 생성 도구와의 통합</strong></h3><ul id="006015b7-e806-48f8-be23-7dd73ec33a38" class="bulleted-list"><li style="list-style-type:disc"><strong>자동 코드 생성</strong>: Schema Registry에 등록된 스키마를 바탕으로 다양한 프로그래밍 언어에서 사용할 수 있는 데이터 모델 코드(예: Java POJO, C# Class 등)를 자동으로 생성할 수 있습니다. 이를 통해 개발자가 중복된 데이터를 정의하는 작업을 줄이고, 중앙에서 관리된 공통 코드를 사용하게 할 수 있습니다.</li></ul><h3 id="c338ad76-c881-45ad-99ca-467867becb82" class="">6. <strong>데이터 일관성 유지</strong></h3><ul id="1d0b1d51-1195-405c-95dc-ac3a976468fd" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 통신의 일관성</strong>: Schema Registry를 사용하여 데이터를 주고받는 모든 마이크로서비스가 동일한 스키마를 사용하게 함으로써 데이터 일관성을 유지할 수 있습니다. 이는 데이터 변환 오류를 줄이고, 서비스 간의 데이터 교환을 더욱 신뢰성 있게 만듭니다.</li></ul><p id="30b299c0-51a8-4e62-987c-0c43979dc33d" class="">Schema Registry는 MSA 환경에서 데이터 구조의 일관성과 호환성을 유지하면서 공통 코드를 중앙에서 관리하고 재사용할 수 있도록 돕는 강력한 도구입니다. 이를 통해 개발 효율성을 높이고, 시스템의 안정성을 강화할 수 있습니다.</p><figure id="e0c311f3-b76f-408c-9f30-fe80e3cbc53a" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2024.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2024.png"/></a></figure><ol type="1" id="83cb644a-55e1-40f4-b4d2-473cd5caa2a0" class="numbered-list" start="1"><li>에이브로 프로듀서는 컨플루언트에서 제공하는 새로운 직렬화를 사용해 스키마 레지스트리의 스키마가 유효한지 여부를 확인합니다. 만약 스키마가 확인되지 않으면, 에이브로 프로듀서는 스키마를 등록하고 캐시한다.</li></ol><ol type="1" id="4003c7cf-9032-4983-aae0-c9a31262275e" class="numbered-list" start="2"><li>2.스키마가 업데이트됐는지 체크 각 스키마에대해 고유 id 할당.</li></ol><ol type="1" id="eb72bd8f-d394-4dd4-a6d5-549874b1c793" class="numbered-list" start="3"><li>3.프로듀서가 스키마 레지스트리로 부터 받은 스키마id를 참고해서 메시지를 카프카로 전송. 이때 스키마 전체내용이 아닌 메시지와 스키마 id만 보냅니다.</li></ol><ol type="1" id="ca8758f8-e54a-4cfc-b45f-a0b5aff5bf2d" class="numbered-list" start="4"><li>에이브로 컨슈머는 스키마id 로 새로운 역직렬화를 사용해서 카프카의 토픽에 저장된 메시지를 읽습니다. 컨슈머가 스키마 id 를 가지고 있지 않다면 스키마 레지스트리로 부터 가져옵니다.</li></ol><p id="873f543e-d24a-4e93-8454-12cd8b5bc5f6" class="">
</p><figure id="5522eae7-b857-4ed3-b8f9-12487c125575" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2025.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2025.png"/></a></figure><figure id="2c678c1b-b49f-4515-b29a-631eb3c5ca90"><a href="https://always-kimkim.tistory.com/entry/kafka101-schema-registry" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">[Kafka 101] 스키마 레지스트리 (Schema Registry)</div><div class="bookmark-description">들어가며 카프카는 메시지를 보내는 프로듀서와 메시지를 복사해오는 컨슈머, 그리고 프로듀서와 컨슈머 사이에서 메시지를 중계하는 브로커로 구성됩니다. 이러한 카프카의 구조는 메시지의 송신자와 수신자 사이의 직접적인 관계를 끊음으로써 구조적인 결합도를 낮추는 장점이 있습니다. 하지만, 반대로 직접적인 관계가 끊어짐에 따라 발생하는 이슈도 있습니다. 이번 글은 카프카에서 발생할 수 있는 운영 이슈와 그 이슈를 해결할 수 있는 스키마 레지스트리(Schema Registry)에 관하여 정리합니다. 스키마 레지스트리 (Schema Registry) 스키마 레지스트리는 카프카 클라이언트 사이에서 메시지의 스키마를 저장, 관리하는 웹 어플리케이션입니다. 그리고 스키마 레지스트리는 많은 카프카 개발자와 운영자들이 카프카 ..</div></div><div class="bookmark-href"><img src="https://t1.daumcdn.net/tistory_admin/favicon/tistory_favicon_32x32.ico" class="icon bookmark-icon"/>https://always-kimkim.tistory.com/entry/kafka101-schema-registry</div></div><img src="https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FwV2Qz%2FbtqDF0XlaEv%2FmJgviuEFPOAEz1UEX6Yua1%2Fimg.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="9107292d-e09e-4757-8556-a6a6a3a96945" class="toggle"><li><details open=""><summary>11번가 - 전시 딜 내재화 프로젝트 회고: MongoDB 기반 데이터 구축과 API 개선 과정</summary><ul id="f38387fb-9e05-4eb5-8dd3-da39ead375fa" class="bulleted-list"><li style="list-style-type:disc"><strong>‘딜’ 그리고 ‘내재화’ 라는게 무슨 뜻인가요?</strong><ul id="c0a28422-a27e-49a7-a815-8863862b52c4" class="bulleted-list"><li style="list-style-type:circle">딜은 상품 판매를 위한 판촉행사라고 생각하면 쉽습니다.예를 들어, 단 10일간! 사과 한 박스에 단돈 3만원!</li></ul><ul id="4c5f26c8-e3cf-41c0-930a-c497c466d68b" class="bulleted-list"><li style="list-style-type:circle">내재화는 외부 기술/데이터를 가져와서우리만의 특성에 맞게 조정하고 직접 관리한다는 뜻입니다.</li></ul><p id="863f6016-f6bd-4f6f-9f57-5ba72b63ced9" class=""><strong>즉, 상품의 판촉행사 정보를 보여주는 영역에 필요한 정보는 우리 전시서비스개발팀에서 직접 구축하고 입맛에 맞게 최적화 시킨다는 뜻입니다.</strong></p></li></ul><ul id="7495dcac-f3c0-4434-aa13-db3e494cce82" class="bulleted-list"><li style="list-style-type:disc"><strong>왜 내재화 하나요?</strong><p id="50859d94-ea71-4b3c-bb4a-4b4aee4c0d34" class="">내재화하는 이유는 간단히 말해, 전시에 사용하는 딜 정보를 최적화 시켜서 더 쉽고 빠르게 유지 보수 하기 위함입니다.</p><p id="86943f3a-1e71-4466-bbe3-cd7a14ca0c46" class="">아래 이미지에서처럼 이미 <strong>THOR 플랫폼</strong> <strong>에서 전시에 사용하는 상품정보는 내재화(with MongoDB)가 완료된 상태</strong>였고</p><p id="ede1a78e-3d9c-44ce-ab22-5d00d9d114f3" class=""><strong>딜 정보(=행사정보)는 내재화하기 전 반정규화 테이블(with OracleDB)을 사용하고있는 상태</strong>입니다.</p><p id="7129fb3a-f337-41fe-8716-866ce0bd8666" class="">다시 말해, [행사 판매 중인 상품] 정보를 가져오기 위해 상품정보는 MongoDB에서,</p><p id="28a1e255-0603-4362-9167-6b36909dd5aa" class="">딜정보는 Oracle에서 조회하여 조합하고 있었습니다.</p></li></ul><p id="c1f5d9f9-63e3-40fd-b416-d46aca139913" class="">반정규화 상품정보(MongoDB)와 반정규화 딜정보(OracleDB)를 각각 조회해서 병합</p><figure id="4aa29d91-3d77-4a88-b817-9c9089aa17ac" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled1.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled1.png"/></a></figure><p id="dad5430f-c63e-431f-9d43-32113c70aa36" class="">이러한 조회방식은 아래와 같은 <strong>단점</strong>을 지니고 있습니다.</p><ul id="7003c4e0-01aa-417e-95b6-f0c2eb1338aa" class="bulleted-list"><li style="list-style-type:disc">매 호출마다 두 번, 서로 다른 DB에 커넥션을 받아야 하는 낭비</li></ul><ul id="fc7e1510-564f-4764-9363-b1e87500925b" class="bulleted-list"><li style="list-style-type:disc">개발이나 이슈 발생 시 딜정보인지 상품정보인지에 구분하여 디버깅 필요(관리 포인트 중복)</li></ul><ul id="36dc4062-dcea-4daf-8225-5281ebf9ed03" class="bulleted-list"><li style="list-style-type:disc">전시서비스개발팀에서 즉각 대응/수정 가능한 상품정보와 달리,딜정보는 OracleDB 관리 팀에 요청하는 프로세스로 개발과정 단위 테스트와 즉각적인 대응에 어려움</li></ul><p id="a1bad13f-1a6f-4d92-9a95-37cdf6fc1f94" class="">이를 반정규화 MongoDB로 전환하면 위의 단점을 극복하고 MongoDB의 <strong>장점</strong>을 그대로 살릴 수 있습니다.</p><ul id="4abcabe5-a356-4efc-8748-bc36820df17f" class="bulleted-list"><li style="list-style-type:disc">탈 오라클(비용 절감, DB 분리에 및 종속성 제거)</li></ul><ul id="25f9e3fc-3c27-4d86-ae44-5f16745cf52b" class="bulleted-list"><li style="list-style-type:disc">유연한 스키마로 구조 변경에 용이하여 개발 단위 테스트 및 개발속도 향상(OracleDB 변경 요청 프로세스가 사라짐)</li></ul><ul id="810d28fa-22bf-4a42-a71f-0ae98fabc3d2" class="bulleted-list"><li style="list-style-type:disc">수평 확장이 용이해져 대량트래픽 대응 비용 감소</li></ul><p id="5aba21f4-9c43-4799-a6c9-354e4866c059" class="">이러한 이유로 OracleDB 반정규화 테이블은 MongoDB 반정규화 테이블로 전환하게 되었고</p><p id="f2ae9217-5561-4a21-8fe9-06e5544e1237" class="">THOR 프로젝트의 일환으로 이번에 딜 내재화를 이어 맡아서 진행하게 되었습니다.</p><ul id="75a6da15-01b0-4b1d-a934-aa784549a0e8" class="bulleted-list"><li style="list-style-type:disc">THOR 플랫폼 이란?</li></ul><blockquote id="0d38d79b-3d7e-47b9-8c4e-80619a611324" class="">다양한 요구사항들에 기민한 대응을 위해 전시서비스 개발팀에 필요한 정보만을<p id="95fc0fc6-b82c-4a14-9280-05f90a62d458" class=""><strong>직접 구축하고 운용하는 MongoDB 기반 전시서비스 데이터 플랫폼.</strong></p><p id="b5f4c21c-b7b9-4a57-8ebd-3704fe4ae524" class="">기존에는 반정규화된 PL/SQL 기반 Oracle Serving 테이블을 참조하였지만</p><p id="8a0f0670-c6ac-4b68-add0-8d54a5f2350f" class="">전시상품 수 증가, 업무로직 복잡성 증가로 인한 PL/SQL 의 한계, PL/SQL의 유지보수에 들어가는 리소스의 증가에</p><p id="1d84dda6-ce01-436e-8227-affcb8ddce1d" class="">기민한 대응을 위해 만들어진 전시데이터 플랫폼입니다</p></blockquote><p id="e4a04ff2-f571-4f42-9469-9b561f14673f" class="">이제 기본적인 궁금한 것도 알았고 왜 하는 건지 이해했으니 다음으로 넘어가보겠습니다.</p><h1 id="e53fc82b-406d-4f01-903b-499c2e43661a" class=""><strong>프로젝트 진행 과정</strong></h1><hr id="413780ba-c19f-41e6-bacf-33be4a7626c2"/><h1 id="0159d7ae-606c-4f75-9231-0184d40fbc1b" class=""><strong>기존 운영 방식의 문제점</strong></h1><p id="661af0b2-a50a-423f-91f5-a9c3bc903daf" class="">MongoDB 상품 정보 + OracleDB 딜 정보를 각각 조회하고 가공하여 전시 API로 응답하는 방식.</p><figure id="a0cb45fb-3677-4303-b226-a6024073e3bd" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled2.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled2.png"/></a></figure><p id="f0da7877-3851-4935-9f4d-16882306890f" class="">MongoDB 상품 정보 + OracleDB 딜 정보를 각각 조회하고 가공하여 전시 API로 응답하는 방식.</p><ul id="747737d0-d189-4283-9031-f6e1021cafed" class="bulleted-list"><li style="list-style-type:disc">기존 방식의 구체적인 문제점<ul id="bb29857a-c83e-485c-9d03-72591b2a2bb9" class="bulleted-list"><li style="list-style-type:circle">DB 트래픽 낭비 문제<ul id="d66b11ee-b260-4ee6-af29-37aad47963f0" class="bulleted-list"><li style="list-style-type:square">한 API 응답에서 두 개의 DB Pool Connection 을 맺는 추가 리소스</li></ul><ul id="51e6c431-4022-4cab-b4e2-15bb5952bece" class="bulleted-list"><li style="list-style-type:square">대량 트래픽 발생시, 오라클 커넥션 풀이 부족한 경우가 발생했고 이는 지연 발생의 원인이 될 수 있음</li></ul></li></ul><ul id="f7d568eb-df00-4374-a0e0-23a1b6539bfb" class="bulleted-list"><li style="list-style-type:circle">유지 보수 한계 (이슈 발생시 딜 정보 추적이 어려움)<ul id="5ebebdd5-5b58-45dc-af8b-5f7b8ec1d649" class="bulleted-list"><li style="list-style-type:square">직접 관리하는 테이블이 아니다 보니, Oracle Serving 테이블의 생성 로직과 엮여있는 배치의 프로세스와 주기, 관계 파악 쉽지 않음</li></ul><ul id="7de4fa36-b42a-4a79-b5c3-858995670ee4" class="bulleted-list"><li style="list-style-type:square">이슈의 원인을 파악하기 위해 Oracle SP의 생성 로직과 갱신 주기 등을 매번 다른 팀에 문의하거나,MongoDB(상품 정보)와 OracleDB(딜 정보)를 모두 확인해야 합니다.</li></ul></li></ul></li></ul><p id="511ac953-2398-44d8-a1a0-46d666815a36" class=""><strong>→ Oracle Serving 테이블 참조를 제거하고 자체 구축한 MongoDB 컬렉션을 참조하도록 변경필요</strong></p><p id="135f54b8-ce65-4b5c-a8a4-a6afdfa1be43" class="">지금부터는 좀 더 깊게 생각해봅니다</p><p id="c341c3f1-2ee1-4355-bee8-c4e2b25683a0" class="">https://namu.wiki/</p><h1 id="4fd82126-471f-4906-a6a0-0f39d3a784c9" class=""><strong>고려할점들</strong></h1><h3 id="b5efda0f-f57f-44ae-ad3c-8454460d263d" class=""><strong>1. 매우 넓은 영향범위</strong></h3><p id="fcbe20b7-8d93-444d-8ee2-95722b4e06c3" class="">기존에 딜 정보를 사용하는 API를 전수조사를 해보니 약 60개, 각 API 마다 사용처는 그보다 훨씬 많았습니다.</p><p id="85c80cea-a238-4588-8884-af5567f0216a" class="">API 내부 딜 조회 메서드에 대한 클래스 다이어그램</p><figure id="6c95505e-839a-468c-af5e-a226d2249952" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled4.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled4.png"/></a></figure><p id="8de82d5a-d8da-476f-be2f-a3c34bc53532" class=""><strong>다행히, 이미 잘 짜여진 구조와 적용된 패턴 덕분에, 일일이 60여개의 API의 코드를 모두 확인해봐야 할 필요는 적었습니다.</strong></p><p id="117db8b1-042f-46d3-ab39-72905247c068" class=""><strong>대부분의 API에서는 facade의 메서드(findProductsBy)만을 호출하여 필요한 정보를 조회하도록 캡슐화되어 있었고,</strong></p><p id="7b1ee7b7-c161-41dd-affe-5144879fb03b" class=""><strong>factory에서 반환하는 하위 객체 별 조회 동작 구현부만 수정하면 되었기 때문입니다.</strong></p><p id="f3b1b1cb-fa2f-4399-b261-9fee2fb74a06" class="">하지만 앞서 말했듯이, API자체가 많았고 이를 이용하는 사용처가 많다보니 로직상 숨겨진 의도와 데이터변환 조건등을 잘 챙겨야만 했습니다.</p><p id="a7a08418-c037-4a56-8263-250d4b01ab29" class="">API별 실제 사용되는 필드가 다르고 재변환로직이 조금씩 달랐기 때문에 필드 하나하나 신중한 접근이 필요해 보였습니다.</p><p id="e222c7bd-605d-40ef-a6ab-be13353e7135" class="">그래서 이를 정확히 검증하기 위해,</p><p id="c7dded3f-04af-4a0b-9474-5a2ac5ac3b0d" class="">최종 작업에서 <strong>as-is VS to-be API 간 응답 값을 확인할 수 있는 validation 기능을 가진 프로세스를 추가</strong>하여 검증하는 것이 필요했습니다.</p><h3 id="687fbd5c-ed25-4086-a3ae-7fadad33f06d" class=""><strong>2. 시시각각 변하는 유기적인 데이터</strong></h3><p id="80faca94-35ec-4d65-82e0-1b244e79744d" class="">각 제품마다 딜은 <strong>[신청-승인-확정-진행-종료] 형태의 라이프사이클이 존재</strong>합니다.</p><p id="482f122c-04c3-4865-abfe-dbfc897863ad" class="">그리고 라이프사이클이 진행되는 동안 <strong>딜 데이터는 계속 변하며, 이를 추적하고 빠르게 갱신 해주어야 합니다.</strong></p><p id="9364f758-cb51-46c1-ab06-c9d251b195bb" class="">상품의 딜 종류별 라이프사이클이 반드시 동일하지 않을 수 있는 조건을 반영하여 MongoDB 에 적재한다</p><figure id="2d819dea-bc46-4e5a-a67c-c4996a99bab7" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled5.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled5.png"/></a></figure><p id="d81354c9-1fa3-4c63-a451-0e3a39777f3f" class="">하지만 AS-IS 모델의 Serving 데이터와 TO-BE 모델의 새로 구축한 Serving 데이터가 갱신되는 시점이 서로 다르다보니,</p><p id="e3b17610-4038-4e41-ab58-4e0fe675812f" class=""><strong>AS-IS와 TO-BE 간에 데이터의 정합성을 비교할 때, 비교하는 시점에 따라 일시적인 다름인지, 잘못된 데이터인지 판단할 수 있어야 합니다.</strong></p><p id="2457d9cc-ed66-4747-96fa-be1d7bd311e1" class="">특정 시점, 예를 들어 15:00:00에 판매 수량 데이터를 확인했을 때,</p><p id="a4378a2e-f6af-4733-8008-a29b05a88f76" class="">A 상품은 15건, B 상품은 10건으로 표시되는 상황이라면, 세 가지 가능성을 염두하고 판단할 수 있습니다.</p><ul id="e94f6875-fbdd-4ae8-9772-d3ea67433270" class="bulleted-list"><li style="list-style-type:disc">A 상품의 판매 수량 15건은 최신 갱신된 결과이지만, B 상품의 10건은 아직 갱신 이전의 값 일 수 있습니다.이 경우, B 상품의 판매 수량이 다음 갱신을 통해 15건으로 변경된다면 TO-BE로의 전환이 잘 되었고 일시적인 다름이었음을 판단 할 수 있습니다.</li></ul><ul id="2e3cca10-bfd0-4235-a021-8eb2a044e3f7" class="bulleted-list"><li style="list-style-type:disc">반대로, 만약 B 상품의 판매 수량 10건이 갱신 이후의 값이었다면, B상품의 판매 수량 결과값이 잘못된 것으로 판단할 수 있습니다.</li></ul><ul id="18bedd5e-e2da-4428-ace6-35e466a26a75" class="bulleted-list"><li style="list-style-type:disc">추가로, B의 10건이 정확한 값이었고, 오히려 A값이 잘못 계산되어왔던 것인지 추가로 확인해 볼 수도 있습니다.예시 이외에도, 각 필드마다 갱신 조건이 있고 어떤 시점에 어떻게 변경될 수 있는지 알아야 검증 과정에서 정상적인 데이터인지 아닌지 판단 할 수 있습니다.</li></ul><p id="85ad90a5-99d6-49b9-90f2-37131e2c92a3" class=""><strong>또한, 딜의 라이프사이클뿐 아니라 상품의 라이프사이클도 영향을 미치기 때문에</strong></p><p id="239c7b12-3abb-45fc-90d3-02b41ecf3b78" class="">딜 한정 수량이 품절되어도 상품 수량이 남아있는지 구분하여 전시 노출 해야하는 부분,</p><p id="6c09321b-d52f-468e-91b6-de566e1f13e6" class="">전시종료 여부는 딜의 기간종료인지 품절종료인지, 품절은 상품품절인지 딜품절인지를 구분하여 전시 노출 결정을 할지를 명확히 알아야합니다.</p><p id="fac7283a-fffd-4c5b-bf6f-1f6020c86e0e" class=""><strong>이를 위해, 전시 딜의 동작방식을 위한 딜의 라이프사이클에 대한 이해도를 높일 필요가 있습니다</strong></p><h3 id="76f8d746-a93a-47e3-a3b1-a47746c9dfcc" class=""><strong>3. 롤백(Rollback)</strong></h3><p id="eee4144c-9b05-4101-a360-71890eb01ccc" class="">11번가를 이용하는 대부분의 사람들은 할인행사들을 잘 파악하고 행사기간을 이용하여 물품을 구매하고 있습니다.</p><p id="827c71ca-d659-40d9-8d78-af37818856f5" class="">행사상품정보는 11번가에서 물품을 구매할때 가장 먼저 보는 진입점인 만큼 중요성이 매우 크다고 생각합니다.</p><p id="b0c7b709-db69-4c69-9231-32e529d67f2f" class=""><strong>그래서 전환과정에 잘못된 데이터가 노출 되었을때 AS-IS 모듈로 가장 빠르게 롤백 할 수 있도록 전환하는 장치를 마련해야 합니다.</strong></p><p id="e3319d2f-f5cb-4cda-83bf-ab0346cd91fc" class="">롤백을 위한 재 배포없이 이전 모듈로 동작 할 수 있는 간편한 방법으로는</p><p id="22813087-d8d9-404a-9a33-efa7fda53a08" class="">DB 테이블에 AS-IS와 TO-BE 모듈의 실행을 분기할수 있는 플래그를 넣어두고 실시간으로 플래그값을 변경하는 방법이 있습니다.</p><h1 id="b027faaa-473d-4323-ba26-1a5e5651a0cc" class=""><strong>작업 진행</strong></h1><hr id="400e53b1-3703-4693-a2be-a40bfc0af9af"/><h3 id="b222d080-67e4-4748-b3f1-02ba5e8b2e88" class=""><strong>📖작업목록 계획</strong></h3><ul id="194d66dc-8cd4-4879-8d26-8a94231e6e66" class="bulleted-list"><li style="list-style-type:disc"><strong>✅ 전시딜 MongoDB 구축</strong><ul id="247a5772-ad8d-4ec1-ba2d-d9c6a68efbf1" class="bulleted-list"><li style="list-style-type:circle">수집 속도 개선(=갱신속도 개선)</li></ul><ul id="139b303e-cf2d-4b7e-8d71-14ae87bb6c48" class="bulleted-list"><li style="list-style-type:circle">적재대상 딜 대상을 추출 및 Kafka로 메시지 수집 및 MongoDB적재</li></ul></li></ul><ul id="79f55627-23a8-42ee-a2ee-ad8476306ba2" class="bulleted-list"><li style="list-style-type:disc"><strong>✅ 전시 API MongoDB 컬렉션 참조로 변경</strong><ul id="5d6270f1-6749-42d3-8577-260ac675ccc0" class="bulleted-list"><li style="list-style-type:circle">롤백 장치 생성(기존 Oracle Serving 테이블 조회)</li></ul><ul id="52439d81-8cde-4e85-94fc-3448abde7148" class="bulleted-list"><li style="list-style-type:circle">Oracle 서빙 테이블과 MongoDB 서빙 컬렉션의 구조 차이로 인한 가공 로직 변경</li></ul></li></ul><ul id="e1d1d6b6-7998-48e3-a77c-1b4512d6721a" class="bulleted-list"><li style="list-style-type:disc"><strong>✅ 검증기 구축</strong><ul id="294ea517-9355-4f7c-bf95-8313ac6ad401" class="bulleted-list"><li style="list-style-type:circle">MongoDB 적재 데이터 검증을 위한 Validator 작성</li></ul><ul id="01276d33-9f79-4abd-ae0f-dc21a1e31daa" class="bulleted-list"><li style="list-style-type:circle">영향범위 API 응답값 검증을 위한 Validator 작성<ul id="ac193d47-bf56-468b-af7f-10f9e0772313" class="bulleted-list"><li style="list-style-type:square">Oracle 서빙 테이블 vs MongoDB 서빙 컬렉션 조회 정합성 비교 (총 개수, 각 필드 별 값)</li></ul><ul id="3184e272-da3b-4bd4-9252-0cf0552a4480" class="bulleted-list"><li style="list-style-type:square">Elasticsearch를 활용한 실시간 모니터링</li></ul></li></ul></li></ul><h3 id="55072609-b47e-406f-a8a9-c086e29ac8c7" class=""><strong>이제 열심히 개발을 해봅니다</strong></h3><p id="222a2994-1a36-472e-b30c-44561487ab52" class="">출처: https://blog.naver.com/youth_pear/222842134763</p><h3 id="5e96c3bc-2331-4cff-b37a-896e1fc69ee3" class=""><strong>완성: TO-BE 모델</strong></h3><p id="818a4045-5df2-4e19-9c2f-4137da530810" class="">플로우(flow): 원천DB에서 대상 데이터 수집 → 메시지발행 → 메시지 수집 및 데이터 가공 → MongoDB 데이터 적재/구축 → API에서 적재된 데이터 사용 → API 응답값 검증</p><figure id="acdd6071-f003-4d9d-abf4-a0900aeaa23e" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled7.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled7.png"/></a></figure><h3 id="ba1d6fad-2630-4aed-8e3d-8ff5e031e96f" class=""><strong>데이터 구축 (SpringBatch, Kafka, MongoDB)</strong></h3><ul id="417ffa73-b768-4377-8afb-1d2064036171" class="bulleted-list"><li style="list-style-type:disc">딜 정보 수집대상 추출 및 메시지 발행 배치 생성<ul id="0600832e-23fc-4f49-982a-57bd43182b3e" class="bulleted-list"><li style="list-style-type:circle">Oracle Serving 테이블 생성 PL/SQL 중, 필요한 딜 정보 생성부분을 분리해내어 추출 배치 생성<ul id="c4a66343-3bbf-421b-966e-7f93e382550a" class="bulleted-list"><li style="list-style-type:square">정각에 정확한 딜정보를 노출해야하는 타임딜은 더 빠른 상품정보 갱신을 위해 <strong>타임딜상품 정보 갱신배치 추가 생성</strong>하여 정확도를 높임</li></ul><ul id="51d8197a-a1ac-4d8b-b231-3843c9be0f52" class="bulleted-list"><li style="list-style-type:square">성능 향상을 위해, <strong>데이터가 많은 딜 정보는 별도의 배치를 추가 생성</strong>하여 데이터를 추출</li></ul><ul id="24ed3886-cbdf-49d0-98a6-5acc66904614" class="bulleted-list"><li style="list-style-type:square"><strong>멀티스레드(thread-pool=5)로 동작</strong>하도록 적용하여 빠른 수집이 이루어지도록 작업</li></ul><ul id="8b8161c3-7ea7-40ba-b964-9e63cac1b8b0" class="bulleted-list"><li style="list-style-type:square"><strong>추출된 딜 정보는 카프카로 메시지 발행</strong>하고 ZeroPayload 방식으로 키값만 송신하여 효율을 높임</li></ul></li></ul></li></ul><ul id="e3b8f741-42c5-483c-8cef-b8dc3c9c27c7" class="bulleted-list"><li style="list-style-type:disc">딜정보 가공 및 적재<ul id="33cd833f-300d-4083-979f-fa9c5dc63dee" class="bulleted-list"><li style="list-style-type:circle">중요한 딜이 덜 중요한 딜정보 메시지에 밀리는 일이 없도록, <strong>배치마다 각각 토픽 나누어 운영하고 메시지를 읽도록 처리</strong></li></ul><ul id="97dbe110-f39e-4058-b53b-ebc3c07e6e19" class="bulleted-list"><li style="list-style-type:circle">Lag의 빠른 소진을 위해 <strong>데이터가 많은 딜은 멀티스레드로(concurrency=3) Conesume</strong> 처리</li></ul><ul id="22e59ffc-f501-460a-880d-d9acd29485e7" class="bulleted-list"><li style="list-style-type:circle">API 조회를 더욱 빠르게 처리하기 위한 전략으로, <strong>데이터 구축 과정에서 데이터 가공 로직을 집중적으로 처리</strong><ul id="e7cb9fca-70d9-49e9-84e2-44c5839cef52" class="bulleted-list"><li style="list-style-type:square">데이터가 이미 가공되어 있으므로 API 조회 시에는 복잡한 처리 없이 데이터를 즉시 사용할 수 있음</li></ul></li></ul><ul id="814f912f-619a-4034-a513-b14f4363c2fe" class="bulleted-list"><li style="list-style-type:circle">조회에 쓰이는 필드에 맞는 단일, 복합 인덱스 생성</li></ul></li></ul><h3 id="48c0380f-3b91-4991-bb8c-9de985eb4cba" class=""><strong>API 적용</strong></h3><ul id="81354ffe-e00e-4f97-b8a5-05efcbb26afa" class="bulleted-list"><li style="list-style-type:disc">OracleDB 조회는 새로 구축된 MongoDB 레포지토리에서 조회되도록 변경</li></ul><ul id="57df7977-0747-4451-a08b-1ff5f9395dba" class="bulleted-list"><li style="list-style-type:disc">MongoDB 조회쿼리 인덱스 활용 조정</li></ul><ul id="e49f8e7f-bfa9-4311-9913-c7d130ab71c9" class="bulleted-list"><li style="list-style-type:disc">기존 로직을 담은 AS-IS 소스코드는 유지하고 변경된 TO-BE 조회 로직은 배포없이 빠르게 롤백 가능한 장치 구성</li></ul><h3 id="4cb9087e-1672-4678-b914-03d9c0025b6c" class=""><strong>검증기 생성</strong></h3><ul id="8a499f54-94fe-4d94-8cf9-40b4225fe904" class="bulleted-list"><li style="list-style-type:disc">5분, 10분 단위 등으로 설정한 스케줄링 단위시간마다 비교할 검증 데이터를 LogStash에 송신하도록 구성</li></ul><ul id="0b6c9b57-36e6-41b1-8ba0-fda584f5a9ab" class="bulleted-list"><li style="list-style-type:disc">ELK 스택을 활용하여 데이터를 수집 및 파싱 후, 데이터 비교 대시보드 구성</li></ul><ul id="f94b84ee-0913-43f9-a31e-f9c198e2bc99" class="bulleted-list"><li style="list-style-type:disc">1차: MongoDB 신규 컬렉션과 Oracle 기존 테이블 데이터 Validator 생성<ul id="3e0c12b9-a568-484d-a7a3-ca677c512759" class="bulleted-list"><li style="list-style-type:circle">방식: 총 데이터 수, 데이터의 차집합을 양방향으로 비교, 랜덤하게 뽑은 딜데이터 비교</li></ul></li></ul><ul id="525a2edd-6fb4-49a5-9c3b-6e0f04f5a3f9" class="bulleted-list"><li style="list-style-type:disc">2차: AS-IS API와 TO-BE API 호출 응답값 데이터 Validator 생성<ul id="973c26b0-ee2c-4c3c-bde7-f66740ea4581" class="bulleted-list"><li style="list-style-type:circle">실제 호출된 Access Log 패턴별 차이나는 응답필드가 있는 경우만 확인할 수 있도록 구성</li></ul></li></ul><h1 id="c2a2ef4b-3337-45d1-a7c6-a541903e0dac" class=""><strong>물론, 시행착오도 있었다.</strong></h1><hr id="60f632f2-1408-4326-928d-fd37e5b7cf47"/><p id="ab517da7-2787-41fe-8630-e4ffa7702bb3" class="">출처: 데브 경수님의 인스타툰 @waterglasstoon</p><h3 id="0ce30d46-c743-41e7-8e7b-b0333adab40a" class=""><strong>1. Embedded Document 미갱신</strong></h3><p id="b48aeed4-1630-4260-90da-c84c07182d52" class="">출처: 데브 경수님의 인스타툰 @waterglasstoon</p><figure id="54ce9a92-f93e-4de8-9ac6-6b432c2d2310" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled9.png"><img style="width:564px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled9.png"/></a></figure><p id="e92122cc-9f0f-47cb-a576-38d6f05e40ab" class="">딜 정보 하위에 임베디드 문서로 상품 정보를 사용했지만,</p><p id="344572a8-c9eb-4f91-8112-4062371c14a8" class="">상품 정보와 딜 정보의 갱신이 개별적으로 이루어지고, 딜 정보가 갱신될 때만 하위의 상품 정보를 갱신하는 문제로,</p><p id="2b555110-2e55-437e-88dc-9b9d272ccffb" class=""><strong>상품 정보의 갱신분이 반영되지 않은 채로 API에서 조회되는 경우가 생겼습니다.</strong></p><p id="3d448762-47d6-4c82-8aee-4ab6a7baf757" class="">딜 정보는 분 단위로 갱신되기 때문에 대부분 빠르게 잘 갱신되었지만,</p><p id="7eab44cb-83f7-42a2-a148-c5be5d39b5af" class=""><strong>가끔 하위의 상품 정보가 미갱신된 상태로 조회되는 경우가 있었는데 정확하게 캐치하지 못한 케이스가 종종 있었습니다.</strong></p><p id="88f06e24-7960-4a81-8788-b2cb235b037e" class="">→ 딜 하위의 임베디드 상품 정보를 활용하지 않는 방향으로 변경하여 대응했고, 성능도 중요하지만 복잡한 로직에서는 로직을 단순하게 가져가는 것도 좋은 방향이라고 생각했습니다.</p><h3 id="e9a4288c-fb19-4a6e-9555-7f9c7ed37483" class=""><strong>2. 예상치 못한 데이터 급증</strong></h3><p id="212d0ec6-b0df-4e7f-94c6-6e62064b5892" class="">1-2분 단위 갱신 딜 정보 → 10분 간의 갱신 지연된 상황이 발생했습니다.</p><p id="abd7f91d-9af9-4dec-8b02-e5167cb54775" class="">최초 상용 배포 직후까지 상용 수집 딜 개수는 16만 건이었고 분 단위 수집 배치 속도에 문제가 없었습니다.</p><p id="39c02b98-15bc-4cdf-a0f3-f40f4fce7e74" class="">하지만, 이후 <strong>37만 건으로 급증한 데이터로 인해 수집 배치 시간이 10분까지 늘어났고 그 동안 딜 정보는 갱신되지 않아 미노출</strong> 되었던 상황이 발생했습니다.</p><figure id="804b049c-91a6-46f6-be73-b68c504cc97c" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled10.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled10.png"/></a></figure><p id="59c27ee0-c7b5-4292-bcff-ca222f5e4c85" class="">→ 해결을 위해, <strong>수집과 적재 처리 시 멀티스레딩 방식으로 변경</strong>하여 처리 속도를 높였고</p><p id="80cdd8f5-fd93-4e9d-93c7-d0723a618166" class="">하나의 배치로 수집했던 배치의 구분점을 찾아 두 개의 배치로 나누고 <strong>각각의 토픽(Topic)으로 메시징 처리되도록 분리</strong>하였습니다.</p><p id="cf13d20a-d177-4d61-b387-63e86e056192" class="">처리 성능을 올릴 수 있는 두 가지 방법을 동원해 해결했습니다.</p><h3 id="8f3ba88f-3b7e-408a-b561-350d8939fb3e" class=""><strong>3. 복잡한 롤백 플랜</strong></h3><p id="3be7db14-06ec-4fb3-b50c-667742354655" class="">최초 상용 테스트 기간에 여러 상황에 대비한 롤백 플랜을 만들고자 하는 생각에 <strong>상황별 대응 가능한 롤백 플랜으로</strong> 만들었습니다.</p><ul id="28b8393b-c18e-4e5d-ad00-c54cb6887276" class="bulleted-list"><li style="list-style-type:disc">2단계까지 단계별로 되돌아갈 수 있도록 구성</li></ul><ul id="8a2b8fc2-ef32-4bbd-828c-5698045574de" class="bulleted-list"><li style="list-style-type:disc">롤백 장치 4개를 삽입하여 원하는 부분만 롤백할 수 있도록 구성<ul id="07133d7b-f7a9-4cb7-80de-d8c24cc0a924" class="bulleted-list"><li style="list-style-type:circle">롤백 장치를 조정하면 직접 데이터 Delete 작업이 필요 하지만, <strong>유연한 롤백 플랜이라고 생각했던 방식이 실제 긴박한 이슈라이징 상황에 어떤 단계로 돌아가야 하는지 오히려 혼란이 되었습니다</strong></li></ul></li></ul><p id="c12ee475-f8d8-43d6-9e90-1d1c656937a5" class="">→ 이후, 롤백 장치 개수는 최소한으로, 롤백 단계는 1단계로 줄이고 롤백 장치 조정 이외 추가 작업은 모두 제거했습니다.</p><p id="c93f2140-c6cf-4ea9-80e5-e2f4e0813992" class="">앞으로 <strong>롤백플랜은 가능한 심플하게 만들고 꼭 필요한 상황이 아니라면 롤백 단계도 최소한으로 줄이는 것이 더 좋은 방향</strong>이라는 생각이 들었습니다.</p><h3 id="cd196758-2e83-410e-822d-370e6f535a91" class=""><strong>4. Validation 대상 선정의 빈틈</strong></h3><p id="d5b166fd-e69e-49c6-811a-2a2ee47e564d" class="">초기 MongoDB에 <strong>적재된 데이터 대상으로만 Validator를 구축</strong>하고 검증 진행을 했습니다.</p><p id="d97cf3b6-1c8f-44da-b87b-1d7e1d884d61" class="">이 방법은 구축된 데이터를 사용하는 로직 부분에서 발생할 수 있는 문제를 캐치하지 못하는 문제가 있었습니다.</p><p id="710eeb67-719e-4904-9017-f07107f707a0" class="">출처: https://chimhaha.net/story/111311</p><figure id="2c6c1011-fd22-487e-a562-cf7a93e174e3" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled11.png"><img style="width:658px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled11.png"/></a></figure><p id="e23fa352-547c-4ded-b8f9-f0819173294c" class="">→ validation 대상을 5분, 10분, 20분 단위로 스케줄러를 생성하여 주기적으로 <strong>최종 API의 응답 결과를 비교</strong>하는 방향으로 수정되었습니다</p><p id="4cf7a042-4036-48a9-9f74-1183d521c83c" class="">새로 구축된 데이터 검증도 중요하지만,</p><p id="ee491ec3-5b5f-4539-a53c-30b664631141" class="">결국 최종적으로 영향이 가는 API 응답 결과를 검증하는 것이 더 우선으로 보아야 모든 문제를 체크할 수 있었습니다.</p><h1 id="78996837-b4f8-4017-8188-746fb789d9a9" class=""><strong>프로젝트 결과 및 개선 사항</strong></h1><hr id="ce333b4b-7596-407f-9b01-0fc87198a6a4"/><ul id="ba3a95b1-c268-4157-885c-59fc89c8db7c" class="bulleted-list"><li style="list-style-type:disc">프로젝트 결과<ul id="580700ca-05f1-4c2e-bd40-89bf27c17be2" class="bulleted-list"><li style="list-style-type:circle">MongoDB 적용으로 오라클 커넥션이 제거되어 대량 트래픽에서 API 응답 지연이 크게 개선되었습니다.</li></ul><figure id="71abecd3-c4d7-4943-8a19-fb670c43e1be" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled12.png"><img src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled12.png"/></a></figure><figure id="b5a453f6-3d39-465a-9734-0fc77ea857c5" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled13.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled13.png"/></a></figure><figure id="97a5ebdd-d3a8-442d-b65e-54defeb7af33" class="image"><a href="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled14.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2024-06-07-retrospective-deal-internalization/Untitled14.png"/></a></figure><ul id="879d1c07-77e8-4bd4-b6c2-eecb236f26de" class="bulleted-list"><li style="list-style-type:circle">딜 갱신 속도가 빨라져 행사 기간 중 급격한 데이터 증가에도 안정적으로 대응할 수 있게 되었습니다.</li></ul><ul id="6fec30db-a27a-455b-bb1e-1cbbe1a91e11" class="bulleted-list"><li style="list-style-type:circle">Oracle 의존성이 제거되었습니다.</li></ul><ul id="6998eb6b-730a-40ae-80f6-6db9e40e943e" class="bulleted-list"><li style="list-style-type:circle">OracleDB와 mongoDB 모두 확인해야 했던 디버깅 지점이 MongoDB로 단순화되었습니다.<p id="2481f0cb-fba5-4c10-adf2-e8c131d02527" class="">이로서, 이슈 대응이 편해졌고, 요구사항에 대한 기민한 대응도 가능해졌습니다.</p></li></ul></li></ul><p id="6885b07a-e662-4ac9-b890-b1385e162c8a" class="">짜란다 짜란다 , 출처: 데브 경수님의 인스타툰 @waterglasstoon</p><h1 id="611c135f-ef3a-4621-875b-2bb6ac4dfc8a" class=""><strong>마치며…</strong></h1><hr id="037d1584-7d1b-4ea3-ba08-bd27c7711031"/><ul id="077a8e77-231e-4a10-be96-1b1cb0c45d90" class="bulleted-list"><li style="list-style-type:disc"><strong>추가 개선 포인트와 향후 계획</strong><ul id="0a7c221c-fdac-4b03-9ffc-e61d90cde023" class="bulleted-list"><li style="list-style-type:circle">최초 데이터 적재 이후 갱신이 필요 없는 필드와 지속적인 갱신이 필요한 필드를 구분하면 갱신에 필요한 리소스를 줄여 더 가벼워질 수 있음</li></ul><ul id="0b42133b-9221-401a-adc5-281c1628ab85" class="bulleted-list"><li style="list-style-type:circle">이어서 향후 Event 기반의 CDC Platform인 카시타(Casita) 에서 딜 정보를 받아오는 방식으로 전환한다면 딜 수집 리소스도 줄일 수 있음</li></ul><ul id="a8828fb2-e44e-403e-a6f6-1f596991eb86" class="bulleted-list"><li style="list-style-type:circle">상품 정보와 딜 정보를 로직상 완전히 분리되도록 리팩토링하면 유지 보수성을 더 높일 수 있음</li></ul></li></ul><p id="8ef63ed7-0362-4822-bddc-a0ec897e1157" class="">현재는 안정적인 운영이 이루어지는지 모니터링하고 있는 중이고</p><p id="825510eb-f8c6-4ab8-bb4e-a6625aa0b8c7" class="">조만간 롤백을 위해 만들어두었던 코드 및 기타 AS-IS 코드를 삭제할 예정입니다.</p><p id="6d1afc82-51d7-4ae5-b9e6-ddf242e342a9" class="">그리고 프로젝트 진행 간 생긴 지저분해진 코드 정리와 개선 포인트의 진행도 계획하고 있습니다.</p><ul id="1ba2d0be-579a-442d-862a-7d86ad91de95" class="bulleted-list"><li style="list-style-type:disc"><strong>느낀점</strong></li></ul><p id="d2029020-69a5-4457-a78d-86214569fc72" class="">이번 회고 글에 넣기에는 너무 소소했던 삽질부터</p><p id="bc84473d-044c-4937-966c-a870ab74756a" class="">실제 상용 환경에서 겪은 큰 이슈들까지 많은 시행착오를 통해 이전보다 더 단단해진 느낌입니다.</p><p id="4690f66a-90d2-41dc-8372-aa710a30a6cf" class="">돌이켜 생각해보면, 평소 스스로 꼼꼼한 편이라고 생각했던 저는, 가끔 놓치는 부분들이 분명히 존재했고</p><p id="e3e1d774-abd0-43f7-a26d-bb4e69e0af13" class="">작업 흐름과 필요한 정보를 알고 있지만, 정확히 이해하고 활용할 줄 몰랐던 상황들이 있었습니다.</p><p id="d678acfc-5192-4604-a58e-e38f2a59e2d3" class="">특히 복잡하고 깊은 고민이 필요한 부분을 쉽게 해결하지 못하고 혼자 고민만 하고 있었습니다.</p><p id="582efcd7-93ec-4c16-b868-178cb78f374a" class="">이러한 부족한 점들을 개선하기 위해 앞으로 프로젝트 진행 상황과 내용을 단계별로 메모하여 주기적으로 정리하려고 합니다.</p><p id="db67c455-7550-482d-a880-614a0e525f6e" class="">크고 복잡한 문제는 작게 쪼개어 분할하여 해결하고, 이렇게 간결한 내용들이 이어져 전체적인 플로우가 만들어지도록 해야겠다고 느꼈습니다.</p><p id="4e8129ff-f257-469b-a3f7-488a5e36d931" class="">다행히도 프로젝트 진행 간, 11번가의 일을 위해서는 자기의 시간을 아끼지 않고 너나 할 것 없이 적극적으로 도움을 주고 싶어 하시는 분들이 많았기에</p><p id="0e88aee0-db7f-4217-a5b9-dac202325bb0" class="">어려운 상황들을 하나씩 헤쳐나갈 수 있어 뿌듯함과 동료애를 느낄 수 있었고,</p><p id="e4f9c266-dee8-4e70-b422-e342873f44c4" class="">앞으로 저도 어려운 상황에 다른 분들에게 적극적인 도움을 줄 수 있는 사람이 되어야겠다고 다짐했습니다.</p><p id="1f6f279a-de9e-47d9-9232-46781d880e12" class="">느꼈던 바를 발판 삼아, 앞으로도 지속적인 개선을 통해 더 나은 서비스를 제공할 수 있도록 노력하겠습니다.</p><p id="c85b395f-f1ee-4d66-9953-b0c34ffbbb90" class="">
</p><figure id="b99e071f-548a-4b3f-b67c-86dbf6acfee7"><a href="https://11st-tech.github.io/2024/06/07/retrospective-deal-internalization/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">전시 딜 내재화 프로젝트 회고: MongoDB 기반 데이터 구축과 API 개선 과정 | 11번가 TechBlog — 11번가 기술블로그</div><div class="bookmark-description">안녕하세요, 11번가 전시서비스개발팀의 서장원입니다. 전시 딜 내재화 업무를 맡아 진행했던 과정과 개선 작업이 갖는 의미에 대한 개인적인 회고를 공유해 보고자 합니다. 내용 이해를 돕기위해, 기초적인 질문을 던져봅니다. 출처: https://chimhaha.net/story/111311 ‘딜’ 그리고 ‘내재화’ 라는게 무슨 뜻인가요? 딜은 상품 판매를 위한 판촉행사라고 생각하면 쉽습니다. 예를 들어, 단 10일간! 사과 한 박스에 단돈 3만원! 내재화는 외부 기술/데이터를 가져와서 우리만의 특성에 맞게 조정하고 직접 관리한다는 뜻입니다. 즉, 상품의 판촉행사 정보를 보여주는 영역에 필요한 정보는 우리 전시서비스개발팀에서 직접 구축하고 입맛에...</div></div><div class="bookmark-href"><img src="https://11st-tech.github.io/assets/apple-touch-icon.png" class="icon bookmark-icon"/>https://11st-tech.github.io/2024/06/07/retrospective-deal-internalization/</div></div><img src="https://11st-tech.github.io/assets/images/og_image.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="f75b26b4-62c5-411f-ae25-612a8a59958f" class="toggle"><li><details open=""><summary>Naver - 분산디비지만 노출은 하고싶어 - mongo로 노출 전용 DB 만들기</summary><h3 id="292aad2f-525c-4c18-a317-7dbbfb19a320" class="">노출DB란?</h3><ul id="e172bba9-b541-4d94-b557-a762a6a5e6e9" class="bulleted-list"><li style="list-style-type:disc">쇼핑의 메인DB는 citus를 활용한 postgreSql로 분산DB입니다.</li></ul><ul id="06ff21bf-c511-4a89-9460-cb2744a3b1cc" class="bulleted-list"><li style="list-style-type:disc">이를 노출에 알맞은 형태로 가공해 새로운 DB를 만든 것이 노출DB입니다.</li></ul><ul id="d3a49493-8643-4781-89f1-12f83c998170" class="bulleted-list"><li style="list-style-type:disc">postgreSql의 CDC 데이터를 받아서, kafka를 통해 데이터를 재가공, mongo에 적재하는 프로젝트입니다</li></ul><figure id="5dc8ad23-e15f-4030-8ab6-0a03ecf68ef9" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-09_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.09.03.png"><img style="width:673.991455078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-09_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.09.03.png"/></a></figure><p id="1f384563-7d7a-496c-99f1-fb91bf0d3f0d" class="">
</p><figure id="3cf8b606-c6bb-4461-ad56-621fabc3cd23" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-09_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.07.51.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-09_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.07.51.png"/></a></figure><p id="c3e00d40-6944-46c1-af5c-955002271051" class="">
</p><figure id="5c629fd9-ffbd-4136-939f-2a0f9017ce97" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-09_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.17.26.png"><img style="width:573.991455078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-09_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.17.26.png"/></a></figure><p id="2f8cfb90-28f4-453d-885f-8115cbbc5584" class="">
</p><figure id="486c83c8-3d47-490e-b06c-5d1ea409d82b" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-09_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.30.22.png"><img style="width:637.96875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-09_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.30.22.png"/></a></figure><p id="24708081-45d5-426b-8aec-cdebfb3a6b98" class="">
</p><figure id="95af6bce-dd3d-463d-b2c9-973d18cd2866"><a href="https://d2.naver.com/helloworld/4381253" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">분산디비지만 노출은 하고싶어 - mongo로 노출 전용 DB 만들기</div><div class="bookmark-description">네이버 사내 기술 교류 행사인 NAVER ENGINEERING DAY(7월)에서 발표되었던 세션을 공개합니다.          이번 발표를 통해서 노출을 위해 고군분투했던 제 경험..</div></div><div class="bookmark-href"><img src="https://d2.naver.com/favicon.ico" class="icon bookmark-icon"/>https://d2.naver.com/helloworld/4381253</div></div><img src="https://d2.naver.com/content/images/2023/08/-----------2023-08-16-------11-26-57.png" class="bookmark-image"/></a></figure><p id="d8c18715-c772-4353-b619-30feb62d1558" class="">
</p></details></li></ul><ul id="f8b26985-edab-4ead-99fd-952c74ed4601" class="toggle"><li><details open=""><summary>DB Slow Query 개선 방안</summary><p id="e4644703-0335-445d-94c0-9855ba51a53a" class="">DB의 슬로우 쿼리를 개선하는 방법은 다양한 기법을 활용하여 쿼리의 효율성을 높이고 데이터베이스의 부하를 줄이는 것을 목표로 합니다. 아래에서는 DB의 슬로우 쿼리를 개선하는 방법을 기술별로 설명하고 그에 따른 세부적인 장단점을 분석하겠습니다.</p><h3 id="cb8e4196-3063-4ee2-9c6c-1cfc531d31e7" class="">1. 쿼리 리팩토링(Query Refactoring)</h3><h3 id="567a9108-9e7e-46a2-b673-29f2ca8fd736" class="">방법</h3><ul id="945936da-0758-4d54-bdc9-b0a16e3882f3" class="bulleted-list"><li style="list-style-type:disc"><strong>불필요한 조인 제거</strong>: 복잡한 조인을 단순화하거나 필요 없는 조인을 제거합니다.</li></ul><ul id="24fe0be8-9394-4c8d-9151-6ee50ddc9641" class="bulleted-list"><li style="list-style-type:disc"><strong>서브쿼리 대신 조인 사용</strong>: 서브쿼리를 피하고, 조인을 사용하여 필요한 데이터를 가져옵니다.</li></ul><ul id="7688a02a-39c9-4aa2-8ecb-4b0b4558bda4" class="bulleted-list"><li style="list-style-type:disc"><strong>필요한 데이터만 선택</strong>: <code>SELECT *</code> 대신 필요한 열만 선택합니다.</li></ul><ul id="fb0818a5-403a-47b4-8cdb-a40b85e2e0ea" class="bulleted-list"><li style="list-style-type:disc"><strong>범위를 좁히는 조건 추가</strong>: WHERE 절에 필요한 조건을 추가해 반환되는 데이터의 범위를 줄입니다.</li></ul><ul id="0bfc4d8e-9c2a-40f7-869e-b6170291a7f4" class="bulleted-list"><li style="list-style-type:disc"><strong>LIMIT 절 사용</strong>: 필요할 경우 반환되는 행 수를 제한합니다.</li></ul><h3 id="ec5e8de9-eabf-435e-a64c-8343593e3d88" class="">장점</h3><ul id="17640946-0536-4f43-a620-8ec4dcbb98c2" class="bulleted-list"><li style="list-style-type:disc">성능을 개선할 수 있는 직접적인 방법입니다.</li></ul><ul id="c48828cc-8b31-4fac-a69d-4333cd978290" class="bulleted-list"><li style="list-style-type:disc">데이터베이스의 부하를 줄이고, 응답 시간을 개선할 수 있습니다.</li></ul><h3 id="810c61f6-71c7-46c3-a04c-86e8ac2feeb2" class="">단점</h3><ul id="ed7a799f-a277-41aa-a876-30912d4832b7" class="bulleted-list"><li style="list-style-type:disc">쿼리 구조에 대한 깊은 이해가 필요합니다.</li></ul><ul id="1d4c6ce2-7ca8-4f6e-8e40-41ca32aac5ec" class="bulleted-list"><li style="list-style-type:disc">복잡한 쿼리의 경우 리팩토링에 시간이 많이 걸릴 수 있습니다.</li></ul><h3 id="0c9f833c-610d-4987-b978-35998281e73b" class="">2. 인덱싱(Indexing)</h3><h3 id="1b5cfe53-bcca-4be1-8539-5de43f5eab6f" class="">방법</h3><ul id="789b5d33-be27-43bb-8f66-8778b2417189" class="bulleted-list"><li style="list-style-type:disc"><strong>적절한 인덱스 추가</strong>: 슬로우 쿼리에서 사용되는 열에 대해 적절한 인덱스를 추가합니다.</li></ul><ul id="024aa6fa-fd75-4f1d-86eb-69435e3bb3cc" class="bulleted-list"><li style="list-style-type:disc"><strong>복합 인덱스 사용</strong>: 여러 조건을 가진 쿼리의 경우 복합 인덱스를 사용합니다.</li></ul><ul id="95238afe-8f1c-49e7-afe4-7760f67fc125" class="bulleted-list"><li style="list-style-type:disc"><strong>사용되지 않는 인덱스 제거</strong>: 데이터베이스의 인덱스를 주기적으로 검토하고 사용되지 않는 인덱스를 제거합니다.</li></ul><h3 id="73f22f1f-4f8a-4537-ae73-773992c8e812" class="">장점</h3><ul id="d47b1158-8333-49f1-a35e-808b8640ecbd" class="bulleted-list"><li style="list-style-type:disc">인덱스를 사용하면 데이터 검색 속도가 크게 향상됩니다.</li></ul><ul id="09be0b8f-29bd-4f86-9a3b-e4282ceb4828" class="bulleted-list"><li style="list-style-type:disc">읽기 작업의 성능을 크게 향상시킬 수 있습니다.</li></ul><h3 id="6b049b11-86e6-466a-8666-4e2bba7c41da" class="">단점</h3><ul id="543e3dc5-88a0-4d86-bc5e-fc76c15bc458" class="bulleted-list"><li style="list-style-type:disc">인덱스가 많은 경우 쓰기 작업이 느려질 수 있습니다.</li></ul><ul id="9d9a98d9-b808-47b2-bc45-ddf6c6139f09" class="bulleted-list"><li style="list-style-type:disc">인덱스 관리를 위한 추가 공간이 필요합니다.</li></ul><h3 id="ae5e7975-8748-4ea5-b2ed-2ba44584e7c2" class="">3. 실행 계획(Execution Plan) 분석</h3><h3 id="c2de6bea-5b17-40d5-8e6b-9b8742a109c4" class="">방법</h3><ul id="ff622c6b-44b7-4939-940a-b01b8dbec216" class="bulleted-list"><li style="list-style-type:disc"><strong>실행 계획 확인</strong>: <code>EXPLAIN</code> 또는 <code>EXPLAIN ANALYZE</code> 명령을 사용하여 쿼리 실행 계획을 확인합니다.</li></ul><ul id="d35332bc-377b-44a4-89bd-35f91b94a239" class="bulleted-list"><li style="list-style-type:disc"><strong>병목 지점 파악</strong>: 쿼리 실행 계획을 통해 쿼리의 병목 지점을 파악합니다.</li></ul><ul id="979f5601-8338-4f23-b678-2b724e7ad742" class="bulleted-list"><li style="list-style-type:disc"><strong>실행 계획 최적화</strong>: 병목 지점을 해결하기 위해 인덱스를 추가하거나 쿼리를 리팩토링합니다.</li></ul><h3 id="c4662b2b-bcaa-4c67-a16e-8345279b305e" class="">장점</h3><ul id="0e0b1b5c-f864-4ebf-a85c-09e3ce5a5fb7" class="bulleted-list"><li style="list-style-type:disc">쿼리의 실행 흐름을 파악할 수 있어, 최적화 방향을 쉽게 찾을 수 있습니다.</li></ul><ul id="5219aace-d38a-441b-a935-61dc8de46be4" class="bulleted-list"><li style="list-style-type:disc">실행 계획의 변경을 통해 즉각적인 성능 개선이 가능합니다.</li></ul><h3 id="b7755538-b9a5-4a22-bb76-de7852bc74c7" class="">단점</h3><ul id="2673c058-19b9-4249-84bc-795cf4915fa4" class="bulleted-list"><li style="list-style-type:disc">실행 계획을 이해하고 분석할 수 있는 전문 지식이 필요합니다.</li></ul><ul id="91d116a7-b72c-4d05-97e0-7a3a53c90a0c" class="bulleted-list"><li style="list-style-type:disc">실행 계획은 데이터베이스 상태에 따라 변경될 수 있으므로 지속적인 모니터링이 필요합니다.</li></ul><h3 id="97db7405-87e7-4571-b298-e00a0cd19489" class="">4. 데이터베이스 설정 최적화</h3><h3 id="2450a86b-88e0-4dbe-ae9d-dee23e2a65b1" class="">방법</h3><ul id="ae35c0f4-81ae-4bce-a8d3-58adf1ba9f4c" class="bulleted-list"><li style="list-style-type:disc"><strong>메모리 설정 조정</strong>: 쿼리 실행에 필요한 메모리를 충분히 제공하도록 데이터베이스 설정을 조정합니다.</li></ul><ul id="cb079787-54ff-4088-b46a-f4ac2162ea02" class="bulleted-list"><li style="list-style-type:disc"><strong>커넥션 풀 설정 최적화</strong>: 커넥션 풀의 크기와 설정을 최적화합니다.</li></ul><ul id="23ecd80b-c7e8-47f7-b2e1-1d57055dc7bc" class="bulleted-list"><li style="list-style-type:disc"><strong>로그 설정 조정</strong>: 슬로우 쿼리 로그 설정을 조정하여 성능에 영향을 주지 않도록 합니다.</li></ul><h3 id="4cad964e-5ce7-46bc-8520-45a08fa18957" class="">장점</h3><ul id="07b9a68a-30a5-4ed3-a816-24bb6b820320" class="bulleted-list"><li style="list-style-type:disc">데이터베이스의 전반적인 성능을 개선할 수 있습니다.</li></ul><ul id="cad814b4-3984-430f-a223-7e494f2972c1" class="bulleted-list"><li style="list-style-type:disc">시스템 리소스를 효율적으로 사용하여 성능을 최적화할 수 있습니다.</li></ul><h3 id="02809221-6bd2-49aa-90c5-18cf8d9c6d1d" class="">단점</h3><ul id="8f713028-78e1-4a53-8246-f466ac235a6b" class="bulleted-list"><li style="list-style-type:disc">설정 변경이 성능에 미치는 영향을 예측하기 어렵습니다.</li></ul><ul id="b1966560-d46b-4b6c-9ed2-aae1094b8d82" class="bulleted-list"><li style="list-style-type:disc">잘못된 설정은 오히려 성능을 저하시킬 수 있습니다.</li></ul><h3 id="127ad7e5-a20b-4557-9be0-5cfa9e6906b0" class="">5. 데이터 모델링 개선</h3><h3 id="082c62e1-3d52-498f-be60-417d1ff3f0b1" class="">방법</h3><ul id="d981735c-0a90-4721-8a4a-716cad112a9b" class="bulleted-list"><li style="list-style-type:disc"><strong>정규화 및 비정규화</strong>: 필요한 경우 테이블을 정규화하거나 비정규화하여 성능을 개선합니다.</li></ul><ul id="4e680cce-bbb9-4953-8845-852909830e4c" class="bulleted-list"><li style="list-style-type:disc"><strong>적절한 데이터 타입 사용</strong>: 데이터 타입을 적절하게 사용하여 저장 공간과 성능을 최적화합니다.</li></ul><ul id="068112fc-7ed3-4a85-8221-aa646cb8631d" class="bulleted-list"><li style="list-style-type:disc"><strong>관계형 설계 개선</strong>: 관계형 데이터베이스의 설계를 개선하여 쿼리 성능을 향상시킵니다.</li></ul><h3 id="decd44d9-817d-4568-8509-2bf4bf3aa60e" class="">장점</h3><ul id="f1c431e1-af0d-41ae-8df6-d74b47646fbe" class="bulleted-list"><li style="list-style-type:disc">데이터 구조를 효율적으로 개선할 수 있습니다.</li></ul><ul id="7898b38f-76b7-4f26-80cb-d6d826ac4286" class="bulleted-list"><li style="list-style-type:disc">장기적으로 데이터베이스 성능에 긍정적인 영향을 줄 수 있습니다.</li></ul><h3 id="7e316c4b-5882-46ca-9208-265cc3a7f597" class="">단점</h3><ul id="36abf1da-952f-4ff8-b79a-5eda6e525008" class="bulleted-list"><li style="list-style-type:disc">데이터 모델링 변경은 시간이 오래 걸릴 수 있으며, 기존 애플리케이션과의 호환성 문제를 야기할 수 있습니다.</li></ul><ul id="7e993f03-92ec-4332-a1b0-9bad9f11dc7f" class="bulleted-list"><li style="list-style-type:disc">데이터 모델링의 변경은 리스크가 따르므로 신중하게 계획되어야 합니다.</li></ul><h3 id="f376d886-8f4d-4220-a308-0a26f4197a17" class="">6. 데이터 캐싱</h3><h3 id="da565dc9-bc0f-4632-9cd2-148c5a0bb582" class="">방법</h3><ul id="5a193a8a-5716-4ff1-9ec6-5b315c7e24a3" class="bulleted-list"><li style="list-style-type:disc"><strong>결과 캐싱</strong>: 자주 사용되는 쿼리 결과를 캐싱하여 데이터베이스의 부하를 줄입니다.</li></ul><ul id="4a72c151-6633-4417-a5f7-d727dcfb8687" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 캐싱</strong>: 데이터베이스에서 자주 액세스되는 데이터를 메모리에 캐싱합니다.</li></ul><h3 id="2db43b8e-4e04-4fbf-8c9c-7647dd836777" class="">장점</h3><ul id="b741aeb6-0d60-4c9a-bb6d-e47be5b336dc" class="bulleted-list"><li style="list-style-type:disc">데이터베이스의 부하를 줄이고, 응답 시간을 개선할 수 있습니다.</li></ul><ul id="737d80af-f0e1-431f-b3e0-1676c814a66c" class="bulleted-list"><li style="list-style-type:disc">자주 사용되는 쿼리에 대한 빠른 응답을 제공할 수 있습니다.</li></ul><h3 id="4aa39dea-6f46-4996-89e1-938040ab30ad" class="">단점</h3><ul id="140565b2-40e2-4a74-9532-190dd272e6cb" class="bulleted-list"><li style="list-style-type:disc">캐시 일관성 문제를 관리해야 합니다.</li></ul><ul id="3a79221b-a6fb-411b-ae56-e0fb0c044df8" class="bulleted-list"><li style="list-style-type:disc">캐시를 관리하고 설정하는 데 추가 노력이 필요합니다.</li></ul><h3 id="353e713a-308a-4aa4-9fd5-aa62bf41f453" class="">7. 데이터 파티셔닝(Partitioning)</h3><h3 id="c78b8838-3bb9-4791-9416-124853f81ba0" class="">방법</h3><ul id="32d9e155-9f4c-4882-95d7-462389cd4f9e" class="bulleted-list"><li style="list-style-type:disc"><strong>테이블 파티셔닝</strong>: 테이블을 파티셔닝하여 성능을 개선합니다.</li></ul><ul id="7b64fa62-7185-432f-acff-f85a3ae73996" class="bulleted-list"><li style="list-style-type:disc"><strong>인덱스 파티셔닝</strong>: 인덱스를 파티셔닝하여 쿼리 성능을 향상시킵니다.</li></ul><h3 id="f64e40d0-d29b-4d2c-b8b0-1730d7e5a466" class="">장점</h3><ul id="c1e73e09-6ec3-40e8-b56b-cab818f25a64" class="bulleted-list"><li style="list-style-type:disc">대용량 데이터 처리 시 성능을 크게 향상시킬 수 있습니다.</li></ul><ul id="ec9cd841-3348-44f1-9a1a-01806772fa57" class="bulleted-list"><li style="list-style-type:disc">특정 파티션에 대한 쿼리 성능을 최적화할 수 있습니다.</li></ul><h3 id="4bdec55c-2a99-4f3d-874f-d56861a0a1b9" class="">단점</h3><ul id="21f5b4ce-1b9c-438d-a25a-1b26deec8330" class="bulleted-list"><li style="list-style-type:disc">파티셔닝 전략 설계 및 관리가 복잡할 수 있습니다.</li></ul><ul id="669e7d70-1408-4318-99f5-30f7d969824c" class="bulleted-list"><li style="list-style-type:disc">파티셔닝으로 인한 추가적인 데이터베이스 오버헤드가 발생할 수 있습니다.</li></ul><h3 id="8fb2eb39-9f3a-41b6-8ea4-bfaad39c21cb" class="">8. 쿼리 프로파일링(Query Profiling)</h3><h3 id="8dbb3eb5-9c7b-43d7-bffb-5861d44cf01e" class="">방법</h3><ul id="c50a0976-aba5-4ea4-9c40-85543c1942ae" class="bulleted-list"><li style="list-style-type:disc"><strong>쿼리 프로파일링 도구 사용</strong>: 데이터베이스에서 제공하는 쿼리 프로파일링 도구를 사용하여 쿼리의 성능을 분석합니다.</li></ul><ul id="3fbed978-b085-4532-b2b3-07c0add43851" class="bulleted-list"><li style="list-style-type:disc"><strong>병목 지점 파악</strong>: 프로파일링을 통해 쿼리의 병목 지점을 파악하고 최적화합니다.</li></ul><h3 id="7dc73088-971b-4b52-8623-c0f6cba7218f" class="">장점</h3><ul id="f4e7c76e-cd1f-47fa-b71d-94b48bb778e0" class="bulleted-list"><li style="list-style-type:disc">쿼리의 성능을 세밀하게 분석할 수 있습니다.</li></ul><ul id="d615ea12-eb2f-459c-8471-fc17d59d4be3" class="bulleted-list"><li style="list-style-type:disc">병목 지점을 쉽게 파악하고 개선할 수 있습니다.</li></ul><h3 id="323daf86-aa0d-4231-a1f8-58e6d60830c7" class="">단점</h3><ul id="ded167a2-b793-4f87-bd99-85de8675521d" class="bulleted-list"><li style="list-style-type:disc">쿼리 프로파일링은 많은 시간이 걸릴 수 있습니다.</li></ul><ul id="7a5c7700-02c5-47d1-8858-3a19b69f654d" class="bulleted-list"><li style="list-style-type:disc">전문적인 지식이 필요하며, 프로파일링 결과를 해석하는 데 어려움이 있을 수 있습니다.</li></ul><h3 id="c790dea7-db1b-41ce-a607-91bd42f2731a" class="">9. 데이터베이스 샤딩(Sharding)</h3><h3 id="b836300a-af9a-46f1-b187-7ce507fd17b3" class="">방법</h3><ul id="aca6e7af-5e90-468d-8a92-2b66c3509369" class="bulleted-list"><li style="list-style-type:disc"><strong>수평적 데이터 분할</strong>: 테이블을 여러 샤드로 분할하여 성능을 향상시킵니다.</li></ul><ul id="892e7b11-c864-4980-9c6e-bd47b7604984" class="bulleted-list"><li style="list-style-type:disc"><strong>샤딩 키 선택</strong>: 효율적인 데이터 분할을 위해 적절한 샤딩 키를 선택합니다.</li></ul><h3 id="a505b1ce-aac8-4008-a79e-e5f043e111c6" class="">장점</h3><ul id="7409e83c-cdaf-47fa-a99a-cc122654bc8e" class="bulleted-list"><li style="list-style-type:disc">대용량 데이터베이스의 부하를 분산하여 성능을 향상시킬 수 있습니다.</li></ul><ul id="1afeddef-cab7-4207-8612-dc529eb63e31" class="bulleted-list"><li style="list-style-type:disc">특정 샤드에 대한 쿼리 성능을 최적화할 수 있습니다.</li></ul><h3 id="29f6f030-06c0-408a-987b-d94952987986" class="">단점</h3><ul id="5232956c-0a15-4c17-a992-b247c07d7e22" class="bulleted-list"><li style="list-style-type:disc">샤딩은 데이터베이스 아키텍처를 복잡하게 만들 수 있습니다.</li></ul><ul id="903c544d-16cf-49f1-ac9f-361f76bab8f1" class="bulleted-list"><li style="list-style-type:disc">샤딩으로 인한 데이터베이스 관리 및 유지보수 비용이 증가할 수 있습니다.</li></ul><h3 id="9a50ffff-2d46-49c6-9ad7-b940125ff37f" class="">10. 데이터 압축(Data Compression)</h3><h3 id="24b7af8a-5133-4d02-91a7-6ba15abf31ab" class="">방법</h3><ul id="786141ec-f87c-4abc-a5a3-055a743cc7c2" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 압축 기능 사용</strong>: 데이터베이스에서 제공하는 데이터 압축 기능을 사용하여 저장 공간을 최적화하고 성능을 향상시킵니다.</li></ul><h3 id="5cf3d893-f5d8-4062-8e1a-2ee7c5505502" class="">장점</h3><ul id="82c972bd-37fb-4705-813e-f5d399d74314" class="bulleted-list"><li style="list-style-type:disc">저장 공간을 줄여 디스크 I/O 성능을 개선할 수 있습니다.</li></ul><ul id="f0d2de79-c219-4b9d-a29c-537c8b63d916" class="bulleted-list"><li style="list-style-type:disc">압축된 데이터를 읽을 때 성능을 향상시킬 수 있습니다.</li></ul><h3 id="815d0d5e-21b9-41ce-8032-440b92ea02fe" class="">단점</h3><ul id="4b3f70e1-8bdc-4e4e-a976-65dc2404ba2d" class="bulleted-list"><li style="list-style-type:disc">데이터 압축 및 압축 해제 과정에서 CPU 부하가 증가할 수 있습니다.</li></ul><ul id="f00589b8-aa83-4094-93c6-c156fd591fd0" class="bulleted-list"><li style="list-style-type:disc">모든 데이터에 대한 압축이 효과적이지 않을 수 있습니다.</li></ul><hr id="a3c471f8-05c6-4ac7-aeca-8574f303f81b"/><p id="ed893eef-383b-43e9-9e4e-a4f5f37f0caa" class="">슬로우 쿼리 개선을 위한 여러 기술 중 적절한 방법을 선택하여 적용하는 것이 중요합니다. 각 방법은 특정 상황에서 더 효과적일 수 있으며, 여러 방법을 복합적으로 적용하여 최상의 성능을 얻을 수 있습니다. 데이터베이스의 종류, 데이터 특성, 사용 사례 등을 고려하여 최적화 전략을 수립하는 것이 필요합니다.</p></details></li></ul><ul id="473c5953-6542-4cd1-a7e9-93938d196ecc" class="toggle"><li><details open=""><summary>DB 성능 개선</summary><p id="fbdc1efd-5d22-472c-9626-0acfd76eb733" class="">데이터베이스(DB) 성능 개선을 위한 기술은 여러 가지가 있으며, 각각의 기술은 특정 상황에 유용하고 다른 상황에서는 덜 효과적일 수 있습니다. 성능 개선 기술은 크게 <strong>데이터베이스 아키텍처, 하드웨어 구성, 쿼리 최적화, 인덱싱, 캐싱, 샤딩, 리플리케이션, 파티셔닝, 데이터베이스 설정 및 튜닝</strong> 등으로 나눌 수 있습니다. 아래에서는 각 기술의 종류와 그에 따른 장단점을 설명하겠습니다.</p><h3 id="f15bbd1c-b820-463f-82f1-ea1a27982dd6" class="">1. 데이터베이스 아키텍처 변경</h3><h3 id="4a592d60-3d86-48c5-91fb-8f568332cf11" class="">(1) 단일 노드에서 다중 노드로 확장</h3><p id="883cc88e-0bbc-4454-b72d-71349f00760e" class=""><strong>장점:</strong></p><ul id="144aa836-e880-4069-b66d-67294a6ab13e" class="bulleted-list"><li style="list-style-type:disc">수평 확장으로 처리량 및 성능 향상.</li></ul><ul id="b3424fad-ae1c-47aa-8b03-14aed6bc9a6c" class="bulleted-list"><li style="list-style-type:disc">시스템 장애 시에도 가용성을 높임.</li></ul><p id="da2873c7-9431-4e73-a2a6-c68994ab3ee5" class=""><strong>단점:</strong></p><ul id="e2f9e971-7996-427a-b8ba-bfc66f2ea37a" class="bulleted-list"><li style="list-style-type:disc">복잡성이 증가하고 관리가 어려워짐.</li></ul><ul id="f959c854-2bbe-493c-8c35-9ad7eb2d623c" class="bulleted-list"><li style="list-style-type:disc">네트워크 비용이 증가할 수 있음.</li></ul><h3 id="3dd9b1fe-09f1-4627-8dfa-07b102959c00" class="">(2) 클라우드 데이터베이스 활용</h3><p id="88318fb4-5c89-42fa-b307-f55e56c693e9" class=""><strong>장점:</strong></p><ul id="7ca9b615-78c9-46ae-a87a-7ad919ce568f" class="bulleted-list"><li style="list-style-type:disc">확장성과 유연성 증가.</li></ul><ul id="689df0c3-374b-4566-b7c4-e72dfee1daf2" class="bulleted-list"><li style="list-style-type:disc">관리 부담 감소 (서비스 제공자가 하드웨어 및 기본 설정 관리).</li></ul><p id="49f89b28-931a-49cd-8df0-3bf7c712c846" class=""><strong>단점:</strong></p><ul id="6bfd7c3d-55d6-453a-81a5-dc7ffc539e2d" class="bulleted-list"><li style="list-style-type:disc">클라우드 종속성 증가.</li></ul><ul id="c767ec92-0430-4cce-b75c-1522878ccb42" class="bulleted-list"><li style="list-style-type:disc">비용 구조가 복잡할 수 있음.</li></ul><h3 id="f1039d21-34b9-47b8-b85e-54ddad3b637b" class="">2. 하드웨어 업그레이드</h3><h3 id="abc2dadc-c539-40ef-8286-327ae0246a77" class="">(1) CPU, RAM, 디스크 등의 업그레이드</h3><p id="1af27a67-9982-4599-9a2f-58f305334139" class=""><strong>장점:</strong></p><ul id="6fec0887-0d4f-4fe3-8e47-5419825a3111" class="bulleted-list"><li style="list-style-type:disc">기존 하드웨어의 성능 향상.</li></ul><ul id="8320aaf3-76e0-4406-9fc8-b419956eb108" class="bulleted-list"><li style="list-style-type:disc">복잡한 소프트웨어 변경 없이 성능 개선 가능.</li></ul><p id="d004cfa8-4218-4916-880d-2d09df810074" class=""><strong>단점:</strong></p><ul id="a4b64f38-2729-402a-bd83-96b689fca2f5" class="bulleted-list"><li style="list-style-type:disc">비용이 많이 들 수 있음.</li></ul><ul id="dc71d593-970e-4fc6-9864-cfed48d2c2b3" class="bulleted-list"><li style="list-style-type:disc">하드웨어의 한계로 인해 무한히 확장할 수 없음.</li></ul><h3 id="2dd96704-4685-4e04-aefd-a0760ec5252d" class="">3. 쿼리 최적화</h3><h3 id="213b29fe-c314-414d-be6c-0cf82fd496ea" class="">(1) 쿼리 리팩토링 및 리라이팅</h3><p id="4636e16d-53a5-4605-868a-d0712add27f5" class=""><strong>장점:</strong></p><ul id="1c840977-9596-4688-b7cc-7240b629d437" class="bulleted-list"><li style="list-style-type:disc">데이터베이스의 불필요한 부하를 줄여 성능 향상.</li></ul><ul id="8e665cde-150a-4cc3-ba5b-41e1afa44d50" class="bulleted-list"><li style="list-style-type:disc">효율적인 데이터 검색 및 처리.</li></ul><p id="485e4397-9bdd-4623-b77c-224e7d8d01a7" class=""><strong>단점:</strong></p><ul id="3c4a95e9-5dc6-4739-a194-6a62ce3664fa" class="bulleted-list"><li style="list-style-type:disc">쿼리 구조에 대한 깊은 이해가 필요.</li></ul><ul id="b19f58a6-dc2c-4d4f-b5e0-f03441b2f1f4" class="bulleted-list"><li style="list-style-type:disc">변경 시 에러 가능성 증가.</li></ul><h3 id="45dc407f-bd02-4de2-92e4-7b4ede2a111c" class="">(2) 실행 계획 분석</h3><p id="22a09c05-d23c-4420-88b5-c02cfe91ff1d" class=""><strong>장점:</strong></p><ul id="6da29aa1-ed3a-42a2-8e39-527029345f59" class="bulleted-list"><li style="list-style-type:disc">쿼리 실행에 대한 구체적인 정보를 얻어 병목 지점 파악.</li></ul><ul id="d3612d78-6a01-42d5-bd44-7f302b4dd193" class="bulleted-list"><li style="list-style-type:disc">필요한 경우 인덱스 또는 쿼리 구조 변경 가능.</li></ul><p id="e04e6a0a-37bf-4b3b-a470-1dae5bcda293" class=""><strong>단점:</strong></p><ul id="5d034ef7-8ef2-4798-a596-88d97aafca3c" class="bulleted-list"><li style="list-style-type:disc">실행 계획을 이해하고 분석할 수 있는 전문 지식이 필요.</li></ul><ul id="d6a7657b-9887-46f5-b961-7bf6fe26fc77" class="bulleted-list"><li style="list-style-type:disc">데이터의 변화에 따라 실행 계획도 변화할 수 있음.</li></ul><h3 id="67806dd2-8563-4a24-a8bc-1548765d8f64" class="">4. 인덱싱</h3><h3 id="990206fb-98d1-40d0-883e-e9bbd3beeba6" class="">(1) 적절한 인덱스 생성</h3><p id="33371dde-0d73-4078-ac33-c8fb35581728" class=""><strong>장점:</strong></p><ul id="966cc994-7adf-49ef-953d-86fe5246256d" class="bulleted-list"><li style="list-style-type:disc">데이터 검색 속도 향상.</li></ul><ul id="53e46a83-88db-4fb9-b0b0-bc589ef5ef17" class="bulleted-list"><li style="list-style-type:disc">쿼리 처리 시간 단축.</li></ul><p id="79ff08cb-c1ae-4099-80b8-b7a7fa2807b6" class=""><strong>단점:</strong></p><ul id="53e81254-ba5b-45a3-9868-40a01c9ca158" class="bulleted-list"><li style="list-style-type:disc">너무 많은 인덱스는 쓰기 작업을 느리게 함.</li></ul><ul id="49d96b1c-8897-4035-a37b-a7eceb12fe0e" class="bulleted-list"><li style="list-style-type:disc">인덱스 관리가 복잡해질 수 있음.</li></ul><h3 id="aa93e753-f330-4b97-a1ea-a7ac04fa71fd" class="">(2) 인덱스 조정 및 제거</h3><p id="91826a7e-6e47-4263-a22f-3ba7628aaaff" class=""><strong>장점:</strong></p><ul id="7fbd82c7-6097-4cd3-aa2f-cb2fccd9e86d" class="bulleted-list"><li style="list-style-type:disc">불필요한 인덱스 제거로 디스크 공간 및 성능 최적화.</li></ul><ul id="e0728b10-4b85-4967-9b7d-ddb40e98b90a" class="bulleted-list"><li style="list-style-type:disc">필요한 인덱스만 남겨 데이터 검색 효율성 유지.</li></ul><p id="18456eb9-5515-4323-a451-0cbd68d2517b" class=""><strong>단점:</strong></p><ul id="dc4823cb-4392-4b33-a6d0-76176fc69ed6" class="bulleted-list"><li style="list-style-type:disc">인덱스가 제거되면 일부 쿼리의 성능이 저하될 수 있음.</li></ul><ul id="86242988-32c6-412c-994d-fa15107b17fb" class="bulleted-list"><li style="list-style-type:disc">인덱스 최적화에 대한 주기적인 모니터링이 필요.</li></ul><h3 id="318e8946-a1ee-4655-8081-b2770e679cb0" class="">5. 캐싱</h3><h3 id="a17f3458-2855-473d-ae53-c7fac60d342f" class="">(1) 데이터 캐싱</h3><p id="52c4ec5f-9454-48ad-8ad5-42c7c3865ff9" class=""><strong>장점:</strong></p><ul id="3f49567b-6ea4-4b80-b7fc-d3b38eb605e3" class="bulleted-list"><li style="list-style-type:disc">자주 사용되는 데이터를 메모리에 저장하여 빠른 액세스 가능.</li></ul><ul id="850fafcb-3983-4c19-a75a-3e5693e32100" class="bulleted-list"><li style="list-style-type:disc">데이터베이스 부하 감소.</li></ul><p id="3b9ca4c3-55a6-427d-8905-2ba82b7c1a01" class=""><strong>단점:</strong></p><ul id="3945d9e3-cc07-4d3c-bf8a-a66479893f03" class="bulleted-list"><li style="list-style-type:disc">캐시 일관성 문제 발생 가능.</li></ul><ul id="a0cd3230-b285-4af3-a293-d332fba39761" class="bulleted-list"><li style="list-style-type:disc">캐시 설정 및 유지 관리 복잡성 증가.</li></ul><h3 id="40714b1e-49b0-4577-b299-f26784b6804c" class="">(2) 쿼리 결과 캐싱</h3><p id="0ae64e38-15d6-4df1-be84-e98131800218" class=""><strong>장점:</strong></p><ul id="19582b81-8b50-45a8-a93e-dfa06cbb8e2d" class="bulleted-list"><li style="list-style-type:disc">동일한 쿼리의 반복 실행 시 빠른 응답 제공.</li></ul><ul id="74cb51c5-a131-4c2a-8d1c-4e6333e78479" class="bulleted-list"><li style="list-style-type:disc">데이터베이스 리소스 사용 최소화.</li></ul><p id="0cdf5f0a-9bf3-41bc-8589-7b43aae9d2eb" class=""><strong>단점:</strong></p><ul id="b83b13de-21d6-44e4-8766-fe2a7f7f53b7" class="bulleted-list"><li style="list-style-type:disc">캐시가 오래되면 정확하지 않은 결과를 반환할 수 있음.</li></ul><ul id="9ad212f9-d131-4089-948f-210678460a1b" class="bulleted-list"><li style="list-style-type:disc">캐시 크기 관리 필요.</li></ul><h3 id="56bae31a-f5d2-48cd-a056-792e163a3119" class="">6. 샤딩(Sharding)</h3><h3 id="85a2dab7-5e43-4499-b0af-9ac29d559b02" class="">(1) 데이터 분할을 통한 수평 확장</h3><p id="be7c34ce-3a66-4ff6-94ff-9cf168eb43b2" class=""><strong>장점:</strong></p><ul id="65270441-0713-4b03-b39e-8647ad2b80a7" class="bulleted-list"><li style="list-style-type:disc">데이터베이스 노드 간 부하 분산으로 성능 향상.</li></ul><ul id="8d28fd05-d9ce-477a-89f9-3947bfeb6766" class="bulleted-list"><li style="list-style-type:disc">특정 노드 장애 시에도 데이터 가용성 유지.</li></ul><p id="d63c5093-59ed-43a0-8b8c-a98b506837a1" class=""><strong>단점:</strong></p><ul id="7190e0e7-3c52-44eb-9e1d-cedea3cc10fd" class="bulleted-list"><li style="list-style-type:disc">데이터 분할 및 관리 복잡성 증가.</li></ul><ul id="42d90f6d-eff6-49c2-aaa2-1670b080402a" class="bulleted-list"><li style="list-style-type:disc">쿼리 작성 및 조정이 어려울 수 있음.</li></ul><h3 id="43c5a2cd-78c8-4758-b20d-3ade6aeb8c13" class="">7. 리플리케이션(Replication)</h3><h3 id="a679e72b-0412-45fe-8ff7-a677924ad964" class="">(1) 데이터 복제를 통한 가용성 및 성능 개선</h3><p id="d6e38623-3417-4db7-a9ff-03c28f64512e" class=""><strong>장점:</strong></p><ul id="7dbf2f56-f13f-4787-b19b-a8eae785f4af" class="bulleted-list"><li style="list-style-type:disc">읽기 성능 향상 및 데이터 가용성 증대.</li></ul><ul id="0e19970d-2e11-4d1f-be98-3153fa4e77cb" class="bulleted-list"><li style="list-style-type:disc">장애 복구 및 백업에 유용.</li></ul><p id="fbc0d4d8-87d0-49df-a760-2427575616e8" class=""><strong>단점:</strong></p><ul id="4921a8a4-1ca8-4367-be07-9bc549733457" class="bulleted-list"><li style="list-style-type:disc">데이터 동기화 지연 및 일관성 문제.</li></ul><ul id="940f54e5-31b1-4a8f-8662-3bc296bfe1ec" class="bulleted-list"><li style="list-style-type:disc">복제본 관리 및 모니터링 복잡성 증가.</li></ul><h3 id="c9b25a69-4a87-4998-a446-73d5e5bab69a" class="">8. 파티셔닝(Partitioning)</h3><h3 id="5af5b2ed-6cb6-4e29-8300-ddf2978aeb59" class="">(1) 데이터베이스 테이블을 파티션으로 분할</h3><p id="879cb253-c8c3-495f-8be1-7071bfb6d890" class=""><strong>장점:</strong></p><ul id="71a56c3a-bfe6-4441-926c-98007e671085" class="bulleted-list"><li style="list-style-type:disc">데이터 관리 및 성능 최적화.</li></ul><ul id="2d0b4e4a-a82c-4b9a-be2e-c52a674365bb" class="bulleted-list"><li style="list-style-type:disc">특정 파티션에 대한 쿼리 속도 향상.</li></ul><p id="2b52795f-be49-4c42-9b2a-aeb8ba906d8b" class=""><strong>단점:</strong></p><ul id="0fb1a361-238f-47d3-83f1-75397c404840" class="bulleted-list"><li style="list-style-type:disc">파티션 전략 설계가 복잡할 수 있음.</li></ul><ul id="b20ed4bc-1c5f-475e-93d6-b6cee5de7955" class="bulleted-list"><li style="list-style-type:disc">파티션 간 쿼리 시 성능 저하 가능.</li></ul><h3 id="5554085f-a6c5-4b18-a50d-86dc2fe2395e" class="">9. 데이터베이스 설정 및 튜닝</h3><h3 id="5522371d-3233-404d-85d3-9a472ae7d63f" class="">(1) 데이터베이스 설정 최적화</h3><p id="cf63ce05-e0d4-465f-800a-b552b02e2208" class=""><strong>장점:</strong></p><ul id="7b19aec3-aff3-455d-9e3b-fd483d3c6472" class="bulleted-list"><li style="list-style-type:disc">데이터베이스 성능을 미세 조정할 수 있음.</li></ul><ul id="eba75091-7284-49a9-abbd-42418ed95cc1" class="bulleted-list"><li style="list-style-type:disc">설정 변경으로 바로 성능 개선 효과 확인 가능.</li></ul><p id="26360355-6af0-41e5-aa03-7ef6438b4d8c" class=""><strong>단점:</strong></p><ul id="79d01728-6dc0-4b70-9116-eea3bf4ec676" class="bulleted-list"><li style="list-style-type:disc">설정 파라미터에 대한 깊은 이해가 필요.</li></ul><ul id="b462d7e3-5e8b-4eae-afba-6fab8a946f84" class="bulleted-list"><li style="list-style-type:disc">잘못된 설정은 성능 저하를 초래할 수 있음.</li></ul><h3 id="8e106948-de53-49ac-b7bd-d309d50224ef" class="">(2) 자원 관리 (Resource Management)</h3><p id="2d2edeea-63d3-4bc4-a897-f8c57da95f82" class=""><strong>장점:</strong></p><ul id="89eaa98b-b4f0-4652-ba27-c6a0c034f46d" class="bulleted-list"><li style="list-style-type:disc">자원 사용을 최적화하여 성능 향상.</li></ul><ul id="b19b2120-a5c2-4964-a83b-c6e44a4a266f" class="bulleted-list"><li style="list-style-type:disc">예기치 않은 부하에 대한 대응력 향상.</li></ul><p id="464999c5-e6a7-4848-ab77-8b6791a435ec" class=""><strong>단점:</strong></p><ul id="b5c29720-2497-424a-a54f-9eb516ec320f" class="bulleted-list"><li style="list-style-type:disc">자원 관리 정책 수립이 복잡할 수 있음.</li></ul><ul id="fc05c136-3c29-40e6-822c-0e59ed9af584" class="bulleted-list"><li style="list-style-type:disc">실제 부하 상황과 맞지 않는 정책은 오히려 성능 저하를 초래할 수 있음.</li></ul><h3 id="158bafcc-52d7-4cc2-b120-fef4215bb6d3" class="">결론</h3><p id="ce4d53fb-fc3a-49da-83e1-3a230f9b223c" class="">데이터베이스 성능 개선을 위해 다양한 기술을 고려할 수 있으며, 각 기술의 적절한 활용은 특정 상황과 요구 사항에 따라 결정됩니다. 여러 기술을 복합적으로 사용하면 최적의 성능을 얻을 수 있지만, 각 기술의 장단점을 잘 파악하고 적용해야 합니다.</p></details></li></ul><ul id="a5cdfa08-d57e-47e4-afee-4064144bcf8b" class="toggle"><li><details open=""><summary>조회 모델 역정규화</summary><p id="7ec7eb04-c8a3-46e8-8f08-4a22f5188d08" class="">조회 모델 역정규화(Query Model Denormalization)는 데이터베이스 성능을 최적화하기 위해 데이터 정규화(Normalization)를 부분적으로 포기하고 데이터 구조를 변경하는 방법입니다. 이는 주로 데이터 조회 시 성능을 개선하고자 할 때 사용되며, 데이터 일관성 유지보다는 읽기 작업의 효율성에 초점을 맞춥니다. 아래에서는 조회 모델 역정규화의 개념, 목적, 장단점, 그리고 적용 예시에 대해 자세히 설명하겠습니다.</p><h3 id="ca29118a-7d85-4ecb-8685-3e3ef7a1d40c" class="">1. 조회 모델 역정규화의 개념</h3><ul id="da0deb55-8edc-410d-aa9b-2fd2792f2012" class="bulleted-list"><li style="list-style-type:disc">*정규화(Normalization)**는 데이터 중복을 최소화하고 데이터 일관성을 유지하기 위해 데이터베이스를 구조화하는 과정입니다. 정규화된 데이터베이스는 여러 테이블로 분할되며, 각 테이블은 특정 주제 또는 엔티티에 대한 정보를 저장합니다.</li></ul><ul id="c806934a-6413-40fd-a950-13b98ae975e7" class="bulleted-list"><li style="list-style-type:disc">*역정규화(Denormalization)**는 정규화의 원칙을 일부 포기하고 데이터베이스 구조를 단순화하거나 변경하여 성능을 향상시키는 방법입니다. 이는 주로 데이터를 합치거나 중복 저장함으로써 읽기 속도를 높이는 것을 목표로 합니다.</li></ul><h3 id="073ff5cd-be98-4cc2-b943-49776c575373" class="">2. 조회 모델 역정규화의 목적</h3><p id="4f174ccf-ffd0-4d37-880d-428fad5451a2" class="">조회 모델 역정규화의 주요 목적은 다음과 같습니다:</p><ul id="2903acdc-7d6b-4f4f-89fa-5912a5117dcf" class="bulleted-list"><li style="list-style-type:disc"><strong>읽기 속도 향상</strong>: 데이터를 미리 조합하거나 계산해 둠으로써 쿼리 실행 시 불필요한 조인(Join) 연산을 피하고, 데이터 접근 시간을 줄입니다.</li></ul><ul id="09b95978-7c64-4637-865a-dcd7956dd533" class="bulleted-list"><li style="list-style-type:disc"><strong>쿼리 복잡성 감소</strong>: 쿼리에서 필요한 정보를 한 번에 가져올 수 있도록 데이터 구조를 단순화하여 쿼리의 복잡성을 낮춥니다.</li></ul><ul id="0835a815-1e31-4962-848a-d73b32f448e4" class="bulleted-list"><li style="list-style-type:disc"><strong>응답 시간 최적화</strong>: 데이터베이스의 응답 시간을 최적화하여 사용자 경험을 향상시킵니다.</li></ul><h3 id="df8894dd-5d07-451b-8356-c44ac411b8fa" class="">3. 조회 모델 역정규화의 장단점</h3><h3 id="f23e3534-505b-4023-a461-461fa156b647" class="">장점</h3><ol type="1" id="c83990e4-85fa-469e-a370-6bbff190c9d0" class="numbered-list" start="1"><li><strong>성능 향상</strong>: 데이터 조회 시 여러 테이블을 조인하지 않아도 필요한 정보를 얻을 수 있어, 조회 성능이 크게 향상됩니다.</li></ol><ol type="1" id="4d1c9069-a416-4d4b-81ec-68bc3927da3a" class="numbered-list" start="2"><li><strong>간단한 쿼리</strong>: 데이터가 미리 결합되어 있기 때문에 쿼리가 단순해지고, 작성하기도 쉬워집니다.</li></ol><ol type="1" id="a0734e0c-f0ec-47cf-8b4b-ae29ba4692fc" class="numbered-list" start="3"><li><strong>빠른 응답 시간</strong>: 자주 조회되는 데이터를 미리 준비해 둠으로써 응답 시간을 줄일 수 있습니다.</li></ol><ol type="1" id="9df07aa4-a93f-48b2-ab9a-021a77c1efbb" class="numbered-list" start="4"><li><strong>리소스 최적화</strong>: 데이터베이스 서버의 리소스 사용을 줄여 더 많은 사용자 요청을 처리할 수 있게 됩니다.</li></ol><h3 id="1bee7de5-72ea-49c2-89d1-d1333a32dbf8" class="">단점</h3><ol type="1" id="8861e710-7abe-4b8b-9ef0-46c993dfc870" class="numbered-list" start="1"><li><strong>데이터 중복</strong>: 역정규화로 인해 데이터 중복이 발생하여 저장 공간이 더 많이 필요할 수 있습니다.</li></ol><ol type="1" id="0d250539-06fa-441d-b6a8-0627c1239b23" class="numbered-list" start="2"><li><strong>데이터 일관성 문제</strong>: 데이터가 여러 위치에 중복 저장되면, 업데이트 시 일관성 문제가 발생할 수 있습니다. 데이터 변경 시 모든 복사본을 동기화해야 하는 부담이 생깁니다.</li></ol><ol type="1" id="46dfcb18-c209-459d-81fd-c9d93b91524b" class="numbered-list" start="3"><li><strong>관리 복잡성 증가</strong>: 중복된 데이터를 관리하고 업데이트하는 데 추가적인 관리 복잡성이 생깁니다.</li></ol><ol type="1" id="ee59e54a-fb4b-4224-bb35-714441bf0f72" class="numbered-list" start="4"><li><strong>유연성 감소</strong>: 데이터 구조가 특정 쿼리에 최적화되어 있어, 새로운 요구 사항에 대응하기 어려울 수 있습니다.</li></ol><h3 id="5ce551a2-4193-4278-8a23-a68156afbcdc" class="">4. 조회 모델 역정규화의 적용 예시</h3><p id="0344319f-2df8-4bb3-a2db-f4f9c72f7ef3" class="">다음은 조회 모델 역정규화의 대표적인 적용 예시입니다.</p><h3 id="ac7b3557-719d-4375-87a8-6fef05e808af" class="">예시 1: 합치기(Merging Tables)</h3><ul id="69882c7a-88e8-44ad-910a-5e6264e0b8a9" class="bulleted-list"><li style="list-style-type:disc"><strong>상황</strong>: 사용자 정보와 주문 정보가 각각 다른 테이블에 저장되어 있고, 특정 사용자의 주문 내역을 조회하는 작업이 빈번하게 발생합니다.</li></ul><ul id="40a5bc1c-e69a-4424-935b-eb65e50d04ce" class="bulleted-list"><li style="list-style-type:disc"><strong>역정규화 적용</strong>: 사용자 정보와 주문 정보를 하나의 테이블에 합쳐 중복 저장합니다. 이렇게 하면, 한 번의 테이블 액세스로 사용자와 주문 정보를 함께 가져올 수 있습니다.</li></ul><ul id="00167b24-db9c-4dfe-9f80-f084544adc5d" class="bulleted-list"><li style="list-style-type:disc"><strong>쿼리 예시</strong>:<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="37dfec1e-758f-4320-a60d-96ec54cb3288" class="code"><code class="language-SQL" style="white-space:pre-wrap;word-break:break-all">sql코드 복사
SELECT *
FROM UserOrders
WHERE user_id = 123;

</code></pre></li></ul><h3 id="eafc7442-0aaf-46c0-a425-905c54b10189" class="">예시 2: 미리 계산된 합계(Precomputed Aggregations)</h3><ul id="0924c798-09ee-4a07-bae0-b3b0c1fc6c52" class="bulleted-list"><li style="list-style-type:disc"><strong>상황</strong>: 판매 데이터를 조회하여 특정 제품의 총 판매량을 자주 계산해야 합니다.</li></ul><ul id="d8f3764c-df75-4918-bc4d-84828058fe4f" class="bulleted-list"><li style="list-style-type:disc"><strong>역정규화 적용</strong>: 제품 테이블에 총 판매량 컬럼을 추가하여 매번 계산하지 않고, 데이터를 추가할 때마다 총 판매량을 갱신합니다.</li></ul><ul id="4e417ecf-eec4-4d6f-9f82-2391fb2f5793" class="bulleted-list"><li style="list-style-type:disc"><strong>쿼리 예시</strong>:<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="288c3cb8-14cb-43c8-be2a-8ebd567a182d" class="code"><code class="language-SQL" style="white-space:pre-wrap;word-break:break-all">sql코드 복사
SELECT product_id, total_sales
FROM Products
WHERE product_id = 456;

</code></pre></li></ul><h3 id="a52a303c-a37a-4764-9f3d-d6fb12d5ce63" class="">예시 3: 자주 사용하는 데이터 복사(Copying Frequently Used Data)</h3><ul id="5384300a-4607-42e5-9305-c5b4680a0977" class="bulleted-list"><li style="list-style-type:disc"><strong>상황</strong>: 자주 사용되는 제품 카테고리 정보가 여러 테이블에서 반복적으로 조인되어 사용됩니다.</li></ul><ul id="042567ac-59b7-4051-863f-6409a414c17c" class="bulleted-list"><li style="list-style-type:disc"><strong>역정규화 적용</strong>: 제품 카테고리 정보를 자주 사용하는 테이블에 복사해 둡니다.</li></ul><ul id="389da17f-3b20-44b0-9e3a-4d9ff8fe5288" class="bulleted-list"><li style="list-style-type:disc"><strong>쿼리 예시</strong>:<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="05326637-0970-4702-9c43-647758885729" class="code"><code class="language-SQL" style="white-space:pre-wrap;word-break:break-all">sql코드 복사
SELECT product_id, category_name
FROM Orders
WHERE order_id = 789;

</code></pre></li></ul><h3 id="8819f201-866f-49fd-8728-cb897d7f5553" class="">5. 조회 모델 역정규화 적용 시 고려사항</h3><ul id="b57a879e-389a-41b9-879d-9c2b93c3f631" class="bulleted-list"><li style="list-style-type:disc"><strong>사용 패턴 분석</strong>: 데이터 조회 패턴을 분석하여 어떤 데이터가 자주 조회되고, 어떤 쿼리가 성능에 영향을 주는지 파악합니다.</li></ul><ul id="15c18cc3-15b6-4bc4-a021-5182553ff0ca" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 일관성 유지</strong>: 데이터 중복으로 인한 일관성 문제를 해결하기 위한 전략(예: 트리거, 애플리케이션 레벨 동기화)을 수립합니다.</li></ul><ul id="280890be-a832-4b78-bc63-9d63608c0750" class="bulleted-list"><li style="list-style-type:disc"><strong>테스트 및 모니터링</strong>: 역정규화 적용 후 데이터베이스 성능을 지속적으로 모니터링하고, 예상치 못한 부작용이 발생하지 않도록 주의합니다.</li></ul><ul id="86124836-c289-48e7-b9f3-d1ae212b023d" class="bulleted-list"><li style="list-style-type:disc"><strong>유연성 유지</strong>: 역정규화로 인한 데이터 구조 변경이 새로운 요구사항에 대응하는 데 제약이 되지 않도록 설계합니다.</li></ul><h3 id="69e9308a-4b64-46c7-a741-940fa311b4ff" class="">6. 결론</h3><p id="e1ea2825-5874-43bb-b7c0-d77a973ab8c8" class="">조회 모델 역정규화는 데이터베이스 성능을 최적화하기 위한 강력한 도구이지만, 데이터 중복과 일관성 문제를 야기할 수 있습니다. 따라서 이러한 단점을 최소화하면서 쿼리 성능을 최대화할 수 있는 방법을 신중하게 고려하여 적용하는 것이 중요합니다. 데이터베이스의 종류, 데이터 특성, 사용 사례 등을 고려하여 최적화 전략을 수립하고, 필요에 따라 역정규화를 활용하는 것이 좋습니다.</p></details></li></ul><ul id="5ab1160c-2772-4c4d-a2c2-417b5306c36c" class="toggle"><li><details open=""><summary>DB 쓰기/읽기 요청 증가에 따른 성능 개선 </summary><h2 id="671e1966-4e73-4e89-979f-b85300165987" class="">쓰기 요청 증가 시 처리 기술</h2><p id="121f6f4b-a276-4896-8282-0f955b999307" class="">쓰기 요청이 증가하는 경우 데이터베이스에 많은 데이터가 동시에 쓰여지므로, 이를 효율적으로 처리하기 위한 기술이 필요합니다. 주요 기술은 다음과 같습니다.</p><h3 id="11dde08a-a96d-4942-bf9e-82839e99c064" class="">1. <strong>수직 확장(Vertical Scaling)</strong></h3><h3 id="33aef840-3e5d-40d9-b21b-9a45d6e4ae89" class="">설명</h3><ul id="1c8afa92-c13c-4a2f-9d1c-77e9ae8d3cae" class="bulleted-list"><li style="list-style-type:disc">서버의 하드웨어 자원을 증가시켜 쓰기 성능을 개선합니다. 이는 CPU, 메모리, 스토리지 등을 업그레이드하는 것을 의미합니다.</li></ul><h3 id="3f076e1c-0d7f-4e28-9050-d01c47c34eda" class="">장점</h3><ul id="09bfbf14-b049-4993-9d04-6773b06343a8" class="bulleted-list"><li style="list-style-type:disc">기존 애플리케이션과 데이터베이스 구조를 변경할 필요가 없습니다.</li></ul><ul id="57a3ebc2-18eb-4d55-81b5-79bba84061ed" class="bulleted-list"><li style="list-style-type:disc">구현이 비교적 단순합니다.</li></ul><h3 id="d2eb8ecd-aa40-43a6-b742-20427bb58053" class="">단점</h3><ul id="66c667b4-37e2-4b28-93f1-d22356f661d5" class="bulleted-list"><li style="list-style-type:disc">하드웨어 비용이 증가할 수 있으며, 물리적 한계가 존재합니다.</li></ul><ul id="1bdd2ef2-08eb-437f-8320-ec838190a795" class="bulleted-list"><li style="list-style-type:disc">특정 한계점에 도달하면 더 이상의 확장이 어려울 수 있습니다.</li></ul><h3 id="76ed19f9-57a1-4650-a61c-66a75d13d2cb" class="">2. <strong>데이터베이스 샤딩(Sharding)</strong></h3><h3 id="2b1260a6-d715-44ec-bba6-cd4c767e9833" class="">설명</h3><ul id="6a6600d0-237f-4d95-9646-f69d932e5bf8" class="bulleted-list"><li style="list-style-type:disc">데이터를 여러 분할된 파티션(샤드)으로 나누어 다수의 데이터베이스 서버에 분산시킵니다.</li></ul><h3 id="363552a0-0cd4-4300-b2e9-a6d65b6f1a5e" class="">장점</h3><ul id="dc55c19e-896e-42de-8866-87ec7983119b" class="bulleted-list"><li style="list-style-type:disc">시스템 전체의 쓰기 성능을 향상시킬 수 있습니다.</li></ul><ul id="a9ce53c1-3733-4938-8355-5dc924932d6f" class="bulleted-list"><li style="list-style-type:disc">데이터베이스 서버 간의 부하 분산이 가능합니다.</li></ul><h3 id="70a0d805-3c06-4f59-a045-543c8c25a6df" class="">단점</h3><ul id="da164bc8-4e86-4446-945b-c6cd6790f851" class="bulleted-list"><li style="list-style-type:disc">샤딩 전략을 잘못 설정하면 복잡성이 증가하고 관리가 어려워질 수 있습니다.</li></ul><ul id="2cea16e2-3b2d-4fde-b4bf-3ed88c183c8c" class="bulleted-list"><li style="list-style-type:disc">샤딩 키의 선택이 성능에 큰 영향을 미칩니다.</li></ul><h3 id="8511a9b9-e9c9-4a93-be8f-dac5c356fb34" class="">3. <strong>쓰기 전용 노드 추가</strong></h3><h3 id="96555358-d292-4ec1-860f-a4148526dc44" class="">설명</h3><ul id="8227de65-3c19-4372-a189-6e2072ef3cbf" class="bulleted-list"><li style="list-style-type:disc">쓰기 전용 노드를 추가하여 쓰기 요청을 분산 처리합니다.</li></ul><h3 id="deebeab5-222c-4ddb-99c9-277ee9260d5d" class="">장점</h3><ul id="ebf3c1b3-5aee-4c9a-8584-7ba38af6104a" class="bulleted-list"><li style="list-style-type:disc">쓰기 처리량을 높일 수 있습니다.</li></ul><ul id="f69d5073-117d-4210-b9dc-ecfdc83758b8" class="bulleted-list"><li style="list-style-type:disc">읽기와 쓰기 작업을 분리하여 병목 현상을 줄입니다.</li></ul><h3 id="3facf2ff-90ca-462b-93d1-56f5e828c06f" class="">단점</h3><ul id="d43d68c7-6b95-41f9-bd7c-4b0364ca1929" class="bulleted-list"><li style="list-style-type:disc">시스템 아키텍처가 복잡해집니다.</li></ul><ul id="0a978c05-dd93-4c22-8002-cf680ff0b344" class="bulleted-list"><li style="list-style-type:disc">데이터 일관성을 유지하기 위한 추가적인 메커니즘이 필요합니다.</li></ul><h3 id="1460fba4-0d41-4c40-ba1e-401ba32732af" class="">4. <strong>비동기 쓰기(Asynchronous Write)</strong></h3><h3 id="694f5603-2239-4347-9102-e3f761bae67d" class="">설명</h3><ul id="c45deffe-6843-4504-99c4-65a45344bb37" class="bulleted-list"><li style="list-style-type:disc">쓰기 작업을 비동기적으로 처리하여 쓰기 요청을 빠르게 응답합니다.</li></ul><h3 id="f969094c-09ff-496c-a285-c7f8d0be34ea" class="">장점</h3><ul id="fb348735-0fd2-4d00-abb2-eb2bb340c846" class="bulleted-list"><li style="list-style-type:disc">응답 시간이 줄어들어 사용자 경험이 개선됩니다.</li></ul><ul id="e31baf14-0ae3-4079-8fa3-6d4776c5928d" class="bulleted-list"><li style="list-style-type:disc">백그라운드 작업으로 실제 쓰기 작업을 처리할 수 있습니다.</li></ul><h3 id="7efb2a53-4d6d-4389-b63b-f15f771b9bec" class="">단점</h3><ul id="326798bb-3720-4aa0-b110-d257037a9329" class="bulleted-list"><li style="list-style-type:disc">데이터 일관성이 즉각적으로 보장되지 않을 수 있습니다.</li></ul><ul id="9c86a0f1-a263-479e-9145-2736a738b860" class="bulleted-list"><li style="list-style-type:disc">데이터 손실의 가능성이 있습니다.</li></ul><h3 id="9eaf2d3e-0f00-49b2-a716-7249aebfd5e1" class="">5. <strong>트랜잭션 배치 처리(Transaction Batching)</strong></h3><h3 id="05904849-c690-486f-8bed-b98365dae10a" class="">설명</h3><ul id="512bee00-ef87-4819-b40b-f098e1a7ec5a" class="bulleted-list"><li style="list-style-type:disc">여러 쓰기 작업을 하나의 트랜잭션으로 묶어 처리합니다.</li></ul><h3 id="24096f9c-9c01-4320-96d6-ec87db654141" class="">장점</h3><ul id="0d4d3331-599d-4902-8a88-6f862466a7c1" class="bulleted-list"><li style="list-style-type:disc">데이터베이스의 트랜잭션 처리 오버헤드를 줄입니다.</li></ul><ul id="56349279-ec96-4343-9c8f-9997381d8757" class="bulleted-list"><li style="list-style-type:disc">데이터베이스 커넥션을 효율적으로 사용합니다.</li></ul><h3 id="9e97dbae-f378-4777-b09d-801346bbe741" class="">단점</h3><ul id="f6f925b7-fc21-4cf3-a5f8-b72789abf78b" class="bulleted-list"><li style="list-style-type:disc">트랜잭션이 커질수록 롤백 비용이 증가합니다.</li></ul><ul id="240dd90b-069b-4d3f-b837-ccad965510ad" class="bulleted-list"><li style="list-style-type:disc">실시간성 요구사항을 만족시키기 어려울 수 있습니다.</li></ul><hr id="281a3c19-38ff-4499-b5ac-5b7a766954c3"/><h2 id="658fab90-f457-4931-b880-be9fc94742d7" class="">읽기 요청 증가 시 처리 기술</h2><p id="3e293750-cfb7-420d-8ca5-66700a684a2d" class="">읽기 요청이 증가하는 경우 데이터베이스의 읽기 처리량을 늘리고, 응답 속도를 개선하기 위한 기술이 필요합니다. 주요 기술은 다음과 같습니다.</p><h3 id="e4d4b669-5aeb-460d-a9d3-9cb3f5357ee5" class="">1. <strong>읽기 전용 복제(Read Replica)</strong></h3><h3 id="dfff4322-93c3-41ee-bc24-2a4f538c8c16" class="">설명</h3><ul id="18ef29a9-1435-4af3-a62a-cc730864013a" class="bulleted-list"><li style="list-style-type:disc">마스터 데이터베이스의 데이터를 읽기 전용 복제본으로 복제하여 읽기 요청을 분산 처리합니다.</li></ul><h3 id="4e4c4254-2572-4f3f-af5f-89a3514f68e4" class="">장점</h3><ul id="ee40f9f0-5e26-4f70-ad6c-facf5e9c3fb0" class="bulleted-list"><li style="list-style-type:disc">읽기 부하를 여러 복제본으로 분산하여 처리할 수 있습니다.</li></ul><ul id="d1f7874d-6101-435f-86ee-12611d8303f9" class="bulleted-list"><li style="list-style-type:disc">데이터베이스의 가용성과 확장성을 높입니다.</li></ul><h3 id="a8347ea0-e9c1-4163-9344-f1bd09ad0276" class="">단점</h3><ul id="a19c0c7b-6577-49a8-aa99-8833051ba942" class="bulleted-list"><li style="list-style-type:disc">복제 지연으로 인해 최신 데이터가 즉시 반영되지 않을 수 있습니다.</li></ul><ul id="9f5b6210-492f-443b-8908-bdf6d7f7466e" class="bulleted-list"><li style="list-style-type:disc">데이터 일관성 문제가 발생할 수 있습니다.</li></ul><h3 id="44f20054-52d8-4258-9c1d-57fba1e05ade" class="">2. <strong>캐싱(Caching)</strong></h3><h3 id="bdd7c957-bd4a-4bdc-b299-8f3db75c10f2" class="">설명</h3><ul id="923a7ae8-e255-4459-a5a9-df9d47a7e679" class="bulleted-list"><li style="list-style-type:disc">자주 사용되는 데이터나 쿼리 결과를 메모리나 외부 캐시 시스템(Redis, Memcached 등)에 저장하여 빠르게 접근합니다.</li></ul><h3 id="0e91b78e-534d-4fee-ac7d-9cd879dec6be" class="">장점</h3><ul id="6d4c65a4-176c-4585-a25c-beb142970ffb" class="bulleted-list"><li style="list-style-type:disc">데이터베이스 부하를 크게 줄일 수 있습니다.</li></ul><ul id="cb05010f-27e7-4e2c-bd30-9a3aabced56b" class="bulleted-list"><li style="list-style-type:disc">읽기 속도를 향상시켜 응답 시간이 빨라집니다.</li></ul><h3 id="8861faa0-7d97-456d-9d6a-4148aaa75326" class="">단점</h3><ul id="447a72bb-97de-4f0c-914a-bedb30c6736d" class="bulleted-list"><li style="list-style-type:disc">캐시된 데이터의 일관성을 유지하기 위해 추가적인 관리가 필요합니다.</li></ul><ul id="3d93e4e1-b3d8-4d2d-a27a-9f029d0a1d1b" class="bulleted-list"><li style="list-style-type:disc">캐시 미스(Cache Miss) 시 데이터베이스에 직접 접근해야 하므로 성능이 일시적으로 저하될 수 있습니다.</li></ul><h3 id="52d5bded-ee0c-4e66-b427-286179554da3" class="">3. <strong>인덱싱(Indexing)</strong></h3><h3 id="88e3d037-a4af-4de3-a15e-788c5b13b945" class="">설명</h3><ul id="f79b0060-1690-44d0-be41-7350f84c059e" class="bulleted-list"><li style="list-style-type:disc">데이터베이스의 검색 성능을 높이기 위해 적절한 인덱스를 생성합니다.</li></ul><h3 id="b6f8d268-713c-40db-87ef-6cdbf0347ec1" class="">장점</h3><ul id="07d4fe6b-bbdc-450a-941a-dbb4bf2cd42e" class="bulleted-list"><li style="list-style-type:disc">데이터 검색 속도가 빨라집니다.</li></ul><ul id="1d490171-adaf-4202-90ce-adddab98c089" class="bulleted-list"><li style="list-style-type:disc">쿼리 성능을 최적화할 수 있습니다.</li></ul><h3 id="180b0d2e-2e36-4eed-bbb3-5be60f324b6f" class="">단점</h3><ul id="1f22ba34-d281-48ba-adef-825be73f3205" class="bulleted-list"><li style="list-style-type:disc">인덱스를 많이 생성하면 쓰기 작업의 성능이 저하될 수 있습니다.</li></ul><ul id="2191617e-adb7-4773-9b56-d55d742ac31b" class="bulleted-list"><li style="list-style-type:disc">인덱스 관리 및 최적화에 추가적인 노력이 필요합니다.</li></ul><h3 id="4f48c44b-925a-424c-b477-7d284aa944ed" class="">4. <strong>수평 확장(Horizontal Scaling)</strong></h3><h3 id="ccf1454d-e8fa-4fae-9b61-117b83b606f4" class="">설명</h3><ul id="1f14dbe8-cbdd-4113-ad5a-7f581f1b6e23" class="bulleted-list"><li style="list-style-type:disc">읽기 전용 노드를 추가하여 읽기 요청을 분산 처리합니다. 샤딩이나 클러스터링 기술을 사용하여 수평 확장을 구현할 수 있습니다.</li></ul><h3 id="1e52fc9d-e691-46d8-8827-29abc68fe518" class="">장점</h3><ul id="dc0d3a8c-edbd-430f-8d57-1c8746160051" class="bulleted-list"><li style="list-style-type:disc">시스템의 확장성이 높아집니다.</li></ul><ul id="238f78a4-0054-430a-8b8a-fac7dfbc59e0" class="bulleted-list"><li style="list-style-type:disc">다양한 서버에 읽기 부하를 분산하여 처리할 수 있습니다.</li></ul><h3 id="e17bf92b-a53e-4268-9a0a-cfdb81ff932e" class="">단점</h3><ul id="a2334fb6-165e-47ec-84f4-7aa80483fc4e" class="bulleted-list"><li style="list-style-type:disc">시스템의 복잡성이 증가합니다.</li></ul><ul id="df810a8c-efb6-4793-b257-58fa2710d160" class="bulleted-list"><li style="list-style-type:disc">네트워크 비용이 증가할 수 있습니다.</li></ul><h3 id="74535ef3-2ce3-4935-b573-f52195cef3d0" class="">5. <strong>결과 집계(Precomputed Aggregations)</strong></h3><h3 id="c182c0d0-898d-474b-bdfd-6dd070d95b55" class="">설명</h3><ul id="156146a4-df6c-4f2f-8c78-cdf8230b2f02" class="bulleted-list"><li style="list-style-type:disc">자주 사용되는 집계 결과를 미리 계산하여 저장하고, 쿼리 시 이를 사용합니다.</li></ul><h3 id="121d87db-997b-48da-b5a8-aedf6bf8db76" class="">장점</h3><ul id="9a3901d9-69a7-44b4-a40e-03f89cb78c9e" class="bulleted-list"><li style="list-style-type:disc">집계 쿼리의 성능을 크게 향상시킬 수 있습니다.</li></ul><ul id="63b917fe-72ef-43b1-8347-d2738a6cd69e" class="bulleted-list"><li style="list-style-type:disc">복잡한 계산을 피하고 빠른 응답을 제공할 수 있습니다.</li></ul><h3 id="0c4b9ee9-390d-4b45-b062-1cee9428a2dc" class="">단점</h3><ul id="9d75b8cc-70a8-483f-88f0-4a5c93ca9734" class="bulleted-list"><li style="list-style-type:disc">집계 데이터가 오래된 경우 정확하지 않은 결과를 반환할 수 있습니다.</li></ul><ul id="e8d36045-3bed-43ce-a05b-55f6f33e0c5b" class="bulleted-list"><li style="list-style-type:disc">데이터를 추가할 때마다 집계 결과를 업데이트해야 하므로 관리가 복잡해질 수 있습니다.</li></ul><h3 id="9b976302-e799-4d7a-8583-546e47c64316" class="">6. <strong>파티셔닝(Partitioning)</strong></h3><h3 id="9c6f152b-770e-4098-a262-b5a4b118c8d2" class="">설명</h3><ul id="27d689cd-428e-4004-babd-77d8db39fea8" class="bulleted-list"><li style="list-style-type:disc">테이블을 여러 파티션으로 나누어 데이터 접근 성능을 최적화합니다.</li></ul><h3 id="d73e6238-2b96-4be9-ad66-2a86ff3b8fb7" class="">장점</h3><ul id="c56741db-a469-4436-863a-19d1dc101ddd" class="bulleted-list"><li style="list-style-type:disc">데이터 검색 시 특정 파티션에만 접근하여 성능을 향상시킵니다.</li></ul><ul id="d1cdabf7-d3af-4614-8db0-48cce0994990" class="bulleted-list"><li style="list-style-type:disc">대규모 테이블의 관리가 용이해집니다.</li></ul><h3 id="c4fa7b10-9591-4730-95dd-923c2aa718d0" class="">단점</h3><ul id="882f7826-b92c-43ff-9a4a-09b159aefe2c" class="bulleted-list"><li style="list-style-type:disc">파티셔닝 전략을 잘못 설정하면 성능 저하를 초래할 수 있습니다.</li></ul><ul id="e147cdfb-caf6-4415-ab26-674b0f38f1ac" class="bulleted-list"><li style="list-style-type:disc">파티셔닝된 테이블에 대한 쿼리 작성이 복잡해질 수 있습니다.</li></ul><hr id="fbb6cef7-1a77-4889-ae65-fc2c1d1e257d"/><p id="9192f411-a61a-4de5-8a7d-386ba80623f3" class="">이처럼 DB 쓰기 요청 증가와 읽기 요청 증가를 처리하기 위한 기술은 다양합니다. 각 기술은 특정 상황에 따라 더 효과적이거나 덜 효과적일 수 있으며, 이러한 기술을 적절히 조합하여 사용하는 것이 중요합니다. 데이터베이스의 성능을 최적화하고 시스템의 안정성을 유지하기 위해서는 현재의 문제점과 요구사항을 명확히 파악하고, 이에 맞는 기술을 신중하게 적용하는 것이 필요합니다.</p><p id="cec040f2-2e90-4d8f-aa63-bcb49db86f5b" class="">
</p></details></li></ul><ul id="4fc23e82-d681-4911-a2b9-73fc79e5dba5" class="toggle"><li><details open=""><summary>DB 샤딩</summary><p id="5097898f-d8d7-4dd1-8650-a137029614ad" class=""><strong>DB 샤딩 방식</strong>은 데이터를 여러 분할된 파티션(샤드)으로 나누어 여러 데이터베이스 인스턴스에 분산시켜 저장하는 기법입니다. 샤딩을 통해 데이터베이스 시스템의 확장성을 향상시키고, 단일 데이터베이스에 대한 부하를 줄일 수 있습니다. 질문하신 바와 같이, 각 샤드는 개별 데이터베이스로 운영됩니다. 그러나 이 운영 방식의 구체적인 방식은 시스템 설계와 샤딩 전략에 따라 다를 수 있습니다. 다음은 DB 샤딩의 일반적인 운영 방식을 설명한 내용입니다.</p><h2 id="6eeae777-2c17-4e81-92f6-d0920fd64a45" class="">샤딩의 운영 방식</h2><h3 id="edccf23d-f313-401d-949b-83e4c50c9b11" class="">1. <strong>개별 샤드의 독립 운영</strong></h3><ul id="a3aec221-64dc-4168-8c3d-a630cdd05d6d" class="bulleted-list"><li style="list-style-type:disc"><strong>개념</strong>: 샤딩을 통해 분리된 각각의 샤드는 독립적으로 운영됩니다. 각 샤드는 자체 데이터베이스 인스턴스나 서버에 배포될 수 있으며, 다른 샤드와는 별개의 데이터와 리소스를 관리합니다.</li></ul><ul id="b1817a82-faac-4a76-b74e-f91f5f77b102" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>:<ul id="b259c4d0-c651-4780-81f4-77790e1cfa94" class="bulleted-list"><li style="list-style-type:circle"><strong>독립성</strong>: 각 샤드는 독립적으로 데이터베이스와 연결되어 있으며, 각기 다른 물리적 서버나 클러스터에 위치할 수 있습니다.</li></ul><ul id="ea6ff98b-bc77-4481-b29e-9c99048c1a91" class="bulleted-list"><li style="list-style-type:circle"><strong>독립된 리소스 관리</strong>: 각 샤드는 개별 CPU, 메모리, 스토리지를 사용하므로, 특정 샤드의 부하가 다른 샤드에 영향을 미치지 않습니다.</li></ul><ul id="e70346b4-56e3-403e-9ae5-681215ef6e04" class="bulleted-list"><li style="list-style-type:circle"><strong>독자적인 쿼리 실행</strong>: 샤드에 저장된 데이터에 대한 쿼리는 해당 샤드에서만 실행되며, 다른 샤드와의 데이터 통신이나 조인 연산이 필요할 경우 어플리케이션 계층이나 샤딩 미들웨어를 통해 처리합니다.</li></ul></li></ul><h3 id="fb1c0e1c-fbcb-4238-aab1-1f3a6235d596" class="">2. <strong>샤딩 전략</strong></h3><ul id="d00d025f-15f4-4ae2-9512-b353e97c9269" class="bulleted-list"><li style="list-style-type:disc"><strong>범위 기반 샤딩(Range-based Sharding)</strong>:<ul id="c7a2c200-0fbe-4180-ad44-932859b24adc" class="bulleted-list"><li style="list-style-type:circle">각 샤드는 키 범위에 따라 데이터를 저장합니다. 예를 들어, 사용자 ID가 1<del>1000인 데이터는 샤드 A에, 1001</del>2000인 데이터는 샤드 B에 저장하는 방식입니다.</li></ul><ul id="91733205-90b1-49b8-8e7c-554f3b914899" class="bulleted-list"><li style="list-style-type:circle"><strong>장점</strong>: 특정 쿼리 패턴에 대해 성능이 좋습니다.</li></ul><ul id="9b1bbfbe-4afa-4902-8185-d254fc3b6ec8" class="bulleted-list"><li style="list-style-type:circle"><strong>단점</strong>: 특정 범위에 데이터가 집중되면, 해당 샤드에 부하가 집중될 수 있습니다.</li></ul></li></ul><ul id="44f3f45e-564d-4d5a-b896-ef229e70d41f" class="bulleted-list"><li style="list-style-type:disc"><strong>해시 기반 샤딩(Hash-based Sharding)</strong>:<ul id="5436c994-62f9-48a8-b5a2-ee4e1360998c" class="bulleted-list"><li style="list-style-type:circle">데이터를 특정 해시 함수로 변환하여 각 샤드에 분배합니다. 예를 들어, 해시 함수의 결과 값에 따라 데이터를 각각 다른 샤드에 저장합니다.</li></ul><ul id="038e1353-fafa-4b15-a485-1874c6afb6c9" class="bulleted-list"><li style="list-style-type:circle"><strong>장점</strong>: 데이터 분배가 균등하게 이루어져, 특정 샤드에 부하가 집중되는 문제를 완화할 수 있습니다.</li></ul><ul id="416c884c-ef98-4ce1-9e58-abec6acc1436" class="bulleted-list"><li style="list-style-type:circle"><strong>단점</strong>: 데이터 이동이 필요할 경우, 해시 함수의 변경이 복잡할 수 있습니다.</li></ul></li></ul><ul id="2242239c-0089-47fd-a6ef-5bd771fb3db8" class="bulleted-list"><li style="list-style-type:disc"><strong>디렉토리 기반 샤딩(Directory-based Sharding)</strong>:<ul id="87ab7f42-a52b-404e-9d18-c3fc70c5486c" class="bulleted-list"><li style="list-style-type:circle">샤딩 정보를 저장하는 별도의 디렉토리 서비스를 사용하여 각 데이터의 위치를 결정합니다.</li></ul><ul id="a42ab5f0-83ad-4a65-9cd5-156ebf63f9b5" class="bulleted-list"><li style="list-style-type:circle"><strong>장점</strong>: 유연한 데이터 분배가 가능합니다.</li></ul><ul id="96b0605d-add2-488a-9a6e-c9d511acd16a" class="bulleted-list"><li style="list-style-type:circle"><strong>단점</strong>: 디렉토리 서비스의 성능과 신뢰성이 전체 시스템에 영향을 줄 수 있습니다.</li></ul></li></ul><h3 id="d15ac22a-6dbf-472d-b1bd-8f0abb8fd07a" class="">3. <strong>개별 샤드 관리 및 모니터링</strong></h3><ul id="07fa7601-5d3a-4d04-a5d9-9121b8cf197c" class="bulleted-list"><li style="list-style-type:disc">각 샤드는 독립적으로 운영되므로, 각 샤드에 대한 모니터링, 백업, 복구, 스키마 변경 등의 작업도 개별적으로 수행됩니다.</li></ul><ul id="ce9d927a-18e8-4756-b64e-6a9d8714c6a8" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링</strong>: 각 샤드의 성능, 리소스 사용률, 장애 등을 모니터링하는 시스템을 구축하여 관리합니다.</li></ul><ul id="9dd2efe9-0bfe-4c75-95f2-64dce1f9efb0" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터베이스 관리 작업</strong>: 데이터베이스의 스키마 변경, 인덱스 추가, 최적화 등의 작업을 각 샤드에 맞게 수행합니다.</li></ul><ul id="7b6ea7ea-c8a4-4e4c-90b2-e62ff41740d7" class="bulleted-list"><li style="list-style-type:disc"><strong>백업 및 복구</strong>: 각 샤드의 데이터에 대해 독립적으로 백업 및 복구 계획을 수립하고 실행합니다.</li></ul><h3 id="837705a3-d7e3-4b0b-bd7f-e22095eb3a37" class="">4. <strong>애플리케이션 계층의 역할</strong></h3><ul id="2933e81a-e1bb-4934-a6b4-5a60247ce270" class="bulleted-list"><li style="list-style-type:disc">샤딩된 데이터베이스는 애플리케이션 계층이나 샤딩 미들웨어를 통해 액세스됩니다. 이 계층은 다음과 같은 역할을 수행합니다.<ul id="9d825dbd-2a8f-480b-8ad2-c02664df7159" class="bulleted-list"><li style="list-style-type:circle"><strong>데이터 라우팅</strong>: 쿼리 요청을 적절한 샤드로 라우팅합니다.</li></ul><ul id="21c90330-c826-4582-817f-f4c7606d118c" class="bulleted-list"><li style="list-style-type:circle"><strong>데이터 통합</strong>: 여러 샤드에서 데이터를 수집하여 하나의 결과로 통합합니다.</li></ul><ul id="258c51d3-e753-4b97-b828-8454f949a578" class="bulleted-list"><li style="list-style-type:circle"><strong>일관성 관리</strong>: 샤딩으로 인해 발생하는 데이터 일관성 문제를 해결합니다.</li></ul></li></ul><h2 id="1fb39be6-a871-452b-829a-efbf549326cf" class="">결론</h2><p id="80fa8aa0-b983-42ee-8265-92a00b6cbb0c" class="">샤딩은 각 샤드를 독립적으로 운영하는 방식으로, 이를 통해 데이터베이스의 확장성과 성능을 개선할 수 있습니다. 그러나 샤딩된 환경에서 데이터베이스를 관리하는 것은 복잡성이 증가할 수 있으며, 데이터 일관성, 부하 분산, 샤딩 키 선택 등의 문제를 신중하게 고려해야 합니다. 샤딩을 도입할 때는 시스템의 특성과 요구사항에 맞는 샤딩 전략과 운영 방식을 선택하는 것이 중요합니다.</p><p id="2ff8ce36-207e-442e-bd8f-e79482237d39" class="">
</p></details></li></ul><ul id="805633bc-d688-4939-900b-5dd95ca5a99b" class="toggle"><li><details open=""><summary>분산 DB 일관성 유지</summary><p id="4375de8a-f6cd-495b-9754-7e690e7cc2ec" class="">샤딩(Sharding)으로 분산된 데이터베이스에서 데이터 일관성과 통합을 구현하는 것은 분산 환경에서 매우 중요한 과제입니다. 샤딩으로 인해 데이터가 여러 샤드에 분산되어 저장되기 때문에, 각 샤드에서 일관성을 유지하고 필요한 경우 데이터를 통합하는 메커니즘을 제공해야 합니다. 이러한 문제를 해결하는 방법에는 여러 가지 기술과 전략이 있습니다. 다음은 샤드로 분산된 데이터베이스에서 데이터 일관성과 통합을 구현하는 주요 방식과 기술을 설명한 내용입니다.</p><h2 id="89d791e5-8015-465e-a825-3f7c49e0ec06" class="">1. 데이터 일관성 유지</h2><p id="5c0b3d35-56cb-43e9-81d8-31692f1d882b" class="">데이터 일관성은 분산된 데이터베이스 시스템에서 데이터의 무결성과 동기화를 보장하는 것이 핵심입니다. 이를 위해 다음과 같은 기술과 전략을 사용할 수 있습니다.</p><h3 id="7a706757-b0ec-492c-ba86-acb2ddd559eb" class="">1.1 트랜잭션 관리(Transaction Management)</h3><h3 id="71bbc644-9cfa-476c-ba85-6e326f189a2a" class="">다중 샤드 트랜잭션(Multi-shard Transactions)</h3><ul id="84bb569e-88fb-4baa-b03e-dfa8c28d5293" class="bulleted-list"><li style="list-style-type:disc"><strong>Two-phase Commit (2PC)</strong>: 트랜잭션을 두 단계로 처리하는 방식으로, 먼저 모든 샤드에 <code>prepare</code> 요청을 보내고 모든 샤드가 준비되면 <code>commit</code> 요청을 보내는 방식입니다. 이는 모든 샤드의 일관성을 보장하지만, 네트워크 지연 및 장애 발생 시 문제가 발생할 수 있습니다.</li></ul><ul id="364b1b32-8a7e-4fe3-b232-1a12a7c34abf" class="bulleted-list"><li style="list-style-type:disc"><strong>Three-phase Commit (3PC)</strong>: 2PC의 단점을 보완하기 위해 도입된 방식으로, 2PC보다 안정적인 트랜잭션 처리가 가능합니다.</li></ul><h3 id="bf099695-2e77-4901-94e2-b88b3721c487" class="">분산 트랜잭션 관리</h3><ul id="3aefa9d5-e811-40e7-afb9-c46e4d0e39a5" class="bulleted-list"><li style="list-style-type:disc"><strong>Distributed Transaction Coordinator (DTC)</strong>: 각 샤드의 트랜잭션을 조정하고 관리하는 중앙 관리 시스템을 통해 데이터의 일관성을 유지합니다.</li></ul><ul id="77655ee2-349e-4b9a-be30-8322391889b9" class="bulleted-list"><li style="list-style-type:disc"><strong>Sagas Pattern</strong>: 트랜잭션을 연속된 단계로 분할하고 각 단계를 개별 트랜잭션으로 처리하여 데이터 일관성을 유지합니다. 각 단계가 실패하면 이전 단계의 보상 트랜잭션을 실행하여 상태를 복구합니다.</li></ul><h3 id="2f7c1f3d-0bdc-4c9b-9324-16f919dada6e" class="">1.2 데이터 동기화(Data Synchronization)</h3><h3 id="da297b62-e1e1-4ee3-882e-d177e82e50ec" class="">마스터-슬레이브 동기화</h3><ul id="931491d0-0a76-475e-948c-c2d4a44acaff" class="bulleted-list"><li style="list-style-type:disc"><strong>Replication</strong>: 데이터를 마스터 샤드에서 슬레이브 샤드로 복제하여 일관성을 유지합니다. 주로 읽기 성능을 향상시키기 위해 사용되며, 쓰기 작업은 마스터 샤드에서 처리됩니다.</li></ul><h3 id="459fef93-7e4b-4c34-aa9e-df6f09d2ba3d" class="">이벤트 기반 동기화</h3><ul id="cfc6d6b9-7525-42fb-8962-e2b23e5a3103" class="bulleted-list"><li style="list-style-type:disc"><strong>Change Data Capture (CDC)</strong>: 데이터베이스의 변경 사항을 캡처하고 이를 다른 샤드 또는 시스템에 전파하는 방법입니다. Kafka, Debezium 등의 도구를 사용하여 구현할 수 있습니다.</li></ul><ul id="e47170b9-7780-42f7-ac64-c494113f48ac" class="bulleted-list"><li style="list-style-type:disc"><strong>Event Sourcing</strong>: 모든 데이터 변경을 이벤트로 기록하고, 이를 다른 샤드 또는 서비스에 전파하여 일관성을 유지합니다.</li></ul><h3 id="7b7c9eae-1f1a-49f6-8588-5b0a165a8fbd" class="">1.3 일관성 모델 선택</h3><h3 id="812e438a-b6a1-4369-ab16-dc4dddeac6bc" class="">강한 일관성(Strong Consistency)</h3><ul id="cf564d25-7045-41e7-869e-173f9f186fcf" class="bulleted-list"><li style="list-style-type:disc">모든 트랜잭션이 즉시 모든 샤드에 반영되는 것을 보장합니다. 분산 트랜잭션 관리, 2PC/3PC 등의 기법을 통해 구현할 수 있습니다. 그러나 성능 저하의 단점이 있습니다.</li></ul><h3 id="5e5350f8-33c2-4a46-ba33-823dbff19d2f" class="">최종 일관성(Eventual Consistency)</h3><ul id="b02ad801-5207-46ee-929d-239819bcee92" class="bulleted-list"><li style="list-style-type:disc">일정 시간이 지나면 모든 샤드가 일관된 상태를 갖게 됩니다. 분산 시스템에서 일반적으로 사용되는 모델로, 성능과 확장성을 우선시하는 경우에 적합합니다.</li></ul><h3 id="11df9349-a403-4cc0-a98a-4947f47080a4" class="">약한 일관성(Weak Consistency)</h3><ul id="a78a3f0b-de45-4007-97e0-8195164c5d82" class="bulleted-list"><li style="list-style-type:disc">일관성을 보장하지 않지만, 성능을 최우선으로 고려할 때 사용하는 모델입니다. 일부 애플리케이션에서는 읽기 작업이 중요한 경우에 적합할 수 있습니다.</li></ul><h2 id="b39cfcfc-edf0-49f9-aee3-faf2ddc8ebdb" class="">2. 데이터 통합 구현</h2><p id="59cc3553-f246-4595-afdf-4a28d4d7c112" class="">샤딩된 데이터베이스에서 분산된 데이터를 통합하여 사용하는 경우, 다음과 같은 방법을 활용할 수 있습니다.</p><h3 id="35eb6c3f-7036-4abe-bc83-cf0e02eb8bf0" class="">2.1 애플리케이션 계층에서의 데이터 통합</h3><h3 id="13c34948-0c5f-4ce2-be37-0c7bc2405958" class="">애플리케이션 레벨 조인(Application-level Join)</h3><ul id="b1e24b72-e50f-46c4-acfb-747e8068cc5f" class="bulleted-list"><li style="list-style-type:disc">애플리케이션 코드에서 여러 샤드의 데이터를 조합하여 필요한 정보를 생성합니다. 각 샤드에 대해 별도의 쿼리를 실행하고, 결과를 애플리케이션에서 조합합니다.</li></ul><h3 id="c07f92dd-079e-4cc8-8ff2-bc35bdabb7ce" class="">샤딩 미들웨어(Sharding Middleware)</h3><ul id="02ed9c11-60e8-43e2-8ed4-80b79a1e5df7" class="bulleted-list"><li style="list-style-type:disc"><strong>Sharding Proxy</strong>: 여러 샤드에 대한 쿼리를 중개하고, 결과를 통합하여 클라이언트에게 반환하는 미들웨어를 사용합니다. MySQL의 <code>ProxySQL</code>, PostgreSQL의 <code>pgpool-II</code> 등이 있습니다.</li></ul><ul id="3145011d-6b60-493c-8b8b-0296b09974a1" class="bulleted-list"><li style="list-style-type:disc"><strong>API 게이트웨이(API Gateway)</strong>: 여러 샤드에 대한 데이터 요청을 중개하고, 필요한 데이터를 통합하여 반환하는 API 계층을 구축합니다.</li></ul><h3 id="9412d92d-77b6-4575-9138-69c489999055" class="">2.2 분산 쿼리 처리(Distributed Query Processing)</h3><h3 id="d75d006c-3f55-432f-8889-6276e9b333d9" class="">분산 SQL 엔진(Distributed SQL Engine)</h3><ul id="0e63ebb3-8865-4c56-86f6-7ccb4635248f" class="bulleted-list"><li style="list-style-type:disc"><strong>Presto, Apache Drill, Apache Spark SQL</strong>: 분산된 데이터베이스에 대해 SQL 쿼리를 실행하고, 결과를 통합하는 분산 SQL 엔진을 사용합니다. 이러한 엔진은 여러 샤드의 데이터를 병렬로 처리하여 성능을 향상시킵니다.</li></ul><h3 id="b22fcaa5-af47-4603-8178-10b153eafa4a" class="">데이터 웨어하우징(Data Warehousing)</h3><ul id="fe87fe74-5379-4d10-b29c-be617cb77212" class="bulleted-list"><li style="list-style-type:disc">여러 샤드의 데이터를 주기적으로 통합하여 데이터 웨어하우스에 저장하고, 분석 및 보고에 사용합니다. 이 방식은 실시간 데이터 통합이 필요하지 않은 경우에 적합합니다.</li></ul><h3 id="9a99bb6b-850e-4ba5-ac45-9f71a0afa1c9" class="">2.3 데이터 모델링 및 설계</h3><h3 id="7fd27119-e234-4358-8768-85a625c5c0ab" class="">전역 테이블(Global Table)</h3><ul id="b216c341-bd97-4d0b-8c48-003ab420b126" class="bulleted-list"><li style="list-style-type:disc">공통으로 사용되는 데이터는 전역 테이블에 저장하여 모든 샤드에서 접근할 수 있도록 합니다. 이러한 데이터는 복제되어 각 샤드에 존재하거나, 별도의 전역 데이터베이스에 저장됩니다.</li></ul><h3 id="6bedbc8b-66f1-4a3c-ba4e-d49aa43e2d18" class="">데이터 파티셔닝 전략 개선</h3><ul id="f0388b06-4808-4fd7-82cc-4ee049834317" class="bulleted-list"><li style="list-style-type:disc">샤딩 키의 선택과 파티셔닝 전략을 개선하여 데이터 통합 시 발생하는 문제를 최소화합니다. 예를 들어, 관련 데이터가 동일한 샤드에 저장되도록 샤딩 키를 설계할 수 있습니다.</li></ul><h2 id="b01b4b29-d936-4f5d-93f8-12a534f1e778" class="">3. 데이터 일관성과 통합의 균형</h2><ul id="565baea9-f9e3-4e06-9fb8-617be15e13be" class="bulleted-list"><li style="list-style-type:disc"><strong>CAP 이론</strong>: 분산 시스템에서 일관성(Consistency), 가용성(Availability), 파티션 허용성(Partition Tolerance)을 동시에 만족시킬 수 없다는 이론입니다. 따라서 샤딩된 데이터베이스에서 일관성과 통합을 구현할 때는 CAP 이론을 고려하여 적절한 균형을 찾아야 합니다.</li></ul><ul id="ddcb8bf5-c783-473b-bba3-f8b44751ebb5" class="bulleted-list"><li style="list-style-type:disc"><strong>일관성과 성능의 균형</strong>: 데이터 일관성을 유지하면서도 성능을 향상시키기 위해, 필요한 경우 강한 일관성 대신 최종 일관성을 선택하거나, 분산 트랜잭션을 최소화하는 등의 전략을 사용할 수 있습니다.</li></ul><h2 id="01b102ec-f9d9-4839-9da1-9b4bccb5d01e" class="">4. 결론</h2><p id="d7031df5-c62c-4a90-ad14-5c9be355a240" class="">샤딩된 데이터베이스에서 데이터 일관성과 통합을 구현하는 것은 분산 환경에서 매우 중요한 과제입니다. 이를 위해 다양한 기술과 전략을 사용할 수 있으며, 시스템의 요구 사항에 따라 적절한 방법을 선택하는 것이 중요합니다. 샤딩으로 인한 복잡성을 최소화하고, 데이터 일관성과 성능을 최적화하기 위해서는 전체 시스템의 설계와 아키텍처에 대한 깊은 이해와 경험이 필요합니다.</p></details></li></ul><ul id="7ee67865-643b-4a47-aa70-8a4e4587b58e" class="toggle"><li><details open=""><summary>CDC를 이용한 DB복제 전략</summary><p id="616ddc53-a783-4615-85e1-93e1d92a32e1" class="">이렇게 초기적재와 실시간 변경분을 분리해서 MongoDB에 데이터가 적재되도록 했습니다.</p><blockquote id="e1a99fd2-fd0f-477d-adac-8d52c75d2dbb" class="">초기 데이터는 복제 DB를 통해 적재새로 들어오는 Change Event는 CDC 데이터 Pipeline을 통해 적재</blockquote><p id="d68b443a-6f32-4bb3-bac9-c30f8cccc314" class="">그리고 작업은 다음의 단계로 진행되었습니다.</p><ol type="1" id="74c322cf-94dc-42c7-ad25-bdc46e675263" class="numbered-list" start="1"><li>Source Connector 생성</li></ol><ol type="1" id="51119b4e-c440-48d6-9cfa-fae74254f949" class="numbered-list" start="2"><li>Oracle 복제 DB 생성<ul id="add50f82-d7c5-4315-b4de-8569eb2735b5" class="bulleted-list"><li style="list-style-type:disc">운영 DB 및 서비스에 부담을 주지 않기 위해 Primary 가 아닌 Secondary 환경에 복제 DB를 생성</li></ul><ul id="c48c690c-6c5e-413f-aadf-be2730f4d4cd" class="bulleted-list"><li style="list-style-type:disc">작업 순서도 중요한데요!! 만약에 1번(Source Connector 생성) 작업을 2번(Oracle 복제 DB 생성) 작업 이후에 하게 되면 1번 작업 이후로 Change Event들이 Kafka Broker에 적재되므로 1, 2번 작업 간의 데이터가 유실되기 때문에 작업 순서에 유의</li></ul></li></ol><ol type="1" id="c91965c9-25bc-4269-916a-b311e8cb5328" class="numbered-list" start="3"><li>MongoDB에 초기 데이터를 적재</li></ol><ol type="1" id="b5682224-8359-4d2e-8cfd-f9b725df451c" class="numbered-list" start="4"><li>Consumer Group을 생성 및 Offset을 설정</li></ol><ol type="1" id="6b9d6a26-632b-46c2-b433-845947b507f4" class="numbered-list" start="5"><li>Sink Connector 생성</li></ol><figure id="9e65c68f-af57-42ee-ac92-ce5e705a7df4" class="image"><a href="https://tech.kakaopay.com/_astro/07_cdc_architecture.653575f8_Z1wipWl.avif"><img src="https://tech.kakaopay.com/_astro/07_cdc_architecture.653575f8_Z1wipWl.avif"/></a></figure><figure id="c496a3a3-a4b0-4194-884f-3a74a4349dd7"><a href="https://tech.kakaopay.com/post/kakaopaysec-mongodb-cdc/#cdc-구축-전략" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Oracle에서 MongoDB로의 CDC Pipeline 구축 | 카카오페이 기술 블로그</div><div class="bookmark-description">Oracle에서 MongoDB로의 초기 데이터 이관 및 CDC Pipeline 구축 경험을 공유합니다.</div></div><div class="bookmark-href"><img src="https://tech.kakaopay.com/favicon.ico" class="icon bookmark-icon"/>https://tech.kakaopay.com/post/kakaopaysec-mongodb-cdc/#cdc-구축-전략</div></div><img src="https://tech.kakaopay.com/_astro/thumb.83382cea_Z2lH96n.png" class="bookmark-image"/></a></figure></details></li></ul><p id="a9ed9022-ef72-4600-8119-508b49ada7c4" class="">
</p><p id="dd7b5bb4-cbec-4a2e-9ad5-02a669ce9efa" class="">AI / ML / BigData</p><ul id="e8d7c242-2ed6-45ac-bcf8-aac4d9e12e72" class="toggle"><li><details open=""><summary>추천시스템 성장 일지: 데이터 엔지니어 편</summary><ul id="33ca06ed-29bb-476b-b59e-0c3001a5c0bd" class="bulleted-list"><li style="list-style-type:disc">오프라인 예측<figure id="186f5426-caa4-4c92-b388-efcb95b14b11" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.03.21.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.03.21.png"/></a></figure><figure id="ecef72d8-6ea0-4b5a-9243-f102079b7160" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.59.46.png"><img style="width:707.9971313476562px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.59.46.png"/></a></figure></li></ul><ul id="86be608c-7e93-4251-a325-2cb040d0385f" class="bulleted-list"><li style="list-style-type:disc">온라인 예측<figure id="e17dbc27-6ef9-4b84-96e7-1dc75c6d8bf8" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.04.06.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.04.06.png"/></a></figure><figure id="f90ce791-623f-46aa-af6b-496a741468cf" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.01.10.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.01.10.png"/></a></figure><figure id="a93332bb-d2d2-4651-9be1-09de6f66fe12" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.01.40.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.01.40.png"/></a></figure></li></ul><ul id="6312fd54-6c09-4d6a-923b-1ca6be044e41" class="bulleted-list"><li style="list-style-type:disc">기존 학습 안정성이 떨어짐, 실행 환경 관리 어려움<figure id="12522092-bdf2-4b2a-af07-bd451cba680e" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.06.50.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.06.50.png"/></a></figure></li></ul><ul id="9a488e9c-9ff3-4c47-9c74-79900c7bca73" class="bulleted-list"><li style="list-style-type:disc">컨테이너 기반 학습 시스템으로 변경<figure id="a352e085-5e29-42ac-9944-7f5e4514f687" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.09.46.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.09.46.png"/></a></figure><figure id="d016743a-b120-4c76-b10c-242d721f117e" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.09.03.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.09.03.png"/></a></figure><figure id="b574ca1a-6c28-41ad-848c-d66ebf27c835" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.11.26.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.11.26.png"/></a></figure></li></ul><ul id="6bc0e1b3-48cc-461f-acf5-2c41f380476e" class="bulleted-list"><li style="list-style-type:disc">실시간 추천 시스템<figure id="de192b89-5898-4cab-9b28-aecf5fc422e5" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.15.11.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.15.11.png"/></a></figure><figure id="12a1c5c8-3b21-493c-bf56-9a78802def0e" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.14.43.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.14.43.png"/></a></figure><figure id="491c2c99-8a4e-4c64-9934-3d60d2954aa0" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.15.52.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.15.52.png"/></a></figure><figure id="b99a1f75-e91a-4393-a8cb-4851cf013319"><a href="https://www.youtube.com/watch?v=x49PqlAQC3U&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=13" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">추천시스템 성장 일지: 데이터 엔지니어 편 #우아콘2023 #우아한형제들</div><div class="bookmark-description">[WOOWACON2023 세션 다시보기]

👉 세션 설명

추천시스템팀이 만들어지고 본격적으로 추천 서비스 개발이 시작된 지도 어느덧 2년이 지났습니다.
이제 두 돌이 된 추천시스템은 지금 어떤 모습일까요?
추천시스템의 아키텍처와 데이터 파이프라인을 소개합니다. 그리고 지금의 추천시스템의 모습을 가능하게 해준 몇 가지 중요 포인트들을 공유합니다ㅤ
ㅤ
👉 발표자 소개

추천시스템 김정헌

누구보다 디지털 미니멀리즘에 관심이 많은 개발자. 추천시스템팀에서 추천 서비스 전반을 개발하고 있습니다.

👍 추천 대상

추천, 검색 등 AI / ML 서비스 개발을 막 시작했거나 시작해보려는 개발자

🙋🏻‍♀️ 세션에 대해 궁금한 점이 있다면 dev_relations@woowahan.com 으로 문의주시기 바랍니다.</div></div><div class="bookmark-href"><img src="https://www.youtube.com/s/desktop/5766dddc/img/favicon_144x144.png" class="icon bookmark-icon"/>https://www.youtube.com/watch?v=x49PqlAQC3U&amp;list=PLgXGHBqgT2TundZ81MAVHPzeYOTeII69j&amp;index=13</div></div><img src="https://i.ytimg.com/vi/x49PqlAQC3U/maxresdefault.jpg" class="bookmark-image"/></a></figure></li></ul></details></li></ul><ul id="beeccfd6-40a0-4cb7-9e58-a57aec242a7b" class="toggle"><li><details open=""><summary>GPT와 함께 하는 서비스 만들기</summary><ul id="e5c7c441-15fa-40ef-9281-64e26b894c14" class="bulleted-list"><li style="list-style-type:disc">GPT<figure id="317704b2-3e88-4dd9-896f-9ad011ec3982" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.25.25.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.25.25.png"/></a></figure><figure id="5f991f61-f7d7-4432-8deb-ba0ba62dfb56" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.23.23.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.23.23.png"/></a></figure><figure id="cf0849c1-34ae-4c6b-a2b2-abceb5dae007" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.24.24.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.24.24.png"/></a></figure></li></ul><ul id="9058611f-c35a-4e5d-b5c3-09c70b7128df" class="bulleted-list"><li style="list-style-type:disc">리뷰 데이터 활용<figure id="bdd004f4-522c-4968-a7dc-072d12493677" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.27.16.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.27.16.png"/></a></figure><figure id="0d19417d-7b24-4f00-9295-6fd33650b333" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.27.37.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.27.37.png"/></a></figure><figure id="dfec9174-1d0f-476a-a329-e815b0821b35" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.31.00.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.31.00.png"/></a></figure></li></ul></details></li></ul><ul id="1d8438cb-f748-4912-8850-33760f32a6ec" class="toggle"><li><details open=""><summary>추천/ML에서 &#x27;예측&#x27;을 서빙한다는 것에 대하여</summary><figure id="a610ef79-f788-45c7-ba19-e26116544822" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.36.17.png"><img style="width:680.007080078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.36.17.png"/></a></figure><figure id="5f1266b4-91c8-463b-aa77-402717c647b4" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.36.57.png"><img style="width:680.007080078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.36.57.png"/></a></figure><figure id="15006e0a-7e9f-498a-9683-738dfcddc651" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.37.41.png"><img style="width:707.9971313476562px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.37.41.png"/></a></figure><figure id="c50f095c-d153-4307-864e-0f05c3fa0fbe" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.38.29.png"><img style="width:680.007080078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.38.29.png"/></a></figure><figure id="3217719c-3f8b-4a07-8ebb-179088f02ab9" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.39.47.png"><img style="width:707.9971313476562px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.39.47.png"/></a></figure><figure id="72becd4c-65b9-469d-9c9a-d614b7e8d6a8" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.41.05.png"><img style="width:680.007080078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-24_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.41.05.png"/></a></figure></details></li></ul><ul id="de3119c7-44c5-41f6-bb47-ed1e281d649a" class="toggle"><li><details open=""><summary>Big Data 처리 전략</summary><p id="da79a608-3db1-4d4b-ac83-5a28ca872029" class="">빅데이터 처리 전략은 대규모 데이터 세트를 효율적으로 수집, 저장, 처리, 분석, 시각화, 및 관리하는 방법을 계획하고 구현하는 것을 목표로 합니다. 이를 위해 다양한 기술과 방법론이 사용됩니다. 다음은 주요 빅데이터 처리 전략에 대한 설명입니다:</p><h3 id="55f19a08-3861-4801-b0a9-9d36a1c7e3a3" class="">1. 데이터 수집 (Data Collection)</h3><h3 id="a0352ce2-f6dd-4e9e-892f-b087e2da3828" class="">스트리밍 데이터 수집</h3><ul id="8690ecc2-f8ed-43d8-a429-15b8be25ea5f" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache Kafka, Amazon Kinesis, Google Pub/Sub</li></ul><ul id="d0354551-37cc-447b-bb17-48c0ad60998b" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 실시간으로 생성되는 데이터를 실시간 스트림 형태로 수집합니다. 스트리밍 데이터 수집은 빠르게 변화하는 데이터를 실시간으로 처리하고 분석하는 데 사용됩니다.</li></ul><h3 id="fd615df5-a753-4abf-9a5a-5c433d1dd2a7" class="">배치 데이터 수집</h3><ul id="cc966a68-c92a-4107-80c0-378ad73d2138" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache Sqoop, Apache Flume, Talend</li></ul><ul id="e3687c53-6e24-4af7-bf1f-804c0ee2510a" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 정기적으로 데이터를 일괄 처리(batch processing) 방식으로 수집합니다. 대규모 로그 파일, 데이터베이스 덤프 등을 주기적으로 수집하는 데 적합합니다.</li></ul><h3 id="c03451cf-978f-4b45-bf4f-82927f330c72" class="">2. 데이터 저장 (Data Storage)</h3><h3 id="be3bfc17-abaf-4e42-9828-d1474ce088fe" class="">데이터 레이크 (Data Lake)</h3><ul id="ace13e64-d73a-460c-9724-95f8ab748f49" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Amazon S3, Azure Data Lake, Google Cloud Storage, Hadoop HDFS</li></ul><ul id="d5a9c9f5-433a-4bb5-bc18-3747be7fc8e0" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 구조화, 반구조화, 비구조화 데이터를 대규모로 저장할 수 있는 저장소입니다. 다양한 데이터 소스를 원시 형식으로 저장하고 필요에 따라 처리합니다.</li></ul><h3 id="6887fb97-9f12-45ba-9429-2c19f5d1fdd9" class="">분산 데이터베이스</h3><ul id="62392a24-ef01-4898-bde3-a5b8022da783" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache HBase, Apache Cassandra, Amazon DynamoDB</li></ul><ul id="ce091eb0-6732-40f4-bafe-e9d900b11123" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 높은 확장성과 가용성을 제공하는 분산형 데이터베이스입니다. 대규모 데이터를 신속하게 읽고 쓸 수 있습니다.</li></ul><h3 id="3841f2b5-78de-4142-9565-bb12bd0490ce" class="">3. 데이터 처리 (Data Processing)</h3><h3 id="5b1eb9cb-3554-4f11-a8bd-af83b49d4f7d" class="">배치 처리 (Batch Processing)</h3><ul id="f66db9aa-efe7-4789-ab82-109a68d3be5c" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache Hadoop, Apache Spark, Apache Flink</li></ul><ul id="0c55b562-0b27-4ac1-91cf-40a75e769fe0" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 대규모 데이터 세트를 주기적으로 일괄 처리합니다. ETL(Extract, Transform, Load) 작업, 데이터 변환, 대규모 집계 작업 등에 사용됩니다.</li></ul><h3 id="ce69e9ed-9106-4f71-8048-bd037d368400" class="">실시간 처리 (Real-time Processing)</h3><ul id="f8905630-c2f3-4094-9445-2a7124cd2e1d" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache Storm, Apache Kafka Streams, Apache Flink, Apache Samza</li></ul><ul id="d13d99c7-90bb-421d-b351-b462f73ced04" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 실시간 스트리밍 데이터를 처리하여 즉각적인 분석과 응답을 제공합니다. 실시간 대시보드, 이벤트 모니터링 등에 사용됩니다.</li></ul><h3 id="7868b7e5-a02a-4a6a-a466-f80d84a9ab14" class="">4. 데이터 분석 및 머신러닝 (Data Analysis and Machine Learning)</h3><h3 id="3aebab56-3c41-41ef-9ab1-ad5999e2542e" class="">데이터 분석</h3><ul id="7adae097-00f8-4af7-9a5b-7e3cc034a5e6" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache Spark, Presto, Apache Drill, Druid</li></ul><ul id="b62f2e85-1c72-472f-956c-f7841a57bf9d" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 대규모 데이터 세트에 대해 복잡한 쿼리를 수행하고 분석합니다. 데이터를 신속하게 탐색하고 통찰을 도출할 수 있습니다.</li></ul><h3 id="bfd5c3cf-a9d4-4806-91ee-db4bb3c48195" class="">머신러닝</h3><ul id="eee657c5-b31e-44d6-88b6-0a1e95f9704f" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache Spark MLlib, TensorFlow, H2O.ai, Apache Mahout</li></ul><ul id="73ed3549-4d5b-4c4e-8746-74ce0513a128" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 대규모 데이터 세트를 기반으로 머신러닝 모델을 학습시키고 예측합니다. 예측 분석, 이상 탐지, 추천 시스템 등에 사용됩니다.</li></ul><h3 id="dedddc78-649a-4944-be9f-09df87944a97" class="">5. 데이터 시각화 (Data Visualization)</h3><ul id="d7ea0088-3b48-4d13-bfea-fa14f6d57b22" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Tableau, Power BI, Apache Superset, Kibana</li></ul><ul id="25958648-fa95-45d0-9055-50723362b82a" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 데이터를 시각적으로 표현하여 인사이트를 도출하고 의사결정을 지원합니다. 대시보드, 리포트, 시각적 분석 도구 등을 제공합니다.</li></ul><h3 id="1b796f18-ae13-4bc1-b66c-261398836972" class="">6. 데이터 관리 및 보안 (Data Management and Security)</h3><h3 id="651b92e2-9c27-4473-90a3-b5d6e7d61f45" class="">데이터 품질 관리</h3><ul id="5001eb8e-1027-45e8-ae00-d233a3837848" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Talend, Informatica, Apache Griffin</li></ul><ul id="dd63b2b2-8da9-4075-b4bf-9b4caa82067d" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 데이터의 정확성, 일관성, 완전성을 유지합니다. 데이터 정제, 데이터 표준화, 데이터 검증 작업을 포함합니다.</li></ul><h3 id="25741b14-af08-4148-9703-21d44afe67d9" class="">데이터 거버넌스</h3><ul id="903809de-b053-40ae-a273-2dbe50ad68b7" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache Atlas, Informatica, Collibra</li></ul><ul id="547e6efb-7880-4779-a3f5-00674ccd2514" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 데이터 자산을 관리하고 데이터 사용 정책을 정의합니다. 데이터 계보, 데이터 카탈로그, 데이터 사용 추적 등을 포함합니다.</li></ul><h3 id="fb665b52-be45-4af7-bf46-b45c778c6fd5" class="">데이터 보안</h3><ul id="ec175a91-f419-4c63-a9f7-7040a1322805" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache Ranger, Apache Sentry, AWS IAM</li></ul><ul id="155b739c-096b-44e7-b5bf-57b1c7a728bf" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 데이터 접근 제어와 보호를 제공합니다. 데이터 암호화, 접근 제어, 감사 로그 등을 포함합니다.</li></ul><h3 id="50db2286-3cee-40a6-a72f-f59a46b803e8" class="">7. 데이터 통합 (Data Integration)</h3><ul id="8f4f0c28-fc16-4819-859d-02ea74bf502e" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> Apache Nifi, Talend, Informatica</li></ul><ul id="3b16dd38-a5b6-4ec2-8368-e4aff46412c3" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 다양한 데이터 소스에서 데이터를 통합하고 일관된 데이터 뷰를 제공합니다. ETL 작업, 데이터 파이프라인, 데이터 동기화를 포함합니다.</li></ul><h3 id="21adf040-38cc-4291-b129-e52a3b0a7f0c" class="">8. 클라우드 기반 빅데이터 처리</h3><ul id="cfb05d7a-fd3e-4f39-a421-c49c77a0bbe9" class="bulleted-list"><li style="list-style-type:disc"><strong>기술:</strong> AWS Big Data Services (EMR, Redshift, Kinesis), Google Cloud Big Data Services (BigQuery, Dataflow, Pub/Sub), Azure Big Data Services (HDInsight, Synapse, Stream Analytics)</li></ul><ul id="f1a78deb-02bf-4b9d-a260-ff04002e4bdb" class="bulleted-list"><li style="list-style-type:disc"><strong>설명:</strong> 클라우드 플랫폼을 활용하여 확장성과 유연성을 제공하는 빅데이터 처리 솔루션입니다. 인프라 관리 부담을 줄이고 필요한 리소스를 신속하게 확장할 수 있습니다.</li></ul><h3 id="659c9fb2-8390-4948-b761-18fa01db7b84" class="">결론</h3><p id="d036e067-135b-4b30-896f-ccdf148acfd8" class="">빅데이터 처리 전략은 조직의 요구 사항과 데이터 특성에 따라 다양한 기술과 방법을 조합하여 설계됩니다. 각 단계마다 적절한 도구와 기술을 선택하여 효율적이고 확장 가능한 데이터 처리 시스템을 구축하는 것이 중요합니다. 이러한 전략을 통해 조직은 데이터를 효과적으로 활용하여 인사이트를 도출하고 비즈니스 가치를 극대화할 수 있습니다.</p><p id="79fa53a6-19b2-447b-8a90-e1cfd62e0a75" class="">
</p></details></li></ul><ul id="892393ba-bd6c-4db3-b2a9-ccf1ba28497b" class="toggle"><li><details open=""><summary>람다 아키텍처(Lambda Architecture)</summary><p id="23bfb7db-3c1a-44a8-8277-15cacfdd7f0c" class="">람다 아키텍처(Lambda Architecture)는 대규모 데이터 처리 시스템을 설계하기 위한 아키텍처 패턴으로, 실시간 데이터 처리와 배치 데이터 처리의 장점을 결합한 모델입니다. Nathan Marz가 제안한 이 아키텍처는 빅데이터 처리에서 자주 사용됩니다. 람다 아키텍처는 세 가지 주요 레이어로 구성됩니다: 배치 레이어(Batch Layer), 속도 레이어(Speed Layer), 서빙 레이어(Serving Layer). 각 레이어는 데이터 처리의 특정 측면을 담당합니다.</p><figure id="b12fb6cb-b4f3-4fe2-8324-74c19ffe79ee" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-08_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.44.35.png"><img style="width:718.3806762695312px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-08_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.44.35.png"/></a></figure><h3 id="ed94b828-47c9-42d5-97e9-0f70db59b930" class="">주요 구성 요소</h3><ol type="1" id="d9d4f3a3-6b77-4e8e-8229-2a40d29c3a61" class="numbered-list" start="1"><li><strong>배치 레이어 (Batch Layer):</strong><ul id="defaa67b-bbea-4c88-a5b2-3f6096f05429" class="bulleted-list"><li style="list-style-type:disc"><strong>역할:</strong> 전체 데이터 세트를 처리하고, 주기적으로 배치 작업을 수행하여 결과를 계산합니다.</li></ul><ul id="16b007d2-dc49-4500-88fe-1dadefe29cf3" class="bulleted-list"><li style="list-style-type:disc"><strong>기능:</strong> 데이터의 정합성을 보장하며, 대규모 데이터 세트를 효율적으로 처리합니다.</li></ul><ul id="1223acac-d137-4aa1-ba1b-e1c24d116617" class="bulleted-list"><li style="list-style-type:disc"><strong>기술 스택:</strong> Hadoop, Apache Spark, Apache Flink 등</li></ul><ul id="22fead11-b2f3-42e5-8f97-3e9c48132332" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 저장소:</strong> HDFS, Amazon S3, 데이터 웨어하우스 등</li></ul></li></ol><ol type="1" id="cdd73d36-abd4-44f9-b3bd-a2fa272d2a70" class="numbered-list" start="2"><li><strong>속도 레이어 (Speed Layer):</strong><ul id="5538f4e9-7335-4695-a286-7db18f8919ae" class="bulleted-list"><li style="list-style-type:disc"><strong>역할:</strong> 실시간으로 유입되는 데이터를 처리하여 즉각적인 결과를 제공합니다.</li></ul><ul id="ff7f6cf1-c2c4-457f-b54c-21fb6d34d691" class="bulleted-list"><li style="list-style-type:disc"><strong>기능:</strong> 저지연 데이터 처리를 통해 최신 데이터에 대한 빠른 응답을 제공합니다. 이 레이어는 일관성을 완벽히 보장하지는 않지만, 최신 데이터를 신속하게 처리하는 데 중점을 둡니다.</li></ul><ul id="a216199f-b411-47ec-a7bb-8232c29b1a20" class="bulleted-list"><li style="list-style-type:disc"><strong>기술 스택:</strong> Apache Storm, Apache Kafka Streams, Apache Flink, Apache Samza 등</li></ul><ul id="545dcef6-6f1f-4851-bbf8-c8610cbda720" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 저장소:</strong> Redis, Memcached, Apache Cassandra 등</li></ul></li></ol><ol type="1" id="8fa48486-98f8-47bd-840d-bbdf64dc914e" class="numbered-list" start="3"><li><strong>서빙 레이어 (Serving Layer):</strong><ul id="eb455fc9-0f50-4c89-8da2-49331054f007" class="bulleted-list"><li style="list-style-type:disc"><strong>역할:</strong> 배치 레이어와 속도 레이어에서 처리된 데이터를 통합하여 사용자가 질의할 수 있도록 준비합니다.</li></ul><ul id="90b50cc5-8cca-4835-9cbe-f66eb93c9061" class="bulleted-list"><li style="list-style-type:disc"><strong>기능:</strong> 데이터를 인덱싱하고, 사용자의 쿼리에 대한 빠른 응답을 제공합니다.</li></ul><ul id="22ee5d14-9d99-45f1-aad2-37020871b793" class="bulleted-list"><li style="list-style-type:disc"><strong>기술 스택:</strong> Elasticsearch, Apache Druid, HBase 등</li></ul></li></ol><h3 id="28318979-0fb3-4168-b865-29cdc9460978" class="">데이터 흐름</h3><ol type="1" id="6b94c351-25a2-4ccf-8c0f-8fa689695c5b" class="numbered-list" start="1"><li><strong>데이터 수집:</strong> 데이터는 다양한 소스(예: 로그 파일, IoT 센서, 사용자 행동 등)에서 실시간으로 수집됩니다.</li></ol><ol type="1" id="348fd9cb-3b18-4563-9a7f-da34d264f09e" class="numbered-list" start="2"><li><strong>배치 처리:</strong> 수집된 데이터는 배치 레이어에서 정기적으로 처리되어 전체 데이터 세트에 대한 결과를 계산합니다. 이는 데이터의 정합성을 보장하며, 대규모 데이터를 효율적으로 처리합니다.</li></ol><ol type="1" id="3c7be243-b241-4075-8342-7cff90035f42" class="numbered-list" start="3"><li><strong>실시간 처리:</strong> 동시에, 실시간으로 수집된 데이터는 속도 레이어에서 즉각적으로 처리됩니다. 이 레이어는 최신 데이터를 빠르게 처리하여 사용자에게 즉각적인 결과를 제공합니다.</li></ol><ol type="1" id="9ca85fa0-a408-4745-9ea6-0d81a13d3e9e" class="numbered-list" start="4"><li><strong>데이터 통합 및 서빙:</strong> 배치 레이어와 속도 레이어에서 처리된 결과는 서빙 레이어로 전달되어, 사용자가 질의할 수 있도록 준비됩니다. 서빙 레이어는 인덱싱된 데이터를 통해 빠른 응답을 제공합니다.</li></ol><h3 id="595252de-4ad1-47de-9d51-47966378c915" class="">장점</h3><ol type="1" id="9213b239-63d0-4cf1-bf40-50c0f0a2c60e" class="numbered-list" start="1"><li><strong>확장성:</strong> 배치와 실시간 처리를 결합하여 대규모 데이터 처리 시스템의 확장성을 제공합니다.</li></ol><ol type="1" id="e5335784-71fa-45af-8169-67e2e566a7a2" class="numbered-list" start="2"><li><strong>유연성:</strong> 다양한 데이터 처리 요구 사항을 충족할 수 있는 유연한 구조를 제공합니다.</li></ol><ol type="1" id="e45adf4f-a22b-4103-b0d2-880442d4d51b" class="numbered-list" start="3"><li><strong>데이터 정합성:</strong> 배치 레이어를 통해 데이터 정합성을 보장하며, 속도 레이어를 통해 최신 데이터에 대한 빠른 응답을 제공합니다.</li></ol><ol type="1" id="b9ea3e86-7ac7-467e-ad28-5a71991bfcf0" class="numbered-list" start="4"><li><strong>고가용성:</strong> 데이터 처리의 두 가지 경로(배치 및 실시간)를 통해 고가용성을 보장합니다.</li></ol><h3 id="bce06752-d9a1-46e6-8f6d-c77ce63f6f22" class="">단점</h3><ol type="1" id="e3656b35-3ece-44e9-a72f-573a720628d0" class="numbered-list" start="1"><li><strong>복잡성:</strong> 두 개의 서로 다른 데이터 처리 경로를 관리해야 하므로 시스템 복잡성이 증가합니다.</li></ol><ol type="1" id="40a6dd78-4bca-4655-bb6a-2fd2fd1723e9" class="numbered-list" start="2"><li><strong>데이터 중복:</strong> 동일한 데이터를 배치와 실시간으로 두 번 처리해야 하는 경우가 발생할 수 있습니다.</li></ol><ol type="1" id="541eca27-00c6-4b37-9c48-e9c8fc967f80" class="numbered-list" start="3"><li><strong>유지 보수:</strong> 배치 레이어와 속도 레이어 모두를 유지 보수해야 하므로 운영 비용이 증가할 수 있습니다.</li></ol><h3 id="8d1ad630-7d7a-4e49-b0f4-11aa188b95bb" class="">결론</h3><p id="13ba2b33-ee3b-4fa8-b1ec-baeae6992602" class="">람다 아키텍처는 대규모 데이터 처리 시스템에서 실시간성과 정합성을 모두 만족시키기 위한 효과적인 아키텍처 패턴입니다. 그러나 복잡성과 유지 보수 비용을 고려해야 하며, 시스템의 요구 사항에 따라 적절히 적용해야 합니다. 최근에는 단점을 극복하기 위해 캡파 아키텍처(Kappa Architecture)와 같은 대안도 제시되고 있습니다.</p></details></li></ul><ul id="fde36bbd-86c7-4345-acf6-4e4761c1b40f" class="toggle"><li><details open=""><summary>캡파 아키텍처(Kappa Architecture)</summary><p id="29727581-9c6d-42da-a966-b50c2c4cc2c5" class="">캡파 아키텍처(Kappa Architecture)는 람다 아키텍처의 복잡성을 줄이고 단순성을 극대화하기 위해 제안된 데이터 처리 아키텍처 패턴입니다. Jay Kreps가 처음 제안한 이 아키텍처는 데이터 처리의 모든 단계를 스트림 처리 방식으로 통합하는 것을 목표로 합니다. 캡파 아키텍처는 데이터 처리 시스템의 설계와 구현을 단순화하고 유지 보수성을 향상시키기 위해 설계되었습니다.</p><h3 id="b1a602cc-f71e-4d15-8e76-1b8ea0376bbe" class="">주요 개념 및 구성 요소</h3><ol type="1" id="f2c3c1fc-2232-4aef-b280-5d0fdedbe87e" class="numbered-list" start="1"><li><strong>스트림 처리 (Stream Processing):</strong><ul id="6b86989d-4458-4fbf-9f99-9b0a6fd1a7e9" class="bulleted-list"><li style="list-style-type:disc">캡파 아키텍처는 모든 데이터 처리를 스트림 처리 방식으로 수행합니다. 데이터는 실시간으로 시스템에 유입되고, 연속적인 데이터 스트림으로 처리됩니다.</li></ul><ul id="98072b08-cc1f-423e-93f1-ab9ef6c4deb9" class="bulleted-list"><li style="list-style-type:disc">스트림 처리 시스템은 이벤트가 발생하는 즉시 데이터를 처리하며, 지연 시간이 매우 짧습니다.</li></ul></li></ol><ol type="1" id="3aea8020-aa72-4bf4-b151-3d08ff1e3627" class="numbered-list" start="2"><li><strong>단일 데이터 처리 경로:</strong><ul id="9739a59a-b489-4f4f-90a0-eccfc1062c2a" class="bulleted-list"><li style="list-style-type:disc">캡파 아키텍처는 람다 아키텍처의 두 가지 데이터 처리 경로(배치 처리와 실시간 처리)를 단일 경로로 통합합니다. 즉, 모든 데이터 처리가 실시간 스트림으로 처리됩니다.</li></ul><ul id="01594e06-5319-4d0f-bd8c-7929bf80710b" class="bulleted-list"><li style="list-style-type:disc">이를 통해 데이터 처리 경로의 복잡성을 줄이고 유지 보수를 단순화할 수 있습니다.</li></ul></li></ol><ol type="1" id="cfeeeace-9356-4777-9bd2-75614e94a7e0" class="numbered-list" start="3"><li><strong>이벤트 소싱 (Event Sourcing):</strong><ul id="0eea2ef3-9f55-45eb-b547-94a9f44dc263" class="bulleted-list"><li style="list-style-type:disc">이벤트 소싱은 시스템의 상태 변화를 이벤트 형태로 기록하는 방법입니다. 캡파 아키텍처는 이 이벤트 소싱 패턴을 활용하여 모든 데이터 변화를 스트림으로 기록하고 처리합니다.</li></ul><ul id="0197f168-06e7-4912-b192-4e458ad781da" class="bulleted-list"><li style="list-style-type:disc">이벤트 소싱을 통해 시스템의 상태를 언제든지 재구성할 수 있으며, 과거 데이터를 쉽게 복구할 수 있습니다.</li></ul></li></ol><h3 id="dd74f23a-da66-47f9-a162-0488cc20cca7" class="">데이터 처리 흐름</h3><ol type="1" id="bb7500f0-ee4e-42a2-88b4-21842b17eb9c" class="numbered-list" start="1"><li><strong>데이터 수집:</strong><ul id="11756433-6537-4c2f-a0af-80aeddf582bf" class="bulleted-list"><li style="list-style-type:disc">데이터는 다양한 소스(예: 센서, 로그, 사용자 활동)에서 스트림 형태로 수집됩니다.</li></ul><ul id="4c858a73-c495-435c-9dc6-90fb174b63b7" class="bulleted-list"><li style="list-style-type:disc">Apache Kafka, Amazon Kinesis와 같은 메시지 브로커가 스트림 데이터를 수집하고 저장하는 데 사용될 수 있습니다.</li></ul></li></ol><ol type="1" id="67a6d610-7b64-4fce-82ad-82a90e101c20" class="numbered-list" start="2"><li><strong>스트림 처리:</strong><ul id="6b6bc708-903c-4fc5-9773-f528cb96a7d9" class="bulleted-list"><li style="list-style-type:disc">수집된 데이터 스트림은 실시간 처리 엔진(예: Apache Flink, Apache Kafka Streams, Apache Samza)을 통해 즉시 처리됩니다.</li></ul><ul id="772d3cfe-c07c-474c-aa21-0d7ce1b90e70" class="bulleted-list"><li style="list-style-type:disc">데이터 변환, 필터링, 집계 등의 연산이 스트림 처리 엔진에서 수행됩니다.</li></ul></li></ol><ol type="1" id="ec547b84-adf1-4c47-b8a8-337d3631c5cf" class="numbered-list" start="3"><li><strong>결과 저장 및 제공:</strong><ul id="8fd36812-e012-4e27-a531-547586d4e557" class="bulleted-list"><li style="list-style-type:disc">처리된 데이터는 실시간으로 저장소에 저장되며, 사용자가 쿼리를 통해 실시간 데이터를 조회할 수 있습니다.</li></ul><ul id="7a0de537-d778-4119-9477-c694b726f51f" class="bulleted-list"><li style="list-style-type:disc">실시간 데이터베이스(예: Apache Cassandra, Elasticsearch)나 데이터 레이크가 결과를 저장하고 제공하는 데 사용될 수 있습니다.</li></ul></li></ol><h3 id="3f5d16d0-d2d5-4c0e-a5a3-72d9a2dfb6f9" class="">장점</h3><ol type="1" id="e7194ecb-6180-4416-a828-4835e84911c8" class="numbered-list" start="1"><li><strong>단순성:</strong><ul id="db2cc187-a170-43ce-98a0-d97036c8f1fb" class="bulleted-list"><li style="list-style-type:disc">모든 데이터 처리를 단일 스트림 처리 경로로 통합하여 시스템 복잡성을 크게 줄일 수 있습니다.</li></ul><ul id="0ebd2435-4e0a-48ed-946d-350301552664" class="bulleted-list"><li style="list-style-type:disc">유지 보수와 운영이 용이해집니다.</li></ul></li></ol><ol type="1" id="3eab4aa5-41a5-4749-a723-d07159e7cc4f" class="numbered-list" start="2"><li><strong>실시간 처리:</strong><ul id="fb90c956-7032-485b-9548-79a7f27806bb" class="bulleted-list"><li style="list-style-type:disc">스트림 처리 방식을 사용하여 데이터가 유입되는 즉시 처리할 수 있어, 실시간 데이터 처리 요구사항을 만족시킵니다.</li></ul><ul id="399e6da0-f0c3-4aa8-b159-b16df1fb617f" class="bulleted-list"><li style="list-style-type:disc">지연 시간이 짧고 빠른 응답성을 제공합니다.</li></ul></li></ol><ol type="1" id="a8189230-0373-442a-94c9-012ff9fb088f" class="numbered-list" start="3"><li><strong>유연성:</strong><ul id="74b7bf5f-42b7-42ed-aeb9-e55466ed2cd6" class="bulleted-list"><li style="list-style-type:disc">이벤트 소싱을 통해 과거 데이터를 재처리하거나 시스템 상태를 복구할 수 있습니다.</li></ul><ul id="7b54a620-4e32-45c5-9b97-8568f7318919" class="bulleted-list"><li style="list-style-type:disc">데이터 처리 로직을 변경하거나 새로운 요구 사항에 대응하기가 용이합니다.</li></ul></li></ol><h3 id="5431f54e-dbf1-497b-adcb-3ca4218d27c7" class="">단점</h3><ol type="1" id="61e44048-9aa4-4d11-ba93-b3d1c0e320bf" class="numbered-list" start="1"><li><strong>이벤트 순서 보장:</strong><ul id="f0ee0d43-1c98-4647-a91d-ebbb50750970" class="bulleted-list"><li style="list-style-type:disc">스트림 처리 시스템에서 이벤트의 순서를 보장하는 것이 어려울 수 있으며, 이는 데이터 정합성에 영향을 줄 수 있습니다.</li></ul></li></ol><ol type="1" id="e62785f6-b216-4f26-98eb-1ec1bd1a2266" class="numbered-list" start="2"><li><strong>재처리 비용:</strong><ul id="eb6713e2-7a75-4758-a3ff-82e61f0dd4c6" class="bulleted-list"><li style="list-style-type:disc">모든 데이터를 스트림 방식으로 재처리해야 하는 경우, 시스템에 높은 부하가 걸릴 수 있습니다.</li></ul></li></ol><ol type="1" id="1f023076-e248-496f-9dd6-0722fe9e4305" class="numbered-list" start="3"><li><strong>기술 선택의 중요성:</strong><ul id="20fbf94c-337d-43e3-8d58-a170a6941930" class="bulleted-list"><li style="list-style-type:disc">스트림 처리 엔진과 메시지 브로커의 선택이 시스템 성능과 안정성에 큰 영향을 미칩니다. 적절한 기술 스택을 선택하는 것이 중요합니다.</li></ul></li></ol><h3 id="24c25413-337d-44d0-a691-cd080e73aec8" class="">결론</h3><p id="302a68fd-a51c-4c79-9472-13d83d8fb5a5" class="">캡파 아키텍처는 데이터 처리 시스템의 단순성과 실시간 처리를 중시하는 접근 방식으로, 람다 아키텍처의 복잡성을 해결하려는 노력에서 비롯되었습니다. 실시간 데이터 처리와 유지 보수성 향상에 중점을 두지만, 특정한 데이터 정합성 요구 사항이나 재처리 비용 등을 고려해야 합니다. 적절한 기술 스택과 설계를 통해 캡파 아키텍처는 대규모 데이터 처리 시스템에서 효과적으로 사용될 수 있습니다.</p></details></li></ul><p id="28836217-53bc-402f-b675-5eb6414f86f6" class="">
</p><p id="98ead663-3b24-4736-95dc-7df41e1c8544" class="">Monitoring / APM</p><ul id="5ac705ca-b474-4d97-b3ba-c249a472bbc2" class="toggle"><li><details open=""><summary>대용량 log 수집/분석 시스템</summary><p id="b806c198-4848-4410-86ac-1d44995034f2" class=""><strong>일반적인 로그 수집 및 분석 시스템 아키텍쳐</strong></p><figure id="aa3c039d-0b3e-417f-a118-f2af35ab169b" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2026.png"><img style="width:707.9971313476562px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2026.png"/></a></figure><ul id="2ceac176-1742-4654-b95b-3e132afb42f6" class="bulleted-list"><li style="list-style-type:disc">앞단의  API 서버가 로그를 클라이언트로 부터 수집하고 데이타를 정재한다.</li></ul><ul id="05624f6e-1c78-4b45-b27f-3e24704d68fd" class="bulleted-list"><li style="list-style-type:disc">로그 저장소가 순간적으로 많은 트래픽을 감당할 수 없는 경우가 많기 때문에, 중간에 Message Q를 넣어서, 들어오는 로그를 Message Q에 저장하여 완충을 한다.</li></ul><ul id="0220d4a8-7e5b-4a44-ac55-b0a53a7250fa" class="bulleted-list"><li style="list-style-type:disc">이 Message Q로 부터 로그를 Message Consumer가 순차적으로 읽어서 Log Storage에 저장한다.</li></ul><ul id="994d9208-f579-4ea3-81d4-cc9f6ad051c0" class="bulleted-list"><li style="list-style-type:disc">저장된 로그는 Reporting 툴을 이용하여 시각화 한다</li></ul><p id="c8b82bf8-4152-406b-82f9-1182a99755f6" class="">
</p><h3 id="c7023efb-8663-45fe-8878-b830a5082745" class="">구성 요소</h3><ol type="1" id="5fa5adae-ce27-4aa5-a3b8-e2110e0caf24" class="numbered-list" start="1"><li><strong>로그 수집기 (Log Collectors)</strong></li></ol><ol type="1" id="e47e9b1b-f9c1-4925-8b72-0153a2642b97" class="numbered-list" start="2"><li><strong>메시지 큐 (Message Queue) - Apache Kafka</strong></li></ol><ol type="1" id="eb257be4-a6d8-41f4-817f-17e33630e85a" class="numbered-list" start="3"><li><strong>데이터 프로세서 (Data Processor) - Data Prepper</strong></li></ol><ol type="1" id="c1e2c22d-ef93-4abd-87ae-613153d963bd" class="numbered-list" start="4"><li><strong>데이터 저장소 (Data Store) - OpenSearch</strong></li></ol><ol type="1" id="283ab32d-c9e6-4ef0-9d3a-83d21df88f38" class="numbered-list" start="5"><li><strong>모니터링 및 알림 시스템</strong></li></ol><p id="847570e1-a8f5-4708-bb8f-636025db3220" class="">
</p><h3 id="1f9e7906-3232-4066-b906-70d83badb772" class="">시스템 아키텍처</h3><ol type="1" id="b86fb464-2ec6-43c1-b607-d7d03a592d58" class="numbered-list" start="1"><li><strong>로그 수집기 (Log Collectors)</strong><ul id="b8761f20-8be3-412e-8448-0c33df18de86" class="bulleted-list"><li style="list-style-type:disc">다양한 애플리케이션 및 서버에서 로그를 수집하여 Kafka로 전송</li></ul><ul id="1248f3f9-3fb3-4d3b-8c5f-718f0d472f10" class="bulleted-list"><li style="list-style-type:disc">Filebeat, Fluentd, Logstash, OpenTelemetry Collector 등을 사용 가능</li></ul></li></ol><ol type="1" id="ec19c66d-07d5-4884-a136-1d363e16a70d" class="numbered-list" start="2"><li><strong>메시지 큐 (Apache Kafka)</strong><ul id="4037d345-d5c8-4ac7-9029-8b967cd2f40c" class="bulleted-list"><li style="list-style-type:disc">로그 데이터를 버퍼링하고 처리 시스템으로 전송</li></ul><ul id="ebae1559-8765-47af-ad10-2a5500688edd" class="bulleted-list"><li style="list-style-type:disc">높은 처리량과 내구성을 제공</li></ul></li></ol><ol type="1" id="ad9d75c9-8f4b-4a5d-b6db-add342bdf29f" class="numbered-list" start="3"><li><strong>데이터 프로세서 (Data Prepper)</strong><ul id="4c5ac38d-6ec0-4afa-99e3-9efdf5d1d6f1" class="bulleted-list"><li style="list-style-type:disc">Kafka에서 데이터를 가져와 전처리 후 OpenSearch로 전송</li></ul><ul id="d39eea36-a61e-42a8-9876-b90d45d0cf4f" class="bulleted-list"><li style="list-style-type:disc">로그 데이터의 필터링, 변환, 집계 등</li></ul></li></ol><ol type="1" id="d82124b0-afab-4cb4-9117-bb88fa1198e4" class="numbered-list" start="4"><li><strong>데이터 저장소 (OpenSearch)</strong><ul id="7804298f-9368-4675-8a41-765681889103" class="bulleted-list"><li style="list-style-type:disc">전처리된 로그 데이터를 저장하고 검색 가능하게 함</li></ul><ul id="b966b612-5ea7-4f26-ac5e-2f0e721b370c" class="bulleted-list"><li style="list-style-type:disc">분산 검색 및 분석 기능 제공</li></ul></li></ol><ol type="1" id="3f7addad-9bc1-4ebf-a0fc-feed73d44461" class="numbered-list" start="5"><li><strong>모니터링 및 알림 시스템</strong><ul id="67c790d0-0daf-4358-b04f-d7ddedc0571b" class="bulleted-list"><li style="list-style-type:disc">시스템의 상태 및 성능 모니터링</li></ul><ul id="413dc022-46c6-49c3-b34f-60677e5c13a8" class="bulleted-list"><li style="list-style-type:disc">장애 발생 시 알림 전송</li></ul></li></ol><h3 id="497966e7-a0c6-441c-aca1-385f907a28ba" class=""></h3><h3 id="e438ad6c-f74a-4eb8-bb66-5b0bb08305f1" class="">세부 구성</h3><ol type="1" id="73a1c02d-3767-4b89-b4d7-37fdc409564f" class="numbered-list" start="1"><li><strong>OpenTelemetry</strong>: 데이터 수집 (로그, 메트릭, 트레이스)<ul id="ac0175f6-17fd-4050-ae2a-355542dede72" class="bulleted-list"><li style="list-style-type:disc">역할: 다양한 애플리케이션 및 서비스에서 로그, 메트릭, 트레이스 데이터를 수집하여 Kafka로 전송.</li></ul><ul id="a8ab595e-2f23-4b5d-b29a-c483f4c08c51" class="bulleted-list"><li style="list-style-type:disc">구성:<ul id="6311a4c6-30e3-4ff3-a58a-395a07f01be5" class="bulleted-list"><li style="list-style-type:circle">수집기 에이전트: 각 애플리케이션 서버에 설치</li></ul><ul id="bdd7b46d-cd1e-4f1c-9eec-8acbc4a9e66d" class="bulleted-list"><li style="list-style-type:circle">수집기: 중앙 서버에 설치되어 에이전트에서 데이터를 수집하여 Kafka로 전송</li></ul></li></ul><ul id="361a1dd0-7553-4758-a5a8-a5af1d3e21d9" class="bulleted-list"><li style="list-style-type:disc">확장: 에이전트 및 수집기 인스턴스를 수평 확장하여 처리량 증가 대응</li></ul></li></ol><ol type="1" id="423bccd7-2b54-4648-879a-5818c3fe116a" class="numbered-list" start="2"><li><strong>Apache Kafka</strong>: 데이터 수집 및 전송<ul id="266c8c90-1b2f-4c06-a45a-f692659adf87" class="bulleted-list"><li style="list-style-type:disc">역할: 데이터를 안정적으로 버퍼링하고 처리 시스템으로 전송</li></ul><ul id="bead7020-c5f2-4002-8372-7c377c5ba531" class="bulleted-list"><li style="list-style-type:disc">구성:<ul id="ebaa50cf-ba00-48b9-9954-feb09aff9211" class="bulleted-list"><li style="list-style-type:circle">클러스터: 브로커 수를 늘려 확장 가능 (초당 10만 건 이상 처리 가능)</li></ul><ul id="544689f2-a123-4b45-a1f9-0a197b3b7f5a" class="bulleted-list"><li style="list-style-type:circle">토픽: 로그, 메트릭, 트레이스 데이터를 위한 별도 토픽 구성</li></ul></li></ul><ul id="5e9479b2-6108-402a-8260-76ce363bb1c5" class="bulleted-list"><li style="list-style-type:disc">확장: 브로커 수 및 파티션 수를 증가시켜 처리량 확장</li></ul></li></ol><ol type="1" id="f6161e45-d7f8-4c85-af61-725e3920c936" class="numbered-list" start="3"><li><strong>Data Prepper</strong>: 데이터 전처리 및 OpenSearch로 전송<ul id="798d1199-9733-4dc7-8b3f-a18fb832676a" class="bulleted-list"><li style="list-style-type:disc">역할: Kafka에서 데이터를 가져와 전처리 후 OpenSearch로 전송</li></ul><ul id="46136501-c743-4780-9089-8cb2a1ee11c7" class="bulleted-list"><li style="list-style-type:disc">구성:<ul id="081b5a30-1b03-4715-a115-6d83679ab48d" class="bulleted-list"><li style="list-style-type:circle">노드: 다수의 Data Prepper 인스턴스로 구성하여 병렬 처리</li></ul><ul id="17e00690-0a1c-425e-865a-7e82db83b251" class="bulleted-list"><li style="list-style-type:circle">파이프라인: 다양한 데이터 전처리 규칙 적용</li></ul></li></ul><ul id="5c729583-3ac5-495f-8e3a-9f08cf93e0dd" class="bulleted-list"><li style="list-style-type:disc">확장: Data Prepper 인스턴스 수를 증가시켜 처리량 확장</li></ul></li></ol><ol type="1" id="fd8afcd1-7c4f-442d-a5f1-cdaa891e4d31" class="numbered-list" start="4"><li><strong>OpenSearch</strong>: 데이터 저장 및 검색<ul id="f1e5ec64-20d3-4465-bd47-17be432979db" class="bulleted-list"><li style="list-style-type:disc">역할: 데이터를 저장하고 검색을 지원</li></ul><ul id="c0947b9a-dca0-4079-9ef9-7b0c8ca75fcd" class="bulleted-list"><li style="list-style-type:disc">구성:<ul id="987b2e56-70e7-41ab-adfb-9f32871fd0a8" class="bulleted-list"><li style="list-style-type:circle">클러스터: 다수의 노드로 구성 (마스터 노드, 데이터 노드, 인제스트 노드)</li></ul><ul id="a614705b-9b79-44a7-8a2c-e685e25d0275" class="bulleted-list"><li style="list-style-type:circle">인덱스: 데이터 유형별로 인덱스 구성</li></ul></li></ul><ul id="ecc82847-6798-4c51-a8f6-428d622ba1a1" class="bulleted-list"><li style="list-style-type:disc">확장: 노드 수를 증가시켜 처리량 및 저장 용량 확장</li></ul><p id="14c3a4cc-090a-8072-b4b4-e4a4e8c847a5" class="">
</p></li></ol></details></li></ul><ul id="6bbb7f37-6315-4ed2-bf0d-a5186b9bee75" class="toggle"><li><details open=""><summary>TOSS - 대규모 로그 처리도 OK! Elasticsearch 클러스터 개선기</summary><h1 id="e6329b76-85ef-497d-bbc1-63b1afd7e8bc" class=""><strong>로그 수집 현황</strong></h1><p id="e2ebadd8-344f-4f33-8707-866b1cb32453" class="">토스증권이 운영하는 서비스와 인프라에서는 매일 수많은 로그들이 생성되고 있고, 이를 Elasticsearch 클러스터로 수집하여 로그를 검색하고 분석하고 있습니다. 이러한 로그들은 약 100여 개의 로그 파이프라인을 통해 하루 기준으로 22테라 바이트, 약 170억 건의 로그를 인덱싱하고 있는데요, 서비스가 커질수록 수집되는 로그는 더욱 늘어나기 때문에 수평적으로 확장하고 안정적으로 운영하기 위해 지속적으로 클러스터의 개선이 필요합니다.</p><p id="a23c45c8-6916-44a9-963f-5b36dc529329" class="">실제로 SLASH23 발표를 준비하던 시기에는 피크 시간에 초당 60만의 인덱싱과 하루 56억 건 정도의 로그를 처리하였지만 수 개월이 지난 지금은 로그가 3배 이상 늘어나서 피크 시간에 초당 200만 이상의 인덱싱, 하루 기준으로 약 170억 건의 로그를 처리하고 있습니다.</p><figure id="9e3d6624-b7c7-489f-88cc-d4938e35cbb4" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/bcc54275-aefd-49f6-81dd-a752de8dfcb4/slash23_%EC%B6%94%EA%B0%80%EC%9E%A5%ED%91%9C-06.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/bcc54275-aefd-49f6-81dd-a752de8dfcb4/slash23_%EC%B6%94%EA%B0%80%EC%9E%A5%ED%91%9C-06.png"/></a></figure><p id="34f3163e-1a9b-464b-954b-58e00dc970a8" class="">토스증권 Elasticsearch 클러스터는 온프레미스로 운영하고 있어 클러스터가 커질수록 상면 공간과 관리 부담이 있기 때문에 가능한 효율적으로 구성을 하는 것이 필요한데요, 거의 대부분의 로그 검색과 분석은 최근 보름 이내의 로그를 대상으로 하기에 Hot-warm 아키텍처를 도입하면 보다 효율적으로 운영할 수 있다고 판단하였고 Hot 노드보다 더 큰 디스크를 가진 Warm 노드를 구성한 후 생성된 지 오래된 인덱스는 Warm 노드로 이동하고, 일정 기간이 지나면 삭제하도록 하는 ILM (Index Lifecycle Management)을 구성하였습니다.</p><p id="ccd05375-af2b-46a0-b646-95c705face32" class="">이러한 구조를 채택하여 만약 최근 로그를 더 오래 보관하고 싶다면 Hot 노드 증설을 하고, 전체 로그를 더 오래 보관하고 싶다면 Warm 노드만 증설하는 등 목적에 따라 확장할 수 있도록 구성하였습니다.</p><figure id="c1d4fe19-c905-4501-9383-5131628e1ea7" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/8f798097-b39f-49cc-8f93-965e05ee9c1f/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_04.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/8f798097-b39f-49cc-8f93-965e05ee9c1f/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_04.png"/></a></figure><h1 id="5b7faeca-d9bc-496b-b03f-d5d1e057119e" class=""><strong>Elasticsearch 클러스터 안정화</strong></h1><p id="6260b622-6d56-4d35-8f87-203194b2b5ff" class="">그런데 이처럼 수백 테라바이트 단위로 로그 수집 규모가 매우 커지면서 Elasticsearch 클러스터의 장애가 종종 발생하였는데요, 클러스터가 매우 느려져서 로그 인덱싱이 크게 지연되기도 하고 키바나에서 로그 검색을 할 때에도 검색 지연이 크게 발생했고 때로 데이터 노드가 내려가는 장애가 있었습니다.</p><p id="f8cdc9c0-56d1-4657-9c5f-8332960ac053" class="">클러스터가 크게 느려졌을 때 노드들의 상태는 공통적인 패턴을 보였는데요, 매우 많은 <code>fielddata</code> 메모리를 사용하고 있었고 매우 긴 가비지 컬렉션이 빈번하게 발생하여 가비지 컬렉션이 끝날 때까지 클러스터가 일시적으로 멈추는 패턴이었습니다.</p><figure id="05606a98-7eae-436b-b0da-5e419a2d7f8f" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/33ecffd1-aa60-43ba-b5a0-908c3eb19b35/slash23_%EC%B6%94%EA%B0%80%EC%9E%A5%ED%91%9C-07.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/33ecffd1-aa60-43ba-b5a0-908c3eb19b35/slash23_%EC%B6%94%EA%B0%80%EC%9E%A5%ED%91%9C-07.png"/></a></figure><p id="0ba70bfe-cdad-4396-b349-815d97e22e6f" class="">매우 많은 fielddata 메모리 사용</p><h1 id="58cf3027-8d19-4f25-97ce-56dafac2f4de" class=""><strong>잘못 사용한 fielddata 옵션</strong></h1><p id="8d44a0d4-4bdf-4e08-af1b-32eee9bb2d83" class="">저희가 장애를 겪은 경우는 인덱스 매핑에서 일부 필드 설정에 <code>fielddata</code> 옵션을 잘못 사용한 경우였습니다.</p><figure id="4456d82b-acad-45a9-9b1b-a5b93bdfb246" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/c090a9aa-7dd7-4f94-ab05-fe7e079df0a2/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_06.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/c090a9aa-7dd7-4f94-ab05-fe7e079df0a2/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_06.png"/></a></figure><p id="4838d5f3-45c5-4751-9a21-fdc131199abc" class="">Elasticsearch 및 Lucene에 Doc value 스토리지가 도입되기 전에는 필드에 대해 aggregation과 정렬을 하기 위해서 필드의 값들을 <code>fielddata</code>라는 메모리 영역으로 올려서 <code>fielddata</code>에서 aggregation을 수행하고 정렬을 하였었는데요, 매우 큰 인덱스의 필드들을 메모리로 올려서 사용하다 보니 Elasticsearch의 JVM 메모리가 항상 부족해지고 매우 긴 가비지 컬렉션이 발생하여 이로 인해 클러스터가 일시적으로 멈추는 현상이 빈번했습니다. 그래서 Elasticsearch는 파일 시스템을 사용하고 컬럼 기반인 Doc value storage를 도입하여 aggregation과 정렬을 수행할 때 힙 메모리를 덜 사용하고 운영체제 레벨 캐시를 적극적으로 사용하는 방향으로 발전되어왔습니다.</p><p id="43093045-664d-4f13-9478-7b456fe820cf" class="">따라서 Doc value 스토리지를 지원하는 지금은 특별한 경우가 아니면 <code>fielddata</code>를 사용할 일이 없습니다. 인덱스의 크기가 작다면 문제가 되지 않겠지만 인덱스의 크기가 커지면 이는 금방 장애로 이어질 수 있습니다. 저희의 장애 당시 설정에서는 단지 7개의 필드에서 <code>fielddata</code> 옵션이 설정되어 있었는데 유입되는 로그의 양이 매우 많다 보니 이로 인해 데이터 노드의 힙 메모리가 금방 가득 차게 되고 가비지 컬렉션이 빈번하게 발생하였습니다.</p><p id="bd110ac9-6aa4-4cd6-b3dd-c42fea932283" class="">Doc value 스토리지를 지원하지 않는 text 타입을 aggregation 하려는 목적에서 <code>fielddata</code>를 사용할 수는 있지만 가급적 사용하지 말고 다른 방법으로 문제를 푸는 것이 좋습니다.</p><h1 id="df04df54-3b3e-4529-a6c6-43b5ea2fdcb3" class=""><strong>인덱스 매핑</strong></h1><p id="a0c09645-7a22-4fd5-a806-a9f7e1f5ad24" class="">또 하나의 Elasticsearch 클러스터의 안정성을 위협하는 것은 mapping explosion입니다.</p><p id="d47157b7-ed7c-4655-9b8d-c07372299a4d" class="">유입되는 로그가 많아지고 규모가 커질수록 인덱스 매핑이 정말 중요해지는데요, Elasticsearch 클러스터가 느려지고 불안정한 경우 원인 분석을 하면 대부분 인덱스 매핑이 비효율적으로 정의되어 있는 경우가 많습니다.</p><p id="fd52d411-9fac-4fbd-b94c-47ebf6488d3c" class="">만약 관리하는 Elasticsearch 클러스터가 느려지고 불안정하다면 맨 먼저 인덱스 매핑을 살펴보는 것이 좋은데요, 인덱스에 너무 많은 필드들이 매핑되어 있는지와 fielddata 옵션을 사용하는 필드가 있는지, default dynamic mapping을 사용하고 있는지 점검해 보면 좋습니다.</p><p id="16703939-fb16-47cd-a051-d32dd9a26147" class="">Elasticsearch는 명시적인 설정을 하지 않는다면 들어온 json의 형태 그대로 인덱싱을 하고 동적으로 인덱스 매핑을 업데이트하는데요,</p><p id="7b8bb7e4-a1b7-473f-b4bb-240b27fbe6bf" class="">이런 특성으로 인해 입력으로 들어오는 json에 key가 매우 많다면 mapping explosion이 일어나고 마스터 노드가 클러스터 상태를 업데이트하고 관리하는 데 리소스를 매우 많이 사용하여 클러스터가 불안정하게 됩니다. 따라서 인덱싱할 데이터가 너무 많은 키를 가지지 않도록 해야 하지만 어쩔 수 없이 임의의 구조를 가진 데이터를 인덱싱해야 한다면 flattened type를 사용하거나 dynamic field를 false로 하는 것이 필요합니다. dynamic field 옵션을 false로 설정하면 명시적으로 매핑한 필드만 인덱싱되고 그 이외의 필드는 인덱싱되지 않기 때문입니다.</p><p id="e19f0362-3867-497c-87d1-2df8dae9d12a" class=""><code>1234567891011121314{ &quot;dynamic_templates&quot;: [   {     &quot;strings_as_keyword&quot;: {       &quot;mapping&quot;: {         &quot;ignore_above&quot;: 256,         &quot;type&quot;: &quot;keyword&quot;       },       &quot;match_mapping_type&quot;: &quot;string&quot;     }   } ]}</code></p><p id="61b14ef4-fd8c-4f82-b1c7-8b11ae6a4ca5" class=""><code>1234567891011121314{ &quot;mappings&quot;: {   &quot;dynamic&quot;: false,   &quot;properties&quot;: {     &quot;user&quot;: {       &quot;properties&quot;: {         &quot;name&quot;: {           &quot;type&quot;: &quot;keyword&quot;         }       }     }   } }}</code></p><p id="530c8817-b92e-4919-81db-15914bde1cd1" class="">명시적인 매핑, flattened type, dynamic field를 끄는 것들은 결국 인덱스에 의도하지 않게 너무 많은 필드가 생성되지 않도록 하는 것이 목적입니다. 안정적인 Elasticsearch 클러스터를 운영하기 위해서 가장 중요한 점은 인덱스 필드를 제어할 수 있어야 합니다.</p><figure id="92087e05-8850-4652-ba00-331b70d0ff23" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/3d8d8a05-5c0f-405a-8eb0-d2f3525795fb/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_11.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/3d8d8a05-5c0f-405a-8eb0-d2f3525795fb/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_11.png"/></a></figure><h1 id="3325052d-71b2-410c-bcbe-3dd8f3afd098" class=""><strong>적절한 샤드 개수</strong></h1><p id="a9b17d59-47a8-446b-aea0-66d00b558481" class="">그 외의 인덱스 설정에서 고려해야 하는 것은 인덱스의 샤드 개수입니다. 샤드 수를 결정하는 데에 정답은 없지만 토스증권에서는 헤비 인덱스의 경우 프라이머리 샤드의 개수는 Hot 노드의 수와 동일하게 하고 있습니다.</p><p id="7b97fd4e-29ca-4749-bdb9-52ebfb0c48ad" class="">데이터 노드의 CPU 사용량이 여유가 있다면 프라이머리 샤드 개수를 더 늘려서 초당 인덱싱 처리량을 개선할 수 있어요. 다만 프라이머리 샤드를 더 늘린다면 샤드가 특정 노드에 쏠려서 핫스팟 노드가 될 수 있기 때문에 샤드의 수를 Hot 노드의 배수로 설정하는 것이 좋습니다.</p><p id="379acd43-ce81-4d78-9208-2b384969639e" class="">index refresh time은 60초로 설정해서 세그먼트 생성과 머지가 적게 발생하도록 하였고, flush_threshold_size는 기본값인 512MB의 두 배인 1GB로 설정하여 트랜스로그 플러시를 실행하는 빈도를 낮추도록 하였습니다.</p><p id="48a33730-1420-4139-8857-181fce9198ba" class="">마지막으로 슬로우 쿼리 로깅을 활성화하여 클러스터에 부하를 줄 수 있는 비용이 비싼 쿼리가 실행되는 것을 모니터링하고 있습니다.</p><p id="58d6e541-7d45-4cc3-aa7b-31b87532933b" class=""><code>1234567891011121314{ &quot;index&quot;: {   &quot;translog&quot;: {     &quot;flush_threshold_size&quot;: &quot;1024MB&quot;   },   &quot;refresh_interval&quot;: &quot;60s&quot;,   &quot;codec&quot;: &quot;best_compression&quot;,   &quot;search&quot;: {     &quot;slowlog&quot;: { … }   },   &quot;indexing&quot;: {     &quot;slowlog&quot;: { … }   }}</code></p><h1 id="0a0fec39-4b0a-4343-a07e-d239da570fa9" class=""><strong>Vector 로그 파이프라인 전환</strong></h1><p id="e40124da-3dd5-4e90-a2e3-66dc534b003f" class="">그 이후에 진행한 것은 로그 파이프라인 전환이었습니다.</p><p id="6754abce-f829-4c05-9d6e-ad80fab530d2" class="">Elasticsearch로 로그를 인덱싱하는 로그 파이프라인은 현재까지 약 100여 개를 운영하고 있습니다. 로그 파이프라인은 Logstash를 사용하여 운영하였는데 Logstash는 범용적으로 사용할 수 있게 다양한 설정을 제공하지만 JVM 기반으로 만들어져있어 시스템 자원을 많이 사용하는 단점을 가지고 있습니다.</p><p id="f09e7260-bcaa-4462-a899-ee0fa288427a" class="">Logstash 기반 파이프라인이 점점 늘어나서 쿠버네티스 클러스터에서 260GB 이상의 메모리를 사용하는 상황이 발생하였고 앞으로 로그 파이프라인은 더욱 늘어날 예정이기 때문에 Logstash를 대체할 수 있는 경량 로그 파이프라인으로 전환이 필요하였습니다.</p><p id="f0225434-9302-4b0d-96e0-18962d61e0f5" class="">로그 파이프라인 전환을 위하여 여러 경량 로그 파이프라인 오픈 소스들을 검토하였고 그중 로그 가공과 정제를 코드로 유연하게 작성할 수 있는 vector를 선택하였습니다.</p><figure id="cdf23948-c953-4b74-868c-436f20afe8ab" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/60e8f24e-dea5-47f3-9ccc-4caa81be9c59/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_15.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/60e8f24e-dea5-47f3-9ccc-4caa81be9c59/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_15.png"/></a></figure><p id="a5e9984b-9df1-442c-9ca6-aeed31762161" class="">Vector는 Datadog에서 공개한 Rust 기반 경량 log shipper이고 고성능과 메모리 효율을 목표로 하여 높은 워크 로드 환경에서 리소스 효율적으로 로그 파이프라인을 운영할 수 있습니다. 또한 다양한 source들과 sink들을 제공하고 있어서 목적에 맞게 로그 파이프라인을 구성하고 확장할 수 있는 장점이 있습니다.</p><p id="76ddb5ee-c61e-4e88-9256-8e6d74ac1aa5" class="">그리고 Logstash에서 아쉬웠던 부분이 로그 파이프라인 모니터링이었는데 Vector로 전환한 후 prometheus exporter로 로그 파이프라인 모니터링을 쉽게 구현할 수 있었고, 로그 파이프라인 모니터링을 통해 파이프라인에 문제가 생겼을 때 이를 빨리 파악하고 개선이 필요한 부분을 쉽게 알 수 있게 되었습니다.</p><figure id="d84cac2a-51a3-4901-ae79-fbef7ff915d3" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/2ff7e87c-51d0-4086-9f4d-1f1995db0fd9/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_18.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/2ff7e87c-51d0-4086-9f4d-1f1995db0fd9/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_18.png"/></a></figure><p id="3de1ce00-d449-4cbd-9ac4-a3b4251e5280" class="">Vector로 로그 파이프라인을 전환한 후 시스템 자원을 많이 절약할 수 있었는데요, Logstash는 범용적으로 사용하기 좋은 장점이 있지만 JVM 기반으로 되어 있어 시스템 리소스를 제법 많이 사용하는 문제가 있었고 운영의 편의성을 위해 로그 파이프라인들을 각각 별도의 프로세스로 띄우고 있었기 때문에 Logstash 인스턴스가 많아지면 메모리 사용량이 많을 수밖에 없었는데 이 부분을 해소할 수 있었습니다. 기존에 약 260GB 정도 사용하고 있던 메모리 사용량이 10GB 수준으로 크게 줄었습니다. 약 96% 이상 메모리를 절약하는 성과가 있었습니다.</p><figure id="20778bed-d98c-4903-91f3-c8294e7b8cb0" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/3dcc4fa1-10c7-4f0c-8fda-3fdcdd3c3f70/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_20.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/3dcc4fa1-10c7-4f0c-8fda-3fdcdd3c3f70/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_20.png"/></a></figure><p id="85641af9-ac62-4c42-a071-3e35b5ffe95d" class="">Vector 전환 이후 시간이 흘러 로그 파이프라인이 더 늘어나고 유입되는 로그도 3배 이상 증가한 현재는 Vector 파이프라인들의 메모리 사용량은 약 23GB 정도로 측정되었습니다. 기존 Logstash 기반의 로그 파이프라인을 그대로 유지하고 있었다면 쿠버네티스 클러스터에서 수백 GB의 메모리를 사용하게 되었을 상황을 예방할 수 있었습니다.</p><h1 id="d4bb543e-166d-477f-917a-f5d6bed56675" class=""><strong>여러 데이터센터 간 클러스터링</strong></h1><p id="53138581-a0a5-4042-86bf-3924ea48df39" class="">로그 파이프라인을 vector로 전환한 후 다음으로 진행한 것은 데이터센터 확장이었습니다. 데이터센터 이중화를 위하여 새로운 데이터 센터가 추가되어 새로운 데이터 센터에서 생성되는 로그를 수집하는 Elasticsearch 클러스터가 필요해졌는데요, 이렇게 커진 Elasticsearch 클러스터를 한 세트 더 구축하고 운영할 수도 있지만 더 나은 방법이 없을까 고민을 하였고 데이터센터 간에 하나의 Elasticsearch 클러스터를 구축할 수 있을지 검토하였습니다.</p><figure id="47b89557-5a42-4161-a452-15b3d74c8571" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/91e33456-7b14-4968-b7af-d95bfbb7d1e6/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_22.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/91e33456-7b14-4968-b7af-d95bfbb7d1e6/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_22.png"/></a></figure><p id="6200f2e0-1aac-4544-9ea2-d27d1ca8d068" class="">사실 서로 다른 데이터센터의 Elasticsearch 노드들을 하나의 클러스터로 묶는 방법은 elastic에서는 권장하지 않는 방법입니다. 이는 노드들이 빈번하게 통신하는데 데이터센터 간의 네트워크 레이턴시가 높으면 클러스터의 전체적인 성능 저하가 발생하기 때문입니다.</p><figure id="18a01eb7-0613-48e5-a181-a0f9d61b3d53" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/675fba13-918a-41bf-99e8-6fedac245e7f/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_23.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/675fba13-918a-41bf-99e8-6fedac245e7f/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_23.png"/></a></figure><p id="26aaa98a-d7ed-4da8-b936-9d1c7efd3e11" class="">하지만 데이터센터 간의 거리가 짧고 네트워크 레이턴시가 작다면 리전 내의 가용성 존(AZ, Availability Zones)로 볼 수 있지 않을까 생각했습니다. AWS가 서울 리전에서 4개의 Zone으로 구성되어 있는 것처럼요. 그리고 수백 테라바이트의 로그 수집과 분석이 목적이기 때문에 조금의 지연보다 비용 절감으로 얻을 수 있는 장점이 더 크다고 생각했습니다.</p><p id="4cce4151-7507-401a-830d-0ad589c54c4d" class="">대신 Elasticsearch가 샤드를 복제하거나 복구할 때 많은 네트워크 트래픽을 점유하기 때문에 클러스터 안정성을 위해서 Elasticsearch 클러스터를 위한 전용 회선을 별도로 구축하였고 하나의 IDC가 장애가 났을 경우를 대비하여 replica shard는 서로 다른 IDC에 저장하도록 구성하였습니다.</p><p id="1013ecc0-353a-4ecf-b09e-010330080608" class="">IDC 간에 하나의 Elasticsearch 클러스터를 구축하기 위해서는 투표 전용 마스터 노드가 필요합니다. 각각의 IDC에는 마스터 노드 1개를 배치하고, AWS에 투표 전용 마스터 노드를 배치하여 총 3대의 마스터 노드를 배치하는 구조입니다. 마스터 선출을 위한 투표만 수행하는 노드를 제3의 장소인 AWS에 배치하여 IDC1의 마스터 노드와 IDC2의 마스터 노드를 타이브레이커로 묶게 됩니다. 이를 통해 DCI 단절 시 발생할 수 있는 split brain 문제를 방지할 수 있습니다.</p><figure id="ab87a7be-0720-4e02-bf29-81096ccdb49a" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/979cc801-2d87-430d-ad85-ba8cfeaaeb2a/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_26.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/979cc801-2d87-430d-ad85-ba8cfeaaeb2a/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_26.png"/></a></figure><p id="f6da067a-ed28-4986-8e81-94d23b18e6fe" class="">또한 하나의 데이터센터가 장애가 발생하였을 때 데이터 유실을 방지하기 위하여 Shard awareness를 설정하여 primary shard와 replica shard가 서로 다른 IDC에 배치되도록 하였습니다. 그리고 일시적인 DCI(Data Center Interconnect) 장애 시 샤드 복제가 과도하게 일어나는 것을 방지하기 위해 force awareness를 설정하여 IDC1과, IDC2의 데이터 노드들이 클러스터에 합류하였을 때만 샤드 배치가 일어나도록 설정하였습니다. 마지막으로 전송 계층에서 인덱싱 데이터에 대해 압축 설정을 하면 전송 시 발생하는 네트워크 대역폭을 많이 줄일 수 있습니다.</p><p id="4a3981f3-0751-474e-ae11-eee88531d71d" class=""><code>123# IDC1의 데이터 노드transport.compress: indexing_datanode.attr.zone: dc1</code></p><p id="a6b5c841-96b9-4ac9-88aa-036f926a9682" class=""><code>123# IDC2의 데이터 노드transport.compress: indexing_datanode.attr.zone: dc2</code></p><p id="462f129b-c816-4c25-b366-e9167b441c2f" class=""><code>1234# 마스터 노드transport.compress: indexing_datacluster.routing.allocation.awareness.attributes: zonecluster.routing.allocation.awareness.force.zone.values: dc1,dc2</code></p><p id="e2b3ba78-d7a8-43a1-b781-dc850e855ac7" class="">다음은 IDC1과 IDC2의 Elasticsearch 노드들을 하나의 클러스터로 묶은 전체 아키텍처 그림입니다.</p><p id="54c4eb22-8d97-4e2a-b28a-e0cddc22a7c5" class="">DCI 간 네트워크 단절이 발생한다면 IDC1 혹은 IDC2의 마스터 노드가 투표 전용 마스터 노드의 투표를 통해 마스터 노드로 선출되고 같은 구역에 있는 노드들만 클러스터에 남게 됩니다.</p><figure id="0996c67c-e599-4214-8d75-7b8072097625" class="image"><a href="https://static.toss.im/ipd-tcs/toss_core/live/7ef0ce7a-7f85-49c3-b767-582e16b065ef/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_28.png"><img src="https://static.toss.im/ipd-tcs/toss_core/live/7ef0ce7a-7f85-49c3-b767-582e16b065ef/slash23_%EC%9D%B4%EC%A4%80%ED%99%98_28.png"/></a></figure><p id="d32c771d-7ce5-4b2b-bd18-bd4aaa2d2b52" class="">이후 DCI 장애가 해소되면 반대편 IDC에 있는 노드들이 다시 클러스터에 합류하게 됩니다. 이런 구조를 통해 하나의 데이터센터 장애에도 견딜 수 있는 Elasticsearch 클러스터를 운영할 수 있게 되었습니다.</p><p id="14c3a4cc-090a-801a-8592-d410beb4c14f" class="">
</p></details></li></ul><ul id="f071f663-4aad-437a-81a2-9426f093ce19" class="toggle"><li><details open=""><summary>카오페이 - 대용량 배치 데이터 처리</summary><p id="44423860-eded-483c-870b-b938674a169f" class="">안녕하세요. if(kakao)에서 ‘Batch Performance 극한으로 끌어올리기: 1억 건 데이터 처리를 위한 노력’ 세션을 진행한 카카오페이 정산개발파트 베니입니다. 세션에서 다루었던 이야기를 2편의 콘텐츠에 걸쳐 보다 자세히 설명드리려고 합니다. 첫 번째 편인 이번 콘텐츠에서는 배치 성능을 고려한 최선의 데이터 Read 경험을 말씀드리겠습니다. 배치 성능에 관심 있는 분들께 도움이 되었으면 좋겠습니다.</p><p id="7b1d5e8f-0ff9-4533-92ef-a0d04c4de73c" class="">아직 if(kakao) 세션 영상을 보지 못하셨다면 영상 먼저 보고 오시길 추천드립니다. <a href="https://if.kakao.com/2022/session/65">Batch Performance 극한으로 끌어올리기: 1억 건 데이터 처리를 위한 노력</a></p><h1 id="5aeceeaf-9b06-44f3-a2dc-0731494e711c" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EB%8C%80%EB%9F%89-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B2%98%EB%A6%AC">대량 데이터 처리</a></strong></h1><p id="89de850d-7874-4ea7-8af4-1c4f1a3220d0" class="">2017년도의 카카오페이와 2022년 4분기를 앞둔 카카오페이를 비교해보면 놀랄 만큼의 사업적 성장이 있었습니다. 제가 속한 팀인 정산플랫폼팀에서는 2017년에는 하루 평균 데이터 Access횟수가 25만 번 정도였다면, 2022년 말 현재는 하루 평균 1억 번 정도 데이터에 Access하고 있습니다. 이 과정에서 얻은 배치 성능 개선의 많은 노하우를 정리해보았습니다.</p><h1 id="87699435-976e-4646-a459-9526514c0bdd" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EB%B0%B0%EC%B9%98%EC%97%90%EC%84%9C-reader%EB%9E%80">배치에서 Reader란?</a></strong></h1><p id="a19ba90f-86be-4d32-aef0-f80b1f722a09" class="">배치에서 데이터(Item)를 Read하는 것(ItemReader)은 배치의 전체 성능에서 매우 큰 부분을 좌우합니다. 감히 저의 예측으로는 평균 80% 이상을 결정할 수 있다고 봅니다. 이렇게까지 READ를 중요하게 생각하는 이유는 무엇일까요?</p><p id="d235d31a-3003-47b5-a29f-292b9501190e" class="">read_1million_in_1million</p><figure id="c3947ad5-66a4-4a6e-a5c6-c166b08108ee" class="image"><a href="https://tech.kakaopay.com/_astro/read_in_small.69d26c3a_Z2fm4pk.avif"><img src="https://tech.kakaopay.com/_astro/read_in_small.69d26c3a_Z2fm4pk.avif"/></a></figure><p id="6a72cb22-0041-4091-aa1e-b5d73ddb1586" class="">전체 데이터인 100만 개 중에 100만 개를 모두 읽는다고 가정해보겠습니다. 아무런 걸림돌 없이 앞에서부터 차례대로 데이터를 읽으면 됩니다. 그러나 대부분의 상황은 이렇지 않습니다.</p><p id="f6688456-3264-49a4-beda-9b9893350966" class="">read_1million_in_10billion</p><figure id="b5d3087f-a110-45a3-9fb0-072c67c58b5b" class="image"><a href="https://tech.kakaopay.com/_astro/read_in_many.ff6648e6_Z1DzQv6.avif"><img src="https://tech.kakaopay.com/_astro/read_in_many.ff6648e6_Z1DzQv6.avif"/></a></figure><p id="d97ae274-0439-4538-b9bb-66342f63c287" class="">보통은 이렇게 10억 개라는 많은 데이터 중에 필요한 데이터만 골라내야 합니다. <strong>10억 개 중에 100만 개를 골라내는 작업</strong>이 바로 배치의 전체 성능을 크게 좌우하는 부분입니다. 대표적인 예시로 RDBMS에서 select 쿼리를 튜닝하는 것만으로도 극적으로 성능이 개선됩니다.</p><h1 id="f91b163a-93ea-49eb-b5b8-7ca4f55362ba" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#chunk-processing">Chunk Processing</a></strong></h1><p id="5d742277-80d5-4dac-b7da-f2866f75d221" class="">Chunk는 하나의 큰 덩어리를 뜻하는 단어입니다. 데이터를 어떤 Chunk(덩어리) 단위로 나누어 처리하는 것을 Chunk Processing이라고 하고 대량 배치 처리 시에는 반드시 Chunk Processing으로 동작해야 합니다. 그 이유는 아래의 예시를 보면 이해할 수 있습니다. 수십 개의 적은 데이터를 처리할 때는 서버 애플리케이션에서 충분히 한 번에 처리할 수 있습니다. 그러나 1,000만 개와 같은 대량의 데이터를 처리하는 경우에는 서버의 물리적 한계로 한 번에 처리할 수 없습니다. 1,000개씩 나누어 10,000번 처리해야 합니다.</p><figure id="3d476b44-bfd1-4f10-b479-d4848d513bb3" class="image"><a href="https://tech.kakaopay.com/_astro/chunk_processing.4a613278_2oa6rJ.avif"><img src="https://tech.kakaopay.com/_astro/chunk_processing.4a613278_2oa6rJ.avif"/></a></figure><h1 id="b5e761b4-5615-41d0-82e7-c5c61621860f" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#1000%EB%A7%8C%EA%B0%9C%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%ED%95%9C-%EB%B2%88%EC%97%90-%EC%B2%98%EB%A6%AC%ED%95%A0-%EC%88%98-%EC%97%86%EB%8A%94-%EC%9D%B4%EC%9C%A0">1,000만개의 데이터를 한 번에 처리할 수 없는 이유</a></strong></h1><ol type="1" id="085d2c5c-0109-4e79-ab8f-017122442c99" class="numbered-list" start="1"><li>데이터가 1,000만 개가 아니라 2,000만 개로 늘어나는 경우도 고려해야 합니다. 결국에는 한계가 존재하고 무한정 메모리를 늘릴 수는 없습니다.</li></ol><ol type="1" id="e93d99a0-7a41-4732-8173-da9424aceff1" class="numbered-list" start="2"><li>배치 애플리케이션이 한 번에 1,000만 개를 받아들일 수 있더라도 그 외의 다른 시스템들은 불가능합니다. 예를 들어 그 어떤 RDBMS, NOSQL이라도 1,000만 개를 한 번에 read하고 write하는 것은 불가합니다.</li></ol><h1 id="aafecbec-e218-4902-8c73-3f4b51446a3d" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#pagination">Pagination</a></strong></h1><p id="2cdb4cdf-5e81-4d08-977a-089994a0485e" class="">Chunk Processing을 하기 위해서 데이터를 일정 개수만큼 나누어야 합니다. 이때, PageItemReader를 사용하게 되면 Page라는 단위로 데이터를 잘라서 처리할 수 있습니다. 전체 데이터 건수가 100만 개고 Page의 크기가 100이라고 하면 1번부터 만 번 Page까지로 나눌 수 있습니다.</p><h1 id="49b53090-5c10-4733-a3b2-1b56f16e0dee" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EA%B8%B0%EC%A1%B4%EC%9D%98-pageitemreader">기존의 PageItemReader</a></strong></h1><p id="7da41cdd-37ec-4588-b2fc-74d1a28fe6e4" class="">일반적으로 많이 사용하는 PageItemReader는 크게 2가지 정도가 있습니다.</p><ol type="1" id="e07e0a75-0bc7-4ce0-8834-e2765e362618" class="numbered-list" start="1"><li><strong>RepositoryItemReader</strong></li></ol><ol type="1" id="6a306534-c70b-483d-8f6f-a728f07178e2" class="numbered-list" start="2"><li><strong>JpaPagingItemReader</strong></li></ol><p id="c4627c16-87ec-4dd5-a397-792f921a4d61" class="">위의 ItemReader는 page number와 page size로 Item(데이터)을 구하는 방식입니다. 이런 ItemReader를 MySQL에서 사용하면 limit, offset 구문을 사용해 데이터를 구합니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="04087c70-d118-4951-9cbf-ff70ff3ab0c2" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">-- 36번째 Page, 100개 Sizeselect * from student where gender = &#x27;MALE&#x27; limit 3600, 100</code></pre><h1 id="77cfe6f4-2b55-4947-b06d-2fc87f048447" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#mysql-limit-offset">MySQL Limit Offset</a></strong></h1><p id="0aeb972c-6df9-4d8c-adc2-c3e0bed43c9a" class="">MySQL의 Limit Offset은 Page 단위로 데이터를 읽는 쉬운 방법입니다. 그러나, Limit Offset은 <strong>태생적인 성능 한계</strong>가 존재합니다.</p><p id="af5eb44f-5e81-4e79-a978-a58efb77da24" class="">Limit Offset이 없는 아래 쿼리의 결과가 1억 건이라고 가정해보겠습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="fc34179f-d0c0-4f54-83e8-1db3d2ddff0d" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">-- 조회결과: 1억 건, gender에 index 추가select * from student where gender = &#x27;MALE&#x27;</code></pre><p id="1f8dd8bd-69a9-4da4-ab36-7fc1ea07e2d3" class="">아래는 1억 건 중 최초의 100건만 조회하는 쿼리입니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="2f02cf9d-1528-4cb7-8b01-1528ce24a541" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">-- 조회 결과: 100건, 조회 속도: 매우 빠름select * from student where gender = &#x27;MALE&#x27; limit 0, 100</code></pre><p id="915dd17d-4f31-4872-a453-dde8b12f8f32" class="">아래는 1억 건 중 5천만 번째부터 100건만 조회하는 쿼리입니다. index가 있는 조건으로 조회하고 결과가 100건밖에 되지 않음에도 불구하고 아래 쿼리는 매우 느리게 조회됩니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="16dd18e6-e8f6-4479-82f8-c432782a095d" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">-- 조회 결과: 100건, 조회 속도: 매우 느림 (환경에 따라 다르지만 최소 수 십 초는 걸림)select * from student where gender = &#x27;MALE&#x27; limit 50000000, 100</code></pre><p id="418cd2ab-5d9e-415a-a357-f4dd7b48d27a" class="">이 문제를 회피하기 위해서는 Limit Offset을 아예 사용하지 않거나 Offset이 작은 경우만 사용해야 합니다.</p><h1 id="c42da85d-29c4-4431-a89c-6edbf82f0b41" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#zerooffsetitemreader">ZeroOffsetItemReader</a></strong></h1><p id="18c2d77c-d643-4479-9706-b3e405400a6a" class="">ZeroOffsetItemReader는 명칭에서 알 수 있듯이 Offset을 0으로 유지합니다.</p><figure id="86d8ced0-d59d-4a8f-a77d-a1c052d06a76" class="image"><a href="https://tech.kakaopay.com/_astro/zerooffset.0818e652_ZfMM6I.avif"><img src="https://tech.kakaopay.com/_astro/zerooffset.0818e652_ZfMM6I.avif"/></a></figure><ol type="1" id="6b77561f-e59a-489b-aaae-7865dd42d07e" class="numbered-list" start="1"><li>PK(id)값 오름차순으로 정렬합니다.</li></ol><ol type="1" id="387e35e7-3a8a-4da7-a5ca-5b80a684668e" class="numbered-list" start="2"><li>3번 Page를 조회한다면 2번 Page의 마지막 id값인 5235를 사용해 ‘where id &gt; 5235’를 쿼리에 자동으로 추가합니다.</li></ol><ol type="1" id="33a123c9-57e7-4ce0-a77f-d3c3d86c2aa0" class="numbered-list" start="3"><li>offset을 0으로 유지합니다.</li></ol><p id="88f90a9d-f88c-48fb-ba52-c4602d587fac" class="">이런 방식이면 offset이 항상 0이기 때문에 쿼리 조회 속도가 느려지지 않게 됩니다. 배치를 구현할 때 ZeroOffsetItemReader를 메인으로 사용하고 있습니다.</p><h3 id="9bafc711-9fc8-48a4-8821-0aed59cb1d91" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#querydslzerooffsetitemreader">QueryDslZeroOffsetItemReader</a></strong></h3><p id="da753861-d12f-4e9a-8355-eb7d59c4bfd7" class="">ZeroOffsetItemReader의 쿼리 구현을 QueryDsl로 할 수 있도록 개선하였습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="3a3f68ac-3284-482d-8793-a89cc3904f29" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">QuerydslZeroOffsetItemReader(    name = &quot;orderQueryDslZeroOffsetItemReader&quot;,    pageSize = 1000,    entityManagerFactory = entityManagerFactory,    idAndSort = Asc,    idField = qOrder.id) {    it.from(qOrder)        .innerJoin(qOrder.customer).fetchJoin()        .select(qOrder)        .where(qOrder.category.eq(CATEGORY.BOOK))}</code></pre><h1 id="8e4b0a7e-f92f-4878-8ea0-13611f474db3" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#cursor">Cursor</a></strong></h1><p id="0cdbd17b-7da6-4031-8fb0-dd8b78e9c0db" class="">Chunk Processing으로 동작하기 위해 데이터를 나눠서 읽는 방법은 Pagination만 있는 것이 아닙니다. Cursor를 사용해 데이터를 조금씩 가져올 수도 있습니다.</p><p id="8fa8babc-246e-40ef-9b54-932d79796aa6" class="">Cursor란?</p><figure id="01a412bf-2d2c-4709-a71c-f19ff1500792" class="image"><a href="https://tech.kakaopay.com/_astro/cursor.09886af4_Z1UqH4m.avif"><img src="https://tech.kakaopay.com/_astro/cursor.09886af4_Z1UqH4m.avif"/></a></figure><h1 id="c24c211d-2ae0-4763-b2a1-f77070e0a1fa" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EA%B8%B0%EC%A1%B4-cursoritemreader">기존 CursorItemReader</a></strong></h1><p id="4c408610-bbef-4ca8-90dd-34eeddfcfbb1" class="">일반적으로 많이 사용하는 CursorItemReader는 크게 3가지 정도가 있습니다.</p><ol type="1" id="20984c1d-4329-4b78-a17a-6e8e250f18e4" class="numbered-list" start="1"><li><strong>JpaCursorItemReader</strong></li></ol><ol type="1" id="7b79286f-986c-4201-89b6-89251cebd3a1" class="numbered-list" start="2"><li><strong>JdbcCursorItemReader</strong></li></ol><ol type="1" id="7b313c17-ebc8-41fd-aeed-ca46ecc6cf16" class="numbered-list" start="3"><li><strong>HibernateCursorItemReader</strong></li></ol><p id="5a62a3bb-04ad-4bb8-bc27-4e941148790f" class="">CursorItemReader별 문제점은 다음과 같습니다.</p><p id="2745cabe-cfc1-4bb3-b4ba-a07adb9f75b6" class="">JpaCursorItemReader는 올바른 MySQL Cursor 방식이 아닙니다. 데이터를 DB에서 모두 읽고 서비스 인스턴스에서 직접 Iterator로 cursor로 동작하는 것처럼 흉내 내는 방식입니다. 즉, 모든 데이터를 메모리에 들고 있기 때문에 OOM을 유발합니다.</p><p id="c234f6e6-e4c1-4770-b938-1b70b6c71ae8" class="">사용한다면 JdbcCursorItemReader 혹은 HibernateCursorItemReader를 사용해야 합니다. MySQL Cursor방식으로 동작해서 데이터를 조금씩 가져와 OOM을 유발하지 않고 안전합니다. 그러나 쿼리를 구현할 때 JdbcCursorItemReader는 Native SQL로 구현해야 하고, HibernateCursorItemReader는 HQL로 구현해야 합니다. 즉, 모든 쿼리를 텍스트로 구현해야 합니다.</p><h1 id="8da26752-c602-43cd-94a4-17b574598296" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EC%83%88%EB%A1%9C%EC%9A%B4-cursoritemreader">새로운 CursorItemReader</a></strong></h1><p id="122a7ca0-5335-4f3e-8a64-6221994a2815" class="">JdbcCursorItemReader 혹은 HibernateCursorItemReader를 사용한다면 배치가 동작할 때 큰 문제는 없습니다. 그러나 ItemReader의 쿼리를 Native SQL이나 HQL와 같은 텍스트로 구현하는 것은 가시적이지 않으며 실수를 유발할 가능성이 높습니다. 이런 문제를 해결하고자 ExposedCursorItemReader를 자체 개발하여 사용하고 있습니다.</p><h3 id="4827d1eb-7b0a-4dbb-b390-144bec485cb7" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#exposedcursoritemreader">ExposedCursorItemReader</a></strong></h3><p id="2d88a4f6-5c71-4c7d-ae22-47f8cc8c0ff1" class="">쿼리를 구현할 때 텍스트로 구현하기보다 DSL(Domain-Specific Languages)형식으로 구현할 수 있다면 더 직관적이며 실수가 적어지게 됩니다. 그래서 Exposed DSL로 쿼리를 구현하는 방식을 도입하였습니다. 동작 방식은 JdbcCursorItemReader와 동일하지만 쿼리만 Exposed DSL로 구현하는 ExposedCursorItemReader를 개발하였습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="d6ac6896-4c67-4116-b77a-6e367faaac5e" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">ExposedCursorItemReader&lt;Order&gt;(    name = &quot;orderExposedCursorItemReader&quot;,    dataSource = dataSource,    fetchSize = 5000) {    (Orders innerJoin Customers)        .slice(Orders.columns)        .select {            (Orders.category eq &quot;BOOK&quot;) and                (Customers.age greaterEq 11)        }}</code></pre><h3 id="3324543f-a88c-4c02-8cf3-f027bb0f7bb6" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#exposed-%ED%8A%B9%EC%A7%95">Exposed 특징</a></strong></h3><p id="fa46f8e5-74b3-4b7a-9dc7-411e665d2363" class=""><a href="https://github.com/JetBrains/Exposed">JetBrains Exposed Github</a></p><ol type="1" id="8df4b467-cdec-4621-ad2d-c329b8687e68" class="numbered-list" start="1"><li>데이터베이스 Access 방식: SQL을 매핑한 DSL 방식, 경량화한 ORM인 DAO 방식</li></ol><ol type="1" id="764bd9c4-6f48-464a-9d05-a702749a3b41" class="numbered-list" start="2"><li>지원하는 데이터베이스: H2, MySQL, MariaDB, Oracle, PostgreSQL, SQL Server, SQLite</li></ol><ol type="1" id="09019f93-aade-4534-917c-b945d89cfbea" class="numbered-list" start="3"><li>Kotlin 호환성 (자바 프로젝트는 사용 불가)</li></ol><h1 id="9a0aee1e-03b7-492a-b659-2b316951ddc3" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EC%84%B1%EB%8A%A5-%EC%B8%A1%EC%A0%95">성능 측정</a></strong></h1><p id="a8573fda-dcb9-4c21-9209-928d2b9ed9b2" class="">JpaPagingItemReader, ZeroOffsetItemReader, ExposedCursorItemReader의 성능 측정자료입니다. 성능 비교는 동일한 네트워크에서 10만, 50만, 100만, 300만 4가지 상황에서 진행하였습니다. ChunkSize, PageSize, FetchSize는 모두 1,000개, Read하는 컬럼 개수는 30개로 통일하였습니다.</p><p id="e72976c1-5fa2-4745-a989-073bf01428ca" class="">reader performance test</p><figure id="d4376607-f9a9-43ff-8469-1e4a67bcb961" class="image"><a href="https://tech.kakaopay.com/_astro/performance_result.d9cebdbf_ZznTjX.avif"><img src="https://tech.kakaopay.com/_astro/performance_result.d9cebdbf_ZznTjX.avif"/></a></figure><h1 id="71c0cbc9-f8a9-4353-85aa-6cab923e4c8e" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EA%B2%B0%EA%B3%BC-%EB%B6%84%EC%84%9D">결과 분석</a></strong></h1><h3 id="33d838ed-b6e6-4229-841e-3d121265ba04" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#10%EB%A7%8C-%EA%B0%9C---50%EB%A7%8C-%EA%B0%9C">10만 개 -&gt; 50만 개</a></strong></h3><p id="9c0098c6-9940-4f03-b686-1cb97398a695" class="">50만 개는 10만 개와 비교하여 데이터 건수는 5배로 늘었지만 ItemReader별 read시간 차이는 더욱 벌어졌습니다.</p><ul id="bde979c6-bc77-4d26-a60f-885c995adc02" class="bulleted-list"><li style="list-style-type:disc">JpaPagingItemReader: 18초 -&gt; 235초(약 4분) <strong>13배 증가</strong></li></ul><ul id="dc77078b-b00a-42ca-b0b9-54b2fd47e841" class="bulleted-list"><li style="list-style-type:disc">QueryDslZeroOffsetItemReader: 9초 -&gt; 47초 <strong>5배 증가</strong></li></ul><ul id="08df0a35-e08a-430f-97c9-cfc8582b56be" class="bulleted-list"><li style="list-style-type:disc">ExposedCursorItemReader: 11초 -&gt; 50초 <strong>5배 증가</strong></li></ul><h3 id="84f2c89d-993a-455d-9b90-b1595cf6183f" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#100%EB%A7%8C-%EA%B0%9C---300%EB%A7%8C-%EA%B0%9C">100만 개 -&gt; 300만 개</a></strong></h3><p id="d9e7fa62-4837-47e2-8d26-29cb95c5847b" class="">위의 상황과 마찬가지로 300만 개는 100만 개와 비교하여 데이터 건수는 3배로 늘었지만 ItemReader별 read시간 차이는 더욱 벌어졌습니다.</p><ul id="3ec87a30-94ac-48e9-b647-47e1dac5d33a" class="bulleted-list"><li style="list-style-type:disc">JpaPagingItemReader: 842초(약 14분) -&gt; 6752초(약 112분) <strong>8배 증가</strong></li></ul><ul id="f65888ac-eb62-485c-b238-4e1bdbf2bf45" class="bulleted-list"><li style="list-style-type:disc">QueryDslZeroOffsetItemReader: 82초(약 1분 20초), 266초(약 4분 26초) <strong>3배 증가</strong></li></ul><ul id="e26632d7-d610-4f75-8f5b-16f291fcac40" class="bulleted-list"><li style="list-style-type:disc">ExposedCursorItemReader: 96초(약 1분 36초), 290초(약 4분 50초) <strong>3배 증가</strong></li></ul><h3 id="cf4c8b18-0260-4e65-bd79-161b7e6ad705" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EC%84%B1%EB%8A%A5-%EA%B2%B0%EB%A1%A0">성능 결론</a></strong></h3><p id="77cdb3c9-99ab-409d-898d-1eebd1fc1909" class="">ZeroOffsetItemReader와 ExposedCursorItemReader는 JpaPagingItemReader보다 절대적인 속도도 훨씬 빠릅니다. 또한 데이터 건수에 비례하여 선형적으로 Read시간이 증가합니다. 새로 구현한 2개의 ItemReader가 수백만, 수천만 개 이상의 대량처리에 더 적합합니다.</p><h1 id="2464de25-9fa6-4032-aa5e-7daf2af0b09c" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EC%95%88%EC%A0%95%EC%84%B1-%EC%B8%A1%EC%A0%95">안정성 측정</a></strong></h1><p id="9068be28-67b5-4117-82d2-39fc7b394939" class="">새로 구현한 2개의 ItemReader의 300만 개 Heap Space 모니터링 결과입니다.</p><p id="b98f58ca-78d1-4f8c-8c4d-e2d4c09445b5" class="">reader heap space monitoring results</p><figure id="6edcae3a-fa0d-4a5a-9b95-ba3fe3dee902" class="image"><a href="https://tech.kakaopay.com/_astro/heap_result.02d60e7a_Z2hr0jj.avif"><img src="https://tech.kakaopay.com/_astro/heap_result.02d60e7a_Z2hr0jj.avif"/></a></figure><h1 id="586d232f-a983-4310-b1d7-d45a7788c145" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EC%95%88%EC%A0%95%EC%84%B1-%EA%B2%B0%EB%A1%A0">안정성 결론</a></strong></h1><p id="87267eae-90ed-497c-b055-24305fb7840a" class="">매우 안정적인 모습의 GC가 발생하며 대량 처리에도 전혀 문제 없습니다.</p><h1 id="a37f40a5-1726-4d7c-8add-9e1ccb256dde" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EC%B5%9C%EC%A2%85-%EA%B2%B0%EB%A1%A0">최종 결론</a></strong></h1><h1 id="f1025b31-ecf9-49a9-8eaa-73a9dd4452f1" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EC%B4%9D%EC%A0%95%EB%A6%AC">총정리</a></strong></h1><table id="7e470ab6-781a-4b3a-a71e-964d2fcc756b" class="simple-table"><tbody><tr id="0a57ea33-c595-4eab-9b31-449cf23acbd5"><td id="{xEP" class=""><strong>구분</strong></td><td id="CzXB" class=""><strong>RepositoryItemReader JpaPagingItemReader</strong></td><td id="[vuS" class=""><strong>JdbcCursorItemReader HibernateCursorItemReader</strong></td><td id="WvhJ" class=""><strong>JpaCursorItemReader</strong></td><td id="@{&gt;`" class=""><strong>(QueryDsl)ZeroOffsetItemReader</strong></td><td id="~H;f" class=""><strong>ExposedCursorItemReader</strong></td></tr><tr id="3e3a4ff8-a986-49ef-a6d0-f5f0f4e7432c"><td id="{xEP" class="">쿼리구현방식</td><td id="CzXB" class="">Query Method, QueryDSL, JPQL</td><td id="[vuS" class="">Native Query, HQL</td><td id="WvhJ" class="">JPQL</td><td id="@{&gt;`" class="">QueryDSL</td><td id="~H;f" class="">Kotlin Exposed</td></tr><tr id="0fbeab00-3d35-40e9-bd30-2dbccfae8ac5"><td id="{xEP" class="">동작 방식</td><td id="CzXB" class="">Pagination Limit Offset 구문 사용</td><td id="[vuS" class="">Cursor 방식</td><td id="WvhJ" class="">애플리케이션에서 직접 Cursor 처리</td><td id="@{&gt;`" class="">Offset을 항상 0으로 유지 PK를 where 조건에 추가하는 방식</td><td id="~H;f" class="">JdbcCursorItemReader와 동일한 방식</td></tr><tr id="d1d33cc2-f275-402c-941e-3ce5d424dc0c"><td id="{xEP" class="">성능</td><td id="CzXB" class="">조회할 데이터가 많다면 뒷 Page로 갈수록 느려짐</td><td id="[vuS" class="">Cursor 기반으로 Fetch size와 DB설정만 제대로 세팅하면 조회 속도가 매우 빠름</td><td id="WvhJ" class="">성능은 매우 우수하나 OOM 유발 가능</td><td id="@{&gt;`" class="">첫 Page를 읽었을 때와 동일하게 항상 일관된 조회 성능을 가짐</td><td id="~H;f" class="">Cursor 기반으로 많은 양의 데이터를 빠르게 가져오며 일관된 조회 성능을 가짐</td></tr></tbody></table><h3 id="a1fd939b-e1b1-4034-bf3e-82d2a98d8d59" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EB%8C%80%EB%9F%89-%EC%B2%98%EB%A6%AC-%EC%8B%9C-%EC%82%AC%EC%9A%A9%ED%95%B4%EB%8F%84-%EC%A2%8B%EC%9D%80-itemreader">대량 처리 시 사용해도 좋은 ItemReader</a></strong></h3><ul id="31b2bc22-b226-4d24-9567-f3a9c2f74c45" class="bulleted-list"><li style="list-style-type:disc">ZeroOffsetItemReader (직접 구현)</li></ul><ul id="813e8517-6f48-4585-972f-2a1c1871fb12" class="bulleted-list"><li style="list-style-type:disc">ExposedCursorItemReader (직접 구현)</li></ul><ul id="bdacf8f0-5dfa-4e11-af06-bfee8f215109" class="bulleted-list"><li style="list-style-type:disc">JdbcCursorItemReader (Spring Batch에서 기본 제공)</li></ul><ul id="1cff797e-af1a-4e63-ba47-37931c7270ba" class="bulleted-list"><li style="list-style-type:disc">HibernateCursorItemReader (Spring Batch에서 기본 제공)</li></ul><h3 id="4f4d4190-9d56-4e43-95cd-59fae5fbb4d0" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EB%8C%80%EB%9F%89-%EC%B2%98%EB%A6%AC-%EC%8B%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%A9%B4-%EC%95%88-%EB%90%98%EB%8A%94-itemreader">대량 처리 시 사용하면 안 되는 ItemReader</a></strong></h3><ul id="e7905c08-da74-43f4-8450-396b5eb2e00e" class="bulleted-list"><li style="list-style-type:disc">RepositoryItemReader (Spring Batch에서 기본 제공)</li></ul><ul id="9830948b-59d7-45c3-ad51-1f6385e7c181" class="bulleted-list"><li style="list-style-type:disc">JpaPagingItemReader (Spring Batch에서 기본 제공)</li></ul><ul id="7e3f3ea4-176c-41bc-9f5c-ddc04757717c" class="bulleted-list"><li style="list-style-type:disc">JpaCursorItemReader (Spring Batch에서 기본 제공)</li></ul><h1 id="6802b1c7-5ec2-4e1d-92f3-c59c965fe2d9" class=""><strong><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/#%EB%A7%88%EC%B9%98%EB%A9%B0">마치며</a></strong></h1><p id="bb7d040d-b69c-4859-b140-b1bd4be4d37f" class="">카카오페이 정산팀에서는 그동안 많은 배치 구현 경험을 통해 가장 이상적인 ItemReader로써 ZeroOffsetItemReader와 ExposedCursorItemReader를 개발해 사용하고 있습니다. 개선된 ItemReader를 사용하면서 수년 전에는 상상할 수 없었던 만큼의 데이터를 처리하고 있습니다.</p><p id="0d76b450-d210-487a-8d01-31410c46cb95" class="">또한, 저희 팀에서는 데이터를 읽는 것뿐만 아니라 대량의 데이터를 어떻게 가공하고(Processor) 합치고(Aggregation) 쓸지(Write) 고민해왔습니다. 다음 편에서는 이런 노하우들 중에 최선의 Aggregation 방법을 소개하고자 합니다.</p><figure id="75a1631f-6ada-476e-9105-8d64ee00f75b"><a href="https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">[if kakao 2022] Batch Performance를 고려한 최선의 Reader | 카카오페이 기술 블로그</div><div class="bookmark-description">if(kakao)2022 대량의 데이터를 Batch로 읽을 때의 노하우를 공유합니다.</div></div><div class="bookmark-href"><img src="https://tech.kakaopay.com/favicon.ico" class="icon bookmark-icon"/>https://tech.kakaopay.com/post/ifkakao2022-batch-performance-read/</div></div><img src="https://tech.kakaopay.com/_astro/thumb.f4bb869d_1nQPYR.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="e6018a8f-9cda-415f-a029-edd3aa6c4bb6" class="toggle"><li><details open=""><summary>Batch Performance 극한으로 끌어올리기: 1억 건 데이터 처리를 위한 노력 요약</summary><h2 id="c528a8fd-aec5-4ef2-b151-11264fec412b" class="">Batch로 개발하는 경우</h2><blockquote id="f3c3e5ce-41e6-40ce-8cdb-33927addb680" class="">흠...오후 4시에 상품 주문 배송 정보를 고객들에게 문자로 일괄 전송해야 하는구나.<p id="8e563845-c7af-4885-9243-9d8b7eb35795" class="">간단하네! Batch로 개발해서 16시에 스케줄을 걸어놔야지!</p></blockquote><ul id="4f2f5e16-1cf5-4f91-be80-1a21603895f0" class="bulleted-list"><li style="list-style-type:disc"><strong>특정 시간</strong>에 <strong>많은 데이터</strong>를 <strong>일괄 처리</strong>에 대해 서버 개발자들이 자주 애용하는 방식</li></ul><ul id="9936cefd-d9f2-4a0c-a85b-7b8f88e68a0e" class="bulleted-list"><li style="list-style-type:disc">배치 방식이 실시간 방식보다 개발 부담이 낮다고 생각함</li></ul><h2 id="c78de5ea-7e4c-45fa-b338-cc1e1a9faa7b" class="">Batch로 개발하는 상황</h2><h3 id="6b5251e4-fcad-4227-9aed-439ae89bdf47" class="">일괄 생성</h3><figure id="34fb0b8e-4597-450e-9017-801acade0d24" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/d7b75dfb-e216-4460-bd8c-5a3da295ebca/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/d7b75dfb-e216-4460-bd8c-5a3da295ebca/image.png"/></a></figure><p id="eb4b2242-c1b8-4491-9c3d-30c80993087e" class="">기존에 저장된 정보를 조합해서 새로운 정보를 만들 때</p><h3 id="bbc5a042-ef1a-4877-8139-2bbba2e893b2" class="">일괄 수정</h3><figure id="16dec638-e60c-4af3-b42b-a5908554e12b" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/92a769d0-23c2-460a-93ca-af332e744175/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/92a769d0-23c2-460a-93ca-af332e744175/image.png"/></a></figure><p id="f347891b-1e87-4ad0-b09e-e1006a0e7189" class="">이미 저장된 데이터를 일괄로 수정할 때</p><h3 id="bed2551c-c404-4e7d-93b6-2b337a511f13" class="">통계</h3><figure id="f8fce4d8-46c9-4e4a-b6ce-76018ec6c1d4" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/07d73412-b2ae-4af0-8cd9-bc4a9e6d68c5/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/07d73412-b2ae-4af0-8cd9-bc4a9e6d68c5/image.png"/></a></figure><p id="aff448db-d1e6-4e6b-b70f-44dfa4e38277" class="">통계 형식의 데이터를 만들 때</p><h2 id="5dfc3c28-b0cd-40be-9a22-80d1492761c4" class="">카카오페이의 Batch Performance</h2><figure id="3ea9bd4b-1a97-498b-af3b-e2a89fd1ec00" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/0804d5c1-3a68-45f7-b85a-2fe83268879f/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/0804d5c1-3a68-45f7-b85a-2fe83268879f/image.png"/></a></figure><blockquote id="bbeb0c57-3fe4-456a-ae7d-783db57d5935" class="">카카오페이는 늘어나는 데이터량에도 불구하고 Batch 수행시간을 5년전과 비슷한 수준으로 유지하고 있음</blockquote><h2 id="1f953a30-459b-4cab-81f2-b3887715a3f3" class="">Batch 처리의 성능 개선 방법</h2><h3 id="a81ef354-c424-4dc0-9f83-a2b075748d69" class="">대량 데이터 READ</h3><p id="fafe8a93-4bfa-45a9-b149-aef4431d3719" class="">Batch 성능 개선의 첫 걸음 = Reader 개선</p><p id="f64f0d46-393f-4f96-86a6-bfd0d002b857" class="">(Batch 성능에서 차지하는 비중이 Reader가 가장 높기 때문)</p><p id="11833e92-9149-4610-84ef-075e9c636e91" class="">Reader의 복잡한 조회 조건이 배치 전체의 성능을 크게 좌우</p><p id="072320cd-9a62-4335-a854-357abc991d60" class="">따라서 SELECT 쿼리를 튜닝하는 것만으로도 극적으로 성능이 개선됨</p><h3 id="5ca5b62c-e1d2-4e44-883d-fb9352ac3474" class="">ZeroOffsetItemReader (with QueryDSL)</h3><p id="fbde7534-9bd4-4420-993b-2fbc6a6f3fdb" class="">Chunk Processing을 위한 Pagination Reader를 사용할 수 있음</p><p id="1d7a4431-cf44-4a10-b799-1c057554d630" class="">(Limit, Offset 사용)</p><figure id="e25045a8-30ec-4330-9ee9-2040dd74abed" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/15f17b53-37dc-4350-9545-47e27d650e89/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/15f17b53-37dc-4350-9545-47e27d650e89/image.png"/></a></figure><p id="8b2ec784-3a9a-450d-9d1f-8d4c7c38b353" class="">하지만 Offset이 커질수록 성능이 크게 저하</p><p id="3d7f9647-0f25-4a1a-9228-cfbbd9e4f442" class="">(MySQL은 N번째 아이템을 찾는 작업에 큰 부담을 느낌)</p><figure id="444b80d1-d504-433d-9519-1f61e2150b55" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/f3c9df8a-1e0e-41c2-917e-a3e882602e5b/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/f3c9df8a-1e0e-41c2-917e-a3e882602e5b/image.png"/></a></figure><p id="11274267-1eac-4e35-8e78-d6848885bc9c" class="">그래서 Offset을 항상 0으로 유지하고 직전 페이지의 마지막 id보다 큰 조건을 넣는 방식 사용</p><p id="2468cd48-00b4-4cc7-a9dd-2ab1b799343f" class="">Offset이 0이기 때문에 조회 속도 저하가 없음</p><p id="f61fdcab-ea8f-44b6-acc2-7b39c21a9be8" class="">이때, 편하고 안전하게 쿼리를 작성하기 위해 QueryDSL을 사용</p><h3 id="dbbacdbf-2fa7-4baa-8360-9f0e3028a6f8" class="">CursorItemReader (with Exposed)</h3><p id="ca2c0c9f-b494-46aa-a28b-517dae39f94e" class="">MySQL Cursor는 데이터가 없을 때까지 일정 개수릐 데이터를 반복해서 가져오는 방식</p><p id="92ec8eeb-df5a-4427-9a42-c47be3610b3a" class="">(Chunk Processing에 잘 어울리는 방식)</p><figure id="d9a7ed41-e193-4c8c-92a8-5e4b25fe4a8d" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/2c697921-d7cc-4a57-a5bf-e285d1542c15/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/2c697921-d7cc-4a57-a5bf-e285d1542c15/image.png"/></a></figure><blockquote id="9716a875-d6d1-4086-91dc-ca0fa533cd30" class="">JpaCursorItemReader는 아예 사용을 안하는 것을 추천</blockquote><p id="8201ce20-89bc-4e61-8aae-560f50d8b9d3" class="">JdbcCursorItemReader는 Native Query를 사용해야 함</p><p id="b20f788a-f3c0-40ee-8a23-db48d2ab0a37" class="">그래서 안전하고 세련된 쿼리 구현 방식으로 Exposed 사용</p><figure id="235a6652-acc5-4e55-8353-4e5611adb951" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/58df19f8-c913-4371-9708-59ede56e3383/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/58df19f8-c913-4371-9708-59ede56e3383/image.png"/></a></figure><figure id="2ecf1153-fb4a-40f7-ad94-d02eca87c6d6" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/a0a948cc-540c-4508-9b29-2754d48c8c08/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/a0a948cc-540c-4508-9b29-2754d48c8c08/image.png"/></a></figure><h3 id="04eb318c-2d6c-49bf-9d71-05177d53c2f9" class="">정리</h3><figure id="0dea6eea-c270-41f9-ac2f-753eefd872e8" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/24f16e48-22d4-40d8-9405-73387b1c8190/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/24f16e48-22d4-40d8-9405-73387b1c8190/image.png"/></a></figure><figure id="4e08631c-0a71-4ce4-ba44-0526b59d1e9b" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/855a164e-912a-4d09-ac92-f62b0995544b/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/855a164e-912a-4d09-ac92-f62b0995544b/image.png"/></a></figure><h3 id="efcbf0fa-f838-4c6c-9523-dbb3cac60e53" class="">데이터 Aggregation 처리</h3><blockquote id="19d5ccf9-3c6e-489b-be92-456609ca9d1b" class="">통계 -&gt; Batch -&gt; GroupBy &amp; Sum</blockquote><p id="42cfefa5-86dc-459c-b22e-5076ef85e956" class="">데이터가 적을 때는 합리적이고 개발도 간단한 흐름</p><p id="592cfc6d-1ade-465c-b360-1718b3628428" class="">하지만, 데이터가 많아지고 쿼리가 복잡해지면 문제 발생</p><figure id="6fc6b12a-c7a7-47fa-8ce0-071a174ff3d3" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/c1c2b1c8-7cc1-49c7-8ef3-b262c8771f72/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/c1c2b1c8-7cc1-49c7-8ef3-b262c8771f72/image.png"/></a></figure><p id="0871f3e5-ed66-4f1d-978b-0a95d1d7f810" class="">쿼리 자체가 너무 느려서 개선된 ItemReader가 무용지물이 됨</p><blockquote id="2614a4f6-2a6a-4e27-b809-ae2b06b9df28" class="">쿼리는 단순하게!<ul id="27288a54-9e34-4a84-8073-6f97e24acfee" class="bulleted-list"><li style="list-style-type:disc">그냥 GroupBy를 안 쓰면 되겠네</li></ul><ul id="d8e45a47-1dfb-4258-91ec-8ca4f20b6a5b" class="bulleted-list"><li style="list-style-type:disc">직접 Aggregation을 하면 되겠네</li></ul></blockquote><p id="6de65c4d-8699-4599-9fe4-2ea3f4a486d7" class="">하지만 직접 Aggregation을 위한 대용량 리소스를 애플리케이션에서 할당하기는 거의 불가능</p><p id="4c31216c-5d8b-4679-87af-1e18c3948aea" class="">(이를 위한 새로운 아키텍처 필요)</p><h3 id="c860b8d7-6b35-4986-bebd-1db39e40d8cc" class="">Redis(with Pipeline)를 통한 Aggregation</h3><figure id="98da7f46-b1d8-41a6-8d7e-326538af8937" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/91251722-5362-416c-96d2-29710bd198eb/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/91251722-5362-416c-96d2-29710bd198eb/image.png"/></a></figure><figure id="dbd813a3-8a02-4237-8e9f-f5f7c330c1c1" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/82071859-c34b-4f11-b421-44bf4ee786e6/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/82071859-c34b-4f11-b421-44bf4ee786e6/image.png"/></a></figure><p id="acfd7a08-91a9-4771-b343-58bb00be4a44" class="">하지만 네트워크 I/O 레이턴시 문제가 생김</p><p id="47a48ddd-6e59-4177-8107-e5c60faeac40" class="">(1000만 개의 데이터를 합상하기 위해 1000만번의 요청 필요)</p><p id="72c4af65-2cf9-4dbc-a19f-b5960f324490" class="">이를 해결하기 위해 Redis Pipeline을 사용해서 다수의 Command를 묶어서 처리</p><p id="330b1af9-6782-464c-93ad-75373be26a21" class="">(Spring Data Redis로는 처리할 수 없는 부분이기 때문에 카카오페이에서는 자체 라이브러리를 개발해서 사용중)</p><h3 id="ab93023d-42fe-4d6c-8c81-627bf9f1f023" class="">대량 데이터 WRITE</h3><ol type="1" id="86fd494b-4ba4-42d6-bd4d-265b5813fde8" class="numbered-list" start="1"><li>Batch Insert 사용(일괄로 쿼리 요청)</li></ol><ol type="1" id="a9e030bd-1fc8-4cb5-bba8-1f507282e2c8" class="numbered-list" start="2"><li>명시적 쿼리(필요한 칼럼만 UPDATE, 영속성 컨텍스트를 사용하지 않음)</li></ol><h3 id="080558e9-11b8-4f83-a616-e8064082dbcf" class="">Batch에서 JPA WRITE에 대한 고찰</h3><ol type="1" id="b4750eab-6e30-48f4-8881-e6953b3bd95b" class="numbered-list" start="1"><li>Dirty Checking과 영속성 관리(불필요한 Check 로직으로 성능상 손해를 봄)</li></ol><ol type="1" id="c4ed54a7-bf31-4486-9a33-4ae0b1344907" class="numbered-list" start="2"><li>UPDATE할 때 불필요한 칼럼도 UPDATE(Dynamic Update가 있지만 이는 동적으로 쿼리를 생성해서 성능 저하가 일어남)</li></ol><ol type="1" id="186af252-813e-420c-8ac1-eb170cf637f9" class="numbered-list" start="3"><li>JPA Batch Insert 지원이 어려운 부분(ID 생성 전략을 IDENTITY로 하면 Batch Insert를 지원하지 않음)</li></ol><blockquote id="dbf9799d-1861-4aa9-9050-97fcd2ead85e" class="">따라서, Writer에서 JPA를 포기하고 Batch Insert할 것</blockquote><figure id="2225cd09-740b-47d5-a6d1-78abec51451b" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/6a34cb3d-5007-4a1b-bb31-4d118b051510/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/6a34cb3d-5007-4a1b-bb31-4d118b051510/image.png"/></a></figure><h3 id="3e796699-3189-4df6-b6ad-d63809568ecf" class="">Batch 구동 환경</h3><h3 id="74549ce3-1af2-4cae-9f27-8be3ecc1cd5d" class="">Batch 구동 환경의 특징</h3><ul id="e447164b-6cf2-46d4-a26c-637f224f5097" class="bulleted-list"><li style="list-style-type:disc">자원 관리의 어려움(언제 자원을 많이 사용하고 언제 적게 사용하는지 판단하기 어려움)</li></ul><ul id="52c20655-74e8-441b-9e3b-2d205bef234b" class="bulleted-list"><li style="list-style-type:disc">Batch 상태 파악(Monitoring)의 어려움<ul id="ac4034cc-f994-46d1-a189-b868ecca3ffd" class="bulleted-list"><li style="list-style-type:circle">Batch에서는 동작 하나하나가 매우 길다</li></ul><ul id="f1ca1feb-0395-463d-9851-e6c166e588d8" class="bulleted-list"><li style="list-style-type:circle">대부분 스케줄 Too에서 로그를 볼 수 있지만 로그 정보가 매우 빈약하다</li></ul><ul id="08cf82e7-3d51-43a4-b998-1e8da9118c49" class="bulleted-list"><li style="list-style-type:circle">서비스 상태를 로그로 판단하는 것 자체가 전혀 시각적이지 않다</li></ul></li></ul><h3 id="fcd1a157-9d02-4e61-83f8-62619f9439fe" class="">Spring Cloud Data Flow</h3><figure id="af4feadf-4174-43db-b3aa-91601bfaf66b" class="image"><a href="https://velog.velcdn.com/images/gongmeda/post/91acd98a-317b-49f6-ba3c-3466b282f5e1/image.png"><img src="https://velog.velcdn.com/images/gongmeda/post/91acd98a-317b-49f6-ba3c-3466b282f5e1/image.png"/></a></figure><ul id="0e1b2b67-5106-4a6e-90ff-a666e560531c" class="bulleted-list"><li style="list-style-type:disc">K8s와 완벽한 연동으로 Botch 실행 오케스트레이션<ul id="0f083d0b-a29b-44dd-8247-244f230000ac" class="bulleted-list"><li style="list-style-type:circle">다수 Batch가 상호 간섭 없이 Running (by 컨테이너)</li></ul><ul id="75e7f19b-9a82-43ef-a2e5-81bd84fff9c4" class="bulleted-list"><li style="list-style-type:circle">K8s에서 Resouce 사용과 반납을 조율</li></ul></li></ul><ul id="d8340f14-0001-4f36-b9e5-e50e581fb28f" class="bulleted-list"><li style="list-style-type:disc">Spring Batch 유용한 정보 시각적으로 모니터링<ul id="66f966a5-aaff-42ed-add2-0a08bbca4a91" class="bulleted-list"><li style="list-style-type:circle">Spring Cloud Data Flow 자체 Dashboard 제공</li></ul><ul id="0f3a2903-9745-4e85-ace7-ab8591d93398" class="bulleted-list"><li style="list-style-type:circle">그라파나 연동 가능</li></ul></li></ul></details></li></ul><ul id="09486330-385f-4d2c-9890-0fd9cf27757c" class="toggle"><li><details open=""><summary>배치 처리 시스템 구성</summary><p id="1530389d-5793-4bbf-97fa-59e6aef40592" class="">1000만 개의 주문 정보 데이터를 배치로 처리하여 통계 DB를 생성하는 시스템을 설계할 때, 목표는 데이터를 효율적으로 처리하고 통계 DB를 최소 시간 내에 업데이트하는 것입니다. 아래는 최소 시간을 목표로 하는 시스템 구조와 기술 스택 제안입니다.</p><h2 id="ad470350-e351-4ef7-b172-99d3a26fe943" class="">시스템 구조 제안</h2><h3 id="a3c7c1ae-3b4d-400d-a8b5-4a20d1f96b9c" class="">1. 데이터 수집 및 저장</h3><h3 id="d598aca9-9463-4d31-9fd9-d7a910b50f6d" class=""><strong>1.1 데이터 소스</strong></h3><ul id="1ce5623e-6f07-4d7a-8337-f02dbf15f6d8" class="bulleted-list"><li style="list-style-type:disc"><strong>주문 정보 데이터베이스</strong>: 원본 데이터는 관계형 데이터베이스(RDBMS)나 NoSQL 데이터베이스에 저장되어 있을 것입니다.</li></ul><h3 id="41237643-cb42-4195-a58a-10189f679cca" class=""><strong>1.2 데이터 추출</strong></h3><ul id="2bf4fdce-6eeb-4e9f-ba2e-b7bb86bea9df" class="bulleted-list"><li style="list-style-type:disc"><strong>ETL 도구</strong>: Apache NiFi, Talend, 또는 custom ETL scripts를 사용하여 데이터 추출을 자동화합니다.</li></ul><h3 id="d0302b61-46f1-426f-aa41-2ef9d27c2db0" class="">2. 데이터 처리</h3><h3 id="513c7210-9495-4f3f-bf6d-09a617a73326" class=""><strong>2.1 데이터 전처리 및 청소</strong></h3><ul id="b19e10bd-fa1f-4386-8dff-38860b0f5e8c" class="bulleted-list"><li style="list-style-type:disc"><strong>Apache Spark</strong>: 대규모 데이터 처리에 강력하며, 빠른 메모리 기반 처리 기능을 제공합니다. 데이터 청소, 변환, 집계 작업을 효율적으로 처리할 수 있습니다.<ul id="95254c80-5097-4c35-9b4d-50c69f23e4a8" class="bulleted-list"><li style="list-style-type:circle"><strong>Cluster Mode</strong>: Apache Spark는 클러스터 모드로 구성하여 처리 성능을 극대화합니다.</li></ul><ul id="933a2494-08f6-4b7b-929f-1dede69d2477" class="bulleted-list"><li style="list-style-type:circle"><strong>In-Memory Computation</strong>: Spark의 메모리 기반 계산 기능을 활용하여 처리 속도를 높입니다.</li></ul></li></ul><h3 id="0bcca13d-2010-4a66-87e9-0c704068b19c" class=""><strong>2.2 데이터 저장 및 집계</strong></h3><ul id="914d65bd-11ff-4ba5-acd3-7ac3f1fce376" class="bulleted-list"><li style="list-style-type:disc"><strong>Apache Kafka</strong>: 실시간 데이터 스트리밍 및 배치 처리 모두 지원. 데이터 처리 파이프라인에서 중간 저장소로 활용할 수 있습니다.</li></ul><ul id="bdb968b5-ee71-4dde-b22f-10e1a46e94b6" class="bulleted-list"><li style="list-style-type:disc"><strong>Hadoop HDFS</strong>: Spark와 함께 사용할 수 있는 분산 파일 시스템으로, 대규모 데이터 저장과 빠른 읽기/쓰기를 지원합니다.</li></ul><h3 id="c7fa11dc-a6ee-46b6-9410-db40daaa5347" class="">3. 통계 DB 생성</h3><h3 id="88263c9a-e8dc-4d9c-9227-d00bdb71e00b" class=""><strong>3.1 데이터 집계 및 분석</strong></h3><ul id="69f44db6-5f9b-4f3e-94d2-bfd1c6535a43" class="bulleted-list"><li style="list-style-type:disc"><strong>Apache Spark SQL</strong>: SQL 쿼리를 통해 대규모 데이터를 집계하고 분석합니다. Spark SQL을 활용하여 복잡한 쿼리와 집계 작업을 수행합니다.</li></ul><ul id="c8527aac-e4e4-471a-87f9-8aba5161f206" class="bulleted-list"><li style="list-style-type:disc"><strong>Pre-aggregated Tables</strong>: 집계 작업을 사전에 수행하여 쿼리 성능을 개선합니다.</li></ul><h3 id="ac04f7fa-1c58-4e2a-92bf-e9e228c9753b" class=""><strong>3.2 데이터 저장</strong></h3><ul id="d0f559cd-9b96-47c5-a983-d1bce95a196a" class="bulleted-list"><li style="list-style-type:disc"><strong>Columnar Storage</strong>: 데이터가 컬럼 기반으로 저장되는 DBMS를 사용하여, 대규모 데이터 집계 쿼리 성능을 개선합니다.<ul id="d39fb6e6-bd2b-43ee-b601-bd9abc861da4" class="bulleted-list"><li style="list-style-type:circle"><strong>Amazon Redshift</strong>: AWS의 managed data warehouse 서비스로, 대규모 데이터 집계와 분석에 적합합니다.</li></ul><ul id="ac5ec1a7-5a09-4ebc-8911-1542f8bb43c3" class="bulleted-list"><li style="list-style-type:circle"><strong>Google BigQuery</strong>: Google Cloud의 serverless 데이터 웨어하우스로, 대규모 쿼리와 분석에 적합합니다.</li></ul><ul id="4608ba27-8acb-48fa-9f66-fd5f65cb1b0d" class="bulleted-list"><li style="list-style-type:circle"><strong>Apache Druid</strong>: 실시간 분석과 대규모 집계에 강점을 가진 데이터베이스입니다.</li></ul></li></ul><h3 id="14dcaed0-57cf-4948-82e2-5ba0085b7830" class="">4. 모니터링 및 성능 최적화</h3><h3 id="82a03497-ed89-4ffc-9f30-9470d271e261" class=""><strong>4.1 성능 모니터링</strong></h3><ul id="bccbfbef-4f4a-4fca-bd99-10259e147e14" class="bulleted-list"><li style="list-style-type:disc"><strong>Prometheus &amp; Grafana</strong>: 시스템의 성능을 모니터링하고 대시보드에서 실시간으로 분석합니다.</li></ul><ul id="463aa7d2-3934-4707-b875-1ee29e785f4c" class="bulleted-list"><li style="list-style-type:disc"><strong>Spark UI</strong>: Spark의 작업과 성능을 모니터링하고 최적화합니다.</li></ul><h3 id="e1ae702b-6b9b-4255-b766-b478e16e276e" class=""><strong>4.2 데이터 파이프라인 최적화</strong></h3><ul id="fcd60226-9f52-4601-9316-86bd1e587dfe" class="bulleted-list"><li style="list-style-type:disc"><strong>Data Partitioning</strong>: 데이터를 파티셔닝하여 병렬 처리 성능을 극대화합니다.</li></ul><ul id="2f34495e-8d3c-4174-b01f-d283183051c9" class="bulleted-list"><li style="list-style-type:disc"><strong>Parallel Processing</strong>: Spark의 분산 처리 기능을 활용하여 데이터 처리 성능을 향상시킵니다.</li></ul><h2 id="c6e7dec7-a248-407e-8f61-031892384128" class="">시스템 구성도</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="6698af3c-4a8d-400b-adf6-684d77fa62ad" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
[Order Database]
        |
        | ETL (Apache NiFi, Talend)
        |
[Raw Data Storage (HDFS, S3)]
        |
        | Data Extraction
        |
[Apache Spark]
        |               \
        |                \
        |                 \
[Data Aggregation]    [Intermediate Storage (Kafka)]
        |               /
        |              /
        |             /
[Statistics DB (Redshift, BigQuery, Druid)]
        |
        | Reporting
        |
[BI Tools (Tableau, Power BI)]

</code></pre><h2 id="d3298650-3e81-4d6e-8b3b-489b799f80d8" class="">과정 요약</h2><ol type="1" id="56e57716-cccb-4ccf-be8b-ea495a41235b" class="numbered-list" start="1"><li><strong>데이터 추출</strong>: 주문 정보를 ETL 도구를 통해 원본 데이터베이스에서 추출하고, HDFS나 S3와 같은 저장소에 저장합니다.</li></ol><ol type="1" id="91f10e00-a442-46cd-872f-98ea5edb32c8" class="numbered-list" start="2"><li><strong>데이터 전처리 및 집계</strong>: Apache Spark를 사용하여 데이터를 전처리하고 집계합니다. 이 과정에서 Spark SQL을 사용하여 통계 정보를 생성합니다.</li></ol><ol type="1" id="51272a78-1a3b-42f2-97b9-434ce8c37383" class="numbered-list" start="3"><li><strong>데이터 저장</strong>: 집계된 데이터를 통계 DB에 저장합니다. Columnar Storage를 지원하는 데이터베이스를 사용하여 쿼리 성능을 최적화합니다.</li></ol><ol type="1" id="98690ee9-cafc-4829-81e8-bbb554d10e5b" class="numbered-list" start="4"><li><strong>모니터링 및 최적화</strong>: Prometheus, Grafana, Spark UI를 통해 시스템 성능을 모니터링하고 최적화합니다.</li></ol><p id="f429e307-6cbc-4ca0-83dd-b3bcb22b204d" class="">이러한 설계를 통해 대규모 데이터 처리 작업을 효율적으로 수행하고, 최소 시간 내에 통계 DB를 생성할 수 있습니다.</p><p id="ac0fb6f9-9d83-4e48-ab3d-9c8cc27b6cc3" class="">4o mini</p><p id="c52b830c-c80e-4dc1-bba6-4f8da789693a" class="">위 시스템을 redis 를 활용해서 설계해줘</p><p id="8ad4fafe-ffe2-4611-9daa-7eea875603ab" class="">ChatGPT</p><p id="f2beae78-70cc-4e5b-8acf-8fed586f5cdb" class="">Redis를 활용하여 대규모 주문 정보를 처리하고 통계 DB를 생성하는 시스템을 설계하는 방법을 설명하겠습니다. Redis는 주로 캐싱과 메모리 기반 데이터 구조 저장소로 사용되지만, 데이터 처리와 집계 작업을 지원하기 위해 Redis Streams와 Redis Sorted Sets 같은 기능을 사용할 수 있습니다.</p><h2 id="72eef554-ca84-4fb6-a3d2-a7f18c300178" class="">시스템 구조</h2><h3 id="3873623e-a43d-4d61-928b-d24a483950e1" class="">1. 데이터 수집 및 저장</h3><h3 id="dabe3e0f-2be4-4862-95de-7c8e1aa7b56a" class=""><strong>1.1 데이터 소스</strong></h3><ul id="e47c1a80-6a47-45e2-a900-51380642b789" class="bulleted-list"><li style="list-style-type:disc"><strong>주문 정보 데이터베이스</strong>: 원본 데이터는 관계형 데이터베이스(RDBMS)나 NoSQL 데이터베이스에 저장되어 있을 것입니다.</li></ul><h3 id="7eba4a90-3419-4bb4-98c6-d015373ac814" class=""><strong>1.2 데이터 추출 및 적재</strong></h3><ul id="d5d96841-4c6c-480f-85af-ac67762b5c14" class="bulleted-list"><li style="list-style-type:disc"><strong>ETL 도구</strong>: Apache NiFi, Talend 등을 사용하여 데이터베이스에서 데이터를 추출하고, Redis에 저장할 수 있는 형식으로 변환합니다.</li></ul><h3 id="cf0baadf-399d-4430-a57c-fa535782496d" class="">2. 데이터 처리 및 집계</h3><h3 id="c904a1fb-0be1-4165-b446-5b1642db2511" class=""><strong>2.1 데이터 전처리 및 적재</strong></h3><ul id="296cdff7-2db3-4c48-b5cc-15db94e52cad" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis Streams</strong>:<ul id="21faf29b-ba53-4d17-aa4f-b7552785ac99" class="bulleted-list"><li style="list-style-type:circle"><strong>설명</strong>: Redis Streams는 로그 형태의 데이터를 관리하며, 데이터의 추가 및 조회가 가능합니다. 데이터를 스트림으로 Redis에 저장하고, 이 스트림을 기반으로 후속 처리를 할 수 있습니다.</li></ul><ul id="4f67c93a-73fe-40dc-b2ba-425c543adc76" class="bulleted-list"><li style="list-style-type:circle"><strong>용도</strong>: 주문 정보를 Redis Streams에 적재하여 실시간 데이터 처리와 집계를 수행합니다.</li></ul></li></ul><ul id="f09cd035-c79e-4ec3-b72d-87aaefa722ef" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis Sorted Sets</strong>:<ul id="cea3ce6b-de54-49d4-8f1f-d8ca4746c274" class="bulleted-list"><li style="list-style-type:circle"><strong>설명</strong>: Sorted Sets는 점수 기반으로 데이터를 정렬할 수 있는 구조입니다. 주문 데이터의 집계 및 순위 정렬에 사용할 수 있습니다.</li></ul><ul id="6c3fb108-b23e-4beb-8cf8-13bbaf10ee2c" class="bulleted-list"><li style="list-style-type:circle"><strong>용도</strong>: 주문량, 매출 등의 통계를 실시간으로 집계하고 정렬합니다.</li></ul></li></ul><h3 id="3895301f-7ae8-4190-a91f-5550c5826343" class=""><strong>2.2 데이터 집계</strong></h3><ul id="f786418c-6db8-4dc9-a6f2-e97e3365b68c" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis Data Structures</strong>:<ul id="5d2e1e61-9eb3-4256-af3a-6bf7ce969f21" class="bulleted-list"><li style="list-style-type:circle"><strong>Streams</strong>: 주문 데이터를 실시간으로 처리하고, 집계 데이터를 스트림에서 소비하여 처리합니다.</li></ul><ul id="3f4dbcc3-5156-4c5a-b289-4ce3a7b51a35" class="bulleted-list"><li style="list-style-type:circle"><strong>Sorted Sets</strong>: 집계된 데이터를 점수 기반으로 정렬하여, 통계 및 순위를 계산합니다.</li></ul></li></ul><ul id="a95a3cf0-3c16-4eea-b8bc-be09c6d30af2" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis Pub/Sub</strong>:<ul id="92fe2128-c55e-478e-980e-672f85ca190f" class="bulleted-list"><li style="list-style-type:circle"><strong>설명</strong>: Redis Pub/Sub 기능을 사용하여 데이터 처리 완료를 알리거나, 실시간 통계 업데이트를 전파합니다.</li></ul><ul id="a7305509-cc57-474d-a3e2-4cf1d05e5ac5" class="bulleted-list"><li style="list-style-type:circle"><strong>용도</strong>: 집계 결과를 실시간으로 업데이트하고, 다른 시스템이나 애플리케이션에 알림을 보냅니다.</li></ul></li></ul><h3 id="daa38eaa-2b72-48b0-bdec-e00fd81af8a0" class="">3. 통계 DB 생성</h3><h3 id="d1a43a5a-65c1-4278-b2e7-1f393e730200" class=""><strong>3.1 데이터 집계 및 분석</strong></h3><ul id="33dea0d4-2880-4d76-b727-ce7d927cea2f" class="bulleted-list"><li style="list-style-type:disc"><strong>Spark Streaming or Flink</strong>:<ul id="2406531c-29ca-416d-af5c-1693ad3e7895" class="bulleted-list"><li style="list-style-type:circle"><strong>설명</strong>: Redis Streams에서 실시간으로 데이터를 읽어와 Apache Spark Streaming 또는 Apache Flink로 추가 집계 및 분석 작업을 수행합니다.</li></ul><ul id="788aa153-fec4-49ec-b4da-d69b0c6ad59d" class="bulleted-list"><li style="list-style-type:circle"><strong>용도</strong>: 실시간 데이터 스트리밍 처리 및 복잡한 집계 작업을 수행합니다.</li></ul></li></ul><h3 id="e8c988af-e5c3-4de4-9a0d-56c0c1c99730" class=""><strong>3.2 데이터 저장</strong></h3><ul id="4be75391-2141-4e0f-be13-0a881228fc0e" class="bulleted-list"><li style="list-style-type:disc"><strong>Columnar Storage DB</strong>:<ul id="a6332dfa-ae94-448c-b0c6-553067947212" class="bulleted-list"><li style="list-style-type:circle"><strong>Amazon Redshift</strong>, <strong>Google BigQuery</strong>, 또는 <strong>Apache Druid</strong> 같은 Columnar Storage DB를 사용하여 최종 집계 결과를 저장합니다.</li></ul><ul id="9ac791a0-ebac-4f90-b214-6af0a2366676" class="bulleted-list"><li style="list-style-type:circle"><strong>용도</strong>: 대규모 데이터 집계 및 분석을 위한 효율적인 저장 및 쿼리 성능을 제공합니다.</li></ul></li></ul><h3 id="aa72558a-5577-4236-a58f-e0496ff28b6c" class="">4. 모니터링 및 성능 최적화</h3><h3 id="aef1e3f0-faa3-492c-bdb5-067081e68067" class=""><strong>4.1 성능 모니터링</strong></h3><ul id="e5bca29d-4a2f-40aa-b404-c0f2fcbf755d" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis Monitoring Tools</strong>:<ul id="aa12e6f5-f5ac-41dd-a6f1-e847e0456520" class="bulleted-list"><li style="list-style-type:circle"><strong>Redis Sentinel</strong>: Redis의 고가용성과 장애 조치를 지원합니다.</li></ul><ul id="72a77ae6-e491-4506-8f4c-129232bbce9c" class="bulleted-list"><li style="list-style-type:circle"><strong>Redis CLI / Redis Insights</strong>: Redis의 성능 및 상태를 모니터링합니다.</li></ul></li></ul><ul id="01bee43b-0cef-441c-ba8b-675aa605686d" class="bulleted-list"><li style="list-style-type:disc"><strong>General Monitoring</strong>:<ul id="a5d8d2c8-45eb-4466-9898-d13fc691a5df" class="bulleted-list"><li style="list-style-type:circle"><strong>Prometheus &amp; Grafana</strong>: 전체 시스템 성능을 모니터링하고, 대시보드를 통해 실시간 성능 데이터를 시각화합니다.</li></ul></li></ul><h3 id="1ec03352-8ea3-470b-91e2-e4684df53c3c" class=""><strong>4.2 데이터 파이프라인 최적화</strong></h3><ul id="50be617a-f4ea-4d5d-a6b3-6046eecafc65" class="bulleted-list"><li style="list-style-type:disc"><strong>Data Partitioning</strong>: Redis의 데이터 구조를 적절히 파티셔닝하여 성능을 최적화합니다.</li></ul><ul id="68eab6f1-b194-4b00-ba99-ee5619eec391" class="bulleted-list"><li style="list-style-type:disc"><strong>Parallel Processing</strong>: Spark Streaming 또는 Flink의 병렬 처리 기능을 활용하여 데이터 처리 성능을 극대화합니다.</li></ul><h2 id="9a663d7d-f397-45a5-8b36-ae90d2484f76" class="">시스템 구성도</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="83444b0c-1e7c-4f39-a13e-6b4fef833a32" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">plaintext코드 복사
[Order Database]
        |
        | ETL (Apache NiFi, Talend)
        |
[Redis Streams]
        |
        | Stream Processing
        |
[Apache Spark Streaming or Apache Flink]
        |
        | Data Aggregation
        |
[Columnar Storage DB (Redshift, BigQuery, Druid)]
        |
        | Reporting
        |
[BI Tools (Tableau, Power BI)]

</code></pre><h2 id="0207fbe4-2e1e-470c-b06b-a09a21538486" class="">과정 요약</h2><ol type="1" id="c4d0d5aa-76d9-47e2-82a1-bcc5a779c656" class="numbered-list" start="1"><li><strong>데이터 추출</strong>: 주문 정보를 ETL 도구를 사용하여 데이터베이스에서 추출하고 Redis Streams에 적재합니다.</li></ol><ol type="1" id="c221f5e4-7368-4321-9460-c737ba48c290" class="numbered-list" start="2"><li><strong>데이터 전처리 및 집계</strong>: Redis Streams를 통해 실시간으로 데이터를 읽고, Redis Sorted Sets를 사용하여 통계를 집계합니다.</li></ol><ol type="1" id="26786405-675f-46ad-9140-614e5a5791ab" class="numbered-list" start="3"><li><strong>데이터 분석</strong>: Apache Spark Streaming 또는 Apache Flink를 통해 실시간 데이터 처리 및 추가 집계를 수행합니다.</li></ol><ol type="1" id="689e6ec8-2545-4f29-a1cd-edcfb4421572" class="numbered-list" start="4"><li><strong>데이터 저장</strong>: 집계된 데이터를 Columnar Storage DB에 저장하여 쿼리 성능을 최적화합니다.</li></ol><ol type="1" id="cc3d3968-0637-4ee8-83bd-b14185327fe6" class="numbered-list" start="5"><li><strong>모니터링 및 최적화</strong>: Redis 및 전체 시스템의 성능을 모니터링하고, 성능 최적화를 진행합니다.</li></ol><p id="4d2bc9ce-6bf6-48f7-aecd-81fd86cecf2a" class="">이 설계를 통해 Redis의 메모리 기반 처리와 스트리밍 기능을 활용하여 대규모 데이터의 처리 및 집계를 효율적으로 수행할 수 있습니다.</p></details></li></ul><ul id="8941888f-a3c3-4a69-b406-85934f4d3308" class="toggle"><li><details open=""><summary>배민 - 사장님용 통계 데이터 서빙하기</summary><p id="ffa64220-f478-4d8b-ab8c-b0ddda3f0613" class="">안녕하세요, 배민상품시스템팀에서 서버 개발을 맡고 있는 한진욱입니다.</p><p id="901e70c0-74cd-4fdb-9bb3-e62e1a793012" class="">작년에 저희 팀은 ‘우리가게NOW’라는, 사장님들을 위한 통계 서비스를 만드는 프로젝트에 참여했습니다.</p><p id="0b5194c4-b34e-4b02-bbe8-5aaa29b9438f" class="">기존에 하던 업무에서 보기 힘들었던 통계 데이터를 다루면서 겪었던 어려움과 문제 해결의 과정에 대해서 소개하고자 합니다.</p><h2 id="eeb7ca08-b019-42f1-897c-838361dbe5a5" class=""><strong>이름도 낯선 프로젝트, ‘우리가게NOW’이름도 낯선 프로젝트, ‘우리가게NOW’</strong></h2><p id="42aaf293-c56d-4892-ab0e-b5e7f29bf672" class="">우리가게NOW 서비스는 작년 6월에 출시한 통계 서비스입니다.</p><p id="d7980afd-4611-45bf-9b27-83e2d1a6e7d2" class="">[출처: 배민사장님광장]</p><figure id="525e0259-0216-4164-907a-643e2b2ccf43" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2027.png"><img style="width:449.9999694824219px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2027.png"/></a></figure><p id="8f523aea-4d94-4d78-a879-f25c119bdc2d" class="">사장님들께 주문 접수율, 주문 접수시간, 조리시간, 조리시간 준수율 등의 지표를 공개하여, 사장님이 직접 가게 운영과 고객만족에 큰 영향을 미치는 지표들을 살펴보고 개선할 수 있도록 하는 통계 서비스입니다.</p><p id="908fdb5c-5964-4461-bff0-e973a305879c" class="">사장님에게 새로운 통계 화면을 제공하기 위해, 다음과 같은 요구사항을 구현해야 했습니다.</p><ul id="2a04a07f-371d-4927-9e0d-cf1306eb98e1" class="bulleted-list"><li style="list-style-type:disc">주문/배달 데이터로부터 주문 접수율, 주문 접수시간, 조리시간 준수율 등의 통계 데이터를 만들 수 있어야 합니다.</li></ul><ul id="5e5ed392-54dc-4f0c-b660-968544bd565a" class="bulleted-list"><li style="list-style-type:disc">통계 데이터를 바탕으로 상대평가를 해야 합니다. 각 지표별로 모든 가게들 중 상위 몇 퍼센트인지 수치로 나타낼 수 있어야 합니다.</li></ul><ul id="e421cebb-8054-4788-ac1d-065dbe7928c7" class="bulleted-list"><li style="list-style-type:disc">매일 아침 9시에 통계/상대평가 데이터 최신본을 업데이트해야 합니다.</li></ul><p id="28d9e10b-3bca-4273-802e-af2e99a1900b" class="">이 프로젝트는 기존에 팀에서 주로 하던 작업과 비교해 생소한 부분이 많았는데, 다음과 같은 점이 생소했습니다.</p><ul id="ddd33f65-cf90-4442-b596-acd8e1fb70ab" class="bulleted-list"><li style="list-style-type:disc">통계 데이터를 다뤄야 했습니다. 실시간 데이터가 아니라는 점이 정말 생소했습니다. 과거 데이터를 처리하는 통계 작업을 진행하는 것은 처음이었습니다.</li></ul><ul id="c6f129c8-19b0-4cb1-9d96-1a727420c214" class="bulleted-list"><li style="list-style-type:disc">처리하는 데이터 크기가 컸습니다. 주문 데이터를 바탕으로 통계 데이터를 계산해야 하는데, 주문 데이터 개수는 이전에 팀에서 취급해왔던 데이터 수(몇 십만 개 수준)의 몇 배를 뛰어넘는 수준이었습니다.</li></ul><ul id="1bc21c59-3664-4126-acd6-d92261cd4077" class="bulleted-list"><li style="list-style-type:disc">Airflow, SparkSQL 기술을 사용해야 했습니다. 데이터 레이크에서 다른 도메인(주문) 데이터를 바탕으로 작업해야 했기 때문입니다.</li></ul><p id="65a375bd-43ca-4c19-828c-e4b6bc2f5111" class="">낯선 작업이었지만, Airflow+SparkSQL을 통해서 외부 데이터를 사용해야 한다는 점은 분명해 보였습니다.</p><p id="734eda4c-729a-4f72-9819-b4b762c4b659" class="">아래 3가지 틀 하에서, 세부적인 구조를 만들며 나아갔습니다.</p><ol type="1" id="b66d70bf-3677-47ca-8a08-d6dcd02868ff" class="numbered-list" start="1"><li>Airflow 스케줄러를 통해 주기적으로 외부에서 필요한 정보를 가져온다.</li></ol><ol type="1" id="c3fb0198-27e4-41c1-b88c-95907fddbc19" class="numbered-list" start="2"><li>데이터 레이크(Data Lake)에서 SparkSQL 쿼리문으로 데이터 추출한다.</li></ol><ol type="1" id="6ee420b8-ba25-4322-a5e8-fb576a196e4c" class="numbered-list" start="3"><li>데이터를 팀 내 RDB로 저장한다.</li></ol><h2 id="edecc40f-533d-496b-bd9b-bffdfe3e555a" class=""><strong>프로젝트를 위한 첫 구조</strong></h2><p id="5d789c00-2014-4436-9e4b-e23f4a3194ef" class="">팀원과 함께 정한 첫 구조는 이렇습니다.</p><p id="97835669-906d-4618-a811-24203130153e" class="">먼저, 사내에서 데이터서비스실이 관리하고 있는 테이블을 모두 ‘데이터 레이크(Data Lake)’라고 하겠습니다.</p><figure id="61b1b4e2-4808-4e4e-9b42-1d066a46bba8" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2028.png"><img style="width:600px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2028.png"/></a></figure><ol type="1" id="6c0a02f7-4922-4be9-ba6a-27ffb8ee589a" class="numbered-list" start="1"><li>데이터 레이크에서 주문 데이터를 뽑은 뒤 팀 내 RDB로 적재합니다.</li></ol><ol type="1" id="1ccfd652-bb8f-43ac-b920-5de2918a3291" class="numbered-list" start="2"><li>적재한 주문 데이터를 바탕으로 주문 접수율, 주문 접수시간, 조리시간, 조리시간 준수율 등의 통계 데이터를 계산합니다.</li></ol><ol type="1" id="4a4c9d99-307d-461c-852b-85c536e529b9" class="numbered-list" start="3"><li>계산한 결과를 다시 팀 내 RDB로 적재합니다.</li></ol><p id="363108f9-79c8-4667-a4c3-6208932f25df" class="">통계 데이터를 배치 애플리케이션으로 계산한다는 점이 핵심입니다.</p><p id="770b81f8-ac40-4c8a-82ae-4732e4605b97" class="">위 구조의 장점은 다음과 같습니다.</p><ul id="a51b487a-5ab4-4559-bb40-ec3526ee724d" class="bulleted-list"><li style="list-style-type:disc">테스트가 쉽습니다.</li></ul><ul id="a9b88b55-301d-4b32-b7ce-e1b3a8459ca5" class="bulleted-list"><li style="list-style-type:disc">변경사항에 유연하게 대응할 수 있습니다.</li></ul><ul id="4204961c-ca50-4416-bd77-570992aea5d1" class="bulleted-list"><li style="list-style-type:disc">통계를 처리하는 부분을 가독성 있게 코드로 표현할 수 있습니다.</li></ul><p id="8c9e59dd-910d-436d-a9e9-89f1fe683701" class="">세 가지 장점 모두 애플리케이션 코드라는 특성에서 나옵니다. Java 코드로 계산 로직을 표현하기 때문에, 테스트를 할 수 있고 따라서 유연성 및 가독성이 증가한다는 것입니다.</p><h2 id="96a1feea-3e1b-4d84-ab1b-b41b85cc6f24" class=""><strong>첫 구조의 문제점</strong></h2><p id="9a5876c5-33fd-427f-a1b0-65247dd7de82" class="">하지만 이 구조는 곧 문제에 부딪혔습니다.</p><p id="2f7bf736-825c-4200-8c16-dee86d2a9dfc" class="">팀에서 겪어보지 못한 엄청난 크기의 데이터 때문이었습니다.</p><p id="e6bc47f2-20d2-41d1-9fb3-94807c736ee5" class="">몇 백만 건의 주문 데이터양 때문에 두 가지 우려가 생겼습니다.</p><ol type="1" id="bbbc6357-d099-493e-a9f8-aba8e3d43308" class="numbered-list" start="1"><li>3시간에 안에 배치를 완료할 수 있을지에 대한 확신이 없었습니다.<ol type="a" id="345e7e44-223b-49a1-b702-623cbaa74fec" class="numbered-list" start="1"><li>적어도 3시간 안에는 통계 계산이 끝나야 합니다. 전날 주문 데이터가 쌓이는 6시 이후부터 시작해서, 사장님에게 통계 데이터가 오픈되는 9시까지 통계 데이터를 생성해야 했기 때문입니다.</li></ol><ol type="a" id="e95e394b-838c-4e19-94f1-cafc61b46996" class="numbered-list" start="2"><li>하지만 14일간의 주문 건을 바탕으로 통계를 내기 때문에, 계산 대상 데이터가 몇 백만 건이 될 수 있습니다.</li></ol><ol type="a" id="3c07f62a-da5a-46ee-a1bb-b1ecc0a6e146" class="numbered-list" start="3"><li>팀에서 평소에 배치가 다루는 데이터가 몇십만 건 수준임을 생각하면, 팀 내 평균 배치 실행 시간보다는 훨씬 오래 걸릴 것으로 추정했습니다.</li></ol></li></ol><ol type="1" id="1aa44a6b-876c-4154-aa6e-4f282d796cbb" class="numbered-list" start="2"><li>팀 내 RDB로 모든 주문 데이터를 적재하는 부담이 컸습니다. 몇 백만 건의 주문 데이터가 팀 내 RDB로 저장됩니다. 활용도가 제한적인 주문 데이터를 관리해야 하는 부담이 있습니다.</li></ol><h2 id="0c100e70-e0a1-4087-9d12-46e109b65f04" class=""><strong>적재하는 과정에서 계산하기로 결정, 하지만…</strong></h2><p id="c7617f35-785d-4d63-8882-9391e8e9d7c1" class="">몇 차례의 팀 내 논의를 거친 후, 애플리케이션이 아닌 적재하는 과정에서 통계 데이터를 함께 계산하는 것으로 결정했습니다.</p><p id="c8811518-7658-4b86-afa4-0604d4b297b7" class="">즉, 데이터 레이크에서 팀 내 RDB로 데이터를 적재하는 과정에서 통계 데이터를 계산하기로 했습니다.</p><p id="bfdf36fa-e016-4cf1-b7e1-db31b3b9c595" class="">이를 통해, 다음 <strong>두 가지 장점을 얻을 것으로 기대</strong>했습니다.</p><ol type="1" id="b3bccb03-eb51-4173-b6de-5efbc3c0f152" class="numbered-list" start="1"><li>성능상 유리하다고 생각했습니다. 데이터 레이크에서 팀 내 RDB로 적재할 때 SparkSQL를 이용하고 있습니다. 분산 환경에서 동작하는 Spark 특성을 이용하여, executor 수를 조절하여 저희가 원하는 만큼 성능을 올릴 수 있을 것이라고 기대했습니다.</li></ol><ol type="1" id="88dacedc-d080-48a3-94dd-4e8385715d49" class="numbered-list" start="2"><li>주문데이터를 팀내 RDB로 적재하는 부담을 없앨 수 있습니다.</li></ol><p id="bb912201-924f-4c24-ad9f-ec82c84aa47d" class="">하지만 아직 SparkSQL로 통계 데이터를 생성하는 구조에 대해 자신이 없었습니다.</p><p id="6f643c17-a3b5-419b-b456-49dc072a942c" class="">평소에 쿼리 형태의 코드를 작성한 적이 드물었고, 쿼리 형태의 코드가 앞으로의 요구사항 변경을 과연 충족할 수 있을지에 대해 의문이 들었기 때문입니다.</p><p id="b744e243-b1f9-4569-ae12-0f346469091c" class="">여기에 대해 동료 개발자 한 분은 다음과 같은 질문을 할 것을 조언했습니다.</p><h2 id="cc54b410-0da3-4144-9f60-09f3327b352e" class=""><strong>나에게 일주일의 시간이 있다고 상상해 보기</strong></h2><p id="cea1de1d-f33b-47c7-a46f-762db422be9d" class=""><em><strong>‘나에게 일주일의 빈 시간이 있을 때, 새로운 기술의 불안감을 해소하기 위해 나는 무엇을 할 것인가?’‘SparkSQL의 불안감을 해소하기 위해 나는 어떤 점을 찾아볼 것인가?’</strong></em></p><p id="8bf1c36d-005b-4713-bc93-eb7f4bd76bc6" class="">스스로에게 이 질문을 던졌을 때, 업주 간 상대평가를 하는 구현하는 부분이 제일 자신이 없었습니다.</p><p id="180e6232-3b6a-4f32-ad56-ce5fea028dcf" class="">그래서 SparkSQL 쿼리로 구현할 수 있을지 직접 확인했습니다.</p><table id="49d71ca7-8aa4-461e-b4b5-80f4718cefa5" class="simple-table"><tbody><tr id="524c10b0-3f71-435e-b039-dd46ce14ccba"><td id="ErO[" class=""><strong>업주</strong></td><td id="||er" class=""><strong>조리시간 준수율</strong></td><td id="rK^v" class=""><strong>순위</strong></td></tr><tr id="251f3cc8-114f-4df7-aba7-d877607e5468"><td id="ErO[" class="">A</td><td id="||er" class="">12%</td><td id="rK^v" class="">1</td></tr><tr id="393e32ca-2218-46e3-9589-721e3096a5db"><td id="ErO[" class="">B</td><td id="||er" class="">9%</td><td id="rK^v" class="">2</td></tr><tr id="98edab36-1cde-4547-8a51-1891c60dfc05"><td id="ErO[" class="">C</td><td id="||er" class="">9%</td><td id="rK^v" class="">2</td></tr><tr id="16015f1a-bdf9-4da8-8461-424fea57f159"><td id="ErO[" class="">D</td><td id="||er" class="">8%</td><td id="rK^v" class="">4</td></tr></tbody></table><p id="2b6216ce-a76d-4af9-aa0f-50d7d2b6df73" class="">현재 요구사항은 위 표와 같이 순위가 나오도록 하는 것입니다. 동점자는 같은 순위가 되고, 그다음 순위는 직전 동점자들 수가 반영되어 매겨집니다.</p><p id="fec6951a-5150-41a1-af1d-b8b5f11e8de9" class="">찾아보니 SparkSQL에도 RANK() 함수가 있었습니다.</p><p id="66c262d4-9c13-4ebd-9287-0ccbffb7f281" class="">다음과 같이 쿼리문을 만드니 상대평가를 하는 로직이 간단히 해결됐습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="3ecddb99-26c2-45a5-a04e-240d0e1ff401" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">RANK() OVER (ORDER BY cooking_time_rate DESC)</code></pre><p id="f3c26baa-6a9b-400f-b93c-1a1b6ec2fdd1" class="">SparkSQL에 대한 불안감을 일정 부분 해소했습니다.</p><p id="c5d29ebf-2bfc-4cd2-82d1-58298757f65b" class="">물론 더 복잡한 요구사항이 들어온다면, 쿼리로 구현하는 게 어려울 수도 있습니다.</p><p id="eeaba454-ac13-4069-8aeb-fc39e40d478c" class="">하지만 더 복잡한 요구사항이 들어올 가능성은 적을 것이라고 생각했습니다. 또한 들어온다고 하더라도, 그때 상대평가 부분만 배치로 계산하도록 바꿔도 됩니다.</p><h2 id="30040275-fbf9-4643-8133-481945474348" class=""><strong>그렇게 해서 만들었습니다, 최종 구조</strong></h2><p id="4c2a2689-9e9f-4ca4-84ab-25e2a325abea" class="">최종 구조는 다음과 같습니다.</p><figure id="68ede97c-b314-47b4-939d-3fd30dfe3df3" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2029.png"><img style="width:600px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/Untitled%2029.png"/></a></figure><p id="cdec9482-26b5-4dde-8d3c-b8582feeebce" class="">중간 통계 결과를 저장하는 hive 테이블을 두고, 중간 결과를 합친 최종 결과만 팀 내 RDB로 저장하도록 만들었습니다.</p><p id="87ec9951-eb89-414d-abaa-77766e95d966" class="">통계 데이터를 계산하는 로직은 데이터 레이크에서 데이터를 추출하는 SparkSQL에 있습니다.</p><p id="1f0c714a-8dd5-4dc2-8054-654ba2e80819" class="">이를 통해, 우리가게NOW 오픈 첫날 30분 안쪽으로 데이터 처리를 완료할 수 있었습니다.</p><p id="a1e55eec-1205-4a25-8b8f-16c284bc99bd" class="">지금까지도 평균적으로 30분 처리 시간을 유지하고 있습니다.</p><h2 id="9d914891-b8bb-4bf5-9d5b-dd61c9780e76" class=""><strong>돌이켜보면</strong></h2><p id="f9bcc518-3f52-4c42-8ff3-62e854eb8e8d" class="">우리가게NOW 통계를 계산하는 작업은 몇백만 건이 넘는 과거 주문 데이터를 처리하는 빅데이터 성격의 작업이었습니다.</p><p id="dcaadee0-6f98-4cf2-be8d-d97fd81b0d1b" class="">하지만 당시에 제가 작업했을 때 빅데이터를 다루고 있다는 인식조차 희박했습니다.</p><p id="de05d34d-71b6-4928-b840-03e039b40fbb" class="">그래서 처음에는 실시간성 데이터를 보정하는 배치 애플리케이션으로 접근하는 등의 시행착오를 겪었습니다.</p><p id="d34d6d82-c4c7-463e-9fcf-595c85efbb66" class="">지식이 부족한 상태였지만, 당시로서 가장 나은 대안을 찾을 수 있었던 이유는 다음 요인이었던 것 같습니다.</p><ul id="844ae73a-d0be-49d5-8ec5-1556af9b3cba" class="bulleted-list"><li style="list-style-type:disc"><strong>가치의 우선순위 파악, 기술의 장단점 분석 후 우선순위에 따라 기술 선택</strong><ul id="2885bcac-023e-4d5b-a1bb-027e8be4e8c1" class="bulleted-list"><li style="list-style-type:circle">당시 아침 9시까지 업주에게 최신화된 통계 화면을 보여주는 것을 최우선 우선순위로 두었습니다.</li></ul><ul id="b692805b-ce0c-45b2-9c2e-f46d484d750c" class="bulleted-list"><li style="list-style-type:circle">따라서 수행 시간 축소를 최우선 순위로 둘 수 있었습니다.</li></ul></li></ul><ul id="a7b78e2d-a435-4fd6-9e40-0ae04351af96" class="bulleted-list"><li style="list-style-type:disc"><strong>생소한 기술에 대한 불안감을 질문으로 해소하기</strong><ul id="b9b35642-4814-4863-bf2a-16c41ef60b16" class="bulleted-list"><li style="list-style-type:circle">SparkSQL에 대한 불안감은 말로 표현하기 전까지는 막연한 상태였습니다.</li></ul><ul id="7ac9ba42-b045-45c2-bba2-f4abf4683c6f" class="bulleted-list"><li style="list-style-type:circle">일주일의 시간이 있으면 어떤 부분을 공부할 것인가? 질문을 통해 불안감의 원인을 구체화할 수 있었습니다.</li></ul></li></ul><p id="e4de8f24-b23e-4705-9689-390658f541a6" class="">이번 우리가게Now 프로젝트를 통해 기술에 대한 막연한 불안감을 해소하는 방법을 배울 수 있었습니다. 더불어 데이터에도 실시간 데이터, 통계 데이터 등 여러 가지 유형이 있다는 점을 배웠습니다.</p></details></li></ul><ul id="165d4bea-87ab-4d59-85f3-3d99f4897430" class="toggle"><li><details open=""><summary>제모옥은 젠킨스 조회로직 개선으로 하겠습니다. 근데 이제 비동기를 곁들인</summary><figure id="1f9415fb-91e0-4033-90d7-fb86c07dec4f"><a href="https://techblog.woowahan.com/2722/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">제모옥은 젠킨스 조회로직 개선으로 하겠습니다. 근데 이제 비동기를 곁들인 | 우아한형제들 기술블로그</div><div class="bookmark-description">제목의 밈은 조림요정의 휴먼강록체입니다. Intro 평화로운 2020년 9월의 어느 날... 데일리 미팅을 마치고 일감을 정리하던 저에게 한 가지 요청이 들어왔습니다. &quot;우빈님 여기 로직이 오래 걸리면 90초 넘게 걸리고 있는데 한번 개선할 수 있을지 확인 부탁드려요.&quot; &#x27;읭 아니 대체 어떤 레거시길래 90초씩이나 걸리는거야&#x27; 라고 생각하며 코드를 열어서 확인했는데요. 개발자들에게는 흔히 있는 일이라고 하는데... 저만 겪고 있는</div></div><div class="bookmark-href"><img src="https://techblog.woowahan.com/wp-content/uploads/2020/08/favicon.ico" class="icon bookmark-icon"/>https://techblog.woowahan.com/2722/</div></div><img src="https://techblog.woowahan.com/wp-content/uploads/2021/06/screenshot.jpg" class="bookmark-image"/></a></figure></details></li></ul><ul id="1453a4cc-090a-80dc-af0f-c1088a896615" class="toggle"><li><details open=""><summary>K8S Observability - 와탭랩스</summary><p id="1453a4cc-090a-8082-81ba-ed2d1305254c" class=""><a href="https://www.youtube.com/watch?v=DXXJEAfhjiQ">https://www.youtube.com/watch?v=DXXJEAfhjiQ</a></p><figure id="1453a4cc-090a-809f-a9ea-eea75ad96ec3" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-21_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.49.48.png"><img style="width:628.0255737304688px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-21_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.49.48.png"/></a></figure><p id="1453a4cc-090a-8012-9f97-d573bbfeb80b" class="">
</p><p id="0c2831cf-fbac-4afd-b0de-d725ca783f36" class="">
</p></details></li></ul><ul id="18e03155-5341-4e4d-ac39-a7b32367e1d3" class="toggle"><li><details open=""><summary>카카오페이 - 마이데이터 플랫폼의 대용량 데이터 처리 개선! 구경 한번 해볼래?</summary><p id="356ad987-788a-4341-a88a-2bb59ab82400" class="">안녕하세요. 카카오페이에서 마이데이터 플랫폼을 개발하고 있는 루피, 류크, 크루스입니다. 저희 팀은 자산관리 서비스를 포함하여 마이데이터를 필요로 하는 모든 서비스에 안정적으로 마이데이터를 제공하기 위한 플랫폼을 개발하기 위해 노력하고 있습니다. 2023년 카카오페이 자산관리 서비스는 급격히 성장했으며, 이에 따라 마이데이터 플랫폼은 기존보다 더 많은 데이터를 처리할 수 있는 아키텍처가 필요했습니다. 본 포스팅에서는 여러 개선 사항 중 “사용자의 금융 데이터 수집 이력 보관과 통계 제공”을 어떻게 개선했는지 공유하고자 합니다.</p><h1 id="5bcb2432-7c8f-4fd3-bb16-9d4c70a4e546" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#%EB%A7%88%EC%9D%B4%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%8C%EB%9E%AB%ED%8F%BC%EC%9D%98-%EB%8C%80%EC%9A%A9%EB%9F%89-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%8A%94-%EC%96%B4%EB%94%94%EC%84%9C-%EC%99%94%EC%9D%84%EA%B9%8C">마이데이터 플랫폼의 대용량 데이터는 어디서 왔을까?</a></strong></h1><p id="e184f1f6-7f41-4531-bee2-b83d19c141d1" class="">마이데이터 플랫폼은 사용자의 요구에 따라 여러 금융기관에 흩어진 금융 데이터를 마이데이터 표준에 따라 수집 및 관리하고있습니다. 또한, 마이데이터 사업자 및 제공자가 준수해야 할 의무를 수행하고 있습니다. 이러한 의무 중 “신용정보법 제20조”에 따라 “사용자의 금융 데이터 수집 이력”을 3년간 보관하고 있습니다.</p><figure id="de0ef6ae-eaaa-4837-9499-b7a9d480b769" class="image"><a href="https://tech.kakaopay.com/_astro/ref_history.0325a51d_Z1AJJPP.avif"><img src="https://tech.kakaopay.com/_astro/ref_history.0325a51d_Z1AJJPP.avif"/></a></figure><p id="96afb65d-7743-492d-83a8-8a77b6780ac4" class="">자산관리 서비스가 성장함에 따라 “사용자의 금융 데이터 수집 이력” 데이터 규모가 마이데이터 플랫폼 초기 구축 당시 예측치보다 빠르게 증가하였습니다. 데이터 규모 증가로 인해 데이터 관리에 대한 아키텍처 재 설계가 필요하였습니다. 개선된 내용을 공유드리기에 앞서 우선 기존 시스템에서 어떤 문제가 있었는지를 살펴보겠습니다.</p><h1 id="0e36d385-6ce5-4c93-96c2-5f9b6903cb10" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#%EA%B8%B0%EC%A1%B4-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%B4-%EA%B0%80%EC%A7%84-%EB%AC%B8%EC%A0%9C%EB%8A%94">기존 시스템이 가진 문제는?</a></strong></h1><p id="734187a7-8712-430b-b07a-e58b773dda09" class="">기존 아키텍처에서 크게 3가지 문제점을 식별했습니다. 높은 QPS, 데이터 보관 용량 부족, 그리고 마지막으로 통계 배치 수행 시간 증가입니다.</p><h1 id="a7063c59-77ab-470b-b79f-15a3203b9179" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#%EC%9D%B4%EC%8A%88-1-%EB%86%92%EC%9D%80-qps">이슈 1. 높은 QPS</a></strong></h1><p id="1f1fbcfa-c7bb-46aa-9876-563f9eff7776" class="">이력성 데이터와 금융 데이터를 같은 데이터소스에 관리하다 보니 해당 데이터소스에 대한 QPS (Queries per second)가 높은 것을 확인하였습니다.</p><figure id="66e95f63-4c7c-4348-8048-ed625a6838a8" class="image"><a href="https://tech.kakaopay.com/_astro/old-qps-detail.d16106b1_19mbH0.avif"><img src="https://tech.kakaopay.com/_astro/old-qps-detail.d16106b1_19mbH0.avif"/></a></figure><p id="f40159fb-ee9e-4d8d-9911-130b9c5f3da9" class="">높은 QPS는 Master 데이터소스와 Slave 데이터소스에 대한 복제지연을 야기하였습니다. 복제지연은 Master 데이터소스에 대한 장애 상황에서 Slave 데이터소스로의 failover가 불가능하다는 점이 있어 빠른 해소가 필요했습니다.</p><figure id="4d3434aa-0168-452f-a4cc-33f67c0d59b8" class="image"><a href="https://tech.kakaopay.com/_astro/db-replication-lag.0ec3b928_Z2q36UB.avif"><img src="https://tech.kakaopay.com/_astro/db-replication-lag.0ec3b928_Z2q36UB.avif"/></a></figure><p id="678d2d7a-9e6c-4770-a9df-c96a332db6ad" class="">이를 해소하기 위한 임시방편으로 카프카를 완충장치로 사용해 처리량을 조절하면서 QPS를 줄여보았는데요. 카프카 처리량을 줄임에 따라 카프카의 Lag 또한 지속적으로 증가하였습니다. 지속적인 사용자 증대로 인한 Produce 양이 Consume 양을 따라가지 못한 이유에서였습니다.</p><figure id="fe7c3e32-dad2-47eb-8356-28eb1cbbd6da" class="image"><a href="https://tech.kakaopay.com/_astro/kafka-lag.19b5d686_ZhNzyo.avif"><img src="https://tech.kakaopay.com/_astro/kafka-lag.19b5d686_ZhNzyo.avif"/></a></figure><h1 id="1b9966c3-647d-46b6-900c-9ddaea0a4a27" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#%EC%9D%B4%EC%8A%88-2-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B3%B4%EA%B4%80-%EC%9A%A9%EB%9F%89-%EB%B6%80%EC%A1%B1">이슈 2. 데이터 보관 용량 부족</a></strong></h1><p id="facbd27d-5531-4819-a57b-9c68bba53036" class="">위에서 소개드린 것처럼 마이데이터 표준을 따르려면 “사용자의 금융 데이터 수집 이력”을 3년 보관해야 합니다. 시간이 지나면서 누적되는 데이터양이 크게 증가했습니다. 이에 따라 데이터소스 용량이 부족해질걸 예상했기에 사전에 용량 확보 방안을 마련해야 했습니다.</p><h1 id="ccb86a33-4d03-41a1-8924-a27445fdb148" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#%EC%9D%B4%EC%8A%88-3-%ED%86%B5%EA%B3%84-%EB%B0%B0%EC%B9%98-%EC%88%98%ED%96%89-%EC%8B%9C%EA%B0%84-%EC%A6%9D%EA%B0%80">이슈 3. 통계 배치 수행 시간 증가</a></strong></h1><p id="b9e7b189-624f-4864-975a-5032256fe4d5" class="">카카오페이는 마이데이터 사업자로서 마이데이터 API 사용에 대한 통계 데이터를 신용정보원 종합포털에 1주일 단위로 전송을 해야 하는 의무가 있습니다. 저희 플랫폼에서는 응답시간, 합계, 표준편차, 성공실패 횟수 등의 통계 데이터를 전송하기 위해 매일 통계 데이터를 저장하는 배치를 수행합니다.</p><figure id="79e4e1db-8d71-4e73-a3fd-e073359adc11" class="image"><a href="https://tech.kakaopay.com/_astro/mydata-statistic-flow.3c2f0a43_nvyYg.avif"><img src="https://tech.kakaopay.com/_astro/mydata-statistic-flow.3c2f0a43_nvyYg.avif"/></a></figure><p id="029a0712-4b9d-45fd-88ae-1ec28215ba12" class="">통계 데이터를 저장하는 배치에서는 통계 데이터인 평균, 합계, 표준편차를 구하기 위해 AVG, STDDEV, SUM 등의 쿼리 함수를 사용합니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="2d277600-64db-43be-bc0a-212c048b6c10" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">SELECT    DATE_FORMAT(request_at, &#x27;%Y%m%d&#x27;) AS &#x27;stat_date&#x27;,    org_code,    api_code,    AVG(duration) AS &#x27;rsp_avg&#x27;,    STDDEV(duration) AS &#x27;rsp_std_dev&#x27;,    SUM(duration) AS &#x27;rsp_total&#x27;,GROUP BY DATE_FORMAT(request_at, &#x27;%Y%m%d&#x27;),    org_code,    api_code,</code></pre><p id="6367462c-9cc5-4c6a-8662-d683093859c8" class="">마이데이터 가입자수 및 연결자수가 늘어나게 되면서 로그성 데이터의 테이블의 크기는 가파르게 상승하기 시작했고, 쿼리의 수행 속도는 점점 느려지고 있었습니다.</p><p id="1540e201-027a-4ae9-95dd-77043a4f7a44" class="">또한, 위에서 언급한 kafka Lag이 점점 쌓이면서 실제 API 요청 시간과 데이터의 created_at 시간이 다른 문제가 발생했습니다. 이전까지는 쿼리의 조회 기간을 통계 날짜의 00:00 ~ 23:59로 했습니다. 그런데 kafka Lag으로 인해 데이터가 늦게 저장되면서, 통계 날짜 00:00 ~ 통계 날짜 +1일 23:59까지 조회 기간을 늘리게 되었습니다. 이에 따라 많은 양의 데이터를 조회하는 상황이 되었습니다.</p><figure id="12987a20-e17c-40d0-8460-5d5b56b52991" class="image"><a href="https://tech.kakaopay.com/_astro/created-at-data-range.2c51501e_Z24kaHd.avif"><img src="https://tech.kakaopay.com/_astro/created-at-data-range.2c51501e_Z24kaHd.avif"/></a></figure><p id="e143029e-af4c-4964-81e6-1a37ad8b62e8" class="">이렇게 많은 양의 데이터를 조회하여 계산하는 쿼리를 수행하다 보니 쿼리는 슬로우 쿼리로 수행되고, DB의 부하는 계속해서 증가했습니다. 또한, 데이터의 양이 계속해서 늘어나 개선을 하지 않으면 24시간이 넘게 수행되는 문제가 발생할 수밖에 없었습니다.</p><figure id="a99f3f25-5b1d-4182-9a9c-8147178332a1" class="image"><a href="https://tech.kakaopay.com/_astro/befor-stat-alarm.f870b78c_P93Nw.avif"><img src="https://tech.kakaopay.com/_astro/befor-stat-alarm.f870b78c_P93Nw.avif"/></a></figure><p id="d635760e-1a29-4a0c-9031-84a9e3f1ed2e" class="">기존 시스템이 가진 문제 중 위와 같은 이슈들을 식별하였고, DB 부하 경감을 목표로 “사용자의 금융 데이터에 대한 수집 이력”에 대한 처리 및 관리 방식을 다시 설계하게 되었습니다. 먼저, 단일 DB에 대한 부하를 낮추기 위해 샤딩을 통해 히스토리 데이터를 여러 곳에 나눠서 적재하는 방안을 도입하였습니다. 다음으로 누적되는 데이터 양에 따른 DB 용량 부족 문제를 해결하고자 DB에 데이터를 보관하는 기간을 줄이고 이후에는 파일로 옮겨서 보관하도록 설계하였습니다. 마지막으로 RDB로 구성된 DB에서 직접 통계를 내지 않고 하둡 기반의 내부시스템인 Palsonic을 사용하여 통계를 내도록 변경하였습니다.</p><p id="ff94b110-cac5-4e56-8fdf-089fbac17faa" class="">그럼 지금부터 각 이슈에 대해서 어떻게 개선하게 되었는지 설명드리겠습니다.</p><h1 id="d8116d95-31c9-402a-a9db-a5463b6c36b1" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#%EC%86%94%EB%A3%A8%EC%85%98-1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%82%B0-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0">솔루션 1, 데이터 분산 저장하기</a></strong></h1><p id="8a5c4713-f980-4662-a718-5c667e015962" class="">앞서 소개드린 “이슈 1. 높은 QPS”에 대한 해결책으로 데이터 분산 저장을 택하였습니다. 높은 데이터 유입량과 많은 데이터로 인한 부하를 분산하기 위해 1차적으로 데이터 유형에 따른 데이터소스를 분리하고, 2차적으로는 데이터소스에 대한 샤딩을 도입했습니다.</p><p id="ea51aae5-36c7-4e4a-a08f-7ceaab8ea2eb" class="">먼저, 데이터 유형에 따른 분리로 서비스에 활용되는 데이터와 이력성 데이터소스를 분리하였습니다. 기존 시스템에서 이력성 데이터의 유입이 INSERT 쿼리의 상당 부분을 차지하고 있었는데요. 이력성 데이터를 서비스성 데이터와 분리함에 따라 서비스 성 데이터에 대한 부하를 1차적으로 낮출 수 있었습니다.</p><figure id="778489f9-963a-48c6-aa75-a0fdb720569f" class="image"><a href="https://tech.kakaopay.com/_astro/qps-changes.ff828995_bhRYq.avif"><img src="https://tech.kakaopay.com/_astro/qps-changes.ff828995_bhRYq.avif"/></a></figure><p id="f8e5de27-2a67-4fdf-acab-a17a201704d0" class="">그다음으로 이력성 데이터에 대한 샤딩 적용입니다. 이력성 데이터의 경우에는 많은 유입뿐만 아니라 누적된 데이터로 인한 DB 용량 이슈도 있었는데요. 부하 분산 및 용량 분산을 위해 샤딩을 도입하였습니다.</p><p id="17097c8a-d51b-4cc1-86ce-a784ea9dfce9" class="">여러 샤딩 방식 중 저희가 도입한 방식은 모듈러 샤딩입니다. 샤딩 방식은 크게 모듈러 샤딩과 레인지 샤딩으로 나뉘는데요. 각 방식에 대한 장/단점은 아래와 같습니다.</p><table id="75db5c65-5f9a-44f8-a5c2-7fc6e1e80f73" class="simple-table"><tbody><tr id="90992c30-9281-45ad-bf6d-df246dd7717f"><td id="Mc?^" class=""></td><td id="lXGP" class=""><strong>모듈러 샤딩</strong></td><td id="?k`w" class=""><strong>레인지 샤딩</strong></td></tr><tr id="69747d3b-8636-4f5d-9eb0-cfa880f30d55"><td id="Mc?^" class="">장점</td><td id="lXGP" class="">레인지 샤딩에 비하여 균등 분배가 가능</td><td id="?k`w" class="">구현 및 서버 증설이 용이</td></tr><tr id="c86b5d65-198d-4df9-9296-e54f38d14851"><td id="Mc?^" class="">단점</td><td id="lXGP" class="">DB가 추가되는 경우 리밸런싱에 대한 비용 발생</td><td id="?k`w" class="">일반적인 방식에서 부하 분산이 되지 않음</td></tr></tbody></table><p id="3e3d0441-ab99-4071-977e-cf9249de2ac9" class="">이번 개선에서 중점을 둔 포인트는 부하 분산이었고, 저희 서비스 환경을 고려하였을 때는 모듈러 샤딩이 적합하다고 판단하여 결정하게 되었습니다. 샤딩은 애플리케이션 레벨에서의 샤딩을 적용하였는데요. 적용한 방법은 다음과 같습니다.</p><h1 id="7cdd43ac-51be-4eb9-b461-72f885d12f07" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#1-%EB%9D%BC%EC%9A%B0%ED%8C%85-%EC%A0%95%EC%B1%85-%EB%A7%8C%EB%93%A4%EA%B8%B0">(1) 라우팅 정책 만들기</a></strong></h1><p id="7b76c61c-a64d-473f-b75f-e670fa766cba" class="">먼저, 샤딩을 적용하기 위해 물리적으로 분산된 데이터소스에 대해 동적으로 타깃 데이터소스를 변경하기 위한 방법으로 JDK에서 기본으로 제공하는 AbstractRoutingDataSource를 사용하였습니다. AbstractRoutingDataSource에서 제공하는 determineTargetDataSource 함수를 사용하면 커넥션을 획득하는 시점에 어떤 데이터소스에 대한 커넥션을 반환할 것인지에 대해 정책을 세울 수 있습니다. 이를 활용하여 샤딩을 위한 정보를 담고 있는 콘텍스트를 만들고 해당 콘텍스트의 정보에 기반하여 정책에 맞는 데이터소스의 커넥션을 반환하도록 하였습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="4c92ef1d-84b3-45d8-b65f-921e50344e4b" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">class RoutingDataSourceForSharding : AbstractRoutingDataSource() {    // ... (생략)    override fun determineCurrentLookupKey(): Any? {        /**         * 콘텍스트 내 샤딩 번호를 사용하여 Datasource Lookup 하도록 처리         */        return ShardingContextHolder.getContext()?.shardNo ?: defaultTargetDataSource    }    // ... (생략)}</code></pre><p id="c05c5b5b-efb7-40ca-8c89-c8f286134ff3" class="">이렇게 샤딩에 대한 정책을 세운 후에는 물리적으로 분산된 각 데이터소스를 위에서 정의한 데이터소스에 지정하였습니다. 이렇게 생성된 데이터소스를 LazyConnectionDataSourceProxy 타입의 DataSource 빈(Bean) 객체로 생성하여 데이터소스에 대한 반환을 커넥션 획득시점에 동적으로 가능하게 하였습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="cb22e587-571f-48d4-95a1-23e3ed2de5a4" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">    @Bean(name = [&quot;dataSourceForSharding&quot;])    fun dataSourceForSharding(        @Qualifier(&quot;dataSources&quot;) dataSources: List&lt;DataSource&gt;    ): DataSource {        // ... (생략)        shardedDataSource.setTargetDataSources(dataSources)        // ... (생략)        return LazyConnectionDataSourceProxy(shardedDataSource)    }</code></pre><h1 id="b4c14f92-8838-4c81-ab50-b952857dad75" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#2-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0">(2) 사용하기</a></strong></h1><p id="60c152be-dde9-4b4b-bf8f-de1eb2f2581f" class="">먼저, 샤딩 정책을 만드는 부분에서 샤딩을 위한 콘텍스트를 사용한다고 말씀드렸습니다. 그렇기 때문에 Repository 함수가 호출되기 전 해당 함수가 실행될 데이터소스에 대한 정보를 콘텍스트에 설정해주어야 합니다. 이를 위해 “Trailing Lambdas” 문법을 사용하여 Repository 실행 전/후에 Context를 설정하고 해지하도록 구현하였습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="60a825cf-be5c-403e-a481-b0aba4b5a991" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">    // ... (생략)    fun &lt;R : Any&gt; sharding(        shardKey: Int,        shardCount: Int,        block: () -&gt; R,    ): R {        ShardingContextHolder.setContext(key.mod(shardCount))        val result = block.invoke()        ShardingContextHolder.clear()        return result    }    // ... (생략)</code></pre><p id="9f5390e8-6ae8-4422-9a8f-5b25968f5129" class="">이렇게 생성한 함수를 Repository 함수를 사용하는 부분에 적용하여 샤딩 처리가 되도록 구현하였습니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8d4ceeab-fd12-495a-a3b3-9904cd433870" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">@Repositoryclass ProviderHistoryPersistenceAdapter(    private val sampleMessageRepository: SampleMessageRepository,) {    // ... (생략)    fun save(sampleMessage: SampleMessageDto) = sharding(sampleMessageDto.key, SHARD_COUNT) {        sampleMessageRepository.save(toEntity(sampleMessageDto))    }    // ... (생략)}</code></pre><p id="eb60a0b0-6daa-4cb1-b85c-8ffaf22a5996" class="">간단하게 예제 코드를 사용해서 애플리케이션 레벨에서의 샤딩을 구현한 방식을 소개드렸는데요. 이렇게 샤딩에 대한 정책을 설정하고, 콘텍스트에 있는 정보를 바탕으로 데이터소스를 획득 시점에 결정될 수 있도록 함으로써 최종적으로 데이터 분산을 적용할 수 있었습니다.</p><h1 id="cd5049da-8f67-4528-bb37-5ca78ed7e9bb" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#%EC%86%94%EB%A3%A8%EC%85%98-2-%ED%8C%8C%EC%9D%BC%EB%A1%9C-%EB%B0%B1%EC%97%85%ED%95%98%EA%B8%B0">솔루션 2, 파일로 백업하기</a></strong></h1><p id="2d5dacc4-a091-4dcb-84bb-e235f12784fe" class="">앞서 말씀드린 것처럼 관련법령 신용정보법에 의해 마이데이터 정보송수신 이력에 관한 데이터를 3년간 기록 보관해야 하는데요. 일반적인 DB의 용량 이슈로 대량으로 발생하는 이력성 데이터를 장기간 보관할 수 없는 문제를 해결하기 위해 별도 스토리지에 백업하는 방법을 도입하였습니다. 별도 스토리지는 세 종류 중 고민했습니다.</p><ol type="1" id="ee5c6730-36b6-469d-ae8f-4eeeb264ff6a" class="numbered-list" start="1"><li><strong>MongoDB</strong></li></ol><ol type="1" id="d24eafcc-a1e3-478b-904a-1daee0d6443d" class="numbered-list" start="2"><li><strong>Elasticsearch</strong></li></ol><ol type="1" id="cb61e552-93b7-46aa-88b1-784d44f58f04" class="numbered-list" start="3"><li><strong>File</strong></li></ol><table id="8aa26593-49aa-4583-8818-c6760e88524a" class="simple-table"><tbody><tr id="0f213032-477e-4173-8766-2646866ab9ed"><td id="sOa\" class=""></td><td id="[U?l" class=""><strong>MongoDB</strong></td><td id="wWB{" class=""><strong>Elasticsearch</strong></td><td id="agHI" class=""><strong>File</strong></td></tr><tr id="81059636-4bff-4541-a87e-5290709077d6"><td id="sOa\" class="">장점</td><td id="[U?l" class="">수평적 확장이 용이하고, 관련 부서의 지원으로 비교적으로 구성과 구현이 간단할 것으로 예상</td><td id="wWB{" class="">기존에 로그 데이터를 대용량으로 저장하는 사용 케이스가 있고, MongoDB와 마찬가지로 관련 부서의 지원을 받기 용이</td><td id="agHI" class="">스토리지를 구성하는데 비용이 합리적이고, 적재 대상 데이터의 특성에 적합</td></tr><tr id="690bbd70-36d3-4466-b2d4-3abe76180f34"><td id="sOa\" class="">단점</td><td id="[U?l" class="">라이선스 비용 발생</td><td id="wWB{" class="">라이선스 비용 발생</td><td id="agHI" class="">운영 지원이 어려운 환경</td></tr></tbody></table><p id="cc769815-f5f9-4a5f-a671-25f53420031a" class=""><strong>MongoDB</strong>, <strong>Elasticsearch</strong>의 경우 사내 여러 사용 케이스가 있고, 관련 부서의 지원을 받기 용이하다는 장점이 있었습니다. <strong>File</strong>의 경우 사내에서 제공하는 파일 적재 서비스는 없었지만, 스토리지를 구성하는데 비용이 합리적이고, 적재 대상 데이터의 특성에 알맞다는 장점이 있었습니다. 기존 구성되어 있는 인프라와 구현 편의성을 고려하였을 때, MongoDB나 Elasticsearch를 사용하는 것이 사내 지원을 받는 데 유리하다는 큰 장점이 있었습니다. 하지만 단순히 이력성 데이터를 저장하기 위한 목적으로 사용하기에는 두 저장소 모두 적합하지 않았습니다. 여러 장점을 상쇄시킬 만큼의 큰 라이선스 비용이 발생하고, 데이터 특성상 당장 조회가 필요하지 않았기 때문입니다. 그래서 이력성 데이터는 파일로 저장하는 것이 가장 적합하다고 판단했습니다.</p><h1 id="6509b2db-6ab1-42d4-8a85-d49d72b02c62" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#1-%ED%8C%8C%EC%9D%BC%EB%A1%9C-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0">(1) 파일로 저장하기</a></strong></h1><p id="ea57137b-6ba0-4892-ae25-a4c453acaca5" class="">정보송수신 이력 데이터의 경우 이미 메시지 브로커(카프카)와 RDB에 적재가 되고 있었기 때문에 기존에 존재하는 데이터 소스를 선택하여 파일로 저장하면 되는 상황이었습니다. RDB는 [<strong>솔루션 1, 데이터 분산 저장하기</strong>]에서 샤딩이 예정되어 있었습니다. 추가 확장 가능성을 고려하면 하나의 엔드 포인트에서 데이터를 가져오기 용이한 메시지 브로커가 적합하다고 판단하였습니다. 직접 메시지를 컨슘하는 서버 애플리케이션을 개발하는 방법도 고려해 봤습니다. 하지만 다양한 input/output 플러그인을 제공하여 데이터 파이프라인 구성에 적합한 오픈소스 <a href="https://www.elastic.co/kr/logstash">로그스태시</a>를 통해 파일로 저장하는 방법을 선택하였습니다.</p><figure id="1804615b-8c69-4981-b605-bc7e45cda96d" class="image"><a href="https://tech.kakaopay.com/_astro/logstash-architecture.2de39b3d_Z1TacJT.avif"><img src="https://tech.kakaopay.com/_astro/logstash-architecture.2de39b3d_Z1TacJT.avif"/></a></figure><p id="7941e4a3-73ed-4300-b0cf-ff936fa335ae" class="">추가로 파일 스토리지에 보관하는 아키텍처로 구성하였지만, 추후 데이터 로드가 필요하게 될 가능성을 대비하여 하둡과 같은 플랫폼에 로드하기 용이한 파일 포맷과 구조로 저장하였습니다.</p><h1 id="52ea1902-6460-4ea0-8842-cc83f2c6a82e" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#2-%EA%B3%A0%EA%B0%80%EC%9A%A9%EC%84%B1-%ED%99%95%EB%B3%B4">(2) 고가용성 확보</a></strong></h1><p id="a9f1206c-2cfb-41e4-87fd-b4d68ebac118" class=""><strong>(1) 파일로 저장하기</strong> 에서 선택한 방법으로 단일 구성한 아키텍처에서는 고가용성을 확보하기 어렵습니다. 이를 해결하기 위해 위 아키텍처를 컨테이너 오케스트레이션이 가능한 쿠버네티스 클러스터에 컨테이너 환경으로 운영할 수 있도록 구성하여 고가용성을 확보하였습니다.</p><figure id="f647b9ad-9eff-4f19-9c5e-6d3b92e42dd0" class="image"><a href="https://tech.kakaopay.com/_astro/mount-storage.b19c3569_ZJn1Jw.avif"><img src="https://tech.kakaopay.com/_astro/mount-storage.b19c3569_ZJn1Jw.avif"/></a></figure><p id="6ea36872-c016-4b24-8f54-ee28f2852b23" class="">관련법령으로 관리되는 이력 데이터인 만큼 파일 자체의 소실 가능성 또한 고려하여 파일 스토리지에 대한 백업을 구성하였습니다. 저장된 파일은 물리적으로 분리된 별도 스토리지에 싱크 작업을 수행하고, 주기적으로 파일 체크섬을 검사하여 동일한 상태의 파일로 백업할 수 있도록 구성하였습니다.</p><figure id="cc4d440c-bd7d-4981-8f2c-923124a0bee5" class="image"><a href="https://tech.kakaopay.com/_astro/sync-storage.04507153_ZzRIBW.avif"><img src="https://tech.kakaopay.com/_astro/sync-storage.04507153_ZzRIBW.avif"/></a></figure><h1 id="a3cf4164-c707-4ad5-a9a4-0ff2e15a536c" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#%EC%86%94%EB%A3%A8%EC%85%98-3-palsonic%EC%9C%BC%EB%A1%9C-%ED%86%B5%EA%B3%84%EB%82%B4%EA%B8%B0">솔루션 3, Palsonic으로 통계내기</a></strong></h1><p id="ae31da78-85a0-4a73-a3f3-42b119c35050" class="">먼저 통계 배치 수행 시간이 오래 걸리는 문제를 개선하기 위해 가장 문제가 되는 쿼리를 개선해보고자 했습니다. 통계 데이터 계산 쿼리의 가장 큰 문제는 많은 양의 데이터를 조회하여 연산하는 것이었습니다. 조회 데이터 양을 줄이기 위해 created_at이 아닌, requested_at을 사용하여 쿼리를 개선하려 했습니다. 그러나, 로그성 데이터 테이블은 created_at 기준으로 파티셔닝을 하고 있었기 때문에, created_at을 사용한 range scan이 그나마 최대의 성능을 낼 수 있는 방법이었습니다. created_at을 필수 조회 조건으로 하면서, 조회되는 데이터 양을 줄이기 위해 아래와 같은 방법을 고민했습니다.</p><ol type="1" id="77c6ff0a-2f21-4f71-8a66-c3eaf837c456" class="numbered-list" start="1"><li>정보제공기관자코드(org_code)를 순회하면서 배치를 수행하여 group by 제거</li></ol><ol type="1" id="885c4ebc-56aa-4a6d-8cf1-f25106217bdf" class="numbered-list" start="2"><li>created_at을 나눠서 조회</li></ol><figure id="9081ebbe-db25-4ebb-898a-1d789f4b0a2b" class="image"><a href="https://tech.kakaopay.com/_astro/data-range.83e1ac28_2t5QD3.avif"><img src="https://tech.kakaopay.com/_astro/data-range.83e1ac28_2t5QD3.avif"/></a></figure><p id="23f2d933-d871-4d88-a03d-b227021c9f0a" class="">이러한 방법으로 쿼리를 개선하면 조회되는 데이터의 크기가 줄어, 배치의 성능도 향상될 것이라 예상했습니다. 하지만 문제는 표준편차였습니다. 표준편차는 전체 데이터를 메모리에 가져와 계산을 해야 하는데, created_at을 나눠서 계산을 하면 구할 수 없었습니다. 더욱이, 위의 솔루션인 데이터 분산 저장을 하게 되면서 쿼리를 통해 통계 데이터를 얻는데 어려워졌습니다.</p><ol type="1" id="09ac55b6-437d-4020-987b-8948b68c192a" class="numbered-list" start="1"><li>DB부하</li></ol><ol type="1" id="116d07e0-7b46-4efc-90e6-a9dff549d4dd" class="numbered-list" start="2"><li>쿼리의 속도</li></ol><ol type="1" id="be5a383e-540d-4a82-8446-e2a442cf0cf9" class="numbered-list" start="3"><li>분산 저장된 데이터에 대한 통계 계산</li></ol><p id="798c1861-d939-4815-9f5a-93ffd2e61b5d" class="">위의 문제를 해결하기 위해, 분산 저장된 데이터에 대한 통계 계산을 수행하면서, 쿼리의 속도 향상과 DB 부하를 감소할 수 있는 솔루션 또는 서비스를 찾던 중 데이터팀에서 개발한 Palsonic을 추천받았습니다.</p><h3 id="5a10597e-c437-4480-97e2-2570b1bcd690" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#palsonic%EC%9D%B4%EB%9E%80">Palsonic이란?</a></strong></h3><p id="3ad8f3d7-bea8-4570-b5af-6b5f66988ea2" class="">카카오페이 데이터팀에서 만든 서비스로 여러 데이터소스에 연결하여 쿼리를 요청하고 하나의 뷰 형태로 결과를 볼 수 있는 쿼리 서비스입니다. Hive, Kudu, Mysql, Mongo, Redis, Kafka, ElasticSearch 등 다양한 저장소를 연결을 제공합니다. 서로 다른 스토리지의 데이터 SQL join이 가능하며, JDBC 인터페이스를 제공합니다. trino 엔진을 사용하여 분산(병렬) 쿼리를 사용해 방대한 데이터를 효율적으로 처리할 수 있습니다.</p><figure id="e9244d0c-5252-4db0-813f-8c3018c85526" class="image"><a href="https://tech.kakaopay.com/_astro/palsonic.77545a77_UJWzh.avif"><img src="https://tech.kakaopay.com/_astro/palsonic.77545a77_UJWzh.avif"/></a></figure><p id="a35bb4d8-ee3d-440c-9d32-222b99c11ef8" class="">Palsonic은 분산된 데이터에 대한 통계계산 쿼리를 수행할 수 있어, 위에 언급한 저희가 겪고 있는 문제를 해결할 수 있다고 생각했습니다. 또한 Spring Batch에서 JDBC Driver를 사용한 데이터 소스의 연결 대신 Palsonic 연결로 변경하면 되어, 기존의 코드를 수정하는 것이 거의 없었습니다. 그러나 기존 쿼리가 너무 무거웠고, 이를 DB를 연결하여 수행하다 보니, 쿼리 속도와 DB 부하를 드라마틱하게 개선하기는 어려웠습니다.</p><p id="fd4ae67b-b4b4-4a82-9341-c983c85afa06" class=""><strong>1차 개선 속도 지표</strong></p><figure id="aba6c3c8-7817-499e-b37c-b3be91d3a991" class="image"><a href="https://tech.kakaopay.com/_astro/graph-1.bdca4eab_Z16Ay9p.avif"><img src="https://tech.kakaopay.com/_astro/graph-1.bdca4eab_Z16Ay9p.avif"/></a></figure><p id="ab468f2a-67ec-4f2f-8e8b-d6878ee041b5" class="">다음으로, Palsonic에서 Hadoop에 연결하여 통계 데이터를 구하는 방법을 선택했습니다. Hadoop 사용은 DB를 연결하지 않아 DB부하를 없앨 수 있었고, 쿼리 속도를 크게 줄일 수 있었습니다. 또한, Hadoop에서는 Mydata의 데이터를 매일 ETL (Extract, Transform, Load)하고 있어, 분산 저장된 데이터에 대한 계산도 문제가 되지 않았습니다. Spring Batch 코드도 Palsonic에서의 Hadoop 테이블명만 바꿔주면 되었기 때문에 수정할 필요가 거의 없었습니다.</p><p id="7c1b7e82-cffc-4fa7-afac-35a2591f8c99" class=""><strong>2차 개선 속도 지표</strong></p><figure id="c9e985f6-4377-49cc-b455-b0be4a47db17" class="image"><a href="https://tech.kakaopay.com/_astro/graph-2.fbcda107_1old1R.avif"><img src="https://tech.kakaopay.com/_astro/graph-2.fbcda107_1old1R.avif"/></a></figure><p id="e1be778a-9619-47d4-8446-72c6ab209984" class="">도입 결과, 위와 같은 드라마틱한 속도개선을 할 수 있었고, DB부하도 없앨 수 있었습니다.</p><h1 id="e9382374-ea18-4189-bff3-b1514467b4bd" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#%EB%A7%88%EC%B9%98%EB%A9%B0">마치며</a></strong></h1><h1 id="12785b21-6c9e-4abd-8649-fe9a7090b9de" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#ryukee">ryuke.e</a></strong></h1><p id="d2541b63-6b43-4afa-9331-262d42dadd3a" class="">배치 개선 과정을 글에 다 적지는 못했지만, 쿼리 분석 및 배치 성능 개선을 시도하며 많은 경험을 할 수 있었습니다. 또한 기존 서비스가 아닌 다른 서비스를 사용하며 새로운 경험을 할 수 있었고, 문제를 해결할 때 레거시 내부에서만 해결해야 한다는 생각에서 벗어날 수 있었습니다.</p><h1 id="d869d36f-48fd-431a-8e35-970e010f6fe4" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#luffydmonkey">luffy.dmonkey</a></strong></h1><p id="7b284cac-1163-49c3-b622-43dd997ffe69" class="">데이터 보관 이슈를 처리하면서 기술적인 부분 이외에도 금융 관련 도메인 특성상 법적 요건 충족을 위한 여러 제약이 있는 상황에서 현재 선택 가능한 방법을 고민하고, 그중에서도 가장 적합한 방법을 선택하는 것이 중요하다는 것을 배울 수 있는 기회였습니다.</p><h1 id="f5525b1a-4226-4bd4-a08a-bdd6535addfe" class=""><strong><a href="https://tech.kakaopay.com/post/mydata-platfrom-improvement/#kroosk">kroos.k</a></strong></h1><p id="0454b70d-84a5-4ebf-b23f-bfc025a1e9c7" class="">이번 개선 작업을 통해 기존 시스템 문제를 바탕으로 해결책들을 나열하고 장/단점을 비교하면서 현 상황에 적합한 방안을 도입하기 위해 고민하고 적용까지 해 볼 수 있는 기회였던 것 같습니다. 문제에 대한 접근 방식과 의사 결정 과정을 경험해 볼 수 있어 좋은 기회였다고 생각합니다.</p><figure id="e7d1ba59-2898-448b-9878-52d7bfa61b0e" class="image"><a href="https://tech.kakaopay.com/_astro/kroos_k.27c520ce_1frkjG.avif"><img style="width:78px" src="https://tech.kakaopay.com/_astro/kroos_k.27c520ce_1frkjG.avif"/></a></figure></details></li></ul><ul id="0aa7bdc5-c2f8-4303-b484-ec66e214bc8e" class="toggle"><li><details open=""><summary>11번가 - 심볼릭 링크로 스프링 배치 무중단 배포하기</summary><p id="bc6d83b6-25e6-4448-ac72-07173433a639" class="">팀 배치 서버에서 한 가지 문제를 발견하게 되었습니다.</p><p id="ba43203d-7bb6-495c-8e3a-a3234bf0d41b" class="">Job 수행을 위해 jar 파일을 실행하는 도중 배포가 진행될 경우, <strong>jar 파일이 변경(업데이트, 제거)되면서 에러가 발생</strong>하는 문제입니다.</p><p id="7e73e51c-160a-4f11-a2af-2a8c19156b2f" class="">이러한 이슈를 해결하기 위해 스프링 배치 무중단 배포를 적용하게 된 과정을 공유해 드리고자 합니다.</p><h1 id="1815749b-c695-4a2e-897d-85f2f7e66541" class=""><strong>문제 상황</strong></h1><p id="fed71016-8808-4122-8d2d-e93c3bf2949b" class="">아래와 같은 상황에 처하게 되면 <code>java.lang.NoClassDefFoundError</code> 또는 <code>java.lang.ClassNotFoundException</code> 예외가 터지면서 비정상적으로 배치가 실패하거나 중단되는 현상이 발생하였습니다.</p><ul id="12308cf6-b117-4e15-ac9a-7f5d8aca7b67" class="bulleted-list"><li style="list-style-type:disc">Job 실행 중일 때 배포 진행</li></ul><ul id="5c62f542-2afd-43b1-8bff-f4288d64af77" class="bulleted-list"><li style="list-style-type:disc">빌드&amp;배포 중일 때 Job 실행</li></ul><p id="a89f6d48-444e-4a90-8bfb-2356658c9b66" class="">마주했던 문제의 로그 일부입니다.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="4ad0fc31-7c22-4bc0-a875-aef1c18964f6" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">Exception in thread &quot;main&quot; java.lang.reflect.InvocationTargetException
...
Caused by: java.lang.NoClassDefFoundError: ch/qos/logback/classic/spi/ThrowableProxy
...
Exception in thread &quot;SpringApplicationShutdownHook&quot; java.lang.NoClassDefFoundError: ch/qos/logback/classic/spi/ThrowableProxy

...</code></pre><p id="7f8ae5e9-6cff-4f8a-825a-f5b1ccfef5c5" class="">이제 열심히 서칭해야 할 시간입니다.</p><p id="6fd25d65-5151-4d33-b8e5-b4ae13fd3d89" class="">출처: https://medium.com/rta902/kermit-the-frog-from-muppets-to-memes-f6fea5be3cf1</p><p id="9230b00b-07aa-4027-aa1f-fab4c53a98c3" class=""><a href="https://stackoverflow.com/questions/32477145/java-lang-classnotfoundexception-ch-qos-logback-classic-spi-throwableproxy">stack overflow</a> 에서 유사한 사례를 발견하게 되었는데, 서론에서 언급했듯이 Job 수행을 위해 jar 파일을 실행하는 도중 배포가 진행될 경우, <strong>jar 파일이 변경(업데이트, 제거)되면서 에러가 발생</strong>한다는 것을 알게 되었습니다.</p><hr id="3fb8c252-b157-454d-bf66-44a08b9a392b"/><h1 id="bb2495d3-b47b-46ab-845d-1a9b87b8664a" class=""><strong>기존 배포 방식</strong></h1><p id="002911b1-2577-4d01-ad72-005f3e0d7a24" class="">개선 방법을 공유하기 전에 팀 배치 서버의 배포 방식을 간단하게 소개하고 가면 좋을 것 같습니다.</p><blockquote id="9aa379c5-86c7-49be-b6c1-1ee7fb37c03a" class="">1) 빌드&amp;배포<ul id="276e0fa7-598a-4b35-ae26-c34bb1795a65" class="bulleted-list"><li style="list-style-type:disc">클레임개발팀의 배치 서버 빌드, 배포는 <strong>사내 배포 시스템</strong>을 사용하고 있습니다.</li></ul><ul id="45b767af-4ecc-4436-a51c-c3648edfe08f" class="bulleted-list"><li style="list-style-type:disc">사내 배포 시스템을 통해 <strong>특정 브랜치를 빌드</strong>하고, <strong>특정 경로(Deploy Path)에 빌드된 파일을 배포</strong>하게 됩니다.</li></ul><p id="5deb3d90-6e71-4975-83f5-c14cf0fe6254" class=""><strong>2) Job 실행</strong></p><ul id="57fb371e-46ef-44c7-be0f-c7f78ba89a7f" class="bulleted-list"><li style="list-style-type:disc">Jenkins 툴의 <code>Build periodically &gt; Schedule</code> 설정에 따라 주기적으로 <code>Execute Shell</code> 명령으로 Job을 실행시키고 있습니다.</li></ul><figure id="2546b797-260e-4d50-a9dc-0209629e1571" class="image"><a href="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image01.png"><img src="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image01.png"/></a></figure></blockquote><p id="1610d69d-e5b7-4268-a02b-ab2a5e2313ab" class=""><code>run_job.sh</code> 파일을 살짝 보면 단순하게 <code>Execute Shell</code> 에 명시된 jobName, jobParameter 정보를 가져와서 Job을 실행하는 역할을 하고 있습니다.</p><p id="9db7aecc-b700-4bd2-921e-b75822cef8f5" class=""><strong>/app/batch/shell/run_job.sh</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="464e6242-7e0f-4e2b-9d86-f4318bdf6d64" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">#!/bin/bash

# Read jobName, jobParameter
jobName=$1
jobParameters=&quot;&quot;
args=(&quot;$@&quot;)
for arg in &quot;$@&quot;; do
  if [[ $arg == $1 ]]; then
    continue
  fi
  jobParameters+=&quot; $arg&quot;
done

# Run batch job
PROFILE=&quot;prod&quot;
JAVA_OPTS=&quot;-Xms512m -Xmx1024m&quot;
$JAVA_HOME/bin/java -jar -Dspring.profiles.active=$PROFILE /app/deploy/batch/batch-0.0.1-SNAPSHOT.jar $JAVA_OPTS --job.name=$jobName $jobParameters</code></pre><hr id="ceb9fb17-76d1-47e1-9b18-b3adf7a37e70"/><h1 id="aa14decb-fe37-4a08-8ff5-a6605f78f55f" class=""><strong>아이디어</strong></h1><p id="dec47bf0-647d-4823-a85e-94f9e9125e49" class="">본론으로 돌아와서, 기존 배포 방식에서 어떤 아이디어로 개선을 진행하게 되었는지 살펴보겠습니다.</p><p id="67b346a1-4c7e-46d6-ba3a-8d5955df6cf4" class="">스프링 배치 무중단 배포는 <strong>심볼릭 링크</strong>를 활용하였습니다.</p><p id="be501e46-e2f3-4d89-b11e-ed37e49d7cae" class="">(심볼릭 링크 아이디어는 향로님의 <a href="https://jojoldu.tistory.com/445">Spring Batch 공통 설정 관리하기</a> 글을 읽으면서 얻게 되었습니다.)</p><p id="0a61f3cb-f388-49c3-8631-e78f057d9c18" class="">사내 배포 시스템을 사용하다 보니 빌드&amp;배포는 기존 방식과 동일하고 <strong>배포 이후</strong>와 <strong>Job 실행</strong> 단계에 심볼릭 링크를 활용하여 스프링 배치 무중단 배포를 적용하는 전략을 세우게 되었습니다.</p><blockquote id="3b150408-8cbe-4620-83a5-7b2cfe7d13fa" class="">1) 빌드&amp;배포 (기존 방식과 동일)<ul id="7330a682-f60f-427d-8006-3a6989108d87" class="bulleted-list"><li style="list-style-type:disc">사내 배포 시스템을 통해 <strong>특정 브랜치를 빌드</strong>하고, <strong>Deploy Path에 빌드된 파일 배포</strong>하기.</li></ul><p id="0cb1289e-19b9-4fc0-94cf-09982c3da1cb" class=""><strong>2) 배포 이후 단계</strong></p><ul id="0b470117-03a4-43aa-bfa3-6ea93b1a2bad" class="bulleted-list"><li style="list-style-type:disc">Deploy Path에 배포된 jar 파일을 <strong>새로운 디렉토리로 복사</strong>하기.</li></ul><ul id="b8be4749-bf00-4ef2-83af-23b739f20a33" class="bulleted-list"><li style="list-style-type:disc">기존 링크를 해제하고 <strong>새로운 디렉토리 경로에 복사된 jar 파일로 링크 연결</strong>하기.</li></ul><p id="4b05a8f4-b9b1-4f8a-be54-77b6732f8af6" class=""><strong>3) Job 실행 단계</strong></p><ul id="567eed40-d38f-42b1-a10d-442700b6c72a" class="bulleted-list"><li style="list-style-type:disc">심볼릭 링크가 연결되어 있는 원본 파일명을 가져오는 <strong>readlink 명령어를 활용하여 새로 배포된 jar 파일로 Job 실행</strong>하기</li></ul><ul id="36739312-d533-4a5d-830e-34e5a35be289" class="bulleted-list"><li style="list-style-type:disc"><strong>기존 jar 파일은 변경(업데이트, 제거)되지 않고 유지</strong>되므로 문제의 상황 해결 기대</li></ul></blockquote><p id="c6657af2-6a6a-4148-a0db-e11621f09097" class="">Idea</p><figure id="12c2ddf2-bc62-437d-b8e2-756f015fe495" class="image"><a href="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image05.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image05.png"/></a></figure><hr id="915a71ae-c528-43a2-b646-89622afcf621"/><h1 id="cee0e018-d5dc-4305-aaf6-e564fa7fa91d" class=""><strong>Symbolic link</strong></h1><p id="a1aadd44-bb09-4860-8f81-f57c74ed5c35" class="">리눅스에서 <a href="https://www.ibm.com/docs/en/aix/7.2?topic=l-ln-command">ln</a> 커맨드는 파일/디렉토리 링크를 생성하는 기능을 가지고 있습니다.</p><p id="4ddd11d0-bded-467c-9ec6-c67f891b7c48" class="">기본적으로 <code>ln</code> 커맨드는 하드 링크(Hard Link)를 생성하고, <code>-s</code> 옵션으로 심볼릭 링크(Symbolic Link, Soft Link)를 생성할 수 있습니다.</p><p id="514b020a-a90c-4f2f-8191-f8715969c540" class=""><code>ln [ -s ] [대상 파일/디렉토리 경로] [링크 파일/디렉토리 경로]</code></p><p id="d654ba94-2f80-4a95-9ebc-3d789a2ded05" class="">하드 링크와 심볼릭 링크를 간략하게 살펴보겠습니다.</p><blockquote id="4633ec86-5d20-44f4-b21c-7a97fe25b01a" class="">심볼릭 링크<ul id="8edc03ee-512b-41d7-b6d6-fcd1f1c3635c" class="bulleted-list"><li style="list-style-type:disc">윈도우의 바로가기와 유사한 기능</li></ul><ul id="d5083e26-7750-47e1-9e93-7efa8bae414c" class="bulleted-list"><li style="list-style-type:disc">링크 파일은 대상 파일에 대한 참조를 가지고 있어서 링크 파일을 대상 파일처럼 사용 가능</li></ul><ul id="a16a16fa-d3a4-4d88-bcf4-84b93e907d83" class="bulleted-list"><li style="list-style-type:disc">대상 파일이 삭제될 경우 링크 파일 사용 불가</li></ul><p id="616942ca-ef3d-449f-9ec8-bcf6b1deef54" class=""><strong>하드 링크</strong></p><ul id="7633c608-8525-4db7-920d-0cf253ef5141" class="bulleted-list"><li style="list-style-type:disc">파일 복사와 유사한 개념</li></ul><ul id="14f836dd-88be-48e9-bb7f-9f9156719815" class="bulleted-list"><li style="list-style-type:disc">원본 파일과 동일한 inode</li></ul><ul id="6791f6c3-41fb-4b26-8471-965a871ac6a4" class="bulleted-list"><li style="list-style-type:disc">원본 파일이 삭제되어도 링크 파일 사용 가능</li></ul></blockquote><p id="5f132b23-69ac-496d-ba34-b748409b1a41" class="">심볼릭 링크도 간략히 알아보았으니 이제 적용해 보겠습니다.</p><hr id="54c0e6a3-1520-40df-a83b-393d84bcb77e"/><h1 id="085116e0-2eba-44f2-9ada-4b89ce2c528c" class=""><strong>적용</strong></h1><h3 id="d3d58f17-4258-492a-a7f8-effae4e0ab4e" class=""><strong>배포 이후 단계</strong></h3><p id="5a20fbc2-fe25-4188-ae9a-9e5e50d50997" class=""><strong>switch-link.sh</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="7e37182d-1247-49ec-932e-19412d0f7060" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">#!/bin/bash

DEPLOY_PATH=/app/deploy/batch
DIRECTORY_NAME=batch-$(/bin/date +%Y%m%d%H%M%S)
# 1) 새로운 디렉토리 생성
mkdir /app/deploy/batch/${DIRECTORY_NAME}
# Deploy Path에 배포된 jar 파일을 새로운 디렉토리로 복사하기.
cp -f ${DEPLOY_PATH}/batch-0.0.1-SNAPSHOT.jar ${DEPLOY_PATH}/${DIRECTORY_NAME}/ 

echo &quot;&gt; $DIRECTORY_NAME Directory has been created.&quot;
echo &quot;&gt; new jar file was copied to a new directory.&quot;

BEFORE_JAR_PATH=$(readlink /app/batch/shell/application.jar)
# 2) 새로운 디렉토리 경로에 복사된 jar 파일로 링크 변경하기.
ln -Tfs ${DEPLOY_PATH}/${DIRECTORY_NAME}/batch-0.0.1-SNAPSHOT.jar /app/batch/shell/application.jar

echo &quot;&gt; Link switched from $BEFORE_JAR_PATH to $DEPLOY_PATH/$DIRECTORY_NAME.&quot;

# 이후 추가될 쉘 파일
sh /app/batch/shell/remove-old-directories.sh</code></pre><p id="8fe812eb-20f5-4a71-b8e9-25726d901f35" class="">참고 1. 새로운 디렉토리 생성</p><blockquote id="5b18d250-10bc-43d2-8164-5a1934683711" class="">mkdir batch-$(/bin/date +%Y%m%d%H%M%S) 명령으로 아래와 같이 날짜 정보로 디렉토리를 생성할 수 있습니다.<figure id="dceb6fbd-4265-44fe-b6ae-bf7fba4e74f4" class="image"><a href="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image02.png"><img src="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image02.png"/></a></figure></blockquote><p id="d204b67c-1294-42a6-91ef-9e7d33940f64" class="">참고 2. 심볼릭 링크 변경</p><blockquote id="eadc584c-b36e-42f0-b584-8ec3b75f91a9" class="">ln -Tfs TARGET LINK 명령으로 링크를 변경할 수 있습니다.<ul id="5afbf898-f79a-4379-a5a2-24dd093189ad" class="bulleted-list"><li style="list-style-type:disc"><code>T option</code>: –no-target-directory treat LINK_NAME as a normal file<ul id="920213e3-8187-42d1-8625-dc5619e0eb8e" class="bulleted-list"><li style="list-style-type:circle">링크 파일을 일반 파일처럼 다루는 옵션</li></ul></li></ul><ul id="d64c20e0-750c-4e9d-8440-e2ad5557f65f" class="bulleted-list"><li style="list-style-type:disc"><code>f option</code>: –force remove existing destination files<ul id="38419982-ae81-46fc-b40b-80b8e5618904" class="bulleted-list"><li style="list-style-type:circle">심볼릭 링크가 이미 존재할 경우 덮어쓰는 옵션</li></ul></li></ul><ul id="2eac619b-1945-42d5-aa18-700748a53c4a" class="bulleted-list"><li style="list-style-type:disc"><code>s option</code>: –symbolic make symbolic links instead of hard links<ul id="43eb3e20-9671-4e3d-8b98-038dff7ddf95" class="bulleted-list"><li style="list-style-type:circle">심볼릭 링크 파일 생성 옵션</li></ul></li></ul></blockquote><p id="67997d10-39be-49be-91b8-342088a9ce4f" class="">참고 3. 실행 결과</p><blockquote id="d700481c-5680-4b91-b14a-ad727f28e075" class="">./switch-link.sh 명령으로 위에 작성한 쉘 파일을 실행해 보면 아래와 같이 디렉토리 생성, jar 파일 복사, 링크 스위칭이 정상적으로 동작하는 것을 확인할 수 있습니다.<figure id="3ab8402c-ac52-4ed0-875e-492bbc51da62" class="image"><a href="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image03.png"><img src="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image03.png"/></a></figure></blockquote><p id="067ceace-8b1d-4ccc-ac8e-e58b21b45c6d" class="">…</p><p id="28bba46a-bab4-4730-b669-9f33f134e076" class="">여기서 잠깐! ✋🏼</p><p id="90a6260d-0d12-45b8-9273-9cc4d51e9984" class="">배포할 때마다 새로운 디렉토리와 jar 파일이 계속 쌓이게 될 텐데요.</p><p id="6899c180-2a5f-490d-b37d-3190cbd42218" class="">계속 생성되는 jar 파일로 서버 용량이 초과하는 문제를 방지하기 위해 최근 배포된 10개의 디렉토리만 남기고 전부 삭제해 주려고 합니다.</p><p id="d344e78d-a182-452e-a470-da73ae4a7c33" class=""><strong>remove-old-directories.sh</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="f4df1c22-81cb-4320-97b2-d7c5f3fc8674" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">#!/bin/bash

# 1) 배포 경로에 생성된 디렉토리 개수
DIRECTORY_COUNT=$(ls -d /app/deploy/batch/*/ | wc -l)

# 디렉토리가 10개보다 많이 존재할 경우
if [ $DIRECTORY_COUNT -gt 10 ]
then
  # 2) 제거할 디렉토리 개수 카운트
  REMOVE_TARGET_COUNT=$(( ${DIRECTORY_COUNT} - 10))
  # 3) 오래된 디렉토리부터 제거할 디렉토리 개수만큼 추출
  REMOVE_TARGET_LIST=$(ls -dltr /app/deploy/batch/*/ | head -$REMOVE_TARGET_COUNT | awk &#x27;{print $9}&#x27;)

  # 제거 대상 디렉토리 제거
  for file in ${REMOVE_TARGET_LIST}
  do
    echo &quot;remove $file&quot;
    /usr/bin/rm -rf ${file}
  done
fi</code></pre><p id="33ba66d2-a4b3-4e73-b95b-2d88f51952f0" class="">흐름은 아래와 같습니다.</p><blockquote id="118ccd1f-7013-49e4-ac1e-893439b72b10" class="">1) 배포 경로에 존재하는 디렉토리(jar 파일이 담긴) 개수 카운팅<p id="2ec77f47-c0be-4fce-b7e0-86053a0b1941" class="">2) 10개의 디렉토리를 제외하고 제거할 디렉토리의 개수 카운팅</p><p id="0f6ae5eb-55d4-4bc3-8977-ab40b7814534" class="">3) 제거할 디렉토리 목록 추출</p><ul id="fe4c82ac-0a76-4e5d-ba5c-4db9503f8c55" class="bulleted-list"><li style="list-style-type:disc">오래된 순으로 제거하기 위해 ls 명령어의 <code>t</code>, <code>r</code> 옵션 사용</li></ul><ul id="72e78f90-048b-460c-a75b-a74c0a6b24ae" class="bulleted-list"><li style="list-style-type:disc"><code>t option</code>: 파일과 디렉토리를 최근 시간 기준 내림차순 정렬</li></ul><ul id="54958719-912e-4881-a766-0d61ca7841cd" class="bulleted-list"><li style="list-style-type:disc"><code>r option</code>: 정렬된 데이터의 순서를 오름차순으로</li></ul></blockquote><p id="6b564a8d-6220-442f-aab8-58a654b2f23b" class="">위에서 생성한 <code>remove-old-directories.sh</code> 파일을 실행하기 전과 후를 비교해 보면 최근 10개의 디렉토리를 제외한, 오래된 디렉토리들이 삭제된 것을 확인할 수 있습니다.</p><p id="7b7b010f-2cfb-4182-9be9-6ba6c7aab577" class="">Result Execute Shell</p><figure id="51636c67-066a-4afa-ba1f-2a046636a5dc" class="image"><a href="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image04.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image04.png"/></a></figure><p id="dc3e219d-3921-481a-90eb-defc768fe98a" class="">배포 이후 <strong>remove-old-directories.sh</strong> 쉘도 동작할 수 있도록 <strong>switch-link.sh</strong> 쉘 마지막 줄에 실행 커맨드를 추가해 줍니다.</p><p id="b46a9f42-a4d7-40ee-89a4-0fcec904a9b7" class=""><code>sh /app/batch/shell/remove-old-directories.sh</code></p><p id="2b6f5476-7ee1-490e-861f-2b9bf13f7b11" class="">이제 마지막으로 Job 실행 단계만 남았습니다.</p><h3 id="b13335ff-3d64-42bc-911d-5fd6024678df" class=""><strong>Job 실행 단계</strong></h3><p id="3c5b720a-df87-4083-a6d0-14bdb48fe6c9" class="">Jenkins Execute Shell</p><figure id="dbd86a17-2d22-4b6d-8426-1a505e54759b" class="image"><a href="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image01.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image01.png"/></a></figure><p id="5fb298bd-6294-41d1-8992-07143e3b21d9" class=""><code>Jenkins Execute Shell</code>에서 입력된 jobName, jobParameter를 읽는 부분은 기존과 동일하고,</p><p id="f9a0934a-fb02-4b64-911c-0cbc97200194" class="">readlink 명령어만 추가해 주면 심볼릭 링크가 연결되어 있는 jar 파일 경로를 가져올 수 있게 됩니다.</p><p id="5615f9e2-1022-413c-a9c8-b35a9e90a551" class=""><strong>/app/batch/shell/run_job.sh</strong></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="b075b836-fae2-47c1-9e4d-4bf988994dd0" class="code"><code class="language-Java" style="white-space:pre-wrap;word-break:break-all">#!/bin/bash

# Read jobName, jobParameter
jobName=$1
jobParameters=&quot;&quot;
args=(&quot;$@&quot;)
for arg in &quot;$@&quot;; do
  if [[ $arg == $1 ]]; then
    continue
  fi
  jobParameters+=&quot; $arg&quot;
done

# Run batch job
PROFILE=&quot;prod&quot;
JAVA_OPTS=&quot;-Xms512m -Xmx1024m&quot;
# 심볼릭 링크가 연결되어 있는 jar 파일 경로 가져오기
ORIGIN_JAR=$(readlink /app/batch/shell/application.jar)

echo &quot;&gt; ORIGIN_JAR_PATH: ${ORIGIN_JAR}&quot;

$JAVA_HOME/bin/java -jar -Dspring.profiles.active=$PROFILE ${ORIGIN_JAR} $JAVA_OPTS --job.name=$jobName $jobParameters</code></pre><h3 id="ceb38a1f-66eb-49d8-aee0-247d45ef4872" class=""><strong>적용 결과</strong></h3><p id="6145410c-b01f-4f07-adb5-510b685385a1" class="">Jenkins Execute Shell</p><figure id="cf990609-5c16-4638-90d2-d02cfa2699b0" class="image"><a href="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image06.png"><img style="width:700px" src="https://11st-tech.github.io/files/post/2023-12-11-spring-batch-non-stop-deploy/image06.png"/></a></figure><blockquote id="a3d0e31c-8a9e-4841-b5d9-6f05489e8d03" class="">1) 배포된 jar 파일을 보관해 둘 디렉토리 생성<p id="8059d75b-fbf2-427e-8228-3d05d3f19c0c" class="">2) 생성한 디렉토리에 배포된 jar 파일 복사</p><p id="c27c9f19-52ae-4e50-a2bb-72f668060b1c" class="">3) 심볼릭 링크를 배포된 jar 파일 경로로 스위칭</p><p id="76b46f8d-a3ae-41f6-bada-80fb6fa8c1cd" class="">4) jar 파일이 담긴 오래된 디렉토리 제거</p></blockquote><hr id="de1aeaf7-b237-456d-a8a5-c3a63511b65f"/><h1 id="5370dacb-ce32-45f4-b3a8-b983d12a530a" class=""><strong>마무리</strong></h1><p id="bc8b3b3d-d12a-4b90-b41f-55c668c2491e" class="">심블릭 링크를 활용하여 스프링 배치 무중단 배포를 적용하면서 쉘 스크립트와 장난도 치면서 즐겁고 유익한 시간을 가질 수 있었습니다.</p><p id="146c3c05-7d51-4774-b484-dd7edbb392e5" class="">나름의 여러 고민과 탐색 끝에 적용한 방식이지만, 분명 더 좋은 개선 방법도 있을 것으로 생각합니다.</p><p id="e47b054c-e84d-44f7-8708-443162dbe641" class="">읽으시면서 궁금하신 사항이나 개선 사항이 있다면 언제든 아래 코멘트 부탁드립니다.</p><p id="87af36f0-95b0-42f7-a1d0-36f6814b6e4c" class="">글을 읽어주신 모든 분께 감사드립니다. 🙇🏻</p><p id="97aba36a-caea-4ae3-910e-565d6a39851f" class="">‍</p><figure id="f13a486f-8cf8-4d75-9db9-538f3e539717"><a href="https://11st-tech.github.io/2023/12/11/spring-batch-non-stop-deploy/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">심볼릭 링크로 스프링 배치 무중단 배포하기 | 11번가 TechBlog — 11번가 기술블로그</div><div class="bookmark-description">안녕하세요. 11번가 클레임개발팀 박지훈입니다. 11번가에서는 전사 배치 서버가 있고, 각 팀별로 팀 전용 배치 서버를 추가로 관리하기도 합니다. (최종 목표는 모든 팀이 함께 관리하는 레거시 배치를 각 팀 전용 배치로 이관하는 것입니다.) 클레임개발팀에서는 한 대의 서버로 운영되는 팀 배치 서버를 추가로 관리하고 있고, Spring Batch Job(이하 Job) 스케줄러는 Jenkins 툴을 사용하여 Job 들을 주기적으로 실행시켜 주고 있습니다. 평화롭던 어느 날..🌞 팀 배치 서버에서 한 가지 문제를 발견하게 되었습니다. Job 수행을 위해 jar 파일을 실행하는 도중...</div></div><div class="bookmark-href"><img src="https://11st-tech.github.io/assets/apple-touch-icon.png" class="icon bookmark-icon"/>https://11st-tech.github.io/2023/12/11/spring-batch-non-stop-deploy/</div></div><img src="https://11st-tech.github.io/assets/images/og_image.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="1493a4cc-090a-805b-aac3-da99b08e2ff8" class="toggle"><li><details open=""><summary>대규모 시스템 Observability 설계</summary><ul id="1493a4cc-090a-80f0-bc20-ee87ae05a046" class="bulleted-list"><li style="list-style-type:disc"><strong>다중 클러스터 설계는 확장성과 가용성을 극대화</strong>하기 위한 필수적인 방법론<ul id="1493a4cc-090a-80c2-9d8e-ca5de83ecf35" class="bulleted-list"><li style="list-style-type:circle">고객 테넌트별 수집 데이터를 각각 별도의 클러스터에 배치</li></ul><ul id="1493a4cc-090a-80af-94e8-e5dbab41ddd0" class="bulleted-list"><li style="list-style-type:circle">단일 클러스터의 부하 감소</li></ul><ul id="1493a4cc-090a-80c5-a575-e9abb4d07033" class="bulleted-list"><li style="list-style-type:circle">클러스터 내 읽기/쓰기 부하 분리로 성능 최적화</li></ul></li></ul><p id="1493a4cc-090a-80c6-a27c-d302c458a356" class="">
</p><p id="1493a4cc-090a-80a2-a08d-d57a51fece5a" class="">대규모 확장 가능한 <strong>Public Cloud 서비스의 메트릭, 로그, 트레이스 데이터 수집 및 처리 시스템</strong> 설계는 고성능, 확장성, 안정성을 중심으로 설계해야 합니다. 아래는 이를 구현하기 위한 전체적인 시스템 아키텍처와 기술 스택을 설명합니다.</p><hr id="1493a4cc-090a-80d4-837f-d296853d01b5"/><h2 id="1493a4cc-090a-8007-9572-d6b6c684b2bd" class=""><strong>1. 시스템 설계 목표</strong></h2><ul id="1493a4cc-090a-806b-b349-cb903655928b" class="bulleted-list"><li style="list-style-type:disc"><strong>확장성</strong>: 대용량 데이터 처리 및 수평 확장 지원.</li></ul><ul id="1493a4cc-090a-80a6-8ea8-f7e1cd2c91f0" class="bulleted-list"><li style="list-style-type:disc"><strong>성능</strong>: 실시간 처리 및 낮은 대기 시간 확보.</li></ul><ul id="1493a4cc-090a-80c9-b158-e2adae8156a9" class="bulleted-list"><li style="list-style-type:disc"><strong>가용성</strong>: 장애 발생 시에도 서비스 연속성 유지.</li></ul><ul id="1493a4cc-090a-807f-94dd-fe86cec245e0" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 통합</strong>: 메트릭, 로그, 트레이스 데이터를 통합 관리.</li></ul><ul id="1493a4cc-090a-8037-928c-ed693f8a0e92" class="bulleted-list"><li style="list-style-type:disc"><strong>분석 및 시각화</strong>: 데이터 기반 실시간 분석 및 대시보드 제공.</li></ul><hr id="1493a4cc-090a-8086-bdfd-fdf3d556ce93"/><h2 id="1493a4cc-090a-8070-861a-ef39a6afecb5" class=""><strong>2. 시스템 아키텍처</strong></h2><h3 id="1493a4cc-090a-80f9-ba38-d0a75d0d9e85" class=""><strong>2-1. 주요 구성 요소</strong></h3><ol type="1" id="1493a4cc-090a-80f8-be1d-f3d16ff91014" class="numbered-list" start="1"><li><strong>데이터 수집 계층</strong><ul id="1493a4cc-090a-80f6-8149-ff3863803fd8" class="bulleted-list"><li style="list-style-type:disc"><strong>수집 대상</strong>: 애플리케이션 로그, 시스템 메트릭, 트레이스 데이터.</li></ul><ul id="1493a4cc-090a-802e-8590-e26414de3f9f" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: OpenTelemetry, Fluentd/Fluent Bit, Filebeat, Metricbeat.</li></ul></li></ol><ol type="1" id="1493a4cc-090a-804d-b192-dd9aa5029d39" class="numbered-list" start="2"><li><strong>데이터 스트리밍 및 처리 계층</strong><ul id="1493a4cc-090a-8009-8448-ef4f6a3626fd" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 수집된 데이터를 버퍼링하고, 스트림 처리 또는 배치 처리.</li></ul><ul id="1493a4cc-090a-80e9-ad6d-c9969a0538cf" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: Apache Kafka, Amazon Kinesis, Google Pub/Sub.</li></ul></li></ol><ol type="1" id="1493a4cc-090a-80e0-a5e4-e08ec2372ba9" class="numbered-list" start="3"><li><strong>데이터 처리 및 변환 계층</strong><ul id="1493a4cc-090a-80fc-849c-f148db73b846" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 데이터 필터링, 변환, 집계.</li></ul><ul id="1493a4cc-090a-8023-9f16-e7329619c26c" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: Apache Flink, Apache Spark Streaming, Logstash.</li></ul></li></ol><ol type="1" id="1493a4cc-090a-809c-b860-f058eb011cb8" class="numbered-list" start="4"><li><strong>데이터 저장 계층</strong><ul id="1493a4cc-090a-80ea-afbb-c8003e79b8b8" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 데이터를 저장하여 검색 및 분석.</li></ul><ul id="1493a4cc-090a-807e-b80a-f59eb470fe15" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>:<ul id="1493a4cc-090a-808a-af7e-d811cdb6ca0e" class="bulleted-list"><li style="list-style-type:circle"><strong>메트릭</strong>: Prometheus, VictoriaMetrics.</li></ul><ul id="1493a4cc-090a-80af-9a38-ef4ad5fbf592" class="bulleted-list"><li style="list-style-type:circle"><strong>로그</strong>: Elasticsearch, ClickHouse.</li></ul><ul id="1493a4cc-090a-8019-bff0-fc22fc0ffb9c" class="bulleted-list"><li style="list-style-type:circle"><strong>트레이스</strong>: Jaeger, Zipkin.</li></ul></li></ul></li></ol><ol type="1" id="1493a4cc-090a-8077-afb2-ca7f5f765107" class="numbered-list" start="5"><li><strong>데이터 분석 및 시각화 계층</strong><ul id="1493a4cc-090a-8081-98af-de3f5d541f35" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 대시보드 및 경고 시스템 제공.</li></ul><ul id="1493a4cc-090a-8016-9f3a-e86e44f6903d" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: Grafana, Kibana.</li></ul></li></ol><ol type="1" id="1493a4cc-090a-8035-8bbe-cebeb37e6079" class="numbered-list" start="6"><li><strong>모니터링 및 관리 계층</strong><ul id="1493a4cc-090a-8062-8f77-dad1bbf4b955" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 시스템 성능, 가용성 모니터링.</li></ul><ul id="1493a4cc-090a-80cf-955b-d9dab255427b" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: Prometheus, CloudWatch (AWS), Stackdriver (Google Cloud).</li></ul></li></ol><hr id="1493a4cc-090a-8064-b599-c0a7fb7684df"/><h3 id="1493a4cc-090a-80da-b934-ce589bf6652a" class=""><strong>2-2. 아키텍처 설계 흐름</strong></h3><h3 id="1493a4cc-090a-808b-a0d8-c3c7561ad743" class=""><strong>1. 데이터 수집</strong></h3><ul id="1493a4cc-090a-806a-b58b-e9ec3e9eb78b" class="bulleted-list"><li style="list-style-type:disc"><strong>메트릭</strong>: Prometheus Exporter 또는 OpenTelemetry SDK.</li></ul><ul id="1493a4cc-090a-80fc-96e9-d57dfdceb219" class="bulleted-list"><li style="list-style-type:disc"><strong>로그</strong>: Fluent Bit 또는 Filebeat로 로그 파일 수집.</li></ul><ul id="1493a4cc-090a-8065-8cd7-ebbfe5cd37ea" class="bulleted-list"><li style="list-style-type:disc"><strong>트레이스</strong>: OpenTelemetry SDK를 사용하여 트레이스 생성.</li></ul><h3 id="1493a4cc-090a-80b1-a5ac-dc221ff8da26" class=""><strong>2. 데이터 버퍼링</strong></h3><ul id="1493a4cc-090a-80b8-8291-e9302d6c9581" class="bulleted-list"><li style="list-style-type:disc">Kafka와 같은 메시지 큐를 통해 데이터를 버퍼링하고, 스파이크 트래픽을 안정적으로 처리.</li></ul><h3 id="1493a4cc-090a-807c-87b9-ee35beb617b7" class=""><strong>3. 데이터 처리</strong></h3><ul id="1493a4cc-090a-80bd-9e29-e61d75218d59" class="bulleted-list"><li style="list-style-type:disc">Apache Flink 또는 Spark Streaming을 사용하여 데이터를 실시간으로 필터링, 변환, 집계.</li></ul><h3 id="1493a4cc-090a-8089-9c00-f361570c58b8" class=""><strong>4. 데이터 저장</strong></h3><ul id="1493a4cc-090a-807d-a59a-cf7a57efa492" class="bulleted-list"><li style="list-style-type:disc"><strong>메트릭</strong>: Prometheus의 TSDB(Time Series Database)에 저장.</li></ul><ul id="1493a4cc-090a-8038-9436-e0f5bc9c6e92" class="bulleted-list"><li style="list-style-type:disc"><strong>로그</strong>: Elasticsearch로 인덱싱하여 검색 가능한 구조로 저장.</li></ul><ul id="1493a4cc-090a-80bc-8c22-f7bca5d0b92f" class="bulleted-list"><li style="list-style-type:disc"><strong>트레이스</strong>: Jaeger의 백엔드에 저장하여 분산 트랜잭션 추적.</li></ul><h3 id="1493a4cc-090a-80dc-a7b7-ebb2811041ec" class=""><strong>5. 분석 및 시각화</strong></h3><ul id="1493a4cc-090a-80c8-b5c6-c9b2a6f65d19" class="bulleted-list"><li style="list-style-type:disc">Grafana와 Kibana를 사용하여 메트릭, 로그, 트레이스 데이터를 시각화.</li></ul><ul id="1493a4cc-090a-80cf-9d69-c12852861469" class="bulleted-list"><li style="list-style-type:disc">경고 시스템 설정: Grafana 알림 채널(예: 이메일, Slack) 사용.</li></ul><hr id="1493a4cc-090a-80a5-bf3a-d97b6a8fbf5f"/><h2 id="1493a4cc-090a-80d6-a4d1-f27aec6fee94" class=""><strong>3. 기술 스택 및 구성</strong></h2><h3 id="1493a4cc-090a-8015-b298-fd02059de5b7" class=""><strong>3-1. 데이터 수집</strong></h3><ul id="1493a4cc-090a-8036-99eb-cc4d7bf60045" class="bulleted-list"><li style="list-style-type:disc"><strong>OpenTelemetry</strong>: 메트릭, 로그, 트레이스 데이터를 통합적으로 수집.</li></ul><ul id="1493a4cc-090a-80ac-9022-d5deffb35aaf" class="bulleted-list"><li style="list-style-type:disc"><strong>Fluent Bit / Fluentd</strong>: 경량화된 로그 수집기.</li></ul><ul id="1493a4cc-090a-8090-b8c6-d879bde3d476" class="bulleted-list"><li style="list-style-type:disc"><strong>Metricbeat / Filebeat</strong>: 로그 및 메트릭 수집.</li></ul><h3 id="1493a4cc-090a-8022-a48d-c2f2f616496e" class=""><strong>3-2. 메시징 및 스트리밍</strong></h3><ul id="1493a4cc-090a-80fc-8172-ee5db29d3c16" class="bulleted-list"><li style="list-style-type:disc"><strong>Apache Kafka</strong>:<ul id="1493a4cc-090a-8056-b9f4-d2adfb97ead5" class="bulleted-list"><li style="list-style-type:circle">데이터를 안정적으로 버퍼링.</li></ul><ul id="1493a4cc-090a-808c-946d-d09999e43868" class="bulleted-list"><li style="list-style-type:circle">파티셔닝을 통해 수평 확장성 제공.</li></ul></li></ul><ul id="1493a4cc-090a-801c-b44b-d1198dbf91a0" class="bulleted-list"><li style="list-style-type:disc"><strong>Amazon Kinesis / Google Pub/Sub</strong>: 관리형 메시징 서비스.</li></ul><h3 id="1493a4cc-090a-806d-b205-ea28062bc251" class=""><strong>3-3. 실시간 데이터 처리</strong></h3><ul id="1493a4cc-090a-80f9-ab40-cb44f155f3fc" class="bulleted-list"><li style="list-style-type:disc"><strong>Apache Flink</strong>: 실시간 데이터 스트림 처리에 최적화.</li></ul><ul id="1493a4cc-090a-80c0-9fda-f83a3d8e384a" class="bulleted-list"><li style="list-style-type:disc"><strong>Apache Spark Streaming</strong>: 배치 및 스트림 데이터 처리.</li></ul><h3 id="1493a4cc-090a-80e4-aa33-fed0e4c12216" class=""><strong>3-4. 데이터 저장</strong></h3><ul id="1493a4cc-090a-80d2-86e5-ede636c2fee2" class="bulleted-list"><li style="list-style-type:disc"><strong>Prometheus / VictoriaMetrics</strong>: 메트릭 데이터 저장 및 쿼리.</li></ul><ul id="1493a4cc-090a-8020-b517-e92a678ea684" class="bulleted-list"><li style="list-style-type:disc"><strong>Elasticsearch</strong>: 로그 데이터 저장 및 검색.</li></ul><ul id="1493a4cc-090a-8023-a11e-c6699ef155a6" class="bulleted-list"><li style="list-style-type:disc"><strong>Jaeger / Zipkin</strong>: 분산 트랜잭션 데이터 저장.</li></ul><h3 id="1493a4cc-090a-80cf-a315-e23cee9f7d07" class=""><strong>3-5. 시각화</strong></h3><ul id="1493a4cc-090a-8060-a70d-d261995ee791" class="bulleted-list"><li style="list-style-type:disc"><strong>Grafana</strong>: 메트릭 및 트레이스 시각화.</li></ul><ul id="1493a4cc-090a-803a-b281-f6f44be34cf1" class="bulleted-list"><li style="list-style-type:disc"><strong>Kibana</strong>: Elasticsearch 로그 시각화.</li></ul><h3 id="1493a4cc-090a-8039-802a-eefc96f413bc" class=""><strong>3-6. 관리 및 모니터링</strong></h3><ul id="1493a4cc-090a-800b-9479-e7dd042879b7" class="bulleted-list"><li style="list-style-type:disc"><strong>Prometheus</strong>: 시스템 상태 및 메트릭 모니터링.</li></ul><ul id="1493a4cc-090a-803a-8233-cdb374a3d7d1" class="bulleted-list"><li style="list-style-type:disc"><strong>CloudWatch (AWS)</strong>, <strong>Stackdriver (Google Cloud)</strong>: 클라우드 네이티브 모니터링.</li></ul><hr id="1493a4cc-090a-8000-9fba-ef3eb56cdc8a"/><h2 id="1493a4cc-090a-80d9-ad92-eeff24069479" class=""><strong>4. 확장성 및 안정성 고려</strong></h2><h3 id="1493a4cc-090a-8045-9356-f2a16c59c799" class=""><strong>4-1. 수평 확장</strong></h3><ol type="1" id="1493a4cc-090a-8063-b2c6-d6dc5b7aad82" class="numbered-list" start="1"><li><strong>메시지 큐</strong><ul id="1493a4cc-090a-8008-8c9e-df97c453c8ef" class="bulleted-list"><li style="list-style-type:disc">Kafka 파티션을 늘려 처리량 확장.</li></ul><ul id="1493a4cc-090a-80fd-b5a0-ef1b6295b86e" class="bulleted-list"><li style="list-style-type:disc">파티션 분배 정책(예: 고객 ID 기반)을 설정하여 데이터 균등 분산.</li></ul></li></ol><ol type="1" id="1493a4cc-090a-8006-8033-e89ac0967f50" class="numbered-list" start="2"><li><strong>데이터 저장</strong><ul id="1493a4cc-090a-8067-aa2a-f38a5a2ed14c" class="bulleted-list"><li style="list-style-type:disc">Elasticsearch 샤드와 복제본 설정으로 저장소 확장.</li></ul><ul id="1493a4cc-090a-806c-95a1-d9a8493b1efa" class="bulleted-list"><li style="list-style-type:disc">Prometheus는 Thanos와 같은 확장형 솔루션 사용.</li></ul></li></ol><ol type="1" id="1493a4cc-090a-807c-b51f-cd7def828c94" class="numbered-list" start="3"><li><strong>데이터 처리</strong><ul id="1493a4cc-090a-80ba-a283-cd9c9affdf35" class="bulleted-list"><li style="list-style-type:disc">Apache Flink/Spark 작업자 노드를 추가하여 처리 성능 증가.</li></ul></li></ol><hr id="1493a4cc-090a-8050-9308-f83bf7709a38"/><h3 id="1493a4cc-090a-80c9-b1a8-e615112a6b1e" class=""><strong>4-2. 고가용성</strong></h3><ol type="1" id="1493a4cc-090a-80bb-96cd-d81b5ac7ec19" class="numbered-list" start="1"><li><strong>메시지 큐</strong><ul id="1493a4cc-090a-80fb-914e-df1b52ea57d1" class="bulleted-list"><li style="list-style-type:disc">Kafka 브로커를 3개 이상 구성.</li></ul><ul id="1493a4cc-090a-8068-95e8-c13cd481f448" class="bulleted-list"><li style="list-style-type:disc">멀티-리전 Kafka 클러스터 설정으로 장애 복구.</li></ul></li></ol><ol type="1" id="1493a4cc-090a-80a9-beb9-dffffd9af66b" class="numbered-list" start="2"><li><strong>데이터 저장</strong><ul id="1493a4cc-090a-80fd-9722-cc4ed42df6e7" class="bulleted-list"><li style="list-style-type:disc">Elasticsearch는 복제본(replica) 수를 늘려 장애 복구 시간 단축.</li></ul><ul id="1493a4cc-090a-8035-a160-c29e530ac33d" class="bulleted-list"><li style="list-style-type:disc">Prometheus는 Thanos로 멀티-리전 백업.</li></ul></li></ol><ol type="1" id="1493a4cc-090a-80d5-abd7-eb5e50e76736" class="numbered-list" start="3"><li><strong>로드 밸런싱</strong><ul id="1493a4cc-090a-8049-abbe-cb44f35a5e42" class="bulleted-list"><li style="list-style-type:disc">수집 계층(Fluentd, Fluent Bit)에 로드 밸런서 설정.</li></ul><ul id="1493a4cc-090a-80d0-807a-c42d59fb8ce1" class="bulleted-list"><li style="list-style-type:disc">데이터 저장소에 로드 밸런서 추가.</li></ul></li></ol><ol type="1" id="1493a4cc-090a-804d-b379-d4a78b3b418a" class="numbered-list" start="4"><li><strong>데이터 분산</strong><ul id="1493a4cc-090a-80ea-a15a-e438bf15fdff" class="bulleted-list"><li style="list-style-type:disc">멀티-리전 클러스터 설계로 데이터 유실 방지.</li></ul></li></ol><hr id="1493a4cc-090a-8099-a3e2-d550b68f9dd3"/><h2 id="1493a4cc-090a-80c0-b621-c7dc66a75ff2" class=""><strong>5. 상세 설계 예시</strong></h2><h3 id="1493a4cc-090a-8098-9b6d-d17b25e617aa" class=""><strong>5-1. 메트릭 처리 예시</strong></h3><ol type="1" id="1493a4cc-090a-8028-b98b-d09801c2460b" class="numbered-list" start="1"><li>Prometheus Exporter로 메트릭 수집.</li></ol><ol type="1" id="1493a4cc-090a-80f7-a970-e7b2cf8f7c03" class="numbered-list" start="2"><li>Prometheus에서 데이터 저장 및 쿼리.</li></ol><ol type="1" id="1493a4cc-090a-80a9-b07e-c51ef38f180c" class="numbered-list" start="3"><li>Grafana에서 대시보드 제공.</li></ol><h3 id="1493a4cc-090a-8017-aaeb-f96d7f286b68" class=""><strong>5-2. 로그 처리 예시</strong></h3><ol type="1" id="1493a4cc-090a-8053-a5e1-e00e8622f448" class="numbered-list" start="1"><li>Fluent Bit으로 로그 수집 → Kafka로 전송.</li></ol><ol type="1" id="1493a4cc-090a-80e5-aab6-ed82eb952c4c" class="numbered-list" start="2"><li>Kafka에서 Logstash로 전달하여 데이터 변환.</li></ol><ol type="1" id="1493a4cc-090a-80ac-a8f0-e0c2c03d4515" class="numbered-list" start="3"><li>Elasticsearch에 데이터 저장.</li></ol><ol type="1" id="1493a4cc-090a-80bc-960e-fe6258efc1b4" class="numbered-list" start="4"><li>Kibana에서 로그 시각화.</li></ol><h3 id="1493a4cc-090a-80c8-8b9f-ee39f82aab02" class=""><strong>5-3. 트레이스 처리 예시</strong></h3><ol type="1" id="1493a4cc-090a-80da-aa6e-c1d2dff7f15d" class="numbered-list" start="1"><li>OpenTelemetry로 트레이스 데이터 생성.</li></ol><ol type="1" id="1493a4cc-090a-800e-a516-c33b0f8ebb65" class="numbered-list" start="2"><li>Jaeger로 데이터를 수집 및 저장.</li></ol><ol type="1" id="1493a4cc-090a-8000-adfc-cc5f439f67b7" class="numbered-list" start="3"><li>Grafana에서 분산 트랜잭션 추적 시각화.</li></ol><hr id="1493a4cc-090a-80a3-b2df-fc3ffd874e78"/><h2 id="1493a4cc-090a-8073-9688-efd00cea4e2b" class=""><strong>6. 장점과 단점</strong></h2><h3 id="1493a4cc-090a-809b-878e-e8b016e5f7c6" class=""><strong>장점</strong></h3><ul id="1493a4cc-090a-80fe-b653-cbd6d5d245ee" class="bulleted-list"><li style="list-style-type:disc"><strong>확장성</strong>: 모든 계층에서 수평 확장 가능.</li></ul><ul id="1493a4cc-090a-8087-b8bc-eed3891b9374" class="bulleted-list"><li style="list-style-type:disc"><strong>고성능</strong>: 메시지 큐와 스트림 처리를 통한 실시간 처리.</li></ul><ul id="1493a4cc-090a-805a-8ca6-f7b5b7c9490b" class="bulleted-list"><li style="list-style-type:disc"><strong>통합 데이터 관리</strong>: 메트릭, 로그, 트레이스를 통합적으로 수집/분석.</li></ul><h3 id="1493a4cc-090a-80ab-a9db-caa8281991b6" class=""><strong>단점</strong></h3><ul id="1493a4cc-090a-8000-92e0-cbaf91bc9add" class="bulleted-list"><li style="list-style-type:disc"><strong>구성 복잡성</strong>: 여러 도구와 계층을 관리해야 함.</li></ul><ul id="1493a4cc-090a-8092-b724-d70b8f2467dc" class="bulleted-list"><li style="list-style-type:disc"><strong>비용</strong>: 대규모 클라우드 환경에서 리소스 비용 증가.</li></ul><hr id="1493a4cc-090a-80e7-8f30-ddcf6a875b25"/><p id="1493a4cc-090a-805e-aba3-f273b5cb50e0" class="">이 설계는 대규모 트래픽과 데이터 처리량을 안정적으로 처리하며, 수평 확장성과 고가용성을 제공합니다. 서비스 요구사항에 따라 기술 스택과 구성 요소를 조정할 수 있습니다.</p></details></li></ul><ul id="14c3a4cc-090a-8044-bc51-c0adab121b82" class="toggle"><li><details open=""><summary>고객 트래픽 증가에 따른 Kafka 확장 방안</summary><p id="14c3a4cc-090a-8014-8166-f7dbe80995e9" class="">Apache Kafka 클러스터의 처리 가능한 데이터 규모는 클러스터의 하드웨어 성능, 네트워크 대역폭, 메시지 크기, 파티션 수 및 사용 사례에 따라 달라집니다. 초기 구성으로 3개의 브로커와 3개의 ZooKeeper 노드를 사용하는 클러스터의 대략적인 처리량은 아래와 같은 요소를 고려해 추정할 수 있습니다.</p><hr id="14c3a4cc-090a-80d7-b8eb-f54106cc0e62"/><h3 id="14c3a4cc-090a-8072-b127-e24d819ca14e" class=""><strong>1. 주요 고려사항</strong></h3><h3 id="14c3a4cc-090a-80d5-9a82-d3be3d1eb1bc" class=""><strong>1.1 브로커 성능</strong></h3><ul id="14c3a4cc-090a-8094-9fd0-cc66be7a3e83" class="bulleted-list"><li style="list-style-type:disc"><strong>디스크 성능 (IOPS):</strong> 메시지는 디스크에 저장되므로, 브로커의 디스크 읽기/쓰기 속도가 중요.</li></ul><ul id="14c3a4cc-090a-809f-b3a5-defe95abf9f9" class="bulleted-list"><li style="list-style-type:disc"><strong>네트워크 대역폭:</strong> Kafka는 네트워크 중심의 애플리케이션으로, 클러스터 내 브로커 간 데이터 복제와 클라이언트와의 통신이 네트워크 대역폭에 의존.</li></ul><ul id="14c3a4cc-090a-804f-93c3-ee6db02656e4" class="bulleted-list"><li style="list-style-type:disc"><strong>CPU:</strong> 압축/디코딩, 데이터 처리, 분산 작업에 필요.</li></ul><h3 id="14c3a4cc-090a-80a5-a3e0-fdd86e475c8d" class=""><strong>1.2 메시지 크기</strong></h3><ul id="14c3a4cc-090a-80b7-98c2-eaaa881d2f50" class="bulleted-list"><li style="list-style-type:disc">메시지 크기가 작을수록 처리 가능한 메시지 수는 늘어나지만, 디스크 IO 및 네트워크 부하가 증가.<ul id="14c3a4cc-090a-803f-9cb3-e94bdfc868c8" class="bulleted-list"><li style="list-style-type:circle">평균 메시지 크기: <strong>1KB ~ 10KB</strong> (일반적인 로그, 메트릭, 트레이스).</li></ul></li></ul><h3 id="14c3a4cc-090a-80b7-96fb-c1cad49fcfee" class=""><strong>1.3 파티션 수</strong></h3><ul id="14c3a4cc-090a-808c-833d-f5c04664e035" class="bulleted-list"><li style="list-style-type:disc">Kafka는 파티션 단위로 병렬 처리를 수행.</li></ul><ul id="14c3a4cc-090a-8098-ba6d-ded42dc5ff32" class="bulleted-list"><li style="list-style-type:disc">파티션 수가 많아질수록 처리량이 증가하지만, 파티션 당 메모리 및 CPU 비용이 증가.</li></ul><h3 id="14c3a4cc-090a-8006-a087-d7371ea2f9ab" class=""><strong>1.4 리플리케이션 팩터</strong></h3><ul id="14c3a4cc-090a-8051-ad64-e78ac647d520" class="bulleted-list"><li style="list-style-type:disc"><strong>Replication Factor</strong>는 데이터 안정성을 결정.<ul id="14c3a4cc-090a-8042-ba25-d2a1610c2d11" class="bulleted-list"><li style="list-style-type:circle">기본 설정은 <code>3</code>으로, 데이터는 3개의 브로커에 복제.</li></ul><ul id="14c3a4cc-090a-807c-b2a7-cdbba991c663" class="bulleted-list"><li style="list-style-type:circle">복제는 쓰기 부하를 증가시키므로 처리량에 영향을 미침.</li></ul></li></ul><hr id="14c3a4cc-090a-8083-9dcb-db7e5d3c83ac"/><h3 id="14c3a4cc-090a-80cf-9898-f969f5ed2a25" class=""><strong>2. 처리량 추정</strong></h3><h3 id="14c3a4cc-090a-8021-9db1-f76e98a86c40" class=""><strong>2.1 메시지 크기 및 속도</strong></h3><ul id="14c3a4cc-090a-806e-b7cb-df159ddab266" class="bulleted-list"><li style="list-style-type:disc"><strong>기본 설정 예시:</strong><ul id="14c3a4cc-090a-802b-9613-f9318b0a01b4" class="bulleted-list"><li style="list-style-type:circle">메시지 크기: <strong>1KB</strong> (로그, 메트릭, 또는 트레이스 데이터).</li></ul><ul id="14c3a4cc-090a-80ac-8620-e0333a16395b" class="bulleted-list"><li style="list-style-type:circle">파티션 수: 브로커 당 50개의 파티션.</li></ul><ul id="14c3a4cc-090a-8029-a95d-ca51256dae8a" class="bulleted-list"><li style="list-style-type:circle">복제 팩터: <strong>3</strong>.</li></ul><ul id="14c3a4cc-090a-8096-80f1-f82231628839" class="bulleted-list"><li style="list-style-type:circle">네트워크: <strong>1Gbps</strong> 네트워크 연결.</li></ul><ul id="14c3a4cc-090a-8081-ada4-cb20ab384080" class="bulleted-list"><li style="list-style-type:circle">디스크: <strong>SSD</strong>, 브로커 당 5000 IOPS 가정.</li></ul></li></ul><ul id="14c3a4cc-090a-8008-811d-dafa230bbd12" class="bulleted-list"><li style="list-style-type:disc"><strong>브로커 당 처리량 (쓰기):</strong><ul id="14c3a4cc-090a-80e3-a7a6-d89bb94a43c8" class="bulleted-list"><li style="list-style-type:circle">1KB 메시지 크기 × 50 파티션 × 10,000 메시지/초 = <strong>500MB/초</strong>.</li></ul><ul id="14c3a4cc-090a-803f-a818-fe5491291df6" class="bulleted-list"><li style="list-style-type:circle">3개의 브로커로 분산 시: <strong>1.5GB/초 (복제 포함)</strong>.</li></ul></li></ul><ul id="14c3a4cc-090a-803d-a7d4-f73e65963705" class="bulleted-list"><li style="list-style-type:disc"><strong>브로커 당 처리량 (읽기):</strong><ul id="14c3a4cc-090a-80a4-af64-f449f03cfb7a" class="bulleted-list"><li style="list-style-type:circle">복제 팩터로 인해 읽기 요청은 주로 리더 파티션에서 발생.</li></ul><ul id="14c3a4cc-090a-808f-bcd3-f768e42b6081" class="bulleted-list"><li style="list-style-type:circle">복제 부하를 제외하면 브로커 당 처리량은 약 <strong>500MB/초</strong>.</li></ul></li></ul><h3 id="14c3a4cc-090a-801c-8aac-cce8bf4db6fa" class=""><strong>2.2 메시지 수</strong></h3><ul id="14c3a4cc-090a-8084-8e28-ed891b288708" class="bulleted-list"><li style="list-style-type:disc">1KB 메시지 기준으로 처리 가능한 메시지 수:<ul id="14c3a4cc-090a-80dd-9b57-c031eb103412" class="bulleted-list"><li style="list-style-type:circle">쓰기: <strong>약 150만 메시지/초 (전체 클러스터 기준)</strong>.</li></ul><ul id="14c3a4cc-090a-8054-9c68-f795ec0b3a55" class="bulleted-list"><li style="list-style-type:circle">읽기: <strong>약 150만 메시지/초</strong>.</li></ul></li></ul><h3 id="14c3a4cc-090a-8029-b0bb-e11e5d62cd41" class=""><strong>2.3 총 데이터량</strong></h3><ul id="14c3a4cc-090a-80ad-a3a0-d69091af7ed9" class="bulleted-list"><li style="list-style-type:disc">메시지 크기가 1KB이고, 초당 150만 메시지가 처리되는 경우:<ul id="14c3a4cc-090a-802e-82d0-f76c7fc7ae4f" class="bulleted-list"><li style="list-style-type:circle">초당 처리 데이터량: <strong>1.5GB/초</strong>.</li></ul><ul id="14c3a4cc-090a-8088-b06c-c1f88e9443a4" class="bulleted-list"><li style="list-style-type:circle">하루 처리 데이터량: <strong>1.5GB × 86,400초 = 약 130TB/일</strong>.</li></ul></li></ul><hr id="14c3a4cc-090a-8017-a549-e01a0be03638"/><h3 id="14c3a4cc-090a-802d-ba73-e3b18b4beb53" class=""><strong>3. 처리량 최적화</strong></h3><h3 id="14c3a4cc-090a-8056-9549-e91f58209a84" class=""><strong>3.1 디스크와 네트워크 업그레이드</strong></h3><ul id="14c3a4cc-090a-8078-a4cc-dd62f8c580f7" class="bulleted-list"><li style="list-style-type:disc">디스크를 NVMe SSD로 업그레이드하여 IOPS를 증가시키면 처리량이 크게 향상.</li></ul><ul id="14c3a4cc-090a-80e9-9d27-eeecdccd31c2" class="bulleted-list"><li style="list-style-type:disc">네트워크를 10Gbps 이상으로 구성하면 대역폭 제약 해소.</li></ul><h3 id="14c3a4cc-090a-8045-859b-fb71e2e9b88f" class=""><strong>3.2 파티션 최적화</strong></h3><ul id="14c3a4cc-090a-8013-9b63-d013875525c5" class="bulleted-list"><li style="list-style-type:disc">브로커 당 파티션 수를 늘리면 처리량이 증가.<ul id="14c3a4cc-090a-80ca-b135-f7c2a34cadd8" class="bulleted-list"><li style="list-style-type:circle">권장 파티션 수: 브로커 당 100~200.</li></ul></li></ul><h3 id="14c3a4cc-090a-802d-ad6c-d5249981fe31" class=""><strong>3.3 압축 활용</strong></h3><ul id="14c3a4cc-090a-80e5-961b-f3fd4dab3b62" class="bulleted-list"><li style="list-style-type:disc">메시지를 <code>lz4</code> 또는 <code>zstd</code>로 압축하면 네트워크 부하를 줄이고 처리량을 향상.</li></ul><hr id="14c3a4cc-090a-8020-b40b-fb808ea18001"/><h3 id="14c3a4cc-090a-8099-af17-f7574fa25149" class=""><strong>4. 확장 고려</strong></h3><p id="14c3a4cc-090a-808c-bf07-f61311aa9e27" class="">3개의 브로커는 중소 규모의 데이터 처리에 적합하며, 대규모 데이터 증가는 아래 방법으로 대응할 수 있습니다:</p><ol type="1" id="14c3a4cc-090a-806c-863d-cb8d5346ad5a" class="numbered-list" start="1"><li><strong>브로커 추가</strong>:<ul id="14c3a4cc-090a-80b5-9154-ed2d1f121a90" class="bulleted-list"><li style="list-style-type:disc">클러스터에 브로커를 추가하면 파티션과 부하가 분산되어 처리량 증가.</li></ul><ul id="14c3a4cc-090a-8058-87c2-d16da3f8673c" class="bulleted-list"><li style="list-style-type:disc">6개 브로커로 확장 시, 약 <strong>3GB/초</strong>의 쓰기 처리량 가능.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80c1-80bf-d69e7949ebd8" class="numbered-list" start="2"><li><strong>멀티 클러스터 구성</strong>:<ul id="14c3a4cc-090a-807a-8b5e-d3c21f7f98cc" class="bulleted-list"><li style="list-style-type:disc">데이터 센터별로 독립 클러스터 구성.</li></ul><ul id="14c3a4cc-090a-801f-8102-f54cbeff108a" class="bulleted-list"><li style="list-style-type:disc">Kafka <strong>MirrorMaker 2</strong>를 사용하여 클러스터 간 데이터를 복제.</li></ul></li></ol><hr id="14c3a4cc-090a-808e-a598-cc58bc58731f"/><h3 id="14c3a4cc-090a-80b8-8211-d21e0924c13e" class=""><strong>5. 결론</strong></h3><p id="14c3a4cc-090a-8099-859b-f87ec6165b96" class="">초기 3개의 브로커와 3개의 ZooKeeper 노드를 사용하는 Kafka 클러스터는 다음과 같은 처리량을 제공합니다:</p><ul id="14c3a4cc-090a-80d6-8525-e3518f89cf7c" class="bulleted-list"><li style="list-style-type:disc"><strong>쓰기:</strong> 약 <strong>1.5GB/초</strong>.</li></ul><ul id="14c3a4cc-090a-800f-b30e-f4498d933269" class="bulleted-list"><li style="list-style-type:disc"><strong>읽기:</strong> 약 <strong>1.5GB/초</strong>.</li></ul><ul id="14c3a4cc-090a-8036-a270-cdffd42ccf55" class="bulleted-list"><li style="list-style-type:disc"><strong>총 데이터량:</strong> 하루 약 <strong>130TB</strong> 처리 가능.</li></ul><p id="14c3a4cc-090a-80a9-a801-ce83bce63d84" class=""><strong>확장성:</strong></p><ul id="14c3a4cc-090a-8096-8af0-ce47c6d8e630" class="bulleted-list"><li style="list-style-type:disc">브로커를 추가하여 처리량을 선형적으로 확장 가능.</li></ul><ul id="14c3a4cc-090a-80e6-a702-fd2ee2831205" class="bulleted-list"><li style="list-style-type:disc">멀티 클러스터로 설계하면 무제한 확장 가능.</li></ul><p id="14c3a4cc-090a-8023-827f-d2643df7a336" class="">
</p><p id="14c3a4cc-090a-8019-8bdd-d8983c18ff5e" class="">Apache Kafka 시스템의 초기 구성(3개 브로커, 3개 ZooKeeper 노드)에서 초당 처리 데이터량이 10배, 100배, 1000배로 증가할 경우, Kafka의 주요 확장 전략은 <strong>브로커 추가</strong>, <strong>파티션 증가</strong>, <strong>멀티 클러스터 구성</strong> 및 <strong>스토리지, 네트워크 업그레이드</strong>로 요약됩니다. 아래는 각각의 단계에서 확장을 고려한 방법입니다.</p><hr id="14c3a4cc-090a-80d8-9856-c0e54ed0acd5"/><h3 id="14c3a4cc-090a-8051-b6d6-eba0d2344a04" class=""><strong>1. 초당 처리량 증가: 10배 (~15GB/s)</strong></h3><h3 id="14c3a4cc-090a-805b-985b-eff0fac6e0bf" class=""><strong>확장 전략</strong></h3><ol type="1" id="14c3a4cc-090a-8051-8ec9-df410c786e5f" class="numbered-list" start="1"><li><strong>브로커 확장</strong><ul id="14c3a4cc-090a-8064-9f88-f1e69470d540" class="bulleted-list"><li style="list-style-type:disc">초기 3개 브로커에서 <strong>30개 브로커</strong>로 확장.</li></ul><ul id="14c3a4cc-090a-8057-9aab-c36f90be0fcc" class="bulleted-list"><li style="list-style-type:disc">브로커 추가로 파티션 리더를 분산하여 처리량 증가.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80e7-bfd4-ed2dc5cffb41" class="numbered-list" start="2"><li><strong>파티션 수 증가</strong><ul id="14c3a4cc-090a-8080-a74c-ee51286d1843" class="bulleted-list"><li style="list-style-type:disc">각 토픽의 파티션 수를 기존 50개에서 500개로 증가.</li></ul><ul id="14c3a4cc-090a-806a-bbdf-e8b9570226c7" class="bulleted-list"><li style="list-style-type:disc">더 많은 컨슈머가 병렬로 처리 가능.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-8030-8cff-e4a6ae6c16fa" class="numbered-list" start="3"><li><strong>네트워크 업그레이드</strong><ul id="14c3a4cc-090a-8037-93de-e67db4b7155d" class="bulleted-list"><li style="list-style-type:disc">기존 1Gbps에서 <strong>10Gbps 네트워크</strong>로 업그레이드.</li></ul><ul id="14c3a4cc-090a-80af-892e-c0b64aca33f5" class="bulleted-list"><li style="list-style-type:disc">브로커 간 복제와 데이터 전송의 병목 해결.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-8063-b591-f08666493bb0" class="numbered-list" start="4"><li><strong>ZooKeeper 클러스터 확장</strong><ul id="14c3a4cc-090a-80ed-a0dd-d58e7be8adf9" class="bulleted-list"><li style="list-style-type:disc">ZooKeeper는 브로커 수 증가에 따라 부하가 증가하므로 <strong>5개 ZooKeeper 노드</strong>로 확장.</li></ul><ul id="14c3a4cc-090a-802f-b5da-d4a84c61a6d2" class="bulleted-list"><li style="list-style-type:disc">데이터 센터 분산 시, ZooKeeper를 멀티 데이터 센터 설정으로 구성.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-8044-959f-dda6807c38ba" class="numbered-list" start="5"><li><strong>하드웨어 스펙 업그레이드</strong><ul id="14c3a4cc-090a-80d8-b51b-eeee751bb4d3" class="bulleted-list"><li style="list-style-type:disc">브로커의 디스크를 <strong>NVMe SSD</strong>로 교체하여 높은 IOPS 확보.</li></ul><ul id="14c3a4cc-090a-8047-816d-e3987cc73bee" class="bulleted-list"><li style="list-style-type:disc">메모리를 64GB 이상으로 확장.</li></ul></li></ol><hr id="14c3a4cc-090a-809f-aa64-f8412a2ad35e"/><h3 id="14c3a4cc-090a-80f5-b1b8-e79d4cdf1a53" class=""><strong>2. 초당 처리량 증가: 100배 (~150GB/s)</strong></h3><h3 id="14c3a4cc-090a-800c-a6c8-ea3e01437af5" class=""><strong>확장 전략</strong></h3><ol type="1" id="14c3a4cc-090a-80d4-85cc-f5ce5cca39af" class="numbered-list" start="1"><li><strong>브로커 확장</strong><ul id="14c3a4cc-090a-804c-999b-ff7999741ba4" class="bulleted-list"><li style="list-style-type:disc">브로커 수를 약 <strong>300개</strong>로 확장.</li></ul><ul id="14c3a4cc-090a-8078-b9ed-c84e489c98f5" class="bulleted-list"><li style="list-style-type:disc">각 브로커는 독립적인 워크로드를 처리하므로 클러스터 처리량이 선형적으로 증가.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-804d-9de3-db16e5144917" class="numbered-list" start="2"><li><strong>파티션 수 최적화</strong><ul id="14c3a4cc-090a-80c4-9731-f3bf31e6c7fe" class="bulleted-list"><li style="list-style-type:disc">토픽당 파티션 수를 약 <strong>5000개</strong>로 증가.</li></ul><ul id="14c3a4cc-090a-8074-876a-dc265b62a2da" class="bulleted-list"><li style="list-style-type:disc">컨슈머 수를 늘려 파티션을 병렬로 소비.</li></ul><ul id="14c3a4cc-090a-803a-9d61-e4b5c1b59d5d" class="bulleted-list"><li style="list-style-type:disc">파티션 수는 브로커 메모리와 CPU에 따라 조정 필요.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80ac-ab79-fcd02b1201df" class="numbered-list" start="3"><li><strong>멀티 클러스터 구성</strong><ul id="14c3a4cc-090a-8045-aadf-cdd32943fe65" class="bulleted-list"><li style="list-style-type:disc">단일 클러스터의 브로커 수가 500개를 초과하면 관리 및 네트워크 부하가 복잡해질 수 있음.</li></ul><ul id="14c3a4cc-090a-804b-b0d7-dd570881f398" class="bulleted-list"><li style="list-style-type:disc">멀티 클러스터를 구성하고, <strong>MirrorMaker 2</strong>를 사용해 클러스터 간 데이터 복제.</li></ul><ul id="14c3a4cc-090a-808f-8ad3-d3a1ebbebe6c" class="bulleted-list"><li style="list-style-type:disc">예: 3개의 데이터 센터에 각각 독립 클러스터를 배치하여 처리량 분산.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-8091-b2b3-e9a8e8fad48c" class="numbered-list" start="4"><li><strong>스토리지 분리</strong><ul id="14c3a4cc-090a-80ac-818e-ea8f64b36694" class="bulleted-list"><li style="list-style-type:disc"><strong>Tiered Storage</strong> 기능을 활성화하여 콜드 데이터를 객체 스토리지(AWS S3, Google Cloud Storage)로 이동.</li></ul><ul id="14c3a4cc-090a-8011-998a-c74229902984" class="bulleted-list"><li style="list-style-type:disc">브로커의 디스크 부담을 줄이고 핫 데이터만 유지.</li></ul></li></ol><hr id="14c3a4cc-090a-802c-86d9-dc54d26725ab"/><h3 id="14c3a4cc-090a-80b7-a15d-d6014a8a9cae" class=""><strong>3. 초당 처리량 증가: 1000배 (~1.5TB/s)</strong></h3><h3 id="14c3a4cc-090a-80e2-9aa4-e1172d4c095a" class=""><strong>확장 전략</strong></h3><ol type="1" id="14c3a4cc-090a-8038-846c-f4e5767bce45" class="numbered-list" start="1"><li><strong>브로커와 클러스터 대규모 확장</strong><ul id="14c3a4cc-090a-80ef-b7b8-d131c3711c18" class="bulleted-list"><li style="list-style-type:disc">브로커 수를 약 <strong>3000개</strong>로 확장.</li></ul><ul id="14c3a4cc-090a-806f-9c3f-df9ccbe17aef" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 센터별로 독립적인 클러스터 구성</strong>하여 복잡도를 줄임.</li></ul><ul id="14c3a4cc-090a-80ee-98ff-db8d442e344f" class="bulleted-list"><li style="list-style-type:disc">예: 10개의 클러스터에 각 300개 브로커를 배치.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80f4-bce3-ce571ce16ac8" class="numbered-list" start="2"><li><strong>멀티 데이터 센터 확장</strong><ul id="14c3a4cc-090a-80ce-9d24-dff9b209c98f" class="bulleted-list"><li style="list-style-type:disc">데이터 센터마다 독립적인 Kafka 클러스터 구성.</li></ul><ul id="14c3a4cc-090a-80f6-ab3d-c13a9c897d36" class="bulleted-list"><li style="list-style-type:disc"><strong>MirrorMaker 2</strong>를 사용해 데이터 센터 간 복제.</li></ul><ul id="14c3a4cc-090a-80d1-902f-d1a37d6bfc7e" class="bulleted-list"><li style="list-style-type:disc">데이터 센터별로 지역 토픽을 분리하고, 필요 시 글로벌 토픽 복제.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80a6-9480-f11df88aca15" class="numbered-list" start="3"><li><strong>데이터 파이프라인 최적화</strong><ul id="14c3a4cc-090a-8072-a426-cff128ffc1db" class="bulleted-list"><li style="list-style-type:disc">메시지 크기 최적화 및 압축 적용(<code>lz4</code>, <code>zstd</code>)으로 네트워크 부하 감소.</li></ul><ul id="14c3a4cc-090a-8077-addf-d22a8f74f52a" class="bulleted-list"><li style="list-style-type:disc">생산자와 컨슈머의 병렬 처리 구조 강화.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80d0-8d8f-c860fc433eb8" class="numbered-list" start="4"><li><strong>전용 네트워크 구축</strong><ul id="14c3a4cc-090a-807d-93e4-c456e240403b" class="bulleted-list"><li style="list-style-type:disc">Kafka 전용 고속 네트워크를 구성(100Gbps 이상).</li></ul><ul id="14c3a4cc-090a-800c-81c7-f8e2d6500795" class="bulleted-list"><li style="list-style-type:disc">데이터 센터 간 네트워크 병목을 방지하기 위해 <strong>전용 광케이블</strong> 또는 <strong>SD-WAN</strong> 구축.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80a6-8952-cdb2decda0da" class="numbered-list" start="5"><li><strong>멀티 테넌트 운영</strong><ul id="14c3a4cc-090a-80a0-9b4b-dbfd47924f46" class="bulleted-list"><li style="list-style-type:disc">고객별, 서비스별로 클러스터를 분리하여 운영.</li></ul><ul id="14c3a4cc-090a-802e-90d7-cb3a62bcb5fd" class="bulleted-list"><li style="list-style-type:disc">Kafka 클러스터를 서비스 간 공유하지 않고 격리하여 확장성과 안정성 강화.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80d9-8789-dc6a3cd88603" class="numbered-list" start="6"><li><strong>클라우드 네이티브 스토리지 연계</strong><ul id="14c3a4cc-090a-805e-887f-fa7cc191a6b2" class="bulleted-list"><li style="list-style-type:disc"><strong>Amazon S3</strong>, <strong>Google Cloud Storage</strong> 같은 객체 스토리지를 활용하여 아카이빙 데이터 저장.</li></ul><ul id="14c3a4cc-090a-8000-9326-c13522b7810a" class="bulleted-list"><li style="list-style-type:disc">Kafka 클러스터는 핫 데이터만 처리.</li></ul></li></ol><hr id="14c3a4cc-090a-804b-aad6-f057839ef90e"/><h3 id="14c3a4cc-090a-80db-bd5a-c93da3463d7b" class=""><strong>4. 각 단계의 예상 구성</strong></h3><table id="14c3a4cc-090a-80c7-bf68-f3ef71e51302" class="simple-table"><tbody><tr id="14c3a4cc-090a-8060-a9ae-c5f5ed07c562"><td id="Dc_y" class=""><strong>확장 단계</strong></td><td id="}=Ix" class=""><strong>브로커 수</strong></td><td id="K[YM" class=""><strong>ZooKeeper 노드 수</strong></td><td id="?v~q" class=""><strong>파티션 수</strong></td><td id="KjUn" class=""><strong>총 처리량</strong></td><td id="almp" class=""><strong>멀티 클러스터 필요성</strong></td></tr><tr id="14c3a4cc-090a-8060-874d-f087b3d6a3d6"><td id="Dc_y" class="">초기 (1.5GB/s)</td><td id="}=Ix" class="">3</td><td id="K[YM" class="">3</td><td id="?v~q" class="">50</td><td id="KjUn" class="">1.5GB/s</td><td id="almp" class="">없음</td></tr><tr id="14c3a4cc-090a-8038-8308-c85dcb660450"><td id="Dc_y" class="">10배 확장 (15GB/s)</td><td id="}=Ix" class="">30</td><td id="K[YM" class="">5</td><td id="?v~q" class="">500</td><td id="KjUn" class="">15GB/s</td><td id="almp" class="">권장</td></tr><tr id="14c3a4cc-090a-8083-9b19-cfb7ef564106"><td id="Dc_y" class="">100배 확장 (150GB/s)</td><td id="}=Ix" class="">300</td><td id="K[YM" class="">7</td><td id="?v~q" class="">5000</td><td id="KjUn" class="">150GB/s</td><td id="almp" class="">필수</td></tr><tr id="14c3a4cc-090a-804b-b3ce-f89067589b10"><td id="Dc_y" class="">1000배 확장 (1.5TB/s)</td><td id="}=Ix" class="">3000</td><td id="K[YM" class="">9+ (분산)</td><td id="?v~q" class="">50,000+</td><td id="KjUn" class="">1.5TB/s</td><td id="almp" class="">필수 (글로벌 분산 필요)</td></tr></tbody></table><hr id="14c3a4cc-090a-80d0-b995-c77428f51957"/><h3 id="14c3a4cc-090a-80d5-97c9-eed03559bc52" class=""><strong>5. 확장성 구현 시 고려 사항</strong></h3><h3 id="14c3a4cc-090a-8027-85ce-d7bb7058c931" class=""><strong>단일 클러스터 제한</strong></h3><ul id="14c3a4cc-090a-8020-ba08-c4975705deef" class="bulleted-list"><li style="list-style-type:disc">단일 Kafka 클러스터의 브로커 수가 500개를 초과하면 ZooKeeper와 브로커 간의 통신 부하가 급격히 증가.</li></ul><ul id="14c3a4cc-090a-80ad-8915-ca0449691713" class="bulleted-list"><li style="list-style-type:disc">브로커당 약 4000~5000개의 파티션이 이상적. 이를 초과하면 브로커 메모리 소모 증가.</li></ul><h3 id="14c3a4cc-090a-8089-aa6e-d2f88c44c1b7" class=""><strong>운영 및 관리 도구</strong></h3><ul id="14c3a4cc-090a-8062-8081-ea0a3b984d5c" class="bulleted-list"><li style="list-style-type:disc"><strong>Confluent Control Center:</strong> 대규모 Kafka 클러스터 모니터링.</li></ul><ul id="14c3a4cc-090a-8007-a94a-d5df9de74ab2" class="bulleted-list"><li style="list-style-type:disc"><strong>Prometheus + Grafana:</strong> 클러스터 상태, 메트릭, 지연 시간 모니터링.</li></ul><ul id="14c3a4cc-090a-8098-914b-db01137fb38d" class="bulleted-list"><li style="list-style-type:disc"><strong>Kafka Manager:</strong> 파티션 리더, 복제 상태, 클러스터 밸런싱 관리.</li></ul><h3 id="14c3a4cc-090a-8062-9d54-f6b372379362" class=""><strong>스토리지 최적화</strong></h3><ul id="14c3a4cc-090a-80f8-a767-c2112f22fb51" class="bulleted-list"><li style="list-style-type:disc">Kafka Tiered Storage를 사용하여 고속 디스크에 핫 데이터만 저장.</li></ul><ul id="14c3a4cc-090a-8051-8ebc-c0bcaf848949" class="bulleted-list"><li style="list-style-type:disc">데이터 보존 기간이 긴 경우, 오브젝트 스토리지로 이동.</li></ul><h3 id="14c3a4cc-090a-8005-9bb9-daeead65ac3c" class=""><strong>컨슈머 병렬 처리</strong></h3><ul id="14c3a4cc-090a-8028-bd39-f2ec13f7f220" class="bulleted-list"><li style="list-style-type:disc">컨슈머가 충분한 처리 성능을 갖추도록 병렬 인스턴스를 늘림.</li></ul><ul id="14c3a4cc-090a-80d5-95e1-edc57b7622a9" class="bulleted-list"><li style="list-style-type:disc">토픽별로 전용 컨슈머 그룹을 생성하여 부하를 분산.</li></ul><hr id="14c3a4cc-090a-80f9-95c4-e1e7ded9e4f2"/><h3 id="14c3a4cc-090a-804b-9c17-e45ffffbee02" class=""><strong>결론</strong></h3><p id="14c3a4cc-090a-803f-a96e-e97e64e67014" class="">Kafka 클러스터는 <strong>브로커 확장</strong>, <strong>멀티 클러스터 구성</strong>, <strong>스토리지 최적화</strong>를 통해 10배, 100배, 1000배 처리량 증가에 대응할 수 있습니다.</p><p id="14c3a4cc-090a-8012-ab92-db57a69c1a82" class="">필요에 따라 Kafka 외부의 데이터 처리를 위한 분석 플랫폼(Hadoop, Spark, Flink 등)과의 통합도 고려하여 확장성을 보완할 수 있습니다.</p><p id="14c3a4cc-090a-8005-a6e1-c8c0f6fa93aa" class="">추가로 궁금한 사항이 있으면 문의해주세요! 😊</p><p id="14c3a4cc-090a-80e7-b6d7-f2485ff47ae4" class="">더 많은 정보는 <a href="https://gptonline.ai/ko/">gptonline.ai/ko</a>에서 확인할 수 있습니다.</p><h3 id="14c3a4cc-090a-800b-8da0-dd71e6b41668" class="">나의 말:</h3><p id="14c3a4cc-090a-8054-a031-fada0a9d7f9d" class="">위 kafka 확장에서 멀티 클러스터 구성 전략을 자세히 알려줘</p><h3 id="14c3a4cc-090a-8040-a899-e2ff3d770ceb" class="">ChatGPT의 말:</h3><figure id="14c3a4cc-090a-8080-9649-dec030146ecc" class="image"><a href="https://chatgpt.com/backend-api/content?id=file-yOO0xA22YQbkjlS6bbbOEoLq&amp;gizmo_id=g-FvT4UOsoA&amp;ts=481342&amp;p=gpp&amp;sig=0ce2e58fdd8d2d910f61513cea5210e496feab2c26b208d2a39fc86809010916&amp;v=0"><img style="width:80px" src="https://chatgpt.com/backend-api/content?id=file-yOO0xA22YQbkjlS6bbbOEoLq&amp;gizmo_id=g-FvT4UOsoA&amp;ts=481342&amp;p=gpp&amp;sig=0ce2e58fdd8d2d910f61513cea5210e496feab2c26b208d2a39fc86809010916&amp;v=0"/></a></figure><p id="14c3a4cc-090a-80ec-aeec-d44d6667c884" class="">Apache Kafka의 멀티 클러스터 구성 전략은 <strong>대규모 데이터 처리</strong>, <strong>지역 간 데이터 분산</strong>, <strong>장애 복구(Disaster Recovery)</strong>, <strong>데이터 격리</strong> 등의 목적을 달성하기 위해 사용됩니다. 멀티 클러스터는 각 클러스터가 독립적으로 동작하면서도, 필요에 따라 데이터를 동기화하거나 특정 데이터를 분산 처리하는 구조를 갖습니다. 아래에 멀티 클러스터 설계의 세부 전략을 설명합니다.</p><hr id="14c3a4cc-090a-80ca-aa88-ff2ab860156c"/><h3 id="14c3a4cc-090a-8090-8719-c766c881e513" class=""><strong>1. 멀티 클러스터 설계 목적</strong></h3><ol type="1" id="14c3a4cc-090a-8087-97f6-dd88049953c7" class="numbered-list" start="1"><li><strong>확장성 확보:</strong> 단일 클러스터의 브로커 및 파티션 수의 한계를 극복.</li></ol><ol type="1" id="14c3a4cc-090a-8099-9247-df4b55b3688b" class="numbered-list" start="2"><li><strong>데이터 지역성:</strong> 데이터 센터 또는 리전별로 클러스터를 구성해 데이터 전송 비용 절감.</li></ol><ol type="1" id="14c3a4cc-090a-80ac-9d3d-f6d4da716477" class="numbered-list" start="3"><li><strong>재해 복구:</strong> 한 클러스터에 장애가 발생해도 데이터 복제 클러스터로 서비스 지속 가능.</li></ol><ol type="1" id="14c3a4cc-090a-8065-a6f5-c5741a18ea6d" class="numbered-list" start="4"><li><strong>운영 격리:</strong> 다른 서비스나 애플리케이션이 동일 클러스터를 사용하지 않도록 분리.</li></ol><ol type="1" id="14c3a4cc-090a-804f-b5ef-f50cf3af1bce" class="numbered-list" start="5"><li><strong>사용 사례 분리:</strong> 메트릭, 로그, 트레이스 데이터를 별도의 클러스터로 분리해 최적화.</li></ol><hr id="14c3a4cc-090a-80ea-aade-c0023a2a34e2"/><h3 id="14c3a4cc-090a-8015-aec4-ca3d321a243b" class=""><strong>2. 멀티 클러스터 구성 전략</strong></h3><h3 id="14c3a4cc-090a-803b-8e53-e8486db93e78" class=""><strong>2.1 클러스터 구성 방식</strong></h3><ol type="1" id="14c3a4cc-090a-8083-a38a-f57a986d7d51" class="numbered-list" start="1"><li><strong>데이터 센터 별 클러스터 (Region-Based)</strong><ul id="14c3a4cc-090a-80a9-ae1a-f804f337939a" class="bulleted-list"><li style="list-style-type:disc">각 데이터 센터에 독립적인 Kafka 클러스터를 배포.</li></ul><ul id="14c3a4cc-090a-8015-a4e5-d05242228921" class="bulleted-list"><li style="list-style-type:disc">지역 간 네트워크 비용 최소화.</li></ul><ul id="14c3a4cc-090a-805e-a637-db1a649a1111" class="bulleted-list"><li style="list-style-type:disc">데이터 복제를 통해 글로벌 동기화.</li></ul><p id="14c3a4cc-090a-807b-8c1b-c727ad4a30c9" class=""><strong>예시:</strong></p><ul id="14c3a4cc-090a-80dc-a37c-d738d21f26c5" class="bulleted-list"><li style="list-style-type:disc">클러스터 A: 미국 데이터 센터</li></ul><ul id="14c3a4cc-090a-803a-80fe-c0ae324bf8bd" class="bulleted-list"><li style="list-style-type:disc">클러스터 B: 유럽 데이터 센터</li></ul><ul id="14c3a4cc-090a-809f-ac00-e5a0509bb1e0" class="bulleted-list"><li style="list-style-type:disc">클러스터 C: 아시아 데이터 센터</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-807e-aca0-c86cbe8d49cd" class="numbered-list" start="2"><li><strong>워크로드 별 클러스터 (Workload-Based)</strong><ul id="14c3a4cc-090a-808e-95ff-e7a8e0b41366" class="bulleted-list"><li style="list-style-type:disc">메트릭, 로그, 트레이스를 각각 독립적인 클러스터로 구성.</li></ul><ul id="14c3a4cc-090a-806a-a2bc-e5a6a25f4d31" class="bulleted-list"><li style="list-style-type:disc">각 워크로드에 특화된 클러스터 설정 가능.</li></ul><ul id="14c3a4cc-090a-8051-9df5-e089f567e9d2" class="bulleted-list"><li style="list-style-type:disc">특정 워크로드의 부하가 다른 워크로드에 영향을 주지 않음.</li></ul><p id="14c3a4cc-090a-80e7-9944-f1273b4fe10a" class=""><strong>예시:</strong></p><ul id="14c3a4cc-090a-80e0-b835-d91dd2614c3b" class="bulleted-list"><li style="list-style-type:disc">클러스터 A: 메트릭 데이터</li></ul><ul id="14c3a4cc-090a-804b-862f-d6455d6809b3" class="bulleted-list"><li style="list-style-type:disc">클러스터 B: 로그 데이터</li></ul><ul id="14c3a4cc-090a-80ce-9744-c92614d5a9d1" class="bulleted-list"><li style="list-style-type:disc">클러스터 C: 트레이스 데이터</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-8039-88b5-d6e911977d23" class="numbered-list" start="3"><li><strong>테넌트 별 클러스터 (Multi-Tenant-Based)</strong><ul id="14c3a4cc-090a-803e-80a8-e58e4b54bae2" class="bulleted-list"><li style="list-style-type:disc">고객 또는 서비스별로 클러스터를 분리.</li></ul><ul id="14c3a4cc-090a-80da-9ed7-e66965e93474" class="bulleted-list"><li style="list-style-type:disc">데이터를 공유하지 않고 완벽한 격리를 보장.</li></ul><p id="14c3a4cc-090a-80ac-8506-c84400a16be5" class=""><strong>예시:</strong></p><ul id="14c3a4cc-090a-8045-890c-de9ea5b9d1b2" class="bulleted-list"><li style="list-style-type:disc">클러스터 A: 고객 1 데이터</li></ul><ul id="14c3a4cc-090a-8076-9f32-fbb6ee8ebe70" class="bulleted-list"><li style="list-style-type:disc">클러스터 B: 고객 2 데이터</li></ul><ul id="14c3a4cc-090a-80a7-85a3-f431d4bfa85c" class="bulleted-list"><li style="list-style-type:disc">클러스터 C: 고객 3 데이터</li></ul></li></ol><hr id="14c3a4cc-090a-8088-aae6-fe680584f8fc"/><h3 id="14c3a4cc-090a-8044-9a43-df3c46661e23" class=""><strong>2.2 클러스터 간 데이터 동기화</strong></h3><h3 id="14c3a4cc-090a-804a-b147-c8714d222abf" class=""><strong>MirrorMaker 2 (MM2)</strong></h3><p id="14c3a4cc-090a-80fd-ad64-f106560020cf" class="">Kafka의 멀티 클러스터 동기화는 <strong>MirrorMaker 2</strong>를 통해 구현됩니다.</p><p id="14c3a4cc-090a-80a2-b9c7-ec64705de43e" class="">MM2는 Kafka Connect 기반의 도구로, 두 개 이상의 클러스터 간에 데이터를 복제하고 동기화할 수 있습니다.</p><ul id="14c3a4cc-090a-8075-81c4-c87130323604" class="bulleted-list"><li style="list-style-type:disc"><strong>MirrorMaker 2 주요 기능:</strong><ul id="14c3a4cc-090a-80ad-8489-d55a242a63f6" class="bulleted-list"><li style="list-style-type:circle"><strong>양방향 복제:</strong> 두 클러스터 간 데이터를 양방향으로 복제 가능.</li></ul><ul id="14c3a4cc-090a-80c5-bc24-cc8f1452d910" class="bulleted-list"><li style="list-style-type:circle"><strong>필터링 및 토픽 선택:</strong> 특정 토픽만 복제하도록 설정 가능.</li></ul><ul id="14c3a4cc-090a-8034-96b7-d534978c6125" class="bulleted-list"><li style="list-style-type:circle"><strong>자동 토픽 생성:</strong> 원본 클러스터의 토픽을 복제 클러스터에서 자동 생성.</li></ul></li></ul><ul id="14c3a4cc-090a-80d5-848b-fbc258034316" class="bulleted-list"><li style="list-style-type:disc"><strong>MirrorMaker 2 구성 예시 (양방향 복제):</strong><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="14c3a4cc-090a-80ef-a155-d3c75d3f1c4c" class="code"><code class="language-YAML" style="white-space:pre-wrap;word-break:break-all">yaml
코드 복사
clusters:
  us:
    bootstrap.servers: us-cluster:9092
  eu:
    bootstrap.servers: eu-cluster:9092

replication.policy.class: &quot;org.apache.kafka.connect.mirror.DefaultReplicationPolicy&quot;
topics: &quot;.*&quot;  # 모든 토픽 복제

</code></pre></li></ul><hr id="14c3a4cc-090a-80ef-a7b8-dace18a857aa"/><h3 id="14c3a4cc-090a-80d8-93a3-f2c9df82aea9" class=""><strong>2.3 데이터 분산 방식</strong></h3><ol type="1" id="14c3a4cc-090a-8092-91c7-f12a2f5e9740" class="numbered-list" start="1"><li><strong>Active-Active 모델</strong><ul id="14c3a4cc-090a-802e-ab8b-f193686924a1" class="bulleted-list"><li style="list-style-type:disc">두 클러스터가 모두 활성 상태로 데이터를 처리.</li></ul><ul id="14c3a4cc-090a-807e-99c3-f130e68abcaa" class="bulleted-list"><li style="list-style-type:disc">각 지역에서 데이터를 생성하고, 상대 클러스터로 복제.</li></ul><ul id="14c3a4cc-090a-805f-ae4b-ca0754324914" class="bulleted-list"><li style="list-style-type:disc"><strong>장점:</strong> 높은 가용성, 지역 데이터 처리.</li></ul><ul id="14c3a4cc-090a-805d-81ea-eed5d8c1af9a" class="bulleted-list"><li style="list-style-type:disc"><strong>단점:</strong> 데이터 충돌 가능성 존재.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80a9-87e3-fa67643c2b68" class="numbered-list" start="2"><li><strong>Active-Passive 모델</strong><ul id="14c3a4cc-090a-8024-ba1e-d60369606282" class="bulleted-list"><li style="list-style-type:disc">한 클러스터는 데이터를 처리(Active), 다른 클러스터는 대기(Passive).</li></ul><ul id="14c3a4cc-090a-80e3-8d32-dfd1c8b2d42c" class="bulleted-list"><li style="list-style-type:disc">복제는 Active에서 Passive로 이루어짐.</li></ul><ul id="14c3a4cc-090a-803d-8ba7-d5ecbdd0db40" class="bulleted-list"><li style="list-style-type:disc"><strong>장점:</strong> 데이터 충돌 문제 없음, 재해 복구에 적합.</li></ul><ul id="14c3a4cc-090a-80f1-8cdf-c05493c18633" class="bulleted-list"><li style="list-style-type:disc"><strong>단점:</strong> Passive 클러스터가 유휴 상태일 수 있음.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-807f-8dd1-e9b395fd6375" class="numbered-list" start="3"><li><strong>Geo-Replication</strong><ul id="14c3a4cc-090a-80f6-bbbc-dd66c1d53ab3" class="bulleted-list"><li style="list-style-type:disc">데이터 센터 간 지리적 복제를 통해 글로벌 분산 처리.</li></ul><ul id="14c3a4cc-090a-8036-a70b-e51674b3ed54" class="bulleted-list"><li style="list-style-type:disc">지역 클러스터에서 데이터를 생성하고, 필요 시 글로벌 데이터 동기화.</li></ul><ul id="14c3a4cc-090a-8062-a039-e8d2c991aaed" class="bulleted-list"><li style="list-style-type:disc"><strong>MirrorMaker 2</strong> 또는 <strong>Confluent Replicator</strong>로 구현.</li></ul></li></ol><hr id="14c3a4cc-090a-809c-9ae1-f9ffe7f857a5"/><h3 id="14c3a4cc-090a-8017-9fe2-e6adc443bc7f" class=""><strong>3. 기술적 고려사항</strong></h3><h3 id="14c3a4cc-090a-809c-b684-d0efe4a25edf" class=""><strong>3.1 네트워크</strong></h3><ul id="14c3a4cc-090a-8068-a6d7-e6e81deba270" class="bulleted-list"><li style="list-style-type:disc">데이터 센터 간 복제 시 대역폭 요구 사항:<ul id="14c3a4cc-090a-8007-b3ad-dbd32130a0e6" class="bulleted-list"><li style="list-style-type:circle">Kafka는 네트워크 대역폭에 민감하므로 고속 전용 회선 필요 (10Gbps 이상 권장).</li></ul></li></ul><ul id="14c3a4cc-090a-8003-9202-fdc26d4c2550" class="bulleted-list"><li style="list-style-type:disc">복제 데이터 압축:<ul id="14c3a4cc-090a-8084-aa69-e221ab7bf3d0" class="bulleted-list"><li style="list-style-type:circle">Kafka의 <strong>lz4</strong> 또는 <strong>zstd</strong> 압축을 사용해 네트워크 부하 감소.</li></ul></li></ul><h3 id="14c3a4cc-090a-802d-9373-f19452efe4a6" class=""><strong>3.2 데이터 정합성</strong></h3><ul id="14c3a4cc-090a-80bf-95b2-e21462d38a20" class="bulleted-list"><li style="list-style-type:disc">클러스터 간 복제 시 데이터 정합성 문제 방지:<ul id="14c3a4cc-090a-8088-9d76-c737d26d6c58" class="bulleted-list"><li style="list-style-type:circle"><strong>일관성 모드:</strong> Ack=all 설정으로 데이터 손실 방지.</li></ul><ul id="14c3a4cc-090a-8047-9753-d6aad92061c1" class="bulleted-list"><li style="list-style-type:circle"><strong>레이지 동기화:</strong> 실시간 동기화 대신 일정 간격으로 복제.</li></ul></li></ul><h3 id="14c3a4cc-090a-80a6-8ca2-f33ef326b5af" class=""><strong>3.3 장애 복구</strong></h3><ul id="14c3a4cc-090a-803a-b907-d126889ea4e9" class="bulleted-list"><li style="list-style-type:disc">Disaster Recovery (DR):<ul id="14c3a4cc-090a-80ed-ae2f-c56fcff57c0a" class="bulleted-list"><li style="list-style-type:circle"><strong>Passive 클러스터 활성화:</strong> Active 클러스터 장애 발생 시, Passive 클러스터로 트래픽 전환.</li></ul><ul id="14c3a4cc-090a-8055-b384-c0d4708f7821" class="bulleted-list"><li style="list-style-type:circle"><strong>복제 지연:</strong> 데이터 손실을 방지하기 위해 최소 2~3초 지연 허용.</li></ul></li></ul><h3 id="14c3a4cc-090a-80c1-be13-f0fdd446d681" class=""><strong>3.4 클러스터 간 데이터 관리</strong></h3><ul id="14c3a4cc-090a-80d7-b921-ffc95e57ff11" class="bulleted-list"><li style="list-style-type:disc"><strong>주요 데이터만 복제:</strong> 모든 데이터를 복제하면 비효율적일 수 있음. 중요한 토픽만 복제.</li></ul><ul id="14c3a4cc-090a-80c0-a9e4-c90843f78d5f" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 TTL 관리:</strong> 오래된 데이터는 로컬 클러스터에서 삭제.</li></ul><hr id="14c3a4cc-090a-8079-8e3f-d32c8c8344d3"/><h3 id="14c3a4cc-090a-80c4-96f3-efc9e375fbde" class=""><strong>4. 멀티 클러스터 설계 예시</strong></h3><h3 id="14c3a4cc-090a-800a-acd4-dbe32d750c8d" class=""><strong>구성 시나리오: 글로벌 데이터 센터</strong></h3><ul id="14c3a4cc-090a-80b0-bd0e-e18a266458b4" class="bulleted-list"><li style="list-style-type:disc"><strong>목표:</strong> 글로벌 서비스 사용자의 데이터를 지역에서 처리하고, 백업 목적으로 다른 지역에 복제.</li></ul><ol type="1" id="14c3a4cc-090a-8019-924e-fc86784bd6c3" class="numbered-list" start="1"><li><strong>북미 클러스터</strong> (us-cluster):<ul id="14c3a4cc-090a-80e5-8409-f50fe8fc3b64" class="bulleted-list"><li style="list-style-type:disc">주요 역할: 북미 사용자 데이터 처리.</li></ul><ul id="14c3a4cc-090a-80ab-96c9-c14e84cda064" class="bulleted-list"><li style="list-style-type:disc">복제 대상: 유럽 및 아시아 클러스터.</li></ul><ul id="14c3a4cc-090a-80cd-b4e6-dece94aca399" class="bulleted-list"><li style="list-style-type:disc">네트워크: 북미-유럽 간 10Gbps, 북미-아시아 간 5Gbps.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-8021-9468-d2008388e2cb" class="numbered-list" start="2"><li><strong>유럽 클러스터</strong> (eu-cluster):<ul id="14c3a4cc-090a-808f-9626-e99767a44733" class="bulleted-list"><li style="list-style-type:disc">주요 역할: 유럽 사용자 데이터 처리.</li></ul><ul id="14c3a4cc-090a-8064-a4e1-c2d1c7fc29ef" class="bulleted-list"><li style="list-style-type:disc">복제 대상: 북미 및 아시아 클러스터.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80bd-82eb-cf118ed6f954" class="numbered-list" start="3"><li><strong>아시아 클러스터</strong> (asia-cluster):<ul id="14c3a4cc-090a-80eb-8e73-d74486f64a35" class="bulleted-list"><li style="list-style-type:disc">주요 역할: 아시아 사용자 데이터 처리.</li></ul><ul id="14c3a4cc-090a-8061-a16d-eabf9d3b0b5b" class="bulleted-list"><li style="list-style-type:disc">복제 대상: 북미 및 유럽 클러스터.</li></ul></li></ol><hr id="14c3a4cc-090a-80fb-9d37-e0ff786f6fc6"/><h3 id="14c3a4cc-090a-802a-b1f2-d4e1aee8d855" class=""><strong>5. 운영 및 모니터링 도구</strong></h3><ol type="1" id="14c3a4cc-090a-806d-a26e-e09f01b601bb" class="numbered-list" start="1"><li><strong>MirrorMaker 2 모니터링</strong><ul id="14c3a4cc-090a-80c5-b2d8-cc9584acc831" class="bulleted-list"><li style="list-style-type:disc">Kafka Connect의 REST API를 통해 복제 상태를 모니터링.</li></ul><ul id="14c3a4cc-090a-80f3-b7e7-e87bab71ccc4" class="bulleted-list"><li style="list-style-type:disc">주요 메트릭:<ul id="14c3a4cc-090a-8057-b4bc-d3baa1663ee1" class="bulleted-list"><li style="list-style-type:circle">Lag (복제 지연 시간)</li></ul><ul id="14c3a4cc-090a-804b-be9d-d3a7f530630c" class="bulleted-list"><li style="list-style-type:circle">Throughput (초당 복제 데이터 양)</li></ul></li></ul></li></ol><ol type="1" id="14c3a4cc-090a-8051-a3cd-f7881e91b042" class="numbered-list" start="2"><li><strong>Kafka 클러스터 모니터링</strong><ul id="14c3a4cc-090a-8054-a92e-d6da131d7a1b" class="bulleted-list"><li style="list-style-type:disc"><strong>Prometheus + Grafana:</strong> 브로커, 파티션, 컨슈머 상태를 시각화.</li></ul><ul id="14c3a4cc-090a-80ef-809d-ff1d0e0c59d2" class="bulleted-list"><li style="list-style-type:disc"><strong>Confluent Control Center:</strong> 클러스터 전반의 메트릭과 복제 상태를 한눈에 확인.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-8076-b434-e9fff59732b0" class="numbered-list" start="3"><li><strong>멀티 클러스터 관리</strong><ul id="14c3a4cc-090a-80a1-afa9-e0011efe66be" class="bulleted-list"><li style="list-style-type:disc"><strong>Kafka Manager:</strong> 브로커와 파티션 리더를 효율적으로 분배.</li></ul><ul id="14c3a4cc-090a-8092-a1b7-f1f153f08c1f" class="bulleted-list"><li style="list-style-type:disc"><strong>Cluster Linking (Confluent):</strong> 클러스터 간 실시간 데이터 공유를 간소화.</li></ul></li></ol><hr id="14c3a4cc-090a-80f5-ab4c-e2358c1127c2"/><h3 id="14c3a4cc-090a-8010-8f69-f4241aa9f360" class=""><strong>결론</strong></h3><p id="14c3a4cc-090a-80bf-bb96-f653310caead" class="">Kafka의 멀티 클러스터 구성은 <strong>MirrorMaker 2</strong>를 통한 복제를 중심으로 이루어지며, 클러스터를 지역, 워크로드, 또는 고객 단위로 분리해 확장성과 안정성을 극대화할 수 있습니다. 네트워크 대역폭과 데이터 정합성을 고려해 Active-Active 또는 Active-Passive 모델을 선택하고, 모니터링 도구를 활용해 운영 효율성을 높이는 것이 핵심입니다.</p><p id="14c3a4cc-090a-805b-8249-f9f8ee060bb8" class="">
</p><p id="14c3a4cc-090a-80c5-b706-d0ea480b50b5" class="">고객별로 Kafka 클러스터를 분리하여 운영하는 경우, <strong>OpenTelemetry</strong>를 통해 데이터 수집 시 대상 Kafka 클러스터를 동적으로 찾아 데이터를 전송해야 합니다. 이를 효율적으로 처리하기 위해 <strong>클러스터 라우팅 전략</strong>과 <strong>동적 구성 방법</strong>을 활용할 수 있습니다.</p><hr id="14c3a4cc-090a-8098-9960-ea0562babfd3"/><h3 id="14c3a4cc-090a-808b-ba8d-fb6ed70587fd" class=""><strong>1. 클러스터 라우팅 전략</strong></h3><h3 id="14c3a4cc-090a-809b-bef7-d56d06af9072" class=""><strong>1.1 고객별 라우팅 정보 저장</strong></h3><ol type="1" id="14c3a4cc-090a-8068-b2aa-f968bccf151a" class="numbered-list" start="1"><li><strong>구성 파일 또는 환경 변수</strong><ul id="14c3a4cc-090a-80f5-b679-d3dc887779a6" class="bulleted-list"><li style="list-style-type:disc">고객 운영 서버에 <strong>Kafka 클러스터 정보</strong>를 환경 변수 또는 설정 파일로 배포.</li></ul><ul id="14c3a4cc-090a-80c2-a914-d7abba8c2429" class="bulleted-list"><li style="list-style-type:disc">예: Kafka 브로커 URL, 토픽 정보, 인증 정보.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-800f-acf4-f646fcc5929c" class="numbered-list" start="2"><li><strong>중앙 서비스 디스커버리 (Service Discovery)</strong><ul id="14c3a4cc-090a-8032-94a2-db85163d3119" class="bulleted-list"><li style="list-style-type:disc"><strong>Consul</strong>, <strong>Etcd</strong>, <strong>Zookeeper</strong> 등을 사용해 고객별 Kafka 클러스터 정보를 저장.</li></ul><ul id="14c3a4cc-090a-809d-bebf-d40d6a614dac" class="bulleted-list"><li style="list-style-type:disc">OpenTelemetry Collector 또는 애플리케이션은 서비스 디스커버리 시스템에서 클러스터 정보를 가져옴.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80b0-9b76-c7be94e2d9de" class="numbered-list" start="3"><li><strong>DNS 기반 라우팅</strong><ul id="14c3a4cc-090a-8026-a305-e9f4c6df4368" class="bulleted-list"><li style="list-style-type:disc">각 Kafka 클러스터에 고유한 DNS 이름을 할당.</li></ul><ul id="14c3a4cc-090a-80ae-af5e-f5390a8fac18" class="bulleted-list"><li style="list-style-type:disc">예: <code>kafka.customer1.example.com</code>, <code>kafka.customer2.example.com</code>.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-80d1-838c-f2473667bf8b" class="numbered-list" start="4"><li><strong>API 기반 동적 라우팅</strong><ul id="14c3a4cc-090a-806a-80e7-fb86cd3a8ef5" class="bulleted-list"><li style="list-style-type:disc">OpenTelemetry Collector가 <strong>API Gateway</strong>를 통해 클러스터 정보를 동적으로 조회.</li></ul><ul id="14c3a4cc-090a-80c7-a286-ebdd0c155bb0" class="bulleted-list"><li style="list-style-type:disc">예: <code>GET /api/kafka-config?customer_id=12345</code></li></ul></li></ol><hr id="14c3a4cc-090a-8072-8ccd-c5864a0aeca0"/><h3 id="14c3a4cc-090a-80a3-9d96-f3e78765b9a7" class=""><strong>1.2 클러스터 선택 방식</strong></h3><ol type="1" id="14c3a4cc-090a-80ab-b03d-f4643c9cc5be" class="numbered-list" start="1"><li><strong>고객 ID 기반 매핑</strong><ul id="14c3a4cc-090a-803a-a740-d1d56e41c89e" class="bulleted-list"><li style="list-style-type:disc">고객 ID 또는 고유 키를 기준으로 Kafka 클러스터를 매핑.</li></ul><ul id="14c3a4cc-090a-8065-a399-f54185d996d8" class="bulleted-list"><li style="list-style-type:disc">예: 고객 ID가 <code>customer1</code>이면 <code>kafka.customer1.example.com</code> 사용.</li></ul></li></ol><ol type="1" id="14c3a4cc-090a-8036-935d-c78255681e20" class="numbered-list" start="2"><li><strong>지역 기반 라우팅</strong><ul id="14c3a4cc-090a-803c-a31d-c7d7f72a7660" class="bulleted-list"><li style="list-style-type:disc">고객 운영 서버가 위치한 지역에 따라 가까운 Kafka 클러스터를 선택.</li></ul><ul id="14c3a4cc-090a-8070-ad06-ff2975a44248" class="bulleted-list"><li style="list-style-type:disc">예:<ul id="14c3a4cc-090a-80b4-9631-d972f7fbcc66" class="bulleted-list"><li style="list-style-type:circle">미국: <code>us-kafka.customer1.example.com</code></li></ul><ul id="14c3a4cc-090a-80d9-a3a1-c55d7a2978bd" class="bulleted-list"><li style="list-style-type:circle">유럽: <code>eu-kafka.customer1.example.com</code></li></ul></li></ul></li></ol><ol type="1" id="14c3a4cc-090a-803e-a5a7-c06c854b3fb4" class="numbered-list" start="3"><li><strong>워크로드 기반 라우팅</strong><ul id="14c3a4cc-090a-80ce-bc73-ee4a7040828e" class="bulleted-list"><li style="list-style-type:disc">로그, 메트릭, 트레이스 데이터를 각각 별도의 Kafka 클러스터로 전송.</li></ul><ul id="14c3a4cc-090a-80dc-9589-dc0bbf45332b" class="bulleted-list"><li style="list-style-type:disc">예:<ul id="14c3a4cc-090a-8020-9ed3-e407a30f8ab2" class="bulleted-list"><li style="list-style-type:circle">로그: <code>log-kafka.customer1.example.com</code></li></ul><ul id="14c3a4cc-090a-80b2-ac58-df346dcb45ea" class="bulleted-list"><li style="list-style-type:circle">메트릭: <code>metrics-kafka.customer1.example.com</code></li></ul><ul id="14c3a4cc-090a-806c-91cc-c9e9b4d062f6" class="bulleted-list"><li style="list-style-type:circle">트레이스: <code>trace-kafka.customer1.example.com</code></li></ul><p id="14c3a4cc-090a-809c-934e-c44d5fed2e7c" class="">
</p></li></ul></li></ol></details></li></ul><ul id="14c3a4cc-090a-80d6-9335-dd8a0cb130ee" class="toggle"><li><details open=""><summary>Next Observability 플랫폼 구축</summary><ol type="1" id="14c3a4cc-090a-8036-a7ab-c4f36801ff9f" class="numbered-list" start="1"><li>설계 가이드<ul id="14c3a4cc-090a-80c0-8aa1-e97e2207e845" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 수집 통합</strong>: OpenTelemetry를 사용하여 메트릭, 로그, 트레이스 데이터를 애플리케이션 및 인프라에서 통합적으로 수집</li></ul><ul id="14c3a4cc-090a-80c1-88ea-e1c4a1008930" class="bulleted-list"><li style="list-style-type:disc"><strong>대규모 트래픽을 고려한 메시징 인프라</strong>: 대용량 데이터를 처리하기 위해 Message Queue (Kafka) 서비스 적용 및 확장 가능한 데이터 파이프라인 구성</li></ul><ul id="14c3a4cc-090a-80ac-a1a1-ddb7be34564e" class="bulleted-list"><li style="list-style-type:disc"><strong>고성능 데이터베이스</strong>: 메트릭은 시계열 데이터베이스(Prometheus), 로그는 검색 데이터베이스(Elasticsearch, Loki), 트레이스는 분산 트레이싱 데이터베이스(Jaeger, Tempo)에 저장</li></ul><ul id="14c3a4cc-090a-80df-b983-d7d50cbcfb01" class="bulleted-list"><li style="list-style-type:disc"><strong>저장 공간의 비용 효율성과 확장성</strong>: 객체 스토리지(AWS S3, GCS 등)를 통합하여 장기 보존 데이터를 효율적으로 저장하며, 클라우드 네이티브 설계로 무한 확장 가능하도록 구성</li></ul><ul id="14c3a4cc-090a-8038-ab7d-f3feda91fa23" class="bulleted-list"><li style="list-style-type:disc"><strong>멀티 클러스터 구조를 통한 확장성 및 안정성</strong>: 각각의 클러스터를 서비스 간 공유하지 않고 고객/지역별로 격리하여 확장성과 안정성 강화 </li></ul><ul id="14c3a4cc-090a-80b6-a3de-c6cce0c7c8d7" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 연동 및 활용성 지원</strong>: 수집 데이터에 대한 내/외부 서비스 연동/분석 지원</li></ul></li></ol><p id="14c3a4cc-090a-802f-aedc-fb83ede60d11" class="">
</p><ol type="1" id="14c3a4cc-090a-80f4-83a0-fc72593a00cc" class="numbered-list" start="2"><li>시스템 구성</li></ol><p id="14c3a4cc-090a-8095-a8cf-c9e142f0307a" class="">
</p></details></li></ul><ul id="1423a4cc-090a-8087-8c74-d123d17f70af" class="toggle"><li><details open=""><summary>AWS Observability Architecture</summary><ul id="1423a4cc-090a-8029-b694-d0e97a55285a" class="bulleted-list"><li style="list-style-type:disc">AWS : <a href="https://www.youtube.com/watch?v=-uWq6W-rD9k&amp;t=103s">https://www.youtube.com/watch?v=-uWq6W-rD9k&amp;t=103s</a><figure id="1423a4cc-090a-80aa-a4fa-c17cf38e3799" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.29.08.png"><img style="width:652.0028076171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.29.08.png"/></a></figure><figure id="1423a4cc-090a-80c9-b27d-ca0a7d5e13ec" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.33.14.png"><img style="width:652.0028076171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.33.14.png"/></a></figure><figure id="1423a4cc-090a-808c-91bc-f6438f2f2e14" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.39.27.png"><img style="width:707.9900512695312px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.39.27.png"/></a></figure><figure id="1423a4cc-090a-80e2-b260-d03097d25448" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.40.17.png"><img style="width:652.0028076171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.40.17.png"/></a></figure><figure id="1423a4cc-090a-80fd-9b13-ee5119f92ab0" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.44.00.png"><img style="width:652.0170288085938px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.44.00.png"/></a></figure><figure id="1423a4cc-090a-8037-b180-cfda5ee2501d" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.45.26.png"><img style="width:652.0099487304688px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.45.26.png"/></a></figure><figure id="1423a4cc-090a-8051-8350-f2bd805b4f8e" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.36.30.png"><img style="width:652.0099487304688px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_7.36.30.png"/></a></figure><p id="1423a4cc-090a-80b8-b08b-e6ee16038b8a" class="">
</p><p id="1423a4cc-090a-80ea-929e-c2bc0f71ca17" class="">AWS CloudWatch는 <strong>메트릭, 로그, 트레이스</strong>를 각각 수집, 처리, 저장, 분석, 시각화하는 종합적인 Observability 서비스를 제공합니다. 아래에 각 데이터 유형별 워크플로와 <strong>트래픽 급증 대응</strong> 및 <strong>대용량 트래픽 데이터 처리</strong>를 위한 기술 스택과 구조를 설명합니다.</p><figure id="1433a4cc-090a-80fa-832d-ed82666ad088" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.08.26.png"><img style="width:2106px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-11-19_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_10.08.26.png"/></a></figure><p id="1433a4cc-090a-8014-bdef-c0336fd20943" class="">
</p><hr id="1423a4cc-090a-805e-b05b-d454a53bb1b9"/><h2 id="1423a4cc-090a-8085-9aa1-dbf541927790" class=""><strong>1. CloudWatch의 Observability 시스템 구성</strong></h2><p id="1423a4cc-090a-803a-a227-c1ebba2c8c31" class="">AWS CloudWatch는 다음과 같은 데이터를 처리합니다:</p><ul id="1423a4cc-090a-80eb-993a-ec75eddab252" class="bulleted-list"><li style="list-style-type:circle"><strong>메트릭</strong>: AWS 서비스와 사용자 정의 메트릭 데이터를 수집.</li></ul><ul id="1423a4cc-090a-8009-bc11-d083e5487499" class="bulleted-list"><li style="list-style-type:circle"><strong>로그</strong>: 애플리케이션, 인프라, 사용자 정의 로그.</li></ul><ul id="1423a4cc-090a-80cf-8d5f-c648611b31e5" class="bulleted-list"><li style="list-style-type:circle"><strong>트레이스</strong>: AWS X-Ray와 통합하여 분산 트랜잭션 추적.</li></ul><h3 id="1423a4cc-090a-80cc-8100-efc3d7bfad6e" class=""><strong>구조 요약</strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1423a4cc-090a-8092-b1c5-c3aa3befb380" class="code"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">수집 → 처리 → 저장 → 분석 및 시각화</code></pre><hr id="1423a4cc-090a-800c-8591-ed74ec47d483"/><h3 id="1423a4cc-090a-809f-9545-d3f450211273" class=""><strong>1.1. 메트릭 (Metrics)</strong></h3><h3 id="1423a4cc-090a-80c4-859c-ffe176f15289" class=""><strong>수집</strong></h3><ul id="1423a4cc-090a-8010-9273-c6412d72a7fe" class="bulleted-list"><li style="list-style-type:circle">AWS 서비스에서 기본적으로 메트릭 데이터를 CloudWatch로 전송:<ul id="1423a4cc-090a-80fa-8078-d0a4b28eaf13" class="bulleted-list"><li style="list-style-type:square">EC2, Lambda, RDS, S3 등 AWS 리소스의 상태 및 성능 데이터를 자동 수집.</li></ul></li></ul><ul id="1423a4cc-090a-804c-a3e1-d0ddef75a15d" class="bulleted-list"><li style="list-style-type:circle">사용자 정의 메트릭:<ul id="1423a4cc-090a-8053-8c54-c3ddf7f3a642" class="bulleted-list"><li style="list-style-type:square">애플리케이션이 <strong>CloudWatch Agent</strong> 또는 <strong>CloudWatch API</strong>를 통해 커스텀 메트릭을 CloudWatch로 전송.</li></ul></li></ul><h3 id="1423a4cc-090a-8006-a47f-d7a6b83e2523" class=""><strong>처리</strong></h3><ul id="1423a4cc-090a-809f-8681-c217ff8b9b59" class="bulleted-list"><li style="list-style-type:circle">메트릭 데이터는 AWS의 분산 처리 시스템에서 처리되며, 데이터는 시간별로 집계하여 저장.</li></ul><h3 id="1423a4cc-090a-8031-9efd-d1bdda691420" class=""><strong>저장</strong></h3><ul id="1423a4cc-090a-80cd-8933-db4bb1fb79c5" class="bulleted-list"><li style="list-style-type:circle">메트릭은 <strong>CloudWatch Metrics Database</strong>에 저장.<ul id="1423a4cc-090a-8097-a965-e6eaf067d852" class="bulleted-list"><li style="list-style-type:square">AWS의 전용 분산형 NoSQL 데이터베이스를 사용하여 시간 단위로 데이터를 관리.</li></ul><ul id="1423a4cc-090a-80a9-96c7-d1b0d8589255" class="bulleted-list"><li style="list-style-type:square">최대 15개월 동안 데이터를 저장.</li></ul></li></ul><h3 id="1423a4cc-090a-8065-8ee8-e7c5e3a2180a" class=""><strong>분석 및 시각화</strong></h3><ul id="1423a4cc-090a-80cf-b13b-ecc71af7bce5" class="bulleted-list"><li style="list-style-type:circle"><strong>CloudWatch 대시보드</strong>:<ul id="1423a4cc-090a-8034-9724-e3551b64f352" class="bulleted-list"><li style="list-style-type:square">메트릭 데이터를 시각화하고 애플리케이션 성능을 모니터링.</li></ul></li></ul><ul id="1423a4cc-090a-8031-acf4-e931f757dc74" class="bulleted-list"><li style="list-style-type:circle"><strong>Alarms</strong>:<ul id="1423a4cc-090a-8008-914e-c16b53b630ec" class="bulleted-list"><li style="list-style-type:square">특정 임계값을 초과하면 알람을 생성하여 SNS를 통해 알림 전송.</li></ul></li></ul><hr id="1423a4cc-090a-80eb-87c6-fc1ff224a6a6"/><h3 id="1423a4cc-090a-80ef-b2ae-fa011d391049" class=""><strong>1.2. 로그 (Logs)</strong></h3><h3 id="1423a4cc-090a-80f0-a4bc-d302ce8815d1" class=""><strong>수집</strong></h3><ul id="1423a4cc-090a-809b-b021-c5773ad3bdb7" class="bulleted-list"><li style="list-style-type:circle"><strong>CloudWatch Logs Agent</strong> 또는 <strong>CloudWatch Agent</strong>를 통해 로그 수집:<ul id="1423a4cc-090a-80d8-b083-edebcc8763b2" class="bulleted-list"><li style="list-style-type:square">애플리케이션, OS 로그, 사용자 정의 로그를 수집.</li></ul></li></ul><ul id="1423a4cc-090a-8009-b28f-dec3968dafae" class="bulleted-list"><li style="list-style-type:circle">AWS 서비스 로그 통합:<ul id="1423a4cc-090a-804c-a148-ddd8e4c53b82" class="bulleted-list"><li style="list-style-type:square">Lambda, API Gateway, VPC Flow Logs 등에서 자동 로그 수집.</li></ul></li></ul><h3 id="1423a4cc-090a-8017-b3ff-f33b51ae519e" class=""><strong>처리</strong></h3><ul id="1423a4cc-090a-80b7-9735-c5ccde5bfcd4" class="bulleted-list"><li style="list-style-type:circle">로그는 실시간으로 수집되어 <strong>CloudWatch Logs Insights</strong>를 통해 검색 및 분석 가능.</li></ul><ul id="1423a4cc-090a-8048-9076-d0e4a808dfbf" class="bulleted-list"><li style="list-style-type:circle"><strong>필터링</strong>:<ul id="1423a4cc-090a-8038-a4c1-e1d6a94aaf4d" class="bulleted-list"><li style="list-style-type:square">메트릭 필터를 적용하여 특정 이벤트를 감지.</li></ul></li></ul><h3 id="1423a4cc-090a-80d5-a196-de5e0275f9b4" class=""><strong>저장</strong></h3><ul id="1423a4cc-090a-80c9-b8e5-ed86b842801a" class="bulleted-list"><li style="list-style-type:circle">로그 데이터는 <strong>CloudWatch Logs Storage</strong>에 저장.<ul id="1423a4cc-090a-80ad-9b0f-c6b91c702f52" class="bulleted-list"><li style="list-style-type:square">로그 그룹과 로그 스트림으로 분리하여 관리.</li></ul><ul id="1423a4cc-090a-80ee-85f0-c2fcda5c9bb9" class="bulleted-list"><li style="list-style-type:square">보존 기간은 기본값 30일, 최대 영구 보관 설정 가능.</li></ul></li></ul><h3 id="1423a4cc-090a-8076-b871-e4715016f404" class=""><strong>분석 및 시각화</strong></h3><ul id="1423a4cc-090a-80ea-b267-dc23b6ba2089" class="bulleted-list"><li style="list-style-type:circle"><strong>CloudWatch Logs Insights</strong>:<ul id="1423a4cc-090a-805f-9897-c617c5cf16e3" class="bulleted-list"><li style="list-style-type:square">로그 데이터를 쿼리하여 분석.</li></ul></li></ul><ul id="1423a4cc-090a-80bd-a1e8-f8806e3a7499" class="bulleted-list"><li style="list-style-type:circle"><strong>CloudWatch 대시보드</strong>:<ul id="1423a4cc-090a-8046-82ef-fa7707ff1e91" class="bulleted-list"><li style="list-style-type:square">로그 데이터를 대시보드에서 시각화.</li></ul></li></ul><hr id="1423a4cc-090a-8047-ad56-d7b9d8c9fdf7"/><h3 id="1423a4cc-090a-80ba-8b0b-c7dde859abf6" class=""><strong>1.3. 트레이스 (Traces)</strong></h3><h3 id="1423a4cc-090a-8016-ad0c-e41d378fde91" class=""><strong>수집</strong></h3><ul id="1423a4cc-090a-80af-a718-d8d54cdb1cb4" class="bulleted-list"><li style="list-style-type:circle">AWS X-Ray와 통합:<ul id="1423a4cc-090a-80a3-ae13-efd45bd254d4" class="bulleted-list"><li style="list-style-type:square">애플리케이션의 요청 경로 및 호출 관계를 추적.</li></ul><ul id="1423a4cc-090a-8024-85c5-cc7ef50232ee" class="bulleted-list"><li style="list-style-type:square">X-Ray SDK를 사용해 애플리케이션에 트레이스 기능 추가.</li></ul></li></ul><h3 id="1423a4cc-090a-80f1-a70a-e5e707b5cd81" class=""><strong>처리</strong></h3><ul id="1423a4cc-090a-80b9-a3a4-ec325f25f406" class="bulleted-list"><li style="list-style-type:circle">트레이스는 X-Ray의 분산 처리 시스템에서 처리:<ul id="1423a4cc-090a-80a3-aaa6-e3b5cf523a8a" class="bulleted-list"><li style="list-style-type:square">트랜잭션 데이터는 AWS 내부 네트워크로 전송.</li></ul><ul id="1423a4cc-090a-8004-b056-daa6aa5ba43e" class="bulleted-list"><li style="list-style-type:square">서비스 간 호출 지연 및 병목현상을 감지.</li></ul></li></ul><h3 id="1423a4cc-090a-8027-9a42-d7dd924a8560" class=""><strong>저장</strong></h3><ul id="1423a4cc-090a-809d-b8f5-e6c3b4e89830" class="bulleted-list"><li style="list-style-type:circle">트레이스 데이터는 X-Ray 전용 데이터베이스에 저장:<ul id="1423a4cc-090a-80c9-be4d-e4c1e1c2f712" class="bulleted-list"><li style="list-style-type:square">트랜잭션 데이터를 위한 DynamoDB와 같은 고성능 스토리지 사용.</li></ul></li></ul><h3 id="1423a4cc-090a-8079-918f-f4ee10812607" class=""><strong>분석 및 시각화</strong></h3><ul id="1423a4cc-090a-8090-9469-fee816c5a707" class="bulleted-list"><li style="list-style-type:circle"><strong>X-Ray Console</strong>:<ul id="1423a4cc-090a-8043-98f2-cacbe55b66fa" class="bulleted-list"><li style="list-style-type:square">서비스 호출 맵(Service Map)으로 호출 관계와 성능 병목을 시각화.</li></ul></li></ul><ul id="1423a4cc-090a-8054-919a-e5b471e23ee1" class="bulleted-list"><li style="list-style-type:circle"><strong>CloudWatch ServiceLens</strong>:<ul id="1423a4cc-090a-8037-a68d-d45920a9a8e2" class="bulleted-list"><li style="list-style-type:square">메트릭, 로그, 트레이스를 통합하여 분석.</li></ul></li></ul><hr id="1423a4cc-090a-8008-bd17-c6304bb994df"/><h2 id="1423a4cc-090a-80b5-9b38-e1dc973b46cd" class=""><strong>2. 트래픽 급증 및 대용량 데이터 처리</strong></h2><p id="1423a4cc-090a-8070-8b02-ccf51686952b" class="">AWS CloudWatch는 트래픽 급증 및 대규모 데이터를 처리하기 위해 다음 기술을 활용합니다:</p><h3 id="1423a4cc-090a-8035-9144-c4e07a2aabbb" class=""><strong>2.1. 트래픽 급증 문제 대응</strong></h3><ol type="1" id="1423a4cc-090a-8078-9e6b-ef9521546ec7" class="numbered-list" start="1"><li><strong>분산 처리 아키텍처</strong>:<ul id="1423a4cc-090a-8062-8ce5-d5eb200aa36b" class="bulleted-list"><li style="list-style-type:disc">메트릭, 로그, 트레이스 데이터를 AWS의 글로벌 분산 인프라에서 처리.</li></ul><ul id="1423a4cc-090a-80d8-aa82-f45698db2c8e" class="bulleted-list"><li style="list-style-type:disc">수집부터 저장까지 고도로 병렬화된 처리 구조를 사용.</li></ul></li></ol><ol type="1" id="1423a4cc-090a-8081-9155-d9c477a33cb8" class="numbered-list" start="2"><li><strong>데이터 버퍼링 및 큐잉</strong>:<ul id="1423a4cc-090a-80d5-9f1a-ce54b5a99ceb" class="bulleted-list"><li style="list-style-type:disc"><strong>Amazon Kinesis Data Firehose</strong>를 사용해 로그 및 메트릭 데이터를 일시적으로 버퍼링하여 처리 병목을 완화.</li></ul></li></ol><ol type="1" id="1423a4cc-090a-8029-b4d8-fb0a8eb027fa" class="numbered-list" start="3"><li><strong>자동 확장 (Auto Scaling)</strong>:<ul id="1423a4cc-090a-809c-b7ae-e80f98f09c8a" class="bulleted-list"><li style="list-style-type:disc">CloudWatch Agent 및 X-Ray Daemon이 트래픽에 따라 자동으로 스케일링.</li></ul></li></ol><ol type="1" id="1423a4cc-090a-80d6-ad7a-ea966e4a74c0" class="numbered-list" start="4"><li><strong>저장소의 확장성</strong>:<ul id="1423a4cc-090a-802d-9503-e8176134e8aa" class="bulleted-list"><li style="list-style-type:disc">로그: Amazon S3, Glacier와 통합하여 오래된 로그 데이터를 아카이브.</li></ul><ul id="1423a4cc-090a-8005-947e-de5f6202ccb2" class="bulleted-list"><li style="list-style-type:disc">메트릭: Amazon S3와 통합된 장기 보관 기능(예: CloudWatch Metrics Retention).</li></ul></li></ol><hr id="1423a4cc-090a-801a-a93f-c34446e1d4dd"/><h3 id="1423a4cc-090a-80d1-8883-e34bf6d6c425" class=""><strong>2.2. 대용량 데이터 관리</strong></h3><ol type="1" id="1423a4cc-090a-802c-a150-c7c4bf6d80d9" class="numbered-list" start="1"><li><strong>데이터 압축 및 최적화</strong>:<ul id="1423a4cc-090a-8035-b50a-c2c47d32398d" class="bulleted-list"><li style="list-style-type:disc">CloudWatch Logs는 데이터를 압축하여 저장.</li></ul><ul id="1423a4cc-090a-80e1-aa02-f76f1c2cba15" class="bulleted-list"><li style="list-style-type:disc">데이터 검색 시 인덱싱 구조로 빠른 검색을 지원.</li></ul></li></ol><ol type="1" id="1423a4cc-090a-80f8-a249-e558f64e5822" class="numbered-list" start="2"><li><strong>장기 보관 및 아카이빙</strong>:<ul id="1423a4cc-090a-806c-a346-edb28b0d5f64" class="bulleted-list"><li style="list-style-type:disc"><strong>CloudWatch Logs Insights Export</strong>:<ul id="1423a4cc-090a-8097-8e25-f85f31969058" class="bulleted-list"><li style="list-style-type:circle">로그 데이터를 S3로 내보내 장기 보관.</li></ul></li></ul><ul id="1423a4cc-090a-80f8-a8ba-e155909edef3" class="bulleted-list"><li style="list-style-type:disc"><strong>Glacier</strong>:<ul id="1423a4cc-090a-80d8-9459-e93d4adda22c" class="bulleted-list"><li style="list-style-type:circle">저비용 아카이브 스토리지로 오래된 데이터를 이동.</li></ul></li></ul></li></ol><ol type="1" id="1423a4cc-090a-800e-8957-d8ddd212c097" class="numbered-list" start="3"><li><strong>지표 데이터의 집계</strong>:<ul id="1423a4cc-090a-803c-85ec-cb3e510177c1" class="bulleted-list"><li style="list-style-type:disc">메트릭 데이터는 시간별 집계(Aggregation)를 통해 저장소 부담을 줄임.</li></ul></li></ol><ol type="1" id="1423a4cc-090a-80a3-8627-f9701008292c" class="numbered-list" start="4"><li><strong>다계층 저장소 구조</strong>:<ul id="1423a4cc-090a-8054-b74d-d2258d2c94ae" class="bulleted-list"><li style="list-style-type:disc">로그 및 메트릭 데이터는 자주 사용되는 데이터와 덜 사용되는 데이터를 분리하여 관리:<ul id="1423a4cc-090a-80b9-b4b4-c382452218e1" class="bulleted-list"><li style="list-style-type:circle"><strong>Hot Storage</strong>: 최신 및 자주 액세스되는 데이터.</li></ul><ul id="1423a4cc-090a-804f-8ada-e0e830ca0940" class="bulleted-list"><li style="list-style-type:circle"><strong>Cold Storage</strong>: 오래된 데이터.</li></ul></li></ul></li></ol><hr id="1423a4cc-090a-80d6-a866-c7fd05dc5206"/><h2 id="1423a4cc-090a-809e-ad9d-ca31876f9786" class=""><strong>3. CloudWatch Observability 기술 스택</strong></h2><h3 id="1423a4cc-090a-809f-aed5-e312ed8ec3b1" class="">주요 기술 및 서비스:</h3><ul id="1423a4cc-090a-8099-8aaa-d269761c3018" class="bulleted-list"><li style="list-style-type:circle"><strong>수집</strong>:<ul id="1423a4cc-090a-805b-8676-c73dab8afd54" class="bulleted-list"><li style="list-style-type:square">CloudWatch Agent (메트릭, 로그).</li></ul><ul id="1423a4cc-090a-80c9-8f57-ca47265baf96" class="bulleted-list"><li style="list-style-type:square">X-Ray Daemon (트레이스).</li></ul></li></ul><ul id="1423a4cc-090a-808b-9964-e44a38a566cc" class="bulleted-list"><li style="list-style-type:circle"><strong>처리</strong>:<ul id="1423a4cc-090a-8072-9538-e08a2df895ae" class="bulleted-list"><li style="list-style-type:square">CloudWatch Logs Insights.</li></ul><ul id="1423a4cc-090a-8029-a77b-cac2d9242e48" class="bulleted-list"><li style="list-style-type:square">Kinesis Data Firehose (버퍼링).</li></ul></li></ul><ul id="1423a4cc-090a-8003-9e73-ebca594e6bf5" class="bulleted-list"><li style="list-style-type:circle"><strong>저장</strong>:<ul id="1423a4cc-090a-808b-8365-d4a0c32854d0" class="bulleted-list"><li style="list-style-type:square">CloudWatch Metrics Database (메트릭).</li></ul><ul id="1423a4cc-090a-80bc-9dda-ff7d31c06d7d" class="bulleted-list"><li style="list-style-type:square">CloudWatch Logs Storage (로그).</li></ul><ul id="1423a4cc-090a-8035-a959-e44f94f5494c" class="bulleted-list"><li style="list-style-type:square">DynamoDB, S3, Glacier (트레이스 및 장기 보관).</li></ul></li></ul><ul id="1423a4cc-090a-80c6-9701-e23982374261" class="bulleted-list"><li style="list-style-type:circle"><strong>분석/시각화</strong>:<ul id="1423a4cc-090a-80e7-be92-d4feee7afc48" class="bulleted-list"><li style="list-style-type:square">CloudWatch Dashboards (통합 분석).</li></ul><ul id="1423a4cc-090a-80ce-a923-fffc71be9644" class="bulleted-list"><li style="list-style-type:square">X-Ray Console (트레이스 분석).</li></ul><ul id="1423a4cc-090a-8070-8050-dfe023e812b9" class="bulleted-list"><li style="list-style-type:square">CloudWatch ServiceLens (메트릭, 로그, 트레이스 통합).</li></ul></li></ul><hr id="1423a4cc-090a-80b8-9400-cc002d43a74e"/><p id="1423a4cc-090a-801e-969d-f60bf58127cd" class="">AWS CloudWatch는 <strong>분산 처리, 자동 확장, 다계층 스토리지</strong>를 통해 대규모 트래픽과 데이터 급증을 효과적으로 처리하며, AWS의 고성능 인프라와 네이티브 통합 기능을 최대한 활용합니다. 추가 질문이 있다면 말씀해주세요!</p><p id="1433a4cc-090a-803c-9885-faa9fe7e20ab" class="">
</p><p id="1433a4cc-090a-806d-be45-ff28cc32f195" class="">AWS CloudWatch와 X-Ray는 다양한 Observability 서비스를 제공합니다. 여기에서는 요청한 세부 서비스들에 대해 <strong>계위</strong>, <strong>특성</strong>, <strong>제공 기능</strong>을 중심으로 정리하겠습니다.</p><hr id="1433a4cc-090a-8041-a3e9-f30fddba317b"/><h2 id="1433a4cc-090a-80ad-a5a7-e4f76eeff50f" class=""><strong>1. X-Ray Traces</strong></h2><h3 id="1433a4cc-090a-8070-a638-f063c9fe128c" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-8050-a7c9-dc8f1bc278b5" class="bulleted-list"><li style="list-style-type:circle"><strong>트레이싱 서비스</strong>: 분산 애플리케이션의 요청 흐름을 추적하는 데 사용.</li></ul><h3 id="1433a4cc-090a-80da-84b4-d8999fe8b9d4" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-80d4-adef-e356437a1834" class="bulleted-list"><li style="list-style-type:circle">AWS Lambda, API Gateway, ECS, EC2와 같은 다양한 AWS 서비스에서 분산 트레이스 데이터를 수집.</li></ul><ul id="1433a4cc-090a-8007-9c2a-cf92b37938a4" class="bulleted-list"><li style="list-style-type:circle">서비스의 병목현상, 오류 지점 등을 시각적으로 표시.</li></ul><h3 id="1433a4cc-090a-8029-bf9a-dca3a2e28ec1" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-809a-b290-e2186a5907cc" class="bulleted-list"><li style="list-style-type:circle">트랜잭션 추적: 사용자 요청의 전체 흐름 추적.</li></ul><ul id="1433a4cc-090a-8040-9141-e31a7dc2b2bc" class="bulleted-list"><li style="list-style-type:circle">서비스 맵 생성: 애플리케이션 아키텍처를 시각적으로 표시.</li></ul><ul id="1433a4cc-090a-8066-8201-e05191aa0514" class="bulleted-list"><li style="list-style-type:circle">레이턴시 분석: 호출 경로의 성능 문제를 식별.</li></ul><hr id="1433a4cc-090a-80e5-b07c-ff733dd827b5"/><h2 id="1433a4cc-090a-809f-abfd-ca632c23d085" class=""><strong>2. X-Ray Analytics</strong></h2><h3 id="1433a4cc-090a-8037-839c-d2e1d601c95c" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-8096-aa91-f360a6ecdb2e" class="bulleted-list"><li style="list-style-type:circle"><strong>고급 트레이스 분석 도구</strong>: X-Ray 데이터 기반의 심층 분석을 제공.</li></ul><h3 id="1433a4cc-090a-8094-ba23-d6356de68427" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-80ad-ba5d-dfbdeb558dcd" class="bulleted-list"><li style="list-style-type:circle">다중 요청에서 패턴, 경향, 이상 탐지를 지원.</li></ul><ul id="1433a4cc-090a-8050-aba2-fb9cd3e62b1c" class="bulleted-list"><li style="list-style-type:circle">특정 시간 범위나 조건에서 성능 문제를 자동으로 분석.</li></ul><h3 id="1433a4cc-090a-8043-9d90-ec927471aa8d" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-8005-9d85-dbba13020ff2" class="bulleted-list"><li style="list-style-type:circle">트레이스 필터링: 지연 시간, 오류, 상태 코드 기준으로 필터링.</li></ul><ul id="1433a4cc-090a-8079-a813-f9c2e986d783" class="bulleted-list"><li style="list-style-type:circle">성능 경향 분석: 지속적인 성능 문제를 시각화.</li></ul><ul id="1433a4cc-090a-80ba-a287-e952b693e838" class="bulleted-list"><li style="list-style-type:circle">통합 대시보드: CloudWatch ServiceLens와 연결해 전반적인 상태 확인.</li></ul><hr id="1433a4cc-090a-808e-b746-f5bf6d56fd45"/><h2 id="1433a4cc-090a-8045-9068-f85b25119f8e" class=""><strong>3. CloudWatch Logs</strong></h2><h3 id="1433a4cc-090a-80c2-9d0b-d0c582e0b261" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-80e1-a07a-f2276988e8b8" class="bulleted-list"><li style="list-style-type:circle"><strong>중앙 로그 저장소</strong>: 애플리케이션 및 AWS 리소스 로그 데이터를 수집, 저장, 검색.</li></ul><h3 id="1433a4cc-090a-8005-ac5c-d990c3e1d94c" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-8096-981a-c4d0ac4e7854" class="bulleted-list"><li style="list-style-type:circle">EC2, Lambda, API Gateway, CloudTrail 등에서 로그를 자동으로 수집.</li></ul><ul id="1433a4cc-090a-805f-ac7f-f71122e75df4" class="bulleted-list"><li style="list-style-type:circle">다양한 데이터 형식을 지원(JSON, 텍스트 로그 등).</li></ul><h3 id="1433a4cc-090a-80ea-a636-c58abf9f96e1" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-8057-9b75-c68a3ba6c7f5" class="bulleted-list"><li style="list-style-type:circle">로그 그룹 관리: 유사한 로그를 그룹화.</li></ul><ul id="1433a4cc-090a-8016-a4d4-e19739cec974" class="bulleted-list"><li style="list-style-type:circle">보존 정책: 로그 데이터의 저장 기간 설정.</li></ul><ul id="1433a4cc-090a-8088-b541-d86c9c002b8f" class="bulleted-list"><li style="list-style-type:circle">실시간 모니터링: 로그 스트림을 통해 실시간 데이터 확인.</li></ul><hr id="1433a4cc-090a-8035-ba07-cc70276defa7"/><h2 id="1433a4cc-090a-80c4-ac8c-c8d6f70bc357" class=""><strong>4. Logs Insights</strong></h2><h3 id="1433a4cc-090a-8067-96d5-c0525ee18f92" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-8086-8e5c-ce7bfd4da46a" class="bulleted-list"><li style="list-style-type:circle"><strong>로그 분석 도구</strong>: CloudWatch Logs 데이터를 SQL 유사한 언어로 분석.</li></ul><h3 id="1433a4cc-090a-800a-bcb8-f049fb279cf1" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-8060-a9c5-f4178232cded" class="bulleted-list"><li style="list-style-type:circle">쿼리를 사용하여 로그 데이터를 검색, 분석.</li></ul><ul id="1433a4cc-090a-80cb-bdc9-d8a571ddd071" class="bulleted-list"><li style="list-style-type:circle">결과를 대시보드 형태로 시각화 가능.</li></ul><h3 id="1433a4cc-090a-80b1-8d11-e203e21e96f8" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-80f6-a250-ed3c10c70beb" class="bulleted-list"><li style="list-style-type:circle">쿼리 인터페이스: 필터링 및 데이터 집계.</li></ul><ul id="1433a4cc-090a-805d-92b3-c87548782e14" class="bulleted-list"><li style="list-style-type:circle">성능 최적화: 수백만 개의 로그 이벤트에서 신속한 결과 제공.</li></ul><ul id="1433a4cc-090a-8096-8254-d0e23759bf17" class="bulleted-list"><li style="list-style-type:circle">대시보드 통합: Logs Insights 결과를 CloudWatch 대시보드에 추가.</li></ul><hr id="1433a4cc-090a-8025-8d00-fd72223f0edc"/><h2 id="1433a4cc-090a-8010-a9f8-d77846f829ab" class=""><strong>5. CloudWatch Metrics</strong></h2><h3 id="1433a4cc-090a-800f-85a8-d983ad00ee8b" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-80ba-b7a1-f8f4a3e8c39e" class="bulleted-list"><li style="list-style-type:circle"><strong>메트릭 모니터링 서비스</strong>: AWS 리소스와 사용자 정의 메트릭 수집.</li></ul><h3 id="1433a4cc-090a-8013-80b7-c54dda3398c4" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-80b9-b16d-d5cc59be36c3" class="bulleted-list"><li style="list-style-type:circle">AWS 서비스에서 자동으로 생성되는 메트릭 제공.</li></ul><ul id="1433a4cc-090a-80e0-b2e0-f458c3ce8306" class="bulleted-list"><li style="list-style-type:circle">사용자 정의 메트릭을 API를 통해 전송 가능.</li></ul><h3 id="1433a4cc-090a-8095-bde5-faf630a7b691" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-802f-94b6-f3f4507f4389" class="bulleted-list"><li style="list-style-type:circle">알람 생성: 특정 메트릭 조건에서 알림 전송.</li></ul><ul id="1433a4cc-090a-80aa-9295-d96b72630ec6" class="bulleted-list"><li style="list-style-type:circle">실시간 모니터링: 애플리케이션 성능 및 리소스 사용량 추적.</li></ul><ul id="1433a4cc-090a-802f-81de-fd73b2fd9beb" class="bulleted-list"><li style="list-style-type:circle">데이터 집계: 초당 데이터부터 월 단위까지 집계 가능.</li></ul><hr id="1433a4cc-090a-80fc-af2f-d335aa5534e1"/><h2 id="1433a4cc-090a-801d-aac8-e9416cd58933" class=""><strong>6. Metrics Explorer</strong></h2><h3 id="1433a4cc-090a-80d1-8621-de841ee8423d" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-809c-bd1d-c00a077f34d3" class="bulleted-list"><li style="list-style-type:circle"><strong>메트릭 탐색 도구</strong>: 메트릭 데이터를 그룹화하여 시각적으로 탐색.</li></ul><h3 id="1433a4cc-090a-8012-9417-eecb1d151341" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-803f-8f1a-f9c497f2ae13" class="bulleted-list"><li style="list-style-type:circle">대규모 메트릭 데이터를 빠르게 탐색.</li></ul><ul id="1433a4cc-090a-8045-9046-e92aec8b65bc" class="bulleted-list"><li style="list-style-type:circle">실시간 또는 과거 데이터를 기반으로 필터링 가능.</li></ul><h3 id="1433a4cc-090a-80cd-8efa-e8e2cf5343e7" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-8067-a635-f1eb3ddd0f49" class="bulleted-list"><li style="list-style-type:circle">메트릭 그룹화: AWS 서비스, 태그, 리소스 유형 기준.</li></ul><ul id="1433a4cc-090a-80f6-ae6a-e3171aeaa185" class="bulleted-list"><li style="list-style-type:circle">조건 검색: 임계값 초과 메트릭 식별.</li></ul><ul id="1433a4cc-090a-80e6-aa34-da96489c392e" class="bulleted-list"><li style="list-style-type:circle">대시보드 통합: 탐색 결과를 대시보드에 추가.</li></ul><hr id="1433a4cc-090a-806e-ba10-d6de545f2edf"/><h2 id="1433a4cc-090a-80c3-a0f6-fc8b52399f15" class=""><strong>7. Synthetics</strong></h2><h3 id="1433a4cc-090a-8058-b31c-d71f6e714de2" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-8052-9dc8-d47b9c6e3918" class="bulleted-list"><li style="list-style-type:circle"><strong>가용성 모니터링</strong>: 외부 요청 시뮬레이션을 통해 애플리케이션 상태 확인.</li></ul><h3 id="1433a4cc-090a-8047-9a8f-fcb077cb98dd" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-805a-9366-f4ecdfb55f35" class="bulleted-list"><li style="list-style-type:circle">URL, API, 엔드포인트를 지속적으로 테스트.</li></ul><ul id="1433a4cc-090a-8061-a6c3-c247e25b5068" class="bulleted-list"><li style="list-style-type:circle">고객 시나리오를 자동으로 시뮬레이션.</li></ul><h3 id="1433a4cc-090a-8037-9c4c-f882e9713dd4" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-8039-959d-e5fc35c033b1" class="bulleted-list"><li style="list-style-type:circle">체크 러너(Canary): 정의된 주기로 테스트 실행.</li></ul><ul id="1433a4cc-090a-8074-98ee-e1af9669463f" class="bulleted-list"><li style="list-style-type:circle">지연 탐지: 성능 이상 및 장애를 조기에 감지.</li></ul><ul id="1433a4cc-090a-807f-83d8-f30dddea1290" class="bulleted-list"><li style="list-style-type:circle">로그 및 메트릭 통합: 결과를 로그 및 메트릭으로 저장.</li></ul><hr id="1433a4cc-090a-80dd-ab67-e0af0e02e8e2"/><h2 id="1433a4cc-090a-8049-9cf5-e93f742cb947" class=""><strong>8. X-Ray Insights</strong></h2><h3 id="1433a4cc-090a-803f-ba37-ddad679a40ba" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-8069-ba94-e85ca1165e28" class="bulleted-list"><li style="list-style-type:circle"><strong>이상 감지 도구</strong>: X-Ray 트레이스 데이터 기반으로 이상 상태를 자동 탐지.</li></ul><h3 id="1433a4cc-090a-8009-b716-d73172e751c6" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-8043-9404-c2da90393f04" class="bulleted-list"><li style="list-style-type:circle">비정상적인 응답 시간, 오류율 등의 성능 문제를 실시간 감지.</li></ul><ul id="1433a4cc-090a-804b-b115-cebe58176a4f" class="bulleted-list"><li style="list-style-type:circle">성능 문제와 관련된 주요 지표를 분석.</li></ul><h3 id="1433a4cc-090a-80d5-86cc-d5a694d9a85f" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-80ba-a9bc-d3721e5fbdd8" class="bulleted-list"><li style="list-style-type:circle">문제 요약: 주요 트랜잭션 이상 상태 요약.</li></ul><ul id="1433a4cc-090a-8072-b85c-d25a159f9304" class="bulleted-list"><li style="list-style-type:circle">트리거 조건 설정: 문제 발생 시 알림 또는 자동 조치.</li></ul><ul id="1433a4cc-090a-80df-936d-f4f6abbe9f66" class="bulleted-list"><li style="list-style-type:circle">X-Ray Analytics와 통합.</li></ul><hr id="1433a4cc-090a-80c8-87a8-f386a9c3d0c4"/><h2 id="1433a4cc-090a-8000-993a-e95ac85a59a7" class=""><strong>9. Container Insights</strong></h2><h3 id="1433a4cc-090a-8017-baf7-ef67b73d9daf" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-802c-afdd-f955136c0a1a" class="bulleted-list"><li style="list-style-type:circle"><strong>컨테이너 모니터링</strong>: Kubernetes 및 Amazon ECS, EKS에서 실행되는 컨테이너를 모니터링.</li></ul><h3 id="1433a4cc-090a-802a-ab0b-eaa8c8373a45" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-80c1-bb77-fc2bb8f0312a" class="bulleted-list"><li style="list-style-type:circle">컨테이너 및 노드 메트릭 제공.</li></ul><ul id="1433a4cc-090a-8020-acde-f39d1edcbdc2" class="bulleted-list"><li style="list-style-type:circle">CPU, 메모리, 네트워크 사용량 추적.</li></ul><h3 id="1433a4cc-090a-80c5-8472-e4e17f6ec147" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-8014-9b5e-fea0f821d06d" class="bulleted-list"><li style="list-style-type:circle">클러스터 상태 확인: 클러스터 레벨에서 리소스 사용량 분석.</li></ul><ul id="1433a4cc-090a-80d7-bb33-f38f5e5a4b8a" class="bulleted-list"><li style="list-style-type:circle">로그 수집: 컨테이너 로그 자동 수집 및 분석.</li></ul><ul id="1433a4cc-090a-8030-98c3-d3805004a51b" class="bulleted-list"><li style="list-style-type:circle">CloudWatch Alarms 통합: 컨테이너 리소스 경고 설정.</li></ul><hr id="1433a4cc-090a-8090-b99b-d83fa84a2988"/><h2 id="1433a4cc-090a-80d2-87b3-e746606fe204" class=""><strong>10. ServiceLens</strong></h2><h3 id="1433a4cc-090a-8064-9606-f9b49b71933a" class=""><strong>계위</strong></h3><ul id="1433a4cc-090a-80f7-b2e3-c0e47f83160f" class="bulleted-list"><li style="list-style-type:circle"><strong>전체 애플리케이션 모니터링</strong>: 메트릭, 로그, 트레이스를 통합적으로 시각화.</li></ul><h3 id="1433a4cc-090a-8022-937f-df29455dbfe1" class=""><strong>특성</strong></h3><ul id="1433a4cc-090a-808e-be3b-ebe3bb17ea13" class="bulleted-list"><li style="list-style-type:circle">CloudWatch Metrics, Logs, X-Ray와 통합.</li></ul><ul id="1433a4cc-090a-80f5-a9a7-c37a6042d05d" class="bulleted-list"><li style="list-style-type:circle">종단 간 관찰성 제공.</li></ul><h3 id="1433a4cc-090a-8061-894e-c5dee2e68414" class=""><strong>제공 기능</strong></h3><ul id="1433a4cc-090a-80b8-beda-d381312a56b0" class="bulleted-list"><li style="list-style-type:circle">서비스 맵: 애플리케이션 아키텍처의 전체 흐름 표시.</li></ul><ul id="1433a4cc-090a-80c9-864e-c137264156be" class="bulleted-list"><li style="list-style-type:circle">병목현상 감지: 성능 이슈를 시각적으로 탐지.</li></ul><ul id="1433a4cc-090a-8005-b944-c730d06119e1" class="bulleted-list"><li style="list-style-type:circle">단일 대시보드: 모든 관찰성을 통합적으로 제공.</li></ul><hr id="1433a4cc-090a-8038-9761-eba8d6c50300"/><h3 id="1433a4cc-090a-8088-95c1-f2423a877d28" class=""><strong>서비스 간 관계 요약</strong></h3><table id="1433a4cc-090a-80b6-b430-e18e0118393a" class="simple-table"><tbody><tr id="1433a4cc-090a-8012-8d5d-c7d5666a80e1"><td id="iPzV" class="">서비스 구성 요소</td><td id="DAUO" class="">계위</td><td id="^mue" class="">주요 데이터 유형</td><td id="bDHe" class="">제공 기능 요약</td></tr><tr id="1433a4cc-090a-8031-8025-c12266d954df"><td id="iPzV" class="">X-Ray Traces</td><td id="DAUO" class="">분산 트레이싱</td><td id="^mue" class="">Traces</td><td id="bDHe" class="">요청 흐름 추적, 병목현상 식별</td></tr><tr id="1433a4cc-090a-8087-8c09-de5ad5bb6498"><td id="iPzV" class="">X-Ray Analytics</td><td id="DAUO" class="">고급 트레이스 분석</td><td id="^mue" class="">Traces</td><td id="bDHe" class="">패턴, 경향, 이상 탐지</td></tr><tr id="1433a4cc-090a-80c1-aaf9-e1bfbfcd00c1"><td id="iPzV" class="">CloudWatch Logs</td><td id="DAUO" class="">로그 수집 및 저장소</td><td id="^mue" class="">Logs</td><td id="bDHe" class="">애플리케이션 및 시스템 로그 관리</td></tr><tr id="1433a4cc-090a-804d-b328-ca2d4064a9c7"><td id="iPzV" class="">Logs Insights</td><td id="DAUO" class="">로그 데이터 분석 도구</td><td id="^mue" class="">Logs</td><td id="bDHe" class="">SQL 유사 쿼리로 로그 분석</td></tr><tr id="1433a4cc-090a-807d-9c49-d489fd4d9c6a"><td id="iPzV" class="">CloudWatch Metrics</td><td id="DAUO" class="">메트릭 모니터링</td><td id="^mue" class="">Metrics</td><td id="bDHe" class="">리소스 및 사용자 정의 메트릭 관리</td></tr><tr id="1433a4cc-090a-8056-9417-f74ebd87d557"><td id="iPzV" class="">Metrics Explorer</td><td id="DAUO" class="">메트릭 탐색 및 시각화</td><td id="^mue" class="">Metrics</td><td id="bDHe" class="">메트릭 그룹화 및 실시간 탐색</td></tr><tr id="1433a4cc-090a-803a-9faa-ee4ec5e51367"><td id="iPzV" class="">Synthetics</td><td id="DAUO" class="">외부 시뮬레이션</td><td id="^mue" class="">Logs, Metrics</td><td id="bDHe" class="">가용성 및 성능 테스트</td></tr><tr id="1433a4cc-090a-8018-8436-fdb4e9b11d55"><td id="iPzV" class="">X-Ray Insights</td><td id="DAUO" class="">트레이스 이상 감지</td><td id="^mue" class="">Traces</td><td id="bDHe" class="">비정상 패턴 감지 및 분석</td></tr><tr id="1433a4cc-090a-801d-985f-e2e02c9f7f01"><td id="iPzV" class="">Container Insights</td><td id="DAUO" class="">컨테이너 모니터링</td><td id="^mue" class="">Metrics, Logs</td><td id="bDHe" class="">클러스터 및 컨테이너 리소스 추적</td></tr><tr id="1433a4cc-090a-8047-896a-cbe2f57fabe3"><td id="iPzV" class="">ServiceLens</td><td id="DAUO" class="">통합 모니터링 대시보드</td><td id="^mue" class="">Metrics, Logs, Traces</td><td id="bDHe" class="">종합 관찰성 및 병목현상 감지</td></tr></tbody></table><p id="1433a4cc-090a-806d-ac1a-de3928e7b146" class="">
</p><p id="1433a4cc-090a-803d-b6c2-df6bf0cebd34" class="">
</p><p id="1433a4cc-090a-803d-9ff8-fbeedef25c84" class="">
</p><p id="1433a4cc-090a-8096-a183-cac13c6c51f1" class=""><a href="https://cloud.google.com/stackdriver/docs/managed-prometheus?hl=ko">https://cloud.google.com/stackdriver/docs/managed-prometheus?hl=ko</a></p><figure id="1433a4cc-090a-80be-afbf-cfaafca70af0" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%208.png"><img style="width:652.0028076171875px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/image%208.png"/></a></figure><ul id="1433a4cc-090a-8086-becd-ff5e02451ebc" class="bulleted-list"><li style="list-style-type:circle"><a href="https://cloud.google.com/stackdriver/docs/managed-prometheus/setup-managed?hl=ko">관리형 데이터 컬렉션</a>, <a href="https://cloud.google.com/stackdriver/docs/managed-prometheus/setup-unmanaged?hl=ko">자체 배포 데이터 컬렉션</a>, <a href="https://cloud.google.com/stackdriver/docs/managed-prometheus/setup-otel?hl=ko">OpenTelemetry Collector</a> 또는 <a href="https://cloud.google.com/monitoring/agent/ops-agent/prometheus?hl=ko">운영 에이전트</a>의 4가지 모드</li></ul><ul id="1433a4cc-090a-80a7-bd30-eec541e3e5fd" class="bulleted-list"><li style="list-style-type:circle"> Prometheus 서버 배포, 확장, 샤딩, 구성, 유지보수의 복잡성을 줄여주므로, 관리 컬렉션을 사용하는 것이 좋습니다</li></ul><ul id="1433a4cc-090a-8087-b2d3-fd3a87b59288" class="bulleted-list"><li style="list-style-type:circle">OpenTelemetry Collector는 Prometheus 내보내기를 스크래핑하고 Managed Service for Prometheus에 데이터를 전송하는 데 사용될 수 있습니다. OpenTelemetry는 모든 신호에 대한 단일 에이전트 전략을 지원합니다. 여기에는 모든 환경의 측정항목(모든 Prometheus 측정항목 포함), 로그, trace에 하나의 수집기가 사용</li></ul></li></ul><p id="1423a4cc-090a-8005-9408-f474ea16ae12" class="">
</p></details></li></ul><ul id="1423a4cc-090a-8010-ae7a-ee7ec44bc173" class="toggle"><li><details open=""><summary>Next Observability Architecture</summary><p id="1423a4cc-090a-80f8-9812-c8b29c4f0d8e" class="">대규모의 Public Cloud를 Kubernetes(K8s) 기반 OpenStack으로 구축하고 Observability를 위해 OpenTelemetry를 활용해서 메트릭, 로그, 트레이스 데이터를 수집/처리/저장/분석/시각화 하는 시스템을 설계해줘. 대용량 서비스를 위해 트래픽 급증과 로그 데이터 급증 시에도 정상적인 서비스 제공이 가능한 시스템 구조가 필요해 </p><hr id="1423a4cc-090a-8005-a464-c7fd9a5248c5"/><h2 id="1423a4cc-090a-80ad-82a4-f961777ae399" class=""><strong>전체 아키텍처</strong></h2><h3 id="1423a4cc-090a-80a1-ab46-e3fc6f38cfe1" class="">1. <strong>데이터 수집 (OpenTelemetry)</strong></h3><ul id="1423a4cc-090a-803c-9006-dc88fc6ff829" class="bulleted-list"><li style="list-style-type:disc">OpenTelemetry를 통해 애플리케이션, 서비스, 및 인프라에서 <strong>로그(Log)</strong>, <strong>메트릭(Metrics)</strong>, <strong>트레이스(Traces)</strong> 데이터를 수집합니다.</li></ul><ul id="1423a4cc-090a-80a7-bc59-e40bfb4aa647" class="bulleted-list"><li style="list-style-type:disc">OpenTelemetry는 각 워크로드에 <strong>Instrumentation SDK</strong> 또는 <strong>Collector</strong>를 설치하여 데이터를 중앙화된 처리 시스템으로 전송합니다.</li></ul><hr id="1423a4cc-090a-809e-bf5e-fa2f0f5de43a"/><h3 id="1423a4cc-090a-80c4-9ee2-cebb8480ed01" class="">2. <strong>데이터 전송</strong></h3><ul id="1423a4cc-090a-80b8-8311-fdb099a92b1e" class="bulleted-list"><li style="list-style-type:disc">OpenTelemetry Collector는 <strong>K8s DaemonSet</strong>으로 배포하여 각 노드에서 데이터 수집.</li></ul><ul id="1423a4cc-090a-8064-8204-fa03643cf811" class="bulleted-list"><li style="list-style-type:disc">전송 프로토콜:<ul id="1423a4cc-090a-800d-8211-c4ad03770586" class="bulleted-list"><li style="list-style-type:circle"><strong>gRPC</strong>: 실시간 메트릭 및 트레이스 전송.</li></ul><ul id="1423a4cc-090a-80af-aa41-eb9bad31ab0f" class="bulleted-list"><li style="list-style-type:circle"><strong>HTTP/OTLP</strong>: 로그 전송.</li></ul></li></ul><hr id="1423a4cc-090a-8075-9b67-ea6e5800baca"/><h3 id="1423a4cc-090a-80c7-93a7-f09c30e0eef3" class="">3. <strong>데이터 저장</strong></h3><p id="1423a4cc-090a-80c2-9ca8-ea89009c10b1" class="">데이터 유형별로 적합한 스토리지 시스템을 설계하여 확장성과 효율성을 극대화합니다.</p><h3 id="1423a4cc-090a-8090-9567-c7b6c48c89ad" class="">a. <strong>메트릭</strong></h3><ul id="1423a4cc-090a-808e-b077-d82374d22ce5" class="bulleted-list"><li style="list-style-type:disc"><strong>Prometheus</strong>:<ul id="1423a4cc-090a-808e-801a-dd7b06f236bf" class="bulleted-list"><li style="list-style-type:circle">메트릭 데이터를 수집하고 저장.</li></ul><ul id="1423a4cc-090a-80ef-a372-e4b035e34177" class="bulleted-list"><li style="list-style-type:circle">장점: Kubernetes 네이티브 지원, 높은 확장성.</li></ul><ul id="1423a4cc-090a-8039-8d38-db4e347b0927" class="bulleted-list"><li style="list-style-type:circle">스토리지:<ul id="1423a4cc-090a-8051-bc4c-dc592c828f02" class="bulleted-list"><li style="list-style-type:square">기본적으로 <strong>Local TSDB</strong> 사용.</li></ul><ul id="1423a4cc-090a-80bd-b8d4-e0357eea4965" class="bulleted-list"><li style="list-style-type:square">대규모 환경에서는 <strong>Thanos</strong> 또는 <strong>Cortex</strong>를 활용해 장기 스토리지로 **Object Storage(Amazon S3, GCS 등)**에 보관.</li></ul></li></ul></li></ul><h3 id="1423a4cc-090a-8005-8890-e881a31a57ab" class="">b. <strong>로그</strong></h3><ul id="1423a4cc-090a-803d-a67a-f49b974cc21a" class="bulleted-list"><li style="list-style-type:disc"><strong>Elasticsearch + Fluentd + Kibana (EFK 스택)</strong>:<ul id="1423a4cc-090a-8017-af5b-f40e707183e8" class="bulleted-list"><li style="list-style-type:circle"><strong>Fluentd</strong> 또는 <strong>Fluent Bit</strong>를 사용하여 OpenTelemetry Collector에서 전달된 로그를 Elasticsearch로 전송.</li></ul><ul id="1423a4cc-090a-8043-9c57-e2ab156ff587" class="bulleted-list"><li style="list-style-type:circle">Elasticsearch는 분산형 검색 및 분석 스토리지로 활용.</li></ul><ul id="1423a4cc-090a-8028-a60d-d19512ab014a" class="bulleted-list"><li style="list-style-type:circle">Kibana를 통해 로그를 시각화 및 분석.</li></ul></li></ul><h3 id="1423a4cc-090a-80b3-bf09-fe0d80bdd200" class="">c. <strong>트레이스</strong></h3><ul id="1423a4cc-090a-8007-adc7-d225d44845c2" class="bulleted-list"><li style="list-style-type:disc"><strong>Jaeger</strong> 또는 <strong>Grafana Tempo</strong>:<ul id="1423a4cc-090a-8074-b1d0-c35b96a56a59" class="bulleted-list"><li style="list-style-type:circle">분산 추적 데이터를 수집 및 분석.</li></ul><ul id="1423a4cc-090a-80b3-ad48-f45dd00f672b" class="bulleted-list"><li style="list-style-type:circle">Jaeger는 OpenTelemetry와 네이티브 통합 가능.</li></ul><ul id="1423a4cc-090a-8021-95cf-e987302b6f84" class="bulleted-list"><li style="list-style-type:circle">Grafana Tempo는 메트릭 시각화 도구와 강력히 통합.</li></ul><ul id="1423a4cc-090a-80b7-8f65-f18cc20d96ff" class="bulleted-list"><li style="list-style-type:circle">스토리지:<ul id="1423a4cc-090a-80ca-aa1b-e4b875133564" class="bulleted-list"><li style="list-style-type:square">Jaeger: <strong>Cassandra</strong>, <strong>Elasticsearch</strong>, 또는 <strong>Amazon DynamoDB</strong>.</li></ul><ul id="1423a4cc-090a-80cf-b88d-f4644daff091" class="bulleted-list"><li style="list-style-type:square">Tempo: <strong>Object Storage</strong>(Amazon S3, MinIO).</li></ul></li></ul></li></ul><hr id="1423a4cc-090a-8097-a542-f02af3d8134d"/><h3 id="1423a4cc-090a-809c-8073-cbbba6bed74b" class="">4. <strong>시각화</strong></h3><ul id="1423a4cc-090a-80dc-b5e6-ea1657eab0e5" class="bulleted-list"><li style="list-style-type:disc"><strong>Grafana</strong>:<ul id="1423a4cc-090a-80f9-9d1d-fb98a5736729" class="bulleted-list"><li style="list-style-type:circle">메트릭, 로그, 트레이스를 한 곳에서 시각화.</li></ul><ul id="1423a4cc-090a-80d5-962c-cb8bcb92386e" class="bulleted-list"><li style="list-style-type:circle">데이터 소스 연결:<ul id="1423a4cc-090a-80fa-9bd9-c9c665319dc8" class="bulleted-list"><li style="list-style-type:square">Prometheus: 메트릭 데이터 대시보드 생성.</li></ul><ul id="1423a4cc-090a-80ea-b1d6-e33257ca1129" class="bulleted-list"><li style="list-style-type:square">Elasticsearch: 로그 데이터 시각화.</li></ul><ul id="1423a4cc-090a-80a4-bf36-ffbd81434058" class="bulleted-list"><li style="list-style-type:square">Jaeger/Tempo: 트레이스 데이터 분석 및 디버깅.</li></ul></li></ul></li></ul><ul id="1423a4cc-090a-800b-b859-c5292c76fcd9" class="bulleted-list"><li style="list-style-type:disc"><strong>Kibana</strong>:<ul id="1423a4cc-090a-804e-ade7-f2249f65085e" class="bulleted-list"><li style="list-style-type:circle">Elasticsearch 기반 로그 분석에 특화된 시각화 도구.</li></ul></li></ul><ul id="1423a4cc-090a-805f-8737-ea5d3e9ab0c0" class="bulleted-list"><li style="list-style-type:disc"><strong>Jaeger UI</strong>:<ul id="1423a4cc-090a-80ce-83c6-da1e1eb3351a" class="bulleted-list"><li style="list-style-type:circle">Jaeger의 기본 UI를 사용하여 트레이스 데이터를 시각화 및 분석.</li></ul></li></ul><hr id="1423a4cc-090a-80e2-9cf8-eae0837a8263"/><h2 id="1423a4cc-090a-80c2-b004-c40236aacc97" class=""><strong>설계 아키텍처 다이어그램</strong></h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1423a4cc-090a-80e7-b8a0-d4829db0f379" class="code"><code class="language-Markdown" style="white-space:pre-wrap;word-break:break-all">1. 데이터 수집:
   - OpenTelemetry Collector → Kafka → 저장소

2. 데이터 저장:
   - 메트릭: Prometheus → Thanos/Cortex → Object Storage (S3 등)
   - 로그: Fluentd → Kafka → Elasticsearch (Hot-Warm-Cold 구조)
   - 트레이스: OpenTelemetry → Jaeger → Cassandra 또는 Tempo

3. 데이터 처리 및 확장:
   - Kafka와 Fluent Bit을 사용해 로그/메트릭 데이터의 버퍼링 및 처리 속도 최적화
   - 스토리지 클러스터링 (Elasticsearch, Cassandra)

4. 시각화 및 알림:
   - Grafana: 모든 데이터 통합 대시보드 제공
   - Kibana: 로그 분석
   - Jaeger UI: 트레이스 분석</code></pre><hr id="1423a4cc-090a-8096-a8b4-cd6306550761"/><p id="1423a4cc-090a-80d5-b176-c0f6f075e207" class="">
</p><h3 id="1423a4cc-090a-8078-a6af-c0daa6f28235" class=""><strong>기술 스택 요약</strong></h3><table id="1423a4cc-090a-800e-a170-ca5c441941ba" class="simple-table"><tbody><tr id="1423a4cc-090a-809c-a661-ecd060857f44"><td id="E=xL" class="">데이터 유형</td><td id="yPc`" class="">수집 기술</td><td id="kyVT" class="">처리 기술</td><td id="?jJT" class="">저장소 기술</td><td id="z\QT" class="">시각화 도구</td></tr><tr id="1423a4cc-090a-801c-ba41-e08377586fe8"><td id="E=xL" class=""><strong>메트릭</strong></td><td id="yPc`" class="">OpenTelemetry</td><td id="kyVT" class="">Kafka + Prometheus + Thanos/Cortex</td><td id="?jJT" class="">Object Storage(S3, MinIO)</td><td id="z\QT" class="">Grafana</td></tr><tr id="1423a4cc-090a-80aa-8541-d8ea0c957249"><td id="E=xL" class=""><strong>로그</strong></td><td id="yPc`" class="">OpenTelemetry + Fluent Bit</td><td id="kyVT" class="">Fluentd + Kafka</td><td id="?jJT" class="">Elasticsearch(Hot-Warm-Cold)</td><td id="z\QT" class="">Kibana, Grafana</td></tr><tr id="1423a4cc-090a-80cd-a91f-f3db467c56c0"><td id="E=xL" class=""><strong>트레이스</strong></td><td id="yPc`" class="">OpenTelemetry + Jaeger</td><td id="kyVT" class="">Kafka</td><td id="?jJT" class="">Jaeger (Cassandra), Tempo</td><td id="z\QT" class="">Jaeger UI, Grafana</td></tr></tbody></table><hr id="1423a4cc-090a-80b9-b3e8-f18da9e27e3c"/><h3 id="1423a4cc-090a-8078-911f-cc5050f2d664" class=""><strong>확장성 및 신뢰성 고려</strong></h3><ol type="1" id="1423a4cc-090a-8060-8d37-fd59b13efedc" class="numbered-list" start="1"><li><strong>고가용성</strong>:<ul id="1423a4cc-090a-8040-9dc4-d8f8244ac1ca" class="bulleted-list"><li style="list-style-type:disc">Prometheus, Elasticsearch, Jaeger/Tempo는 클러스터링 또는 분산형 설정.</li></ul></li></ol><ol type="1" id="1423a4cc-090a-80ff-96ef-d3878d28c72c" class="numbered-list" start="2"><li><strong>백업 및 장기 보관</strong>:<ul id="1423a4cc-090a-80a0-8499-fd9e3edc7d60" class="bulleted-list"><li style="list-style-type:disc">Thanos/Cortex: 장기 메트릭 보관.</li></ul><ul id="1423a4cc-090a-80ad-8e97-e49aa1b9000b" class="bulleted-list"><li style="list-style-type:disc">Elasticsearch Snapshot: Amazon S3 등의 외부 저장소로 백업.</li></ul></li></ol><ol type="1" id="1423a4cc-090a-8044-941f-c0e9df8066f4" class="numbered-list" start="3"><li><strong>K8s 네이티브 통합</strong>:<ul id="1423a4cc-090a-8002-b93e-e607663cbbf4" class="bulleted-list"><li style="list-style-type:disc">Helm Chart 및 Operator를 사용하여 각 구성 요소를 배포하고 관리.</li></ul></li></ol><ol type="1" id="1423a4cc-090a-803d-bbf4-f4d2b49da62d" class="numbered-list" start="4"><li><strong>멀티 클러스터 지원</strong>:<ul id="1423a4cc-090a-80f7-ae27-ccc0c5ca13ee" class="bulleted-list"><li style="list-style-type:disc">Thanos Query 또는 Jaeger Query로 여러 K8s 클러스터 데이터 통합.</li></ul></li></ol><hr id="1423a4cc-090a-805d-80dc-cefc9497919a"/><h2 id="1423a4cc-090a-80fd-9c02-f724ef7fe25e" class=""><strong>트래픽 급증 대응을 위한 보완</strong></h2><h3 id="1423a4cc-090a-809a-a140-e773d6c4a2c6" class="">a. <strong>비동기 데이터 처리</strong></h3><ul id="1423a4cc-090a-8083-aa28-ffc653646f92" class="bulleted-list"><li style="list-style-type:disc">데이터 수집에서 저장소로 데이터를 전송하기 전에 <strong>큐 시스템</strong>을 도입하여 급격한 데이터 유입을 버퍼링.<ul id="1423a4cc-090a-8074-bc74-d4ca363f5650" class="bulleted-list"><li style="list-style-type:circle"><strong>Kafka</strong>: 고성능 메시지 브로커로, 데이터 처리 속도와 확장성에서 우수.</li></ul><ul id="1423a4cc-090a-808c-b0b7-c5289e306436" class="bulleted-list"><li style="list-style-type:circle"><strong>Amazon SQS</strong>: AWS 기반으로 관리형 메시지 대기열 서비스.</li></ul></li></ul><ul id="1423a4cc-090a-8000-a395-ff71986888be" class="bulleted-list"><li style="list-style-type:disc">OpenTelemetry Collector → 메시지 큐 → 저장소로 데이터를 전달하여 저장소 과부하를 방지.</li></ul><h3 id="1423a4cc-090a-808e-8faa-f4ebb0c6037f" class="">b. <strong>로드 밸런싱</strong></h3><ul id="1423a4cc-090a-801b-834f-fb91aa4d37fc" class="bulleted-list"><li style="list-style-type:disc">중앙집중식 저장소로 전송되는 데이터를 <strong>로드 밸런서</strong>로 분산 처리.<ul id="1423a4cc-090a-804b-8bdc-cfe201a98379" class="bulleted-list"><li style="list-style-type:circle">Prometheus Pushgateway 또는 Thanos Receive를 활용하여 메트릭을 분산 처리.</li></ul><ul id="1423a4cc-090a-8007-8ef4-df52cb79227b" class="bulleted-list"><li style="list-style-type:circle">Fluentd 및 Kafka와 통합해 로그 데이터를 여러 로그 처리기로 나누어 처리.</li></ul></li></ul><p id="1423a4cc-090a-804f-a44b-e71c12bac941" class="">
</p><h2 id="1423a4cc-090a-80dc-9b5e-c49ee3003cf5" class=""><strong>대용량 로그 및 데이터 처리</strong></h2><h3 id="1423a4cc-090a-808c-916a-f26195ec72a3" class="">a. <strong>로그의 분산 저장</strong></h3><ul id="1423a4cc-090a-8079-b8d8-d90ba3b9f60b" class="bulleted-list"><li style="list-style-type:disc"><strong>Elasticsearch</strong>는 로그 데이터를 저장하기 위한 강력한 도구지만, 대규모 로그 데이터의 처리는 클러스터 구성을 통해 확장성을 보장.<ul id="1423a4cc-090a-800f-9838-c97bd6db8d96" class="bulleted-list"><li style="list-style-type:circle"><strong>Elasticsearch 클러스터 확장</strong>:<ul id="1423a4cc-090a-8090-8947-d430c3358830" class="bulleted-list"><li style="list-style-type:square">다수의 마스터 노드와 데이터 노드를 구성.</li></ul><ul id="1423a4cc-090a-801e-bc08-d1672401365e" class="bulleted-list"><li style="list-style-type:square"><strong>Hot-Warm-Cold 아키텍처</strong>를 사용하여 데이터 접근 빈도에 따라 노드를 분리.<ul id="1423a4cc-090a-8030-9612-f10cb9202448" class="bulleted-list"><li style="list-style-type:disc"><strong>Hot 노드</strong>: 자주 접근하는 최신 데이터.</li></ul><ul id="1423a4cc-090a-8048-ab05-cfcfb440c0f8" class="bulleted-list"><li style="list-style-type:disc"><strong>Warm 노드</strong>: 오래된 데이터.</li></ul><ul id="1423a4cc-090a-8097-9206-fd882cd65a36" class="bulleted-list"><li style="list-style-type:disc"><strong>Cold 노드</strong>: 장기 보관 데이터.</li></ul></li></ul></li></ul></li></ul><h3 id="1423a4cc-090a-80c1-a745-fcc3a65f92f0" class="">b. <strong>로그 압축 및 장기 보관</strong></h3><ul id="1423a4cc-090a-802a-9cf3-f17648dee433" class="bulleted-list"><li style="list-style-type:disc">과거 로그 데이터를 장기 보관 시스템으로 이전하여 Elasticsearch의 부하를 줄임.<ul id="1423a4cc-090a-808a-838d-d2f454e3286f" class="bulleted-list"><li style="list-style-type:circle"><strong>Logstash</strong> 또는 <strong>Curator</strong>를 사용해 데이터를 <strong>S3</strong>, <strong>GCS</strong>, 또는 <strong>Glacier</strong>로 이전.</li></ul><ul id="1423a4cc-090a-80b7-ab55-f0d328e8ca9d" class="bulleted-list"><li style="list-style-type:circle">Elasticsearch에서 압축을 통해 저장 공간 최적화 (예: ILM(수명주기 관리) 적용).</li></ul></li></ul><h3 id="1423a4cc-090a-8067-bc34-ee3782792d61" class="">c. <strong>고성능 로그 처리</strong></h3><ul id="1423a4cc-090a-8006-8f79-ecd07dc7e1f2" class="bulleted-list"><li style="list-style-type:disc"><strong>Fluent Bit</strong>:<ul id="1423a4cc-090a-8017-b15b-fe60a76eb72b" class="bulleted-list"><li style="list-style-type:circle">Fluentd의 경량화 버전으로 메모리 사용량이 적고, 높은 처리량을 지원.</li></ul><ul id="1423a4cc-090a-80fc-9800-f8465abeecff" class="bulleted-list"><li style="list-style-type:circle">대규모 로그 처리 시 Fluent Bit을 OpenTelemetry Collector 앞단에 배치.</li></ul></li></ul><hr id="1423a4cc-090a-8021-8ffa-f4b5bbe172fe"/><h2 id="1423a4cc-090a-804c-b522-ef53b5530c95" class=""><strong>메트릭 데이터의 효율적 관리</strong></h2><h3 id="1423a4cc-090a-80be-a83a-cd9534cfe2c8" class="">a. <strong>Thanos 또는 Cortex 기반의 글로벌 메트릭 관리</strong></h3><ul id="1423a4cc-090a-80f4-9d35-d2ba80b48794" class="bulleted-list"><li style="list-style-type:disc">Prometheus는 고립된 스토리지에서 동작하므로 트래픽 급증 시 스케일링에 제한이 있음.</li></ul><ul id="1423a4cc-090a-8030-b494-c56a9bd4e5f8" class="bulleted-list"><li style="list-style-type:disc"><strong>Thanos</strong>:<ul id="1423a4cc-090a-8020-a4aa-f4800ca8b186" class="bulleted-list"><li style="list-style-type:circle">Prometheus 데이터를 Object Storage(S3, MinIO 등)로 아카이브하여 장기 데이터를 효율적으로 관리.</li></ul><ul id="1423a4cc-090a-8085-8c99-f3ddf109ded1" class="bulleted-list"><li style="list-style-type:circle">Prometheus 간 글로벌 쿼리를 지원해 중앙집중형 메트릭 관리 가능.</li></ul></li></ul><ul id="1423a4cc-090a-80e4-bc2c-e26db0fe8adf" class="bulleted-list"><li style="list-style-type:disc"><strong>Cortex</strong>:<ul id="1423a4cc-090a-80c0-a356-d9022ae452bb" class="bulleted-list"><li style="list-style-type:circle">클라우드 네이티브 메트릭 시스템으로 다수의 Prometheus 인스턴스를 통합하여 중앙집중화.</li></ul></li></ul><h3 id="1423a4cc-090a-8072-99eb-ebd99b97c48e" class="">b. <strong>Pushgateway로 비동기 처리</strong></h3><ul id="1423a4cc-090a-804e-92bf-cd81838cf8f8" class="bulleted-list"><li style="list-style-type:disc">트래픽 급증 시 메트릭 데이터의 손실을 방지하기 위해 Prometheus Pushgateway를 활용하여 데이터를 임시로 저장.</li></ul><hr id="1423a4cc-090a-8071-96a7-c6ffd2efa148"/><h2 id="1423a4cc-090a-80b4-aee7-c0c70ce7b3ae" class=""><strong>트레이스 데이터 확장</strong></h2><h3 id="1423a4cc-090a-803c-a9aa-c7e44f4228c5" class="">a. <strong>Jaeger / Tempo 분산 스토리지</strong></h3><ul id="1423a4cc-090a-800e-b877-c1f66753322f" class="bulleted-list"><li style="list-style-type:disc">트레이스 데이터는 대용량 및 고빈도 요청의 특성을 가지므로 분산 스토리지를 활용.</li></ul><ul id="1423a4cc-090a-80f2-ad32-cc70303ed835" class="bulleted-list"><li style="list-style-type:disc"><strong>Jaeger with Cassandra</strong>:<ul id="1423a4cc-090a-8095-89e5-da910043ba0d" class="bulleted-list"><li style="list-style-type:circle">Jaeger의 트레이스 데이터를 <strong>Cassandra</strong>에 저장하여 고성능 분산 처리를 보장.</li></ul><ul id="1423a4cc-090a-8098-9e26-f9ac71080993" class="bulleted-list"><li style="list-style-type:circle">트래픽 급증 시 Cassandra 클러스터를 확장하여 데이터 처리를 분산.</li></ul></li></ul><ul id="1423a4cc-090a-802d-ad61-fd31189f4445" class="bulleted-list"><li style="list-style-type:disc"><strong>Grafana Tempo</strong>:<ul id="1423a4cc-090a-80fb-ab75-ec127c4b00bc" class="bulleted-list"><li style="list-style-type:circle">Tempo는 Object Storage를 기본 스토리지로 사용하며, 높은 확장성을 제공.</li></ul><ul id="1423a4cc-090a-8030-87a6-c8cf1100d7c7" class="bulleted-list"><li style="list-style-type:circle">로그와 메트릭을 연계한 분석에 최적화.</li></ul></li></ul><hr id="1423a4cc-090a-8005-93d7-efc45e357df9"/><h2 id="1423a4cc-090a-800c-a75c-c1e02f58c10c" class=""><strong>모니터링 및 알림 시스템 강화</strong></h2><ul id="1423a4cc-090a-803e-8021-c946a13967ea" class="bulleted-list"><li style="list-style-type:disc"><strong>Autoscaling 기반 알림</strong><ul id="1423a4cc-090a-8098-a424-f2b969ef9a59" class="bulleted-list"><li style="list-style-type:circle">OpenTelemetry Collector 및 저장소 시스템(Kafka, Elasticsearch 등)에 대해 Kubernetes의 <strong>Horizontal Pod Autoscaler (HPA)</strong> 설정.</li></ul><ul id="1423a4cc-090a-805f-ac7d-fc2278235ddc" class="bulleted-list"><li style="list-style-type:circle">메트릭과 로그 수집 파이프라인의 병목을 실시간으로 감지하고 자동으로 확장.</li></ul></li></ul><ul id="1423a4cc-090a-8085-b6f4-f3be1cfb4fce" class="bulleted-list"><li style="list-style-type:disc"><strong>대시보드와 알림</strong>:<ul id="1423a4cc-090a-80ea-9236-d922965e3316" class="bulleted-list"><li style="list-style-type:circle">Grafana에서 <strong>Alertmanager</strong>와 통합하여 트래픽 급증 시 알림 전송.</li></ul></li></ul><p id="1423a4cc-090a-8039-b352-f393586cfc36" class="">
</p><h3 id="1423a4cc-090a-80be-ba60-d92a5a45015b" class=""><strong>시스템 구현 시 장점</strong></h3><ul id="1423a4cc-090a-8062-a8a9-fde1db5d92b2" class="bulleted-list"><li style="list-style-type:disc">OpenTelemetry 기반으로 데이터 수집 표준화.</li></ul><ul id="1423a4cc-090a-80e2-b70e-e031795787fc" class="bulleted-list"><li style="list-style-type:disc">Prometheus 및 Elasticsearch의 확장성과 다양한 스토리지 옵션.</li></ul><ul id="1423a4cc-090a-804f-b22b-ddac97f03c3c" class="bulleted-list"><li style="list-style-type:disc">Grafana와 Kibana로 통합 시각화 가능.</li></ul></details></li></ul><p id="097ca9f4-9884-470e-bd3e-964f2af1b495" class="">
</p><p id="b0af40c9-66af-4fa7-8026-a82773716b2f" class="">Interactive</p><ul id="1e13a4cc-090a-806e-99c0-f9ae4ae500dc" class="toggle"><li><details open=""><summary><a href="https://www.youtube.com/watch?v=_F6k0tg8ODo">https://www.youtube.com/watch?v=_F6k0tg8ODo</a></summary><p id="1e13a4cc-090a-8086-885e-fe46ae0eaf1a" class="">
</p></details></li></ul><ul id="d9cb8d46-029f-4f12-8199-1c56cfac439e" class="toggle"><li><details open=""><summary>Chatting System 설계</summary><h2 id="1bab3937-c074-4eaf-b64e-335b279db2bd" class="">과제</h2><ul id="de86e8fe-d6cb-4ec3-aa2b-4dbb14e21426" class="bulleted-list"><li style="list-style-type:disc">1:1 채팅, 그룹 채팅 기능 모두 지원해야 한다.</li></ul><ul id="2680552e-fb66-43c7-bd27-2a8bafc2cbf8" class="bulleted-list"><li style="list-style-type:disc">모바일, 웹 앱 모두를 지원해야 한다.</li></ul><ul id="7244b4bc-a502-46f6-995e-e259fcc1afc4" class="bulleted-list"><li style="list-style-type:disc">일별 능동 사용자 수 (DAU: Daily Active User) 5천만명을 처리할 수 있어야 한다.</li></ul><ul id="29010e0d-750f-4c38-abbf-2c78e84b8419" class="bulleted-list"><li style="list-style-type:disc">그룹 채팅의 경우 100명까지 참여 가능해야 한다.</li></ul><ul id="176f0f10-adec-4bcd-b1fb-14e48213da74" class="bulleted-list"><li style="list-style-type:disc">사용자 접속 상태를 표시할 수 있어야 하며 텍스트 메시지만 주고 받을 수 있다.</li></ul><ul id="7f02eedc-e0d9-416b-8a97-d83bed498320" class="bulleted-list"><li style="list-style-type:disc">메시지 길이 제한은 100,000자 이하이다.</li></ul><ul id="21bfeddc-80cb-4747-b61a-2b8632dd8f20" class="bulleted-list"><li style="list-style-type:disc">종단 간 암호화 (end-to-end encryption)은 선택 사항이다.</li></ul><ul id="7d915ded-7b9b-43d8-9167-3f861e30232a" class="bulleted-list"><li style="list-style-type:disc">채팅 이력은 영원히 보관해야 한다.</li></ul><ul id="71691f87-bcc4-4855-8842-0501f31b96e2" class="bulleted-list"><li style="list-style-type:disc">푸시 알림이 가능해야 한다.</li></ul><ul id="ae0e8b04-1a8e-4cf8-92b5-c6471da1b6fa" class="bulleted-list"><li style="list-style-type:disc">하나의 계정으로 여러 단말에 동시 접속 지원해야 한다.</li></ul><h2 id="69e3214b-4300-486c-8b2f-60b3c1423641" class="">설계안</h2><p id="76cd9f02-491b-414d-950a-bc5db57f2d4d" class="">클라이언트는 채팅 서비스(서버)를 이용해서 서로 통신한다.</p><figure id="4e58b679-546a-4701-9706-e5488fd4862d" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fa4f75bc8-0cd1-4ac9-9282-f89b8a42cbb2%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.16.42.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fa4f75bc8-0cd1-4ac9-9282-f89b8a42cbb2%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.16.42.png"/></a></figure><h3 id="b7176bb5-1f50-4fff-8ce1-66e6eab8ac0b" class="">프로토콜</h3><ul id="33125988-d24e-46aa-8466-dd2b9a56f7f1" class="bulleted-list"><li style="list-style-type:disc">송신 클라이언트가 채팅 서비스에 메시지를 보낼 때 HTTP 프로토콜을 사용한다.</li></ul><ul id="5c1f754f-e182-4958-8e2a-4455bc6ebd9f" class="bulleted-list"><li style="list-style-type:disc">초기 페이스 북 메세지 앱의 송신 클라이언트는 서버에 HTTP 프로토콜을 이용해 수신 클라이언트에게 보낼 메세지를 정한다. 이 때 keep-alive 헤더를 사용하면 TCP 핸드쉐이크 횟수를 줄일 수 있다.</li></ul><ul id="afe349ae-9a4a-4047-859e-52aabd791478" class="bulleted-list"><li style="list-style-type:disc">HTTP는 클라이언트가 연결을 만드는 프로토콜이며, 서버에서 수신 클라이언트에 임의 시점에 메세지를 보낼 때는 사용하기 어렵기 때문에, 다음의 기술이 사용되고 있다.</li></ul><h2 id="778bc259-1ffe-4408-8728-f6ef15546129" class="">폴링</h2><p id="d3bb97f5-5c33-4906-8391-671ec0742009" class="">폴링은 수신 클라이언트가 서버에게 주기적으로 새 메세지가 있는지 물어보는 방법이다. 실제 주고 받는 글이 없음에도 불구하고 클라이언트에서 폴링이 없기 때문에 서버 자원이 불필요하게 낭비될 수 있다.</p><figure id="3969aee5-ae1e-40c3-a080-12ffceb210e6" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F2f0cf703-d5b9-4fe3-897c-711091c53b41%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.30.59.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F2f0cf703-d5b9-4fe3-897c-711091c53b41%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.30.59.png"/></a></figure><h2 id="bc9852ff-f300-4754-bad5-f92f3632d972" class="">롱 폴링</h2><p id="10e71c8a-8342-4d06-b283-36b7cb964d23" class="">롱 폴링의 경우 클라이언트는 새 메시지가 반환되거나 타임아웃 될 때까지 연결을 유지한다. 클라이언트가 새 메시지를 받으면 기존 연결을 종료하고 서버에 새로운 요청을 보내어 모든 절차를 다시 시작한다.</p><blockquote id="4e11fb13-dc04-49b0-a266-ddaa1602c291" class="">클라이언트가 최대 대기 할 수 있는 시간은 얼마일까?</blockquote><figure id="2b477b8e-45af-4a57-88b0-ecdd4dd1f480" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fc759f030-da6f-4c69-a273-2fda495f5437%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.39.33.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fc759f030-da6f-4c69-a273-2fda495f5437%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.39.33.png"/></a></figure><p id="4236b500-0d37-477a-ba12-a98a4ba85b62" class="">롱폴링의 단점은 다음과 같다.</p><ul id="7124586e-1b02-475c-8e44-a994424d3095" class="bulleted-list"><li style="list-style-type:disc">서버 로드밸런스가 로드 밸런스 알고리즘을 사용한다면 송신 클라이언트와 수신 클라이언트가 같은 채팅 서버에 접속하지 않을 수 있다. 메시지를 받은 서버는 해당 메시지를 받을 수신 클라이언트의 연결을 가지고 있지 않을 수 있다. 로드 밸런싱에 sticky route 방식을 이용해야 한다</li></ul><ul id="4e655166-5d2d-4425-a52e-e4ab98a206e5" class="bulleted-list"><li style="list-style-type:disc">서버 입장에서는 클라이언트가 연결을 해제했는지 아닌지 알 수 없다.</li></ul><ul id="c5ce84a0-04d3-4034-aa63-4d31c5180c54" class="bulleted-list"><li style="list-style-type:disc">폴링에 비해서는 불필요한 리퀘스트 횟수가 줄지만 여전히 메시지를 받지 않는 클라이언트도 타임아웃이 일어날 때마다 주기적으로 서버에 다시 접속해야 한다.</li></ul><h2 id="c6fee930-2125-4e61-9eec-ffdc05ac538a" class="">웹소켓</h2><p id="8afd88cf-e9ad-4c3e-9b45-aa57ddbd5d2b" class="">웹 소켓은 서버가 클라이언트에게 비동기 메시지를 보낼 때 사용되는 기술이다.</p><figure id="1b66a65c-3c26-46e8-9897-652418a14922" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fdaeff752-5a02-4d26-aa86-dd2b2508842c%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.14.47.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fdaeff752-5a02-4d26-aa86-dd2b2508842c%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.14.47.png"/></a></figure><p id="bdac0064-6905-40b3-b92d-3ead77164e42" class="">웹소켓 연결은 클라이언트가 시작한다. 첫 연결은 HTTP 핸드쉐이크를 이용하고, 이후에는 서버가 클라이언트에게 비동기적으로 메시지를 전송할 수 있다. 웹소켓은 방화벽이 있는 환경에서도 잘 동작한다.</p><p id="b24fee44-4ba8-4a4e-9922-87acc4e7fdf0" class="">HTTP 프로토콜과 가장 다른 점은 양방향 통신이 가능하다는 것인데, 이 부분 떄문에 웹 소켓 대신 HTTP를 고집할 이유가 없다.</p><blockquote id="55923d0c-f63c-4f96-8a0f-324f05055c05" class="">그래서 우리는 웹소켓을 쓰기로 했어요.<figure id="9770c7f2-a7f3-4e1f-a55a-973b2284b345" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F63c8cebe-b664-4af5-aa0c-e20a3dff0a1f%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.22.55.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F63c8cebe-b664-4af5-aa0c-e20a3dff0a1f%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.22.55.png"/></a></figure></blockquote><h1 id="e838a2ff-333b-4e7c-8502-7c34914d9827" class="">개략적 설계안</h1><p id="3c84f883-d42e-42a1-aaba-34b0c8ea6d51" class="">전체 시스템의 개략적 설계안을</p><ul id="2de912fc-64a8-4c32-bbb3-ff805b0d885c" class="bulleted-list"><li style="list-style-type:disc">무상태 서비스</li></ul><ul id="7ad0e22e-3372-4c91-a6fd-8452a57f2604" class="bulleted-list"><li style="list-style-type:disc">상태 유지 서비스</li></ul><ul id="f724399f-126b-4d1f-b966-f816579d6bcf" class="bulleted-list"><li style="list-style-type:disc">제 3자 서비스 연동세 부분으로 나눈다.<figure id="bc153906-bb56-4ce3-ad35-53768ef2e8f4" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F3f8d00e0-59e0-401a-8a9b-81ed813bc930%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.25.28.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F3f8d00e0-59e0-401a-8a9b-81ed813bc930%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.25.28.png"/></a></figure></li></ul><h2 id="ec951e78-0bf6-42e6-9ef3-0501a5f7c494" class="">무상태 서비스</h2><p id="73ee02ad-497a-4e46-88b0-a4ae75eb2b48" class="">무상태 서비스는 로드밸런스 뒤에 붙어있다.</p><h3 id="852d34b6-2c25-499d-9ddd-ddb9ffd9fc24" class="">서비스 탐색</h3><p id="454c96e9-df9e-4e12-bf4b-225ae933d6a4" class="">클라이언트가 접속할 채팅 서버의 DNS 호스트 명을 클라이언트에게 알려주는 역할을 한다. 특정 서버에 부하가 몰리지 않도록 한다.</p><h2 id="80b4af1b-2818-494b-9178-99b6459f9d3a" class="">상태 유지 서비스</h2><p id="d41b7b2c-33c5-4a16-8e5f-3491ead5a947" class="">각 클라이언트가 채팅 서버와 독립적인 네트워크 연결을 유지하기 위해 필요한 서비스이다.</p><h2 id="707d6cf3-bd88-400a-b6e5-0cb03b926f74" class="">제 3자 서비스 연동</h2><p id="ad3cb11d-72db-48d3-b177-693723c25f76" class="">가장 중요한 제 3자 서비스는 푸시 알림이다. 설사 앱이 실행 중이지 않더라도 알림을 받아야 해서다.</p><h2 id="e5f23056-7e93-4942-a549-ce75eeec52db" class="">규모 확장성</h2><p id="38b40ac3-3bf2-4fa1-ab40-81ea1483b293" class="">동시 접속자가 백만 명이라고 할 때, 언어에 따라 다르지만 접속당 10KB의 메모리가 필요하고, 10GB의 메모리만 있으면 모든 연결을 처리할 수 있다.</p><p id="5b98cc70-7529-4353-a1c9-a5993187d82d" class="">하지만 SPOF(Single Point Of Failure) 문제가 있기 때문에 여러 대의 서버로 구성하는 것을 고려해야 한다.</p><p id="aa25511f-728d-44c0-8fae-6ad1e5c6afff" class="">다음은 여러 개의 서버들로 구성된 채팅 시스템이다.</p><figure id="5024f665-23d3-49d6-acd1-58e88e916692" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F3c4457a7-43e3-4a80-b261-9529fe547fbc%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.05.21.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F3c4457a7-43e3-4a80-b261-9529fe547fbc%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.05.21.png"/></a></figure><ul id="c778a068-5fde-4b89-b5d8-77b740daa98d" class="bulleted-list"><li style="list-style-type:disc">채팅 서버는 클라이언트 사이에 메시지를 중계하는 역할을 담당한다.</li></ul><ul id="ecbf9c38-4c63-4fda-91e4-b0d5baa62ecc" class="bulleted-list"><li style="list-style-type:disc">접속 상태 서버는 사용자의 접속 여부를 관리한다.</li></ul><ul id="8264f9fd-8561-4f61-9b68-3b64f70b7d34" class="bulleted-list"><li style="list-style-type:disc">API 서버는 로그인, 회원가입, 프로필 변경등 그 외 나머지 전부를 처리한다.</li></ul><ul id="672538da-6c5d-4d40-953f-aaa674c14d54" class="bulleted-list"><li style="list-style-type:disc">알림 서버는 푸시 알림을 보낸다.</li></ul><ul id="d5c05bd9-1ade-408f-9923-735e2b0fa4c9" class="bulleted-list"><li style="list-style-type:disc">키-값 저장소에 채팅 이력을 보관한다.</li></ul><h2 id="69754593-53b0-4b8a-a5a7-a82f495f0db4" class="">저장소</h2><p id="ff1e9075-7a90-41cc-aff5-fc84c334ac15" class="">중요 한 것은 어떤 데이터베이스를 쓰는지이다.</p><p id="82305875-6890-489d-9d2c-50f91cb9fdc4" class="">SQL, NoSQL중 하나를 선택하기 위해 고려해야 하는 점은 데이터의 유형과 읽기/쓰기 연산의 패턴이다.</p><p id="46a3f336-91be-4f9f-91d2-47095d7c3495" class="">채팅 시스템이 다루는 데이터는 두 가지로 나뉘어진다.</p><ul id="c41f7df5-205b-4d7e-99d4-441efe0ae7ec" class="bulleted-list"><li style="list-style-type:disc">사용자 프로필, 설정, 친구 목록처럼 일반적인 데이터: 안정성을 보장하는 관계형 데이터 베이스에 보관한다. 다중화(replication), 샤딩(sharding)은 데이터의 가용성과 규모 확장성을 보증하기 위해 보편적으로 사용되는 기술이다.</li></ul><ul id="57b524bb-da01-49bf-b0aa-50a48e75f3b6" class="bulleted-list"><li style="list-style-type:disc">채팅 시스템에 고유한 데이터: 채팅 이력 데이터를 의미한다.</li></ul><h3 id="85734dd4-b2a0-474d-833a-d8163342d771" class="">읽기/쓰기 연산 패턴</h3><ul id="acf404ef-7ae4-4d46-9f8c-d420b8f80109" class="bulleted-list"><li style="list-style-type:disc">페이스북 메신저나 왓츠앱은 매일 600억개의 메시지를 처리한다.</li></ul><ul id="ae3d731b-6881-4a89-93c9-2e630e84aeb9" class="bulleted-list"><li style="list-style-type:disc">채팅 앱에서 빈번하게 쓰이는 데이터는 최근 메시지이다. 대부분 오래된 메시지는 들여다 보지 않는다.</li></ul><ul id="95acc373-add3-495d-99fa-043a6dbe9b8d" class="bulleted-list"><li style="list-style-type:disc">사용자는 대체로 최근 메시지를 보나 검색 기능, 특정 사용자가 언급된 메시지를 보거나, 특정 메시지로 점프하여 무작위 데이터를 접근하는 경우도 있다.</li></ul><ul id="aa7ee5cf-d17e-420d-a9a8-132acad7066e" class="bulleted-list"><li style="list-style-type:disc">1:1 채팅 앱의 경우 읽기:쓰기 비율은 대략 1:1정도다.</li></ul><p id="7c1c497f-9045-4bda-9c42-a7188a5e9e80" class="">이번 설계에서는 아래와 같은 이융로 SQL이 아닌 NoSQL을 선택한다.</p><h3 id="ddb9fec4-1ba4-4054-9c18-1868b6097805" class="">이번 시스템에 NOSQL을 선택하는 이유</h3><ul id="d5484947-c731-4f4c-af46-26475c8af4e8" class="bulleted-list"><li style="list-style-type:disc">키/값 저장소는 수평적 규모 확장이 쉽다.</li></ul><ul id="c77174a5-d4b1-402d-8d27-ab4fbfb3a63e" class="bulleted-list"><li style="list-style-type:disc">키/값 저장소는 데이터 접근 지연시간(latency)가 낮다.</li></ul><ul id="e8183aa6-dd69-4300-ad69-893440cfa217" class="bulleted-list"><li style="list-style-type:disc">관계형 데이터베이스는 롱 테일(long tail)에 해당하는 부분을 잘 처리하지 못하는 경향이 있다. 인덱스가 커지면 데이터에 대한 무작위적 접근(random access)를 처리하는 비용이 늘어난다.</li></ul><ul id="1ece6173-14af-4352-9a81-d853e450b6f7" class="bulleted-list"><li style="list-style-type:disc">페이스북 메신저는 HBase를 사용하고 디스코드는 카산드라 NoSQL을 사용하고 있다.</li></ul><h3 id="e305f9b7-7553-4b13-9023-6400705b46cd" class="">데이터 모델</h3><h3 id="d96c6353-d09a-4598-b45d-7b052a077522" class="">1:1 채팅을 위한 메시지 테이블</h3><p id="b16d755e-9699-4776-88ea-2844f3e7e102" class="">이 테이블의 기본 키(primary key)는 message_id로, 메시지 순서를 쉽게 정할 수 있도록 하는 역할도 담당한다. 두 메시지가 동시에 만들어질 수 있기 때문에 create_at을 사용하여 메시지 순서를 정할 수는 없다.</p><figure id="a4b12e23-493e-4810-a51f-059e0a959c49" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fe3404669-bc5c-443c-acb3-1588862bbe28%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.28.15.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fe3404669-bc5c-443c-acb3-1588862bbe28%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-02%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.28.15.png"/></a></figure><h3 id="1fb441e3-7a0b-4485-8c03-3a18b06b9ad0" class="">그룹 채팅을 위한 메시지 테이블</h3><p id="15058908-2dd0-45bb-8c13-5f7eb55953fc" class="">channel_id, message_id의 복합 키를 기본 키로 사용한다. channel_id는 파티션 키(partition key)로도 사용할 것인데, 그룹 채팅에 적용될 모든 질의는 특정 채널을 대상으로 할 것이기 떄문이다.</p><h3 id="3168ab7e-6df3-4b41-a75b-704db2a64f81" class="">message_id</h3><p id="bcb90a4a-6ff3-4d13-8883-5d6fcb2d94e5" class="">message_id는 아래를 만족해야 한다.</p><ul id="769b3bc0-3667-494e-9f56-98d0cc8b9708" class="bulleted-list"><li style="list-style-type:disc">고유해야 하며</li></ul><ul id="273b1624-c34b-475a-8302-e1764c03ff9b" class="bulleted-list"><li style="list-style-type:disc">정렬 가능해야 하며 시간 순서와 일치해야 한다. 새로운 ID는 이전 ID보다 큰 값이어야 한다.<p id="123b83a8-4cb7-4071-98c3-76ecbd2395bf" class="">NoSQL은 auto_increment를 제공하지 않기 때문에 스노플레이크 같은 전역적 64-bit 순서 번호(sequency number) 생성기를 이용한다.</p><p id="55c099c0-4560-4f9b-be55-8fcc48bce674" class="">또 다른 방법은 ID의 유일성은 같은 그룹 안에서만 보증하면 충분하기 떄문에 지역적 순서 번호 생성기 (local sequence number generator)를 사용한다.</p><h1 id="d50a831e-5498-4800-9621-32bb2fdd36d7" class="">상세설계</h1><p id="ba87238f-8a41-4f0d-aa24-db17bfa7342f" class="">개략적인 설계안에 포함된 컴포넌트 중 아래 컴포넌트를 좀 더 자세히 살펴본다</p><h2 id="cc7f50f1-a2ce-469d-8c57-4b67d1c40765" class="">서비스 탐색</h2><p id="ddb4421c-ed49-4ffc-83b4-406c7577d365" class="">클라이언트에게 가장 적합한 채팅 서버를 추천하는 것이다. 추천 기준은</p></li></ul><ul id="45c51651-b978-4711-9527-e89049dff0db" class="bulleted-list"><li style="list-style-type:disc">클라이언트의 위치(geographical location)</li></ul><ul id="7c5e649b-4f2f-4b79-b25e-76d52f398470" class="bulleted-list"><li style="list-style-type:disc">서버의 용량(capacity) 등이 있다.<p id="949d598b-f295-4802-8c61-156aaae72ce8" class="">널리 쓰이는 오픈 소스 솔루션으로는 아파치 주키퍼가 있다. 사용 가능한 채팅 서버를 여기에 등록해 두고, 클라이언트가 접속을 시도하면 사전에 정한 기준에 따라 최적의 채팅 서버를 골라준다.</p><p id="0f3116e2-a9b3-4d56-b609-036f9d3f8912" class="">다음은 서비스 탐색 컴포넌트 기능이 어떻게 동작하는지 보여준다.</p><figure id="a81251a3-ee14-4129-ae98-2b942fca2af2" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F85befaf7-53f9-48b7-9eb9-3406baaf1cf4%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.27.16.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F85befaf7-53f9-48b7-9eb9-3406baaf1cf4%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.27.16.png"/></a></figure></li></ul><ol type="1" id="4b52b53d-c93d-407d-9970-dfed4b4b85d3" class="numbered-list" start="1"><li>사용자 A가 시스템에 로그인을 시도한다.</li></ol><ol type="1" id="11d4862e-e8dc-4f05-808a-0df1b854f168" class="numbered-list" start="2"><li>로드 밸런서가 로그인 요청을 API 서버들 가운데 하나로 보낸다.</li></ol><ol type="1" id="78f313b4-fd29-4800-8d30-8a44d9d2bb86" class="numbered-list" start="3"><li>API 서버가 사용자 인증을 처리하고 나면 서비스 탐색 기능이 동작하여 해당 사용자를 서비스할 최적의 채팅 서버를 찾는다. 예제의 경우 채팅 서버 2가 선택되어 사용자 A에게 반환된다.</li></ol><ol type="1" id="6753c3e2-52aa-456b-9d63-691d48c2b415" class="numbered-list" start="4"><li>사용자 A는 채팅 서버2와 웹 소켓 연결을 맺는다.<blockquote id="8d6feb6c-5e39-4127-b8e8-4515c0d0c63c" class="">주키퍼란?</blockquote><h2 id="6805b16f-34c3-49a1-baea-38d54cc5d2c8" class="">메시지 흐름</h2><p id="d59c29fa-8569-4fdd-a14a-86b9c6f3a7d2" class="">메시지 흐름은 다음의 순서로 살펴본다.</p></li></ol><ul id="86ec074a-59f0-4839-bfde-852b3aa1bff4" class="bulleted-list"><li style="list-style-type:disc">1:1 채팅 메시지 처리 흐름</li></ul><ul id="2745ff92-31ea-4241-9b77-48d8c0cbcbb0" class="bulleted-list"><li style="list-style-type:disc">여러 단말 간 메시지 동기화 과정</li></ul><ul id="0f3c9fe4-0806-4cee-9b4e-06204da1da5f" class="bulleted-list"><li style="list-style-type:disc">그룹 채팅 메시지 처리 흐름도</li></ul><h3 id="ccc76ff0-38f2-4519-80d1-02b0a2ef4acc" class="">1:1 채팅 메시지 처리 흐름</h3><figure id="0e73965f-bba3-45ad-87a3-69555abbbfa1" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F7613d271-6751-40f2-8c19-7a060a40d5b8%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.31.53.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F7613d271-6751-40f2-8c19-7a060a40d5b8%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.31.53.png"/></a></figure><p id="459df796-6b3d-4d8c-9030-23b6e11fd529" class="">1. 사용자 A가 채팅 서버 1로 메시지 전송</p><p id="7afc1c0b-c728-4862-9710-4ea159cc6b6e" class="">2. 채팅 서버 1은 ID 생성기를 사용해 해당 메시지의 ID 결정</p><p id="fd25fecb-546a-410b-aeba-d00c1d72f6a6" class="">3. 채팅 서버 1은 해당 메시지를 메시지 동기화 큐로 전송</p><p id="4a048415-8eba-464f-9966-700dd7ac4e2d" class="">4. 메시지가 키-값 저장소에 보관됨</p><p id="21714eed-c2c3-4d6c-9d4b-6d0565735585" class="">5.</p><ul id="1a62e8d4-5f40-43d2-87f3-0d30bab7255c" class="bulleted-list"><li style="list-style-type:disc">(a) 사용자 B가 접속 중인 경우, 메시지는 사용자 B가 접속 중인 채팅 서버인 채팅 서버2로 전송됨</li></ul><ul id="acd0a179-5b77-4710-8ffa-ee633e2acb12" class="bulleted-list"><li style="list-style-type:disc">(b) 사용자 B가 접속 중이 아니라면 푸시 알림 메시지를 푸시 알림 서버로 보냄</li></ul><ol type="1" id="9bca10cb-a639-46ed-a965-4e2d807ce191" class="numbered-list" start="1"><li>채팅 서버 2는 메시지를 사용자 B에게 전송. 사용자 B와 채팅 서버 2 사이에는 웹 소켓 연결이 되어있어 소켓을 사용함.</li></ol><h3 id="b62aff5b-4627-45d1-9f8a-ea0a9e4779d0" class="">여러 단말 사이의 메시지 동기화</h3><figure id="ee40ca24-7c5e-4662-b6eb-4abb51e0430d" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F9d82a1c2-c56a-444f-9cb1-a11a1bd814f4%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.37.25.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F9d82a1c2-c56a-444f-9cb1-a11a1bd814f4%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%209.37.25.png"/></a></figure><p id="85000ca6-4558-46ec-8aec-eda5e4773fc1" class="">사용자 A는 전화기와 랩톱 두 대의 단말을 사용하고 있다. 사용자 A가 전화기에서 채팅 앱에 로그인 한 결과로 채팅 서버 1과 해당 단말 사이에 웹 소켓이 만들어진다.</p><p id="3f927f1e-575d-414b-a1e8-28a281564790" class="">랩톱에서 로그인한 결과 또한 별도 웹 소켓이 채팅 서버 1에 연결되어 있다.</p><p id="82b90c92-eb72-472d-830b-587ae95c03e7" class="">각 단말은 <code>cur_max_message_id</code> 변수를 유지하는데, 해당 단말에서 관측된 가장 최신 메시지의 ID를 추적하는 용도이다. 아래 두 조건을 만족하는 메시지는 새 메시지로 간주한다.</p><ul id="84d901f0-7587-4564-9052-4fd55a22e9ea" class="bulleted-list"><li style="list-style-type:disc">수신자 ID가 현재 로그인한 사용자 ID와 같다.</li></ul><ul id="2dfaf210-af7d-4134-9087-c6a23131287d" class="bulleted-list"><li style="list-style-type:disc">키-값 저장소에 보관된 메시지로서, 그 ID가 cur_max_message_id보다 크다.</li></ul><p id="a84d77d4-a7e4-458f-9e41-be8aad3ba065" class=""><code>cur_max_message_id</code>는 단말마다 별도로 유지 관리하면 되는 값이라 키-값 저장소에서 새 메시지를 가져오는 동기화 작업도 쉽게 구현할 수 있다.</p><h3 id="087d2ce0-a6ee-4fd0-b8e0-b98d7ad087ef" class="">소규모 그룹 채팅에서의 메시지 흐름</h3><figure id="f965e782-792b-49ef-847b-19b94333ca61" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F54d16594-9ce6-4ea4-a160-ff01dc48b725%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.16.38.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F54d16594-9ce6-4ea4-a160-ff01dc48b725%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.16.38.png"/></a></figure><p id="153883c4-315b-45e1-81ce-9bfe86304683" class="">그림 12-14를 보면, 사용자 A가 그룹 채팅 방에서 메시지를 보냈을 때 메시지가 사용자 B,C앞에 존재하는 각각의 메시지 동기화 큐에 들어가는데, 이 큐는 각 사용자를 위한 메시지 수신함 같은 것이다. 이 설계는 다음의 이유로 소규모 채팅방에 적합하다.</p><ul id="c95d7453-e2e0-4189-8ef6-eea4960c5bc2" class="bulleted-list"><li style="list-style-type:disc">새로운 메시지가 왔는지 확인하려면 자기 큐만 보면 되니까 메시지 동기화 플로우가 단순하다.</li></ul><ul id="d69f82b4-c06f-45d0-95bc-224d6a6dd57d" class="bulleted-list"><li style="list-style-type:disc">그룹이 크지 않으면 메시지를 수신자별로 복사해서 큐에 넣는 작업의 비용이 문제가 되지 않는다.<p id="cd32afc2-42a0-4bbe-a978-e3c654ea83f7" class="">위챗이 위와 같은 접근법을 쓰고 있으며 그룹의 크기는 500명으로 제한하고 있다.</p><p id="b3d8dc92-a7a0-4ba2-9edb-c96ed90b00a6" class="">위와 같은 설계를 수신자 관점에서 살펴보자. 여러 사용자가 보내는 메시지를 받아야 한다.</p><figure id="fc6abb9e-6363-43c0-a088-8a88e1b8cc66" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F74e203ee-731b-4c98-8261-0dfbed060119%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.21.31.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F74e203ee-731b-4c98-8261-0dfbed060119%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.21.31.png"/></a></figure></li></ul><h3 id="2a15de56-2cb6-439b-89c6-b416861463cc" class="">접속 상태 표시</h3><p id="54338644-9327-44c0-b8e8-c03bfee2f966" class="">채팅 어플리케이션을 사용하다보면 사용자 프로필 이미지나 대화명 옆에 녹색 점이 붙어 있는 것을 보게 된다. 이 녹색점을 표현하기 위해 무엇이 필요한지 자세히 살펴보겠다. 개략적 설계안에서는 접속 상태 서버를 통해 사용자의 상태를 관리한다고 했다.</p><p id="8ed8b527-ee77-4f5d-8c5a-640d01c24e9d" class="">사용자의 상태가 바뀌는 시나리오는 아래와 같다.</p><h3 id="6b87ca4e-1aaf-4aa5-9d7f-09e14e08533f" class="">사용자 로그인</h3><p id="dcd85a46-594f-4b78-acb5-6fd570280d71" class="">로그인 절차는 <code>서비스 탐색</code>절에서 설명했었다. 클라이언트와 실시간 서비스 사이에 웹 소켓 연결이 맺어지고 나면 접속상태 서버는 A의 상태와 last_active_at 타임스탬프 값을 키-값 저장소에 보관한다. 이 절차가 끝나고 나면 해당 사용자는 접속 중인 것으로 표시된다.</p><figure id="c3ca873f-c5b7-4d2c-952e-4584fbdbfc4d" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fb6931286-1d67-4473-9852-8d1fabdf501e%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.56.18.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fb6931286-1d67-4473-9852-8d1fabdf501e%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2010.56.18.png"/></a></figure><h3 id="2a3cb2c9-eda0-4e6f-b28e-9378bee27f43" class="">로그아웃</h3><figure id="16c5dc4a-7228-4733-adf1-180ccbc0fe2c" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fb1134bb8-17b2-4fc3-8ad8-616f3d50f2b3%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.04.50.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2Fb1134bb8-17b2-4fc3-8ad8-616f3d50f2b3%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.04.50.png"/></a></figure><p id="9b011df2-2c23-4f4c-a5d7-46f048493f0d" class="">사용자 로그아웃 시 키-값 저장소에 보관된 사용자 상태가 online에서 offline으로 변경된다.</p><p id="ee550215-b8c1-439d-a217-fd69d5e4f186" class="">이 절차가 끝나고 나면 UI 상에서 사용자의 상태는 접속 중이 아닌 것으로 표시된다.</p><h3 id="af97e8f5-a29e-4ea0-a4ba-1e59f467bdd4" class="">접속 장애</h3><p id="bf29f794-d65b-4f77-84a4-3eac278ba9fe" class="">짧은 시간동안 인터넷 연결이 끊어졌다 복구되는 현상에 대응할 수 있는 설계를 준비해야 한다. 사용자의 인터넷 연결이 끊어지면 웹소켓 같은 지속성 연결도 끊어진다. 이런 장애에 대응하는 간단한 방법은 사용자를 오프라인 상태로 표시하고 연결이 복구되면 온라인 상태로 변경하는 것이다. 하지만 짧은 터널을 반복해서 통과하는 동안 사용자의 접속 상태를 변경한다면 UX 측면에서 바람직하지 않다.</p><p id="adc91865-2af4-4e9a-8a78-554ba44d6ef8" class="">본 설계에서는 heartbeat 검사를 통해 이 문제를 해결해 본다.</p><p id="45bf2ed3-cae9-4652-b3dd-73a98cc736ed" class="">온라인 상태의 클라이언트로 하여금 주기적으로 heartbeat event를 접속상태 서버로 보내고, 마지막 이벤트를 받은 지 x초 이내에 또 다른 heartbeat event 메시지를 받으면 해당 사용자의 접속 상태를 계속 온라인으로 유지한다. 그렇지 않은 경우에만 오프라인으로 바꾼다.</p><figure id="9a7fcf87-4d12-40f2-bf6d-f4880498865e" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F6e0f69d8-a2a9-4510-8c6d-f7eed3abe703%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.16.17.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F6e0f69d8-a2a9-4510-8c6d-f7eed3abe703%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.16.17.png"/></a></figure><p id="959db253-7ee6-4290-bb2e-6f61762bbf9f" class="">그림 12-18의 클라이언트는 heartbeat event를 5초에 한번씩 서버로 보낸다. 이벤트를 3번 보낸 후, 클라이언트가 30초 동안 heatbeat event를 보내지 않았기 때문에 서버는 사용자를 오프라인 상태로 변경한다.</p><h3 id="0e3a6c49-2048-4682-9b23-0c994eb624d5" class="">상태 정보의 전송</h3><p id="c6a677e4-b5af-4b9e-b11b-cd110bb3225a" class="">그렇다면 사용자 A와 친구 관계에 있는 사용자들은 어떻게 해당 사용자의 상태변화를 알게 될까?</p><figure id="dd134ec0-83dd-430a-ae50-963b31658d01" class="image"><a href="https://velog.velcdn.com/images%2Fjay%2Fpost%2F5edeff90-a3ea-4462-8c39-a175ec83fe7e%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.18.19.png"><img src="https://velog.velcdn.com/images%2Fjay%2Fpost%2F5edeff90-a3ea-4462-8c39-a175ec83fe7e%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-03-03%20%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE%2011.18.19.png"/></a></figure><p id="23322da1-8851-43da-8560-b16657f10097" class="">상태 정보 서버는 publish-subscribe model을 사용하며 친구 관계마다 채널을 하나씩 둔다. 가령 사용자 A의 접속 상태가 변경되었다고 하면 A-B,A-C,A-D 세 개의 채널에 쓴다.</p><p id="88b9aacc-71d8-4700-ba9f-8058da016a6e" class="">채널 A-B : B가 구독</p><p id="18f1067b-4bab-4dfb-b9b9-c4ec324fe28d" class="">채널 A-C : C가 구독</p><p id="caae1d62-03d0-4c56-80ec-1b3ffb89f6e9" class="">채널 A-D : D가 구독</p><p id="32b4daac-961f-4d29-8b41-bc4811b20a29" class="">클라이언트와 서버 사이의 통신에는 실시간 웹소켓을 사용한다.</p><p id="d0aa2b87-2f0a-4101-9d7c-486b84ede776" class="">이 방안은 그룹의 크기가 작을 때 효과적이다. 위쳇이 이와 유사한 접근법을 사용한다.</p><p id="6f79d1dd-013a-4655-a329-622ca8267483" class="">그룹의 크기가 커지면 이런 식의 접속 상태 변화 알림은 비용과 시간이 많이 든다. 가령 100,000 명의 사용자가 사용하는 채팅 그룹에서는 상태 변화 1건당 100,000개의 이벤트 메시지가 발생한다. 이를 해결하기 위해서는 입장하는 순간에만 상태 정보를 읽어가게 하거나, 친구 리스트에 있는 접속 상태를 갱신하고 싶으면 수동으로 하도록 유도한다.</p><h2 id="2660e5cd-d39c-41a1-a8e9-3b1770ae922f" class="">마무리</h2><ul id="05184998-7e59-45ec-b028-eaba42ee9beb" class="bulleted-list"><li style="list-style-type:disc">클라이언트와 서버 사이의 실시간 통신에는 웹소켓을 사용한다.</li></ul><p id="a11ccdd8-24a6-4041-aa63-2c126f82312f" class="">설계에 포함되는 컴포넌트들은 다음과 같다.</p><ul id="fb094f97-7824-4176-947e-ce95b4a45522" class="bulleted-list"><li style="list-style-type:disc">실시간 메시징을 지원하는 채팅 서버</li></ul><ul id="7941757c-1bc4-4886-b8e8-ebeeb58b4cd4" class="bulleted-list"><li style="list-style-type:disc">접속 상태 서버</li></ul><ul id="d6b47e50-8b53-49f3-aff1-3f5451ad7b75" class="bulleted-list"><li style="list-style-type:disc">푸시 알림 서버</li></ul><ul id="bfb9977e-01fd-4d6e-a81a-eff01fc30a68" class="bulleted-list"><li style="list-style-type:disc">채팅 이력을 보관할 키-값 저장소</li></ul><ul id="053d8b00-3904-4a0f-bc8c-4db7fba159dd" class="bulleted-list"><li style="list-style-type:disc">나머지 기능을 구현할 API 서버</li></ul><h3 id="27255d89-cf70-45e2-9d71-3a340a0d1ab0" class="">추가 고려 사항</h3><ul id="86b7140a-6a2b-466c-aaf5-14ff61ad29cc" class="bulleted-list"><li style="list-style-type:disc">로딩 속도 개선: <a href="https://slack.engineering/flannel-an-application-level-edge-cache-to-make-slack-scale/">슬랙은 사용자의 데이터, 채널등을 지역적으로 분산하는 네트워크를 구축하여 앱 로딩 속도를 개선하였다.</a></li></ul><ul id="d30a32a7-7613-49f9-b476-976dd52d0542" class="bulleted-list"><li style="list-style-type:disc">종단 간 암호화: <a href="https://faq.whatsapp.com/general/security-and-privacy/end-to-end-encryption">왓츠앱은 메시지 전송에 있어 종단 간 암호화를 지원한다. 메시지 발신인과 수신자 이외에는 아무도 메시지를 볼 수 없다는 뜻이다.</a></li></ul><ul id="0d5cd80b-0e33-441d-a6d8-c942299671b4" class="bulleted-list"><li style="list-style-type:disc">오류 처리:<ul id="b1772fa2-3a74-4076-b1b2-af04a3df1907" class="bulleted-list"><li style="list-style-type:circle">채팅 서버 오류: 채팅 서버 하나에 수십만 사용자가 접속해 있는 상황을 생각해보자. 그런 서버 하나가 죽으면 서비스 탐색 기능(주키퍼)가 동작하여 클라이언트에게 새로운 서버를 배정하고 다시 접속할 수 있도록 해야 한다.</li></ul><ul id="86e71f6d-b137-40bd-b40f-a1acaa198e8e" class="bulleted-list"><li style="list-style-type:circle">메시지 재전송: 재시도(retry)나 큐(queue)는 메시지의 안정적 전송을 보장하기 위해 흔히 사용된다.</li></ul></li></ul></details></li></ul><ul id="df2ed0de-46d7-48bf-9155-5f42b91145fe" class="toggle"><li><details open=""><summary>Web Socket Chat</summary><p id="71f5c6e7-f88d-4ec5-858e-40c6c6f9583e" class="">카카오톡과 디스코드 채팅방을 모티브로 웹 소켓과 REST API를 구성해 만든 실시간 다중 채팅 서버 입니다. 회원은 자유롭게 채팅방을 개설 할 수 있고 공개된 다른 사람의 채팅방에 입장할 수 있습니다.</p><p id="f4220ee3-737b-40a5-849b-9cfc6fa369f5" class="">지난 CMP 프로젝트를 경험하며 실시간으로 변화하는 정보를 클라이언트에 전달하기위한 양방향 통신을 적용하지 못해 아쉬웠던 기억이 있습니다. 웹 소켓을 이용해 양방향 통신을 어떻게 적용할 지 고민하며 채팅, 간단한 웹 게임, 파일 업로드 모니터링 시스템을 떠올렸습니다. 양방향 통신과 분산환경에서 메시지 전달 등 궁금한 기술에 대해 공부 할 수 있을 것 같아 웹 채팅 서버를 구현했습니다.</p><p id="185f92d0-6c4c-48ab-8828-f877e8f7f092" class=""><strong>1. 설계</strong></p><p id="a2ff4745-bb10-4124-9aa8-a5e29443765d" class=""><strong>1.1 데이터와 요청의 흐름</strong></p><p id="3f180776-267b-4bf5-9b5d-d460c2e3d02c" class=""><strong>1.2 웹 소켓 메시지 프로토콜 디자인</strong></p><ul id="feb731c0-fb61-45e7-b857-f1ec87654669" class="bulleted-list"><li style="list-style-type:disc">채팅 메시지의 전달과 채팅 방 이벤트 메시지를 전달하기위한 웹 소켓 서버(WebFlux)와 회원 가입, 채팅 방 생성 등 요청을 처리하기위한 REST API 서버(MVC)를 분리해 멀티-모듈 프로젝트로 구성했습니다.</li></ul><ul id="5919d315-0aec-40b1-bd43-df2d920924ce" class="bulleted-list"><li style="list-style-type:disc">지난 버전 v0.0.1에서는 웹 소켓 서버도 Spring MVC로 구성해 STOMP를 사용했고 미리 구현된 내부의 브로커를 이용해 메시지를 전달하는 방식을 사용했습니다. v1.0.0 업그레이드 과정을 거치며 비동기 리액티브 프로그래밍을 공부하고자 웹 소켓 서버를 WebFlux로 구성했습니다.</li></ul><ul id="36f88f46-6db1-4862-abc2-d1214218bc83" class="bulleted-list"><li style="list-style-type:disc"><strong>Raw Web-Socket</strong>을 사용하며 이번 프로젝트에서 사용 할 자체 프로토콜을 간단히 디자인했습니다.</li></ul><p id="326ed64c-485a-488f-9ace-29e3048799d8" class=""><strong>1.3 데이터베이스</strong></p><p id="def23d3a-4917-43b8-9a1b-d43f7dc68218" class=""><strong>1.3.1 엔티티 관계도</strong></p><ul id="c346e404-c662-4db5-9d56-37a00fbddff5" class="bulleted-list"><li style="list-style-type:disc">ERD 상 관계를 표현하기위해 FK 관계를 입력 했지만 실제 스키마에는 FK를 설정하지 않았습니다.</li></ul><p id="04c3f4c5-fae2-41c7-82e4-b6ea2de94fb3" class=""><strong>1.3.2 채팅 메시지 도큐먼트 구조</strong></p><p id="a8271129-a5c5-4c23-9df9-369c9e867efe" class=""><strong>1.3.3 데이터베이스를 분리한 이유</strong></p><ul id="49aa78e3-0d8f-4468-973a-6ba4ccab5a3a" class="bulleted-list"><li style="list-style-type:disc">동시성 처리의 필요성<ul id="431e09fc-6b3d-4419-bb10-3e3432d3bac0" class="bulleted-list"><li style="list-style-type:circle">채팅 방 참여정보는 일관된 데이터 정합성이 요구됩니다.</li></ul><ul id="66bcde8f-35a7-49e7-8f72-c96e0062c7bd" class="bulleted-list"><li style="list-style-type:circle">동시에 채팅 방 입/퇴장 요청이 몰렸을 경우 트랜잭션과 Lock을 기반한 동시성 처리가 용이합니다.</li></ul></li></ul><ul id="43d42629-ab8d-4d70-bde8-faaa1b2c55be" class="bulleted-list"><li style="list-style-type:disc">쓰기 성능의 확보<ul id="994add97-4e62-4e56-9f2d-72d0b0546360" class="bulleted-list"><li style="list-style-type:circle">채팅 메시지는 읽기 작업 만큼 쓰기 작업 빈도가 많이 발생합니다.</li></ul><ul id="3871ba2c-5a44-44dd-bf48-71c9803cbf06" class="bulleted-list"><li style="list-style-type:circle">MySQL과 같은 RDBMS는 쓰기 작업에 데이터 정합성을 위해 Lock을 사용하고 디스크에 동기화 하는 과정에서 디스크 I/O가 발생합니다.</li></ul><ul id="72c094a4-1032-4e7c-8566-beaf52496950" class="bulleted-list"><li style="list-style-type:circle">MongoDB는 일반적인 쓰기작업에서 락을 사용하지 않고 메모리에 데이터를 적재해 I/O 작업을 최소화 할 수 있어 쓰기작업에서 소요시간을 줄일 수 있습니다.</li></ul></li></ul><ul id="0e0b3e61-a19b-4783-a230-02adedbf3197" class="bulleted-list"><li style="list-style-type:disc">빠르게 증식하는 데이터<ul id="f2f9c41f-2838-4d43-8b91-c3cbd0c2d984" class="bulleted-list"><li style="list-style-type:circle">채팅 메시지는 주기적인 삭제 전략이 없는 경우 시간이 흐름에 따라 빠르게 데이터 규모가 증가합니다. 데이터 규모 증가에 따른 수평확장이 용이해야 합니다.</li></ul><ul id="86e399cc-6e02-4008-adec-12a404cc42a7" class="bulleted-list"><li style="list-style-type:circle">MongoDB는 수평확장(샤딩)이 용이합니다. 적재되는 데이터가 증가함에 따라 Auto Sharding이 가능하고 샤드 노드 추가 시 데이터의 리밸런싱이 필수적이지 않습니다.</li></ul><figure id="9afb20cd-eb58-4121-8bb7-61638514dac8"><a href="https://github.com/jthugg/websocket-chat?tab=readme-ov-file" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">GitHub - jthugg/websocket-chat: 🚀 웹소켓을 이용한 아이디어 프로젝트 - 채팅편 2023.12 ~ 2024.4</div><div class="bookmark-description">🚀 웹소켓을 이용한 아이디어 프로젝트 - 채팅편 2023.12 ~ 2024.4. Contribute to jthugg/websocket-chat development by creating an account on GitHub.</div></div><div class="bookmark-href"><img src="https://github.com/fluidicon.png" class="icon bookmark-icon"/>https://github.com/jthugg/websocket-chat?tab=readme-ov-file</div></div><img src="https://opengraph.githubassets.com/16c5e590ce388bda30f270f165d57869103727b65afc963667f35b65dc636387/jthugg/websocket-chat" class="bookmark-image"/></a></figure></li></ul></details></li></ul><ul id="d3135e7a-bddc-4b7b-80cd-b9ffe543ade3" class="toggle"><li><details open=""><summary>LINE 오픈챗 서버가 100배 급증하는 트래픽을 다루는 방법</summary><p id="fb187217-6bed-4676-a754-6f0f790e7c82" class="">안녕하세요. Square Dev 팀 김인제입니다. 이번 글에서는 LINE 오픈챗(OpenChat) 서버에서 100배 급증하는 트래픽을 다루는 방법을 소개하겠습니다.</p><p id="f1dcbb80-2c94-44a1-bfb6-386a70cb8750" class="">아래는 이번 글에서 공유하고자 하는 핵심 내용을 슬라이드 한 장으로 요약한 것입니다. SNS 팔로워 수가 수백만 명인 유명한 가수의 콘서트를 팬들이 함께 보며 실시간으로 오픈챗에서 활발하게 메시지를 주고받았던 사례입니다.</p><p id="198e0453-1709-4342-8408-ee410ff8969c" class="">수천 명의 사용자가 한 오픈챗 안에서 많은 메시지를 동시에 주고받다 보면 일반 오픈챗 대비 100배 이상 트래픽이 급증할 수 있습니다. 오픈챗 서버 팀에서는 이와 같은 챗을 &#x27;핫 챗&#x27;이라고 부르는데요. 이번 글에서는 오픈챗 서버 팀이 경험한 두 가지 핫 챗 패턴과 핫 챗 때문에 발생한 문제, 그 문제를 어떤 방식으로 해결했는지 공유하겠습니다. 글은 LINE 오픈챗 소개, 오픈챗 서버 팀이 핫 챗에서 급증하는 트래픽을 다루는 방법, 향후 계획 순으로 진행합니다.</p><h1 id="709b990b-56a3-4936-8bf8-74b81dea9eb8" class=""><strong>LINE 오픈챗 소개</strong></h1><p id="60430fb7-fe53-416e-9644-83eb5f2348a5" class="">먼저 간단히 LINE 오픈챗을 소개하겠습니다. LINE 오픈챗은 LINE 앱 대화 탭 우측 상단에 있는 네모 모양의 오픈챗 로고를 클릭해 사용할 수 있습니다. 다양한 오픈챗을 추천받거나 검색할 수 있으며, 오픈챗에 들어가면 메시지나 이미지, 메시지 리액선 등을 실시간으로 주고받을 수 있습니다.</p><p id="9b788a2c-1cf8-41e6-9d0d-441c112892a1" class="">오픈챗 서버는 1분에 천만 개, 하루에 약 100억 개의 API 요청을 처리하고 있습니다. 한 오픈챗에 수천 명부터 수만 명의 사용자가 참여할 수 있고, 활발한 오픈챗은 한 오픈챗에서만 1분에 20만 개의 API 요청을 처리하기도 합니다.</p><p id="d2c76d67-5964-477c-a60a-609e1b6281f7" class="">만약 한 오픈챗에 참여한 5천 명의 사용자가 모두 동시에 활발하게 메시지를 주고받는다면 어떤 일이 발생할까요? 실제로 소셜미디어 팔로워가 수백만 명에 달하는 유명 가수의 콘서트를 팬들이 함께 보며 참여하는 오픈챗이 있었고, 배우나 모델, 인플루언서의 방송 출연을 함께 보는 오픈챗, 온라인 게임의 이벤트를 함께 즐기는 오픈챗 등이 있었습니다.</p><p id="6efeaf5d-1e08-4024-9497-5927566e7580" class="">이와 같은 오픈챗에선 일반적인 오픈챗 대비 트래픽이 100배 이상 급증할 수 있습니다. 아래 오른쪽 사진을 보면 5천 명이 참여해 1초에 수백 개의 메시지가 전송될 정도로 활발하게 활동하는 한 오픈챗이 나타나서, 이 챗의 새로운 메시지들을 가져가려는 API 요청 수가 1분에 최대 20만 건에 달하며 급증하는 것을 확인할 수 있습니다. 이와 같이 트래픽이 급증하는 오픈챗을 오픈챗 서버 팀에서는 핫 챗이라고 부릅니다.</p><figure id="85aac070-116a-4382-ac67-5d9d714635b2" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.53.23.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.53.23.png"/></a></figure><p id="bd98ba8b-9985-45bc-9fb4-b672a9fdc6de" class="">핫 챗에서 이렇게 많은 수의 API 요청이 발생하는 이유는 오픈챗 서버의 이벤트 기반 아키텍처와 깊은 관련이 있습니다. 오픈챗 서버에서는 메시지 전송과 메시지 리액션, 메시지 읽음 등과 같은 오픈챗 내 다양한 행위를 모두 이벤트로 간주하고 이벤트가 생성될 때마다 스토리지에 저장한 후 오픈챗에 참여하고 있는 모든 사용자에게 서버 푸시로 &#x27;새로운 이벤트가 생성됐으니 받아 가세요&#x27;라고 알립니다. 서버 푸시를 받은 사용자(클라이언트)는 스토리지에 새로 들어온 이벤트를 페치(fetch) 이벤트 API를 이용해 받아 가서 새 메시지 등을 화면에 추가하는 액션을 실행합니다.</p><p id="d6454c3b-ee46-45d8-b59b-5e0e93dd5558" class="">이와 같은 이벤트 기반 아키텍처에서는 이벤트가 생성될 때마다 오픈챗에 참여하고 있는 모든 사용자에게 전달해야 합니다. 5천 명이 한 오픈챗에 참여하고 있다고 가정하면 이벤트가 하나 생성될 때마다 5천 명의 사용자가 이 이벤트를 전달받기 위해 5천 개의 페치 이벤트 API 요청을 호출하는 것입니다. 따라서 1초에 수십 개의 이벤트가 생성되는 핫 챗에서는 그만큼 페치 이벤트 API 요청이 급증하게 됩니다.</p><h1 id="50af9003-9423-4bcc-81e3-b17bdd775f86" class=""><strong>핫 챗에서 급증하는 트래픽을 다루는 방법</strong></h1><p id="0a3b84e0-aeb2-47c3-a56d-616154faaae5" class="">이와 같이 트래픽이 급증하는 핫 챗은 오픈챗 서비스가 성장하고 있다는 지표임과 동시에 오픈챗 서버가 해결해 할 도전 과제이기도 합니다. 핫 챗 때문에 오픈챗 서버에서 실제로 발생했던 문제와 해결해 나간 과정을 핫 챗 패턴별로 설명하겠습니다.</p><h3 id="c3efa6c8-4a40-46ea-90ea-df7761728b19" class=""><strong>패턴 1: 페치 이벤트 API 요청 급증</strong></h3><p id="3921fb0c-742e-4934-b1dc-ecb005f2f1fc" class="">첫 번째로 소개할 핫 챗 패턴은 사용자가 새로운 이벤트들을 받아기 위한 페치 이벤트 API 요청이 급증하는 핫 챗입니다.</p><h3 id="b8f323ef-f2d0-4788-bccf-0e43e37862bc" class=""><strong>문제 현상</strong></h3><p id="c7c643d9-9461-4f9c-8348-ac683c90285d" class="">아래는 오픈챗 서버 구조를 조금 더 자세히 그려본 다이어그램입니다. 메시지를 전송하면 오픈챗 서버가 이를 스토리지에 저장하고 Kafka 이벤트를 전달하며, 오픈챗 서버 팀에서 &#x27;퍼블리시(publish) 서버&#x27;라고 부르는 별도 서버 그룹에서 Kafka 이벤트를 소비해서 새로운 이벤트가 생성됐다고 알리는 서버 푸시를 사용자에게 보냅니다.</p><figure id="edb52566-2ed7-4d29-9039-865903aa6146" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.54.21.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.54.21.png"/></a></figure><p id="b1d88b55-e660-42a9-a587-4f5f7421f06d" class="">이런 구조에서 5천 명의 사용자가 1초에 수십 개의 메시지를 주고받는 핫 챗에서는 페치 이벤트 API 요청 수가 평소 대비 100배 이상 급증하면서 특히 오픈챗 서버에서 사용하는 스토리지에 큰 부하가 발생하는 문제가 있었습니다.</p><p id="1dd9f87d-d611-43b8-91a4-100594977634" class="">아래는 관련 지표입니다. 왼쪽 사진을 보면 한 핫 챗에서 페치 이벤트 API 요청이 급증하면서 MySQL과 Redis 등의 스토리지에서 한 샤드(shard)에 전달되는 요청량이 3배 이상 급증하거나 <strong>스토리지 부하 때문에 오픈챗 서버에서 응답 타임아웃이 발생</strong>하는 경우가 발생했습니다.</p><p id="0b9da0ee-685c-4d1e-b3d7-c1e0cbd9713f" class="">또한 이 핫 챗의 이벤트를 처리하는 Kafka의 한 파티션에 대량 이벤트가 생성돼 <strong>오프셋 랙(offset lag)이 증가하거나 핫 챗 요청을 처리하는 서버 그룹의 GC(garbage collect)와 CPU 사용량이 급증</strong>하는 것을 지표로 확인할 수 있었습니다.</p><p id="35ae36d2-366a-45b3-92bf-ce39bdcc611b" class="">그렇다면 왜 핫 챗은 스토리지에 이런 큰 부하를 발생시키는 걸까요? 오픈챗 서버에서는 데이터를 저장하기 위해 MySQL과 Redis, HBASE, Kafka 등 다양한 스토리지를 사용하고 있으며, 챗 ID를 기반으로 샤딩(sharding)해서 데이터를 저장합니다. 오픈챗 서비스가 성장해 더 많은 챗이 생성되면 샤드를 추가하는 방식으로 확장할 수 있는 구조이지만, 핫 챗은 하나의 오픈챗이므로 챗 ID를 기반으로 샤딩하는 구조에서는 하나의 핫 챗 안에서 발생하는 데이터를 더 이상 분산시킬 수 없습니다. 따라서 하나의 핫 챗에서 발생하는 모든 요청은 스토리지에서 하나의 샤드, 하나의 키로 몰리면서 부하가 집중됩니다.</p><figure id="a87589f4-296c-4dee-b312-5d8ea6664237" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.56.44.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.56.44.png"/></a></figure><h3 id="585d6413-9fe1-4de5-a027-5c89073a04b7" class=""><strong>해결 방안</strong></h3><p id="eb88b462-6ae2-479e-885d-648f94c7de0d" class="">한 샤드로 집중되는 핫 챗의 부하를 줄이기 위해서는 샤드를 추가해 전체 샤드 수를 늘리거나 샤드의 복제본 수를 늘리는 등의 방법을 고려해 볼 수 있습니다.</p><figure id="a2e756b9-cc77-4a3f-8b45-8409ffdb36a7" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.57.15.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.57.15.png"/></a></figure><p id="154514f2-b922-49cd-a012-041517119745" class="">하지만 핫 챗이 전체 오픈챗에서 차지하는 비중은 0.1% 미만에 불과합니다. 언제 발생할지 모르는 극소수의 핫 챗을 위해 샤드를 추가하거나 전체 데이터의 애플리케이션 수를 늘리는 등의 방법은 오버헤드가 너무 크다고 판단했습니다.</p><p id="54e264e0-0ea5-4ae5-95d9-64f5823fcf40" class="">딱 핫 챗만 타깃으로 적용할 수 있는 해결 방법이 없을까 고민했고, 그 결과 실시간으로 핫 챗을 탐지해서 핫 챗에서 발생하는 페치 이벤트 API 요청만 줄이는 방법을 택했습니다. 이 방법으로 핫 챗 때문에 하나의 샤드에 몰리는 부하만을 효과적으로 줄일 수 있다고 판단했습니다. 이 방식을 핫 챗 감지 및 스로틀링(detection &amp; throttling)이라고 부르고 있으며, 어떻게 작동하는지 조금 더 자세히 설명하겠습니다.</p><figure id="e5ac2330-f953-4690-af7a-ee8e8cfbee2e" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.58.02.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.58.02.png"/></a></figure><p id="a1edd19d-f0d7-471f-b0ce-0e9e15f90548" class="">우선 실시간으로 어떤 챗이 핫 챗인지 탐지할 수 있는 방법이 필요했고, Kafka와 버킷(bucket)으로 구현했습니다. 페치 이벤트 API가 요청될 때마다 Kafka로 이벤트를 전송하고 퍼블리시 서버에서 이를 소비해 하나의 챗에 최근 몇 초 동안 몇 개의 페치 이벤트 API가 요청됐는지 실시간으로 기록합니다. 만약 페치 이벤트 API 요청이 미리 설정해 둔 임곗값(스토리지에 큰 부하를 주기 시작하는 요청 수)보다 더 많이 들어온다면 이를 핫 챗으로 판단, 해당 챗이 핫 챗이라고 Redis에 잠시 저장합니다.</p><p id="7ebb157c-91ea-4ef1-8329-a52c43601569" class="">이 과정을 코드로 살펴보면, 챗 ID별로 최근 몇 초 동안 몇 개의 페치 이벤트 API 요청이 들어왔는지를 기록할 수 있는 버킷을 준비하고, 페치 이벤트 API 요청마다 이 버킷에 기록하다가 임곗값을 넘으면 Redis에 해당 챗이 핫 챗임을 잠시 저장합니다.</p><p id="6555fedc-24f5-4145-85e4-dd7ec36b50b3" class="">퍼블리시 서버에서는 사용자에게 새로운 이벤트가 생성됐다고 알리는 서버 푸시를 보내기 전에 이 이벤트가 생성된 챗이 핫 챗인지 Redis에서 확인합니다. 만약 핫 챗이면 서버 푸시를 확률적으로 스로틀링해서 보내지 않는 방법으로 대량의 페치 이벤트 API 요청이 발생하지 않도록 조절합니다. 이 방법으로 핫 챗 때문에 발생하는 스토리지 부하만 타깃으로 잡고 줄일 수 있었습니다.</p><figure id="da53122d-f73a-4ebc-ae3e-02969b05018c" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.01.44.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.01.44.png"/></a></figure><p id="67bc19cb-381d-4b9b-bf44-f893972ae6b8" class="">핫 챗 스로틀링이 없던 과거에는 아래 왼쪽 그림처럼 1초에 수십 개의 이벤트가 한 챗에서 생성되면 이벤트 생성마다 5천 개의 서버 푸시를 전송했고, 사용자는 5천 개의 페치 이벤트 API 요청을 호출했습니다. 하지만 핫 챗 스로틀링을 적용한 후에는 오른쪽 그림처럼 핫 챗을 대상으로만 서버 푸시 개수를 조절할 수 있게 됐습니다. 사용자 입장에서는 하나의 서버 푸시만 받으면 새롭게 생성된 이벤트를 모두 받아 갈 수 있기 때문에, 1초에 수십 개의 이벤트가 발생하더라도 사용자에게 거의 영향을 주지 않고 핫 챗의 페치 이벤트 API 요청량만 효과적으로 줄일 수 있습니다.</p><figure id="afa70e61-4fd1-44e4-84a2-edbfbd102f65" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.03.02.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.03.02.png"/></a></figure><p id="04b56b97-0c7f-413b-b2e0-23d079933314" class="">핫 챗을 탐지하는 기준치나 핫 챗일 때 서버 푸시 스로틀링을 몇 초 간 어느 정도로 적용할지, 특정 챗에 스로틀링을 적용할지 등은 모두 LINE의 오픈 소스인 <a href="https://line.github.io/centraldogma/">LINE Central Dogma</a>만으로 서버 재기동 없이 동적으로 변경할 수 있도록 구현했습니다. 따라서 갑자기 발생한 핫 챗에서 큰 부하가 발생해도 오픈챗 서버 팀에서 신속하게 대응할 수 있습니다.</p><p id="018f37bd-f634-4281-879d-da80591a527d" class="">이전에는 아래 상단 사진처럼 핫 챗에서 부하가 급증하면 스토리지의 샤드 하나로 요청이 몰려 느린 쿼리(slow query)나 응답 타임아웃이 발생하는 경우가 종종 있었는데요. 핫 챗 감지 및 스로틀링을 적용한 뒤로는 핫 챗을 자동으로 탐지한 뒤 핫 챗에만 스로틀링을 적용하므로 핫 챗으로 인한 스토리지 부하 등의 이슈가 더 이상 발생하지 않고 있습니다.</p><p id="1b1838b5-20d9-4231-a3e1-ca2819b6ec4c" class="">또한 어떤 챗이 핫 챗인지, API 요청이 어느 정도 발생하고 있는지 실시간으로 확인할 수 있는 핫 챗 대시보드를 만들었습니다. 이 대시보드를 이용해 오픈챗 서버 팀에서 핫 챗을 모니터링하면서 신속하게 대응하고 있습니다.</p><h3 id="f7e7303b-2d79-491c-8ca5-3dcdcf6f53e2" class=""><strong>패턴 2: 오픈챗 참여 요청 급증</strong></h3><p id="b25b6ec7-f70a-4e34-bce1-02127522b83c" class="">두 번째로 소개할 핫 챗 패턴은 오픈챗 참여 요청이 급증하는 핫 챗입니다.</p><h3 id="ac6e0835-4f4c-4dc7-9dbe-d4fffa63715d" class=""><strong>문제 현상</strong></h3><p id="2777822e-b95b-42d4-b0db-1face42de8a0" class="">LINE 오픈챗에서는 직접 오픈챗을 검색하거나 추천 오픈챗을 통해 오픈챗에 참여할 수 있고, 오픈챗 참여 QR 코드나 링크 공유를 통해서도 참여할 수 있습니다.</p><p id="27ba5d4b-773e-4012-85a4-e98ee16eacba" class="">2021년까지만 해도 한 오픈챗에 짧은 시간 동안 오픈챗 참여가 급격하게 몰리는 경우는 거의 없었는데요. 2022년부터는 최대 1초에 2천 개의 오픈챗 참여 요청이 한 오픈챗에 몰리는 경우가 발생했습니다. 소셜미디어 팔로워를 수백만 명 보유하고 있는 인플루언서 분들이 자신의 오픈챗 참여 QR 코드를 소셜미디어에 업로드하는 등 오픈챗 서비스가 성장하며 점점 더 많은 곳에서 다양한 방법으로 활용되고 있기 때문이었습니다.</p><p id="f921a8ab-6be6-4d3a-84ea-7f36839d376f" class="">오픈챗 서버는 오픈챗 참여 요청이 오면 챗 멤버 데이터를 MySQL에 저장하는데요. 오픈챗 참여 요청이 한 챗에 몰리자 특히 MySQL 부하가 급증하는 것을 확인할 수 있었습니다.</p><figure id="02ecd9a6-4ae9-4aa5-bc4a-028ed5af8e7b" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.03.56.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.03.56.png"/></a></figure><p id="4077487e-3d8c-4b17-96cc-7c77ab99a1af" class="">실제로 1초에 2천 개 이상의 오픈챗 참여 요청이 한 챗에서 발생했을 때의 지표입니다. MySQL 1개 샤드에 INSERT 쿼리가 순간적으로 몰리고 느린 쿼리와 CPU 사용량이 급증하는 것을 확인할 수 있었습니다.</p><p id="d674341f-1785-49ab-b387-8ed0c0ca8241" class="">이에 따라 오픈챗 서버에서는 응답 타임아웃이 발생하고, MySQL의 한 샤드로 전달되는 요청들의 처리가 지연되는 것을 확인할 수 있었습니다.</p><h3 id="7111dc53-2c84-4d46-abb4-67d751ddfdac" class=""><strong>해결 방안 1 - MySQL 병목 지점 제거</strong></h3><p id="bb9f8597-83f7-4556-9240-c626af8544b1" class="">이 문제를 해결하기 위해 우선 MySQL의 병목 지점들을 찾아서 해결했습니다.</p><p id="d4dbc722-9330-4c24-862a-7c9508b2637c" class="">첫 번째로 찾은 병목 지점은 바로 &#x27;챗 멤버 <code>INSERT</code> 쿼리&#x27;였습니다. MySQL에서는 오픈챗 참여 요청이 오면 해당 쿼리를 실행하는데요. 이때 이미 가입된 사용자인지, 중복된 멤버 이름인지를 검사하기 위해 아래 왼쪽 사진처럼 <code>INSERT</code> 쿼리 내부에서 다시 <code>SELECT</code> 쿼리를 사용하는 서브 쿼리를 사용하고 있었습니다.</p><p id="bab694ab-edf5-4c32-ae74-4f6d3f9eaaf6" class="">이와 같은 서브 쿼리는 간단한 <code>INSERT</code> 쿼리와는 달리 MySQL에서 벌크 <code>INSERT</code> 구문으로 취급합니다. 이때 MySQL의 <code>innodb_autoinc_lock_mode</code>가 기본값인 1이라면 벌크 <code>INSERT</code> 구문은 <code>AUTO-INCREMENT</code> 값을 증가시키기 위해 테이블 락을 잡습니다. 오픈챗 서버에서는 MySQL의 <code>AUTO-INCREMENT</code> 락(lock) 모델을 기본값(1)으로 사용하고 있었기 때문에 한 오픈챗에 참여 요청이 급증하면 <code>AUTO_INCREMENT</code> 테이블 락 경합도 같이 급증했습니다.</p><p id="adaf5ab1-b70f-46bc-992b-03ddbcdfdac8" class="">실제로 한 오픈챗에 참여 요청이 몰렸을 때의 MySQL 지표를 확인해 보면 <code>AUTO_INCREMENT</code> 테이블 락을 잡기 위한 경합이 굉장히 많았고 이 때문에 MySQL의 CPU 사용률이 100%에 도달해 응답 타임아웃이 발생하는 것을 확인할 수 있었습니다.</p><p id="133c480f-2e64-4e88-8c63-b090f27a6bd6" class="">이와 같은 <code>AUTO_INCREMENT</code> 테이블 락 경합을 줄이기 위해 테이블 락을 잡지 않도록 MySQL의 <code>AUTO-INCREMENT</code> 락 모드를 기본값인 1에서 2(<code>interleaved</code> 모드)로 변경했습니다. 변경한 모드에서는 동시에 여러 개의 값을 <code>INSERT</code>할 때 <code>AUTO-INCREMENT</code> 값이 연속적이지 않을 수 있는데요. 사용하고 있는 쿼리에서는 한 번에 한 명만 <code>INSERT</code>하고, 또 <code>AUTO-INCREMENT</code> 값이 연속된다고 가정한 로직이 없어서 <code>AUTO-INCREMENT</code> 락 모드를 변경해도 괜찮다고 판단했습니다.</p><p id="fe00654e-a1f4-4557-8d16-7e6f0c8bd63d" class="">그 결과 한 오픈챗에 1초에 수천 개의 참여 요청이 들어와도 MySQL은 CPU 사용률을 10~20% 사이를 유지하며 안정적으로 처리했습니다.</p><p id="e46dd50d-c3a3-4a1f-ab59-150a5afa48e8" class="">두 번째로 오픈챗에 참여하고 있는 멤버 수를 가져오는 쿼리에서도 병목 지점을 찾을 수 있었습니다. 해당 쿼리는 <code>state = JOINED</code>인 멤버 수를 집계하는 방식이었는데요. 이전에는 오픈챗에 참여가 몰리는 일이 거의 없어서 성능을 높이기 위해 오픈챗 멤버를 MySQL 쿼리 캐시를 이용해 캐싱해서 사용하고 있었습니다.</p><p id="9760693f-141d-42ee-9c2c-e7c1e5580156" class="">하지만 1초에 2천 개 이상의 오픈챗 참여 요청이 몰리자 문제가 발생했습니다. 참여하고 있는 멤버 수를 캐싱하고 있는 MySQL 쿼리 캐시가 참여 요청 하나를 처리할 때마다 멤버 수 값을 갱신했는데요. 이때 테이블 락을 잡고 멤버 수를 재계산해 쿼리 캐시를 갱신하면서 큰 부하가 발생했습니다.</p><p id="347e3666-3d13-408c-a97f-6695125e9792" class="">아래는 오픈챗 참여 요청이 몰리자 쿼리 캐시 갱신 때문에 테이블 락 경합이 높아지는 현상을 지표를 통해 확인한 것입니다.</p><p id="a1c9faf4-0032-48ae-8800-2343e89fa0af" class="">이 문제는 참여하고 있는 멤버 수 값을 집계하는 별도 테이블을 도입하고 MySQL 쿼리 캐시는 제거하는 것으로 해결할 수 있었습니다.</p><p id="d1f1b071-fb38-4cc7-b9f7-78bfcb94a991" class="">이런 병목 지점들은 오픈챗 참여 요청이 많이 몰리지 않던 2021년까지는 불거지지 않다가 2022년에 오픈챗 참여 요청이 급격히 몰리면서 수면 위로 드러난 문제점들이었습니다.</p><h3 id="de55df6b-fe7c-407d-b38e-120503da8e99" class=""><strong>해결 방안 2 - 조인 스로틀링 적용</strong></h3><p id="2501aa0b-042f-41be-83f3-adcffd67fdb9" class="">MySQL 병목 지점을 조사하는 중에도 오픈챗 참여 요청이 몰리는 핫 챗들이 지속적으로 발생했습니다. 이에 MySQL 병목 지점 조사를 하면서 동시에 오픈챗 참여 요청이 MySQL 처리 한계를 넘지 않도록 빠르게 조인 스로틀링을 적용했습니다.</p><p id="382c7d58-606e-48eb-8be0-5e9ab87cf9a5" class="">조인 스로틀링은 핫 챗 스로틀링과 비슷하게 오픈챗 참여 요청 처리를 완료할 때마다 Kafka로 이벤트를 전송해 퍼블리시 서버에서 각 챗 별로 몇 개의 조회 요청이 들어오고 있는지 버킷에 기록합니다. 기록한 값이 설정해 둔 MySQL 처리량 한계를 넘으면 &#x27;잠시 뒤 다시 참여 요청해 주세요&#x27;라는 팝업 메시지를 반환하도록 구현했습니다. MySQL 병목 지점 해결 작업을 아직 진행하고 있던 시점이었기 때문에 몰리는 참여 요청으로 MySQL이 사용 불능이 되는 것보다는 참여 요청이 몰린 핫 챗에만 잠시 스로틀링을 걸어서 다른 챗에 미치는 영향을 줄인 것입니다.</p><p id="85ba6afd-fb89-4ddd-9b21-e5b27e16f08e" class="">조인 스로틀링을 적용하면서 얻은 교훈이 있습니다. Kafka를 사용하는 조인 스로틀링은 항상 몇 초 정도의 지연이 발생할 수 있다는 점이었습니다. 참여 요청 완료 후 Kafka를 통해 퍼블리시 서버로 참여 완료 이벤트를 전달하려면 Redis와 MySQL, Kafka 등 거쳐야 하는 스토리지가 많습니다 이때 특히 Kafka는 핫 챗 때문에 특정 파티션의 오프셋 랙이 순간적으로 증가해 몇 초 정도의 처리 지연이 발생할 수 있습니다. 즉 퍼블리시 서버 앞단에서 지연이 발생하면 조인 스로틀링도 그만큼 지연되는 구조인 것입니다.</p><p id="9c19bf2f-14c6-44d2-8116-64af7fe59027" class="">만약 1초에 수천 개의 오픈챗 참여 요청이 한 챗에 몰리고 있는 상황에서 조인 스로틀링이 몇 초 지연되면 어떻게 될까요? 1초 동안 몰린 수천 개의 오픈챗 참여 요청이 조인 스로틀링이 지연된 시간만큼 정상적으로 스로틀링되지 않고 모두 MySQL로 넘어갑니다. 이렇게 조인 스로틀링이 지연돼 MySQL로 넘어간 요청들은 MySQL에 더 큰 부하를 발생시키면서 지연 시간을 증가시키고, 결국 조인 스로틀링을 더욱더 지연시킵니다.</p><p id="a3068c48-d07a-46c1-9cfb-2cb120ec5f18" class="">실제로 조인 스로틀링이 잘 작동하다가 몇 초 정도 지연된 적이 있었는데요. 하필 그때 1초에 수천 개의 요청이 몰리면서 MySQL로 모든 요청이 넘어가 큰 부하를 발생시키면서 조인 스로틀링을 더욱더 지연시켜서 결국 모든 참여 요청이 허용되며 MySQL의 처리 한계를 넘겼고, 응답 타임아웃이 발생한 적이 있습니다.</p><p id="68f35ce8-c62a-420f-a164-d91f8105cec4" class="">이 문제를 해결하기 위해 조인 스로틀링에 Kafka가 아닌 Redis를 사용해서 오픈챗 참여 요청이 들어올 때마다 바로 Redis에서 참여 요청 수를 챗별로 집계하는 방식을 사용할 수도 있는데요. 핫 챗은 0.1% 비율로 발생하는 극소수의 챗인데 이를 위해 99.9%에 해당하는 일반적인 챗의 모든 참여 요청까지 Redis에 함께 기록하는 것은 큰 오버헤드라고 생각했습니다. 이에 Redis가 아닌 로컬 캐시를 사용해 챗별로 허용하는 참여 요청의 최대치를 제한하는 방식을 적용했습니다.</p><figure id="8058a022-279c-47aa-b0c7-729655988a42" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.17.33.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.17.33.png"/></a></figure><h3 id="8685a006-71dc-4929-a168-6b957f9c3932" class=""><strong>해결 방안 3 - 서킷 브레이커와 벌크헤드 도입</strong></h3><p id="d9b84a38-648e-4159-bc78-f4f8a7db7626" class="">핫 챗 때문에 스토리지의 한 샤드의 처리 속도가 느려지거나 사용 불능이 되더라도 다른 샤드로 가는 요청은 영향받지 않고 처리되도록 서킷 브레이커와 벌크헤드(bulkhead)를 도입했습니다.</p><figure id="5fa73609-358f-4597-9eda-8fab9ed81f9c" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.18.50.png"><img style="width:718.3948364257812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-08-07_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.18.50.png"/></a></figure><p id="38aa46b9-f6d6-4de4-b62a-b691c431a1a7" class="">서킷 브레이커는 스토리지의 샤드별로 응답 타임아웃과 같은 에러가 많이 발생하면 요청들을 빠르게 실패로 처리합니다. 벌크헤드는 하나의 샤드로 몰린 요청들이 스레드 풀을 독점하지 않도록 막아줍니다. 이를 통해 한 샤드에 요청이 몰릴 때 다른 샤드에 영향을 주지 않도록 부하를 격리할 수 있습니다.</p><p id="71c19ed0-f9ed-48ed-aeb4-aedaa4773c8e" class="">서킷 브레이커와 벌크헤드를 도입한 결과 오픈챗 참여 요청이 하나의 챗에 1초에 수천 개가 몰려도 문제없이 안정적으로 처리할 수 있게 개선할 수 있었습니다.</p><h3 id="3fff44dc-dc1a-4098-a63a-04810d58c3a3" class=""><strong>문제 해결 과정에서 배운 점</strong></h3><p id="6d25f9c8-5f4e-4fa6-b9ba-77ac4c784725" class="">여기까지 그동안 경험했던 두 가지 핫 챗 패턴과 각 패턴에서 발생한 문제 및 해결 방식을 설명했습니다. 이 과정에서 오픈챗 서버 팀이 배운 교훈은 다음과 같습니다.</p><p id="c37ba490-c933-4d15-ab6d-57b810df8417" class="">첫 번째로 핫 챗을 이해할 필요가 있다는 것입니다. 오픈챗 서비스가 성장하면서 다양한 패턴의 핫 챗이 새롭게 발생했으며, 이 핫 챗들이 스토리지에 큰 부하를 줄 수 있다는 것을 알게 됐습니다. 또한 핫 챗은 그 패턴이나 발생 시점을 미리 예측해서 대응하기 어렵다는 사실도 알게 됐습니다.</p><p id="6c8af5cf-f042-4742-93b0-59317cfbea96" class="">두 번째로 핫 챗을 찾고 병목 지점을 해결하기 위해서는 API 단위의 요청량 모니터링뿐 아니라 국가와 애플리케이션 종류나 챗별 요청량까지 모니터링할 수 있어야 한다는 것입니다. API 단위 요청량을 모니터링하는 것만으로는 급증하는 부하가 핫 챗 때문에 발생한 부하인지, 어떤 챗이 핫 챗인지를 파악할 수 없었습니다.</p><p id="863e8d78-5748-4993-b2e4-b2f7600ccd26" class="">세 번째로 병목 지점을 찾는 과정에서도 지속해서 핫 챗이 발생할 수 있으므로 스토리지 처리량 한계를 넘지 않도록 스로틀링을 먼저 빠르게 적용한 뒤 병목 지점을 찾아 해결해 나가는 방식이 효과적이라는 것을 알게 됐습니다. 이때 메모리에서 작동하는 로컬 캐시와 서버 재시작 없이 설정값을 변경할 수 있는 동적 설정이 갑자기 발생한 핫 챗 부하에 신속하고 유연하게 대응하는 데 큰 도움이 됐습니다.</p><p id="de777d30-c6b4-4bfe-a1dc-bb5c35f3449c" class="">마지막으로 핫 챗 때문에 하나의 샤드에 몰리는 부하를 잘 격리하기 위해서는 스토리지 샤딩뿐 아니라 샤드별로 서킷 브레이커와 벌크헤드까지 필요하다는 것을 알게 됐습니다. 또한 핫 챗은 0.1% 미만의 극소수 챗이며 매일 발생하는 것도 아니기 때문에 해결책을 생각할 때 핫 챗만 타깃으로 삼아 적용할 수 있는 적절한 방법을 고려해야 한다는 것도 알게 됐습니다.</p><h1 id="3b2ca6e4-874e-4c86-90fa-1ccc5b3e0d64" class=""><strong>마치며</strong></h1><p id="22ab8c98-036a-4b0a-a17b-c7a43ad9fda0" class="">이번 글을 슬라이드 한 장으로 요약해 보겠습니다.</p><p id="fca28ea2-fd62-4bf6-ad77-f6f58881ebf9" class="">오픈챗 서버 팀은 페치 이벤트 API 요청과 오픈챗 참여 요청이 급증하는 패턴을 경험했고, 각 문제와 병목 지점을 핫 챗 감지 및 스로틀링과 MySQL 성능 개선, 조인 스로틀링을 통해서 해결할 수 있었습니다. 이 과정에서 핫 챗 때문에 발생한 영향이 다른 일반 오픈챗으로 번지는 것을 막기 위해 서킷 브레이커와 벌크헤드를 도입했고, 해결책을 고를 때에는 핫 챗이 전체 오픈챗 중 0.1% 미만이라는 사실을 고려해 선정했습니다. 결국 극소수 핫 챗 때문에 서비스에 발생한 영향을 격리하고 최소화하는 것을 목표로 한 것입니다.</p><p id="f27e723a-688c-4525-b824-1ef4bb482442" class="">마지막으로 앞으로 오픈챗 서버가 어느 방향으로 나아가려고 하는지 말씀드리겠습니다.</p><p id="bfbbd537-d195-4672-aac8-71f9b53f0df2" class="">먼저 핫 챗이 발생했을 때 핫 챗만 저장하는 별도 스토리지로 핫 챗 데이터를 자동으로 옮기거나 핫 챗 부하를 더 잘 분산시킬 수 있는 방법을 찾아서 적용해 나갈 예정입니다. 또한 핫 챗을 판단하는 기준을 고정값이 아닌 핫 챗의 최근 부하에 따라 변화하는 값으로 적용하고, 핫 챗 기준도 핫 챗이 활발한 정도에 따라 여러 개를 도입해 더 활발한 핫 챗에는 더 높은 스로틀링을 적용하는 등의 개선안도 도입하고자 합니다.</p><p id="98573b2d-c43a-4f49-af29-574c0f3d5286" class="">오픈챗 서비스는 꾸준히 성장하고 있습니다. 이에 따라 더욱 다양한 기능을 추가할 예정이고, 더 많은 트래픽이 몰릴 것으로 예상합니다. 아직 경험하지 못한 더 다양한 패턴의 핫 챗이 발생할 것이라고 예상하는데요. 어떤 핫 챗에도 유연하게 대응할 수 있도록 오픈챗 서버 아키텍처를 개선할 예정이며, 결과적으로 서비스 성장을 뒷받침할 수 있는 신뢰할 수 있는 오픈챗 서버로 나아가고자 합니다. 긴 글 읽어주셔서 감사합니다.</p><p id="fcdf5572-a8fb-474d-9fe1-db7fec0147bd" class="">
</p><figure id="86fcbbb5-5701-42e3-8986-fac2f310a56f"><a href="https://engineering.linecorp.com/ko/blog/how-line-openchat-server-handles-extreme-traffic-spikes" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">LINE 오픈챗 서버가 100배 급증하는 트래픽을 다루는 방법</div><div class="bookmark-description">Tech-Verse 2022에서 김인제 님이 발표한 LINE 오픈챗 서버가 100배 급증하는 트래픽을 다루는 방법 세션 내용을 옮긴 글입니다.  안녕하세요. Square Dev 팀 김인제입니다. 이번 글에서는 LINE 오픈챗(OpenChat) 서버에서 100배 급증하...</div></div><div class="bookmark-href"><img src="https://engineering.linecorp.com/icons/icon-512x512.png?v=6d6085f233d02c34273fa8a8849b502a" class="icon bookmark-icon"/>https://engineering.linecorp.com/ko/blog/how-line-openchat-server-handles-extreme-traffic-spikes</div></div><img src="https://vos.line-scdn.net/landpress-content-v2_1761/1682049547736.png?updatedAt=1682049548000" class="bookmark-image"/></a></figure></details></li></ul><ul id="c22a5a10-72a3-431f-896d-ea9885225d65" class="toggle"><li><details open=""><summary>Global Web Game Service</summary><p id="f40d6a3b-dbd5-4a5f-bc11-70ede0d7537d" class="">글로벌 웹 게임 서비스 제공을 위한 시스템 구조와 소프트웨어 아키텍처는 고가용성, 확장성, 성능, 보안 등을 고려하여 설계되어야 합니다. 아래에서는 이러한 요구 사항을 충족하기 위한 전체적인 구조와 주요 구성 요소들을 자세히 소개합니다.</p><h3 id="2824edeb-4090-4a08-972c-275b87cfa7bd" class="">1. <strong>시스템 구조 (System Architecture)</strong></h3><h3 id="5424f239-96fd-4faf-983e-fc02e05a8bd6" class=""><strong>1.1 사용자 레이어</strong></h3><ul id="659498cd-c200-4cf8-8feb-a61e1fb2b56d" class="bulleted-list"><li style="list-style-type:disc"><strong>클라이언트</strong>: 웹 브라우저, 모바일 브라우저 또는 네이티브 앱을 통해 접근.</li></ul><ul id="ca0748b5-83cb-4df9-b6ba-64bb1d0ec6cc" class="bulleted-list"><li style="list-style-type:disc"><strong>CDN(Content Delivery Network)</strong>: 게임 리소스(이미지, 동영상, JavaScript 파일 등)를 전 세계적으로 빠르게 제공하기 위해 사용됩니다. Akamai, Cloudflare, AWS CloudFront 등이 대표적입니다.</li></ul><h3 id="fbadc3f2-e1a8-48a4-916e-29758e8bdb78" class=""><strong>1.2 네트워크 레이어</strong></h3><ul id="b57e6b43-1637-4959-9874-adacfa9c6f91" class="bulleted-list"><li style="list-style-type:disc"><strong>API 게이트웨이</strong>: 사용자 요청을 받아 적절한 백엔드 서비스로 라우팅합니다. API 게이트웨이는 보안, 인증, 로깅, 모니터링, 트래픽 관리 등을 처리합니다.</li></ul><ul id="80241bfa-985c-4bea-a5aa-aa2a3f00f4c9" class="bulleted-list"><li style="list-style-type:disc"><strong>로드 밸런서</strong>: 트래픽을 여러 서버에 분산시켜 서버 과부하를 방지하고, 시스템의 고가용성을 보장합니다. AWS Elastic Load Balancing(ELB), NGINX, HAProxy 등이 사용됩니다.</li></ul><h3 id="063f53d5-fdad-4c1f-b7e9-8267f1a37ed3" class=""><strong>1.3 애플리케이션 레이어</strong></h3><ul id="711aefd7-b7e4-475a-bee7-085412903d77" class="bulleted-list"><li style="list-style-type:disc"><strong>웹 서버</strong>: 사용자로부터의 HTTP 요청을 처리하고, 정적 파일을 제공하며, API 게이트웨이와 상호작용합니다. NGINX, Apache가 많이 사용됩니다.</li></ul><ul id="c3f7b832-174d-4901-9743-25089d16f133" class="bulleted-list"><li style="list-style-type:disc"><strong>애플리케이션 서버</strong>: 비즈니스 로직을 처리하는 서버입니다. 일반적으로 마이크로서비스로 구성되며, 각각의 마이크로서비스는 특정한 기능을 담당합니다. Node.js, Spring Boot, Django 등이 사용될 수 있습니다.</li></ul><ul id="df0d2d9c-15e4-4f84-a883-3d6685007fbe" class="bulleted-list"><li style="list-style-type:disc"><strong>게임 서버</strong>: 실시간 게임 로직을 처리하며, 유저의 게임 세션, 매치메이킹, 랭킹 등을 관리합니다. 게임 서버는 높은 성능과 낮은 레이턴시가 요구됩니다. 주로 TCP/UDP 프로토콜을 사용하며, 엔진으로는 Unity, Unreal, Photon 등이 사용될 수 있습니다.</li></ul><ul id="7ef106fb-c0c6-454d-ba84-3d1f3247fa85" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터베이스 서버</strong>: 유저 정보, 게임 상태, 랭킹, 통계 데이터 등을 저장합니다. RDBMS(MySQL, PostgreSQL)와 NoSQL(MongoDB, Cassandra)을 혼합해 사용하여 성능과 확장성을 확보합니다.</li></ul><h3 id="9ae153cc-9a12-475f-933e-f30bf361f190" class=""><strong>1.4 데이터 레이어</strong></h3><ul id="7ae62bf5-1a34-4754-9989-fdebaea6d774" class="bulleted-list"><li style="list-style-type:disc"><strong>RDBMS</strong>: 게임 계정, 결제 정보 등 구조화된 데이터를 저장합니다. 데이터 무결성 및 트랜잭션 관리가 필요할 때 사용합니다.</li></ul><ul id="633d28d1-dd0a-4d5d-8610-5df0d8d8f98b" class="bulleted-list"><li style="list-style-type:disc"><strong>NoSQL DB</strong>: 게임 상태, 로그, 세션 데이터와 같이 빠른 읽기/쓰기가 요구되거나 스키마가 유연한 데이터를 저장합니다.</li></ul><ul id="77ce897b-eaaa-4fab-8a1a-6d92f5c02032" class="bulleted-list"><li style="list-style-type:disc"><strong>캐시 서버</strong>: Redis 또는 Memcached를 사용해 자주 조회되는 데이터(예: 게임 세션 정보, 사용자 프로필)를 캐싱하여 성능을 최적화합니다.</li></ul><ul id="15adb4f1-1098-4f75-9d35-7d07c4febc54" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 웨어하우스</strong>: 빅데이터 분석을 위해 S3, Google BigQuery, Snowflake와 같은 솔루션을 사용합니다.</li></ul><h3 id="255bf32d-8696-4f54-b96f-e46e00e02cf4" class=""><strong>1.5 통신 레이어</strong></h3><ul id="3da49149-8786-4686-a331-7eb19f9e8c88" class="bulleted-list"><li style="list-style-type:disc"><strong>메시지 브로커</strong>: 비동기 통신을 위해 메시지 큐를 사용합니다. RabbitMQ, Apache Kafka 등이 대표적입니다. 이를 통해 이벤트 기반 아키텍처를 구축할 수 있습니다.</li></ul><ul id="eecc4ca4-9051-4b58-b313-f4041dc23cef" class="bulleted-list"><li style="list-style-type:disc"><strong>WebSocket/Socket.IO</strong>: 실시간 게임 업데이트, 채팅, 알림 등을 위해 사용됩니다.</li></ul><h3 id="8490b3ee-5670-456d-9719-2a11a27d07e5" class=""><strong>1.6 인프라스트럭처 레이어</strong></h3><ul id="421a998d-f8b3-4cd8-ae5c-c750cc9b0945" class="bulleted-list"><li style="list-style-type:disc"><strong>클라우드 플랫폼</strong>: AWS, GCP, Azure와 같은 클라우드 플랫폼을 사용하여 글로벌 리전에 분산된 인프라를 구축합니다. 이를 통해 다양한 지역에서의 접근 속도를 최적화하고, 트래픽 증가에 따른 자동 확장이 가능합니다.</li></ul><ul id="fc7865a0-0d1e-4a03-8337-8eb695635d58" class="bulleted-list"><li style="list-style-type:disc"><strong>컨테이너 오케스트레이션</strong>: Kubernetes를 사용해 컨테이너화된 애플리케이션을 관리하고 배포합니다. 이로 인해 확장성과 복원력이 강화됩니다.</li></ul><h3 id="973fa898-9bb5-484c-836c-7689dabd81f9" class="">2. <strong>소프트웨어 아키텍처 (Software Architecture)</strong></h3><h3 id="d0665f4c-10a6-47c2-b3e2-78e4aaeacb21" class=""><strong>2.1 마이크로서비스 아키텍처</strong></h3><ul id="8358842c-cbd7-4816-90fa-3caab57d6dd6" class="bulleted-list"><li style="list-style-type:disc">각 기능(사용자 관리, 결제, 게임 로직, 랭킹 관리 등)을 별도의 마이크로서비스로 분리하여 독립적으로 개발, 배포, 확장할 수 있습니다. 이는 유지보수성과 확장성을 크게 높여줍니다.</li></ul><h3 id="63300075-f05e-4c8e-b06b-c866303608db" class=""><strong>2.2 이벤트 기반 아키텍처</strong></h3><ul id="cc08b57f-c6dc-4af3-961a-f14e34dc72c2" class="bulleted-list"><li style="list-style-type:disc">게임 내 이벤트(예: 레벨 업, 보상 지급)를 처리하기 위해 이벤트 기반 아키텍처를 도입합니다. 마이크로서비스 간 통신을 위해 메시지 브로커를 사용하여 비동기식으로 이벤트를 처리합니다. 이벤트 소싱 패턴을 도입하여 이벤트의 히스토리를 관리할 수도 있습니다.</li></ul><h3 id="2aba7499-79cd-4382-9970-ce0460fa4ec0" class=""><strong>2.3 CQRS (Command Query Responsibility Segregation)</strong></h3><ul id="3cf578d1-2da0-4c5b-958d-8ae3aca3e258" class="bulleted-list"><li style="list-style-type:disc">쓰기(커맨드)와 읽기(쿼리) 작업을 분리하여 성능을 최적화합니다. 예를 들어, 게임 상태 업데이트는 NoSQL DB에 기록하고, 게임 상태 조회는 캐시 또는 별도의 읽기 전용 데이터베이스에서 처리합니다.</li></ul><h3 id="4cfec435-214e-4585-8205-567ee22a6977" class=""><strong>2.4 API First Design</strong></h3><ul id="ea39604a-94d5-493d-8813-d8c45332935d" class="bulleted-list"><li style="list-style-type:disc">각 마이크로서비스는 명확한 API를 정의하여 다른 서비스 또는 클라이언트와 통신합니다. 이는 서비스 간의 독립성과 상호작용을 명확하게 관리하는 데 도움을 줍니다.</li></ul><h3 id="f2f20ab7-00f5-4c58-8346-907d375d3b88" class=""><strong>2.5 지속적 통합/지속적 배포 (CI/CD)</strong></h3><ul id="a1142d69-5765-455e-9fba-69edd718a383" class="bulleted-list"><li style="list-style-type:disc">자동화된 CI/CD 파이프라인을 구축하여 각 마이크로서비스의 변경 사항이 자동으로 테스트되고 배포됩니다. Jenkins, GitLab CI, CircleCI와 같은 도구를 사용하여 버그를 신속하게 발견하고 새로운 기능을 빠르게 배포할 수 있습니다.</li></ul><h3 id="ba3596de-77a1-4439-b5b0-98edda797abe" class="">3. <strong>보안 및 운영 관리</strong></h3><ul id="8ac078c4-8b90-4d8a-a41e-c62896c425c8" class="bulleted-list"><li style="list-style-type:disc"><strong>인증 및 권한 관리</strong>: OAuth2, OpenID Connect를 사용하여 사용자 인증 및 권한 관리를 처리합니다.</li></ul><ul id="81ee26b7-cf7c-4b73-9f94-bd6850f253dd" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링 및 로깅</strong>: Prometheus, Grafana, ELK 스택을 사용해 시스템 모니터링, 로그 분석, 알림 기능을 구축합니다.</li></ul><ul id="67a32eac-de77-419c-8d6a-b9dbd0c4e1f9" class="bulleted-list"><li style="list-style-type:disc"><strong>자동화된 테스트</strong>: 유닛 테스트, 통합 테스트, 성능 테스트 등을 자동화하여 서비스의 품질을 보장합니다.</li></ul><ul id="968680b1-ed5c-407d-b160-c6a33c3504cb" class="bulleted-list"><li style="list-style-type:disc"><strong>DDoS 방어</strong>: 클라우드 기반의 DDoS 방어 시스템(AWS Shield, Cloudflare)과 WAF(Web Application Firewall)을 활용하여 서비스 가용성을 유지합니다.</li></ul><h3 id="821c0ce5-f3ee-437d-b504-b2eb81995ac9" class="">4. <strong>글로벌 서비스 최적화</strong></h3><ul id="c295d165-7e3f-4b16-b16a-f335cb5e5e10" class="bulleted-list"><li style="list-style-type:disc"><strong>다국어 지원</strong>: 사용자 인터페이스(UI)와 콘텐츠의 다국어 지원을 통해 글로벌 사용자 기반을 확보합니다.</li></ul><ul id="e72b1e0f-6843-477e-a7e1-d9e6d7d32e0e" class="bulleted-list"><li style="list-style-type:disc"><strong>타임존 처리</strong>: 전 세계 유저가 동일한 게임 내 이벤트를 경험할 수 있도록 타임존을 고려한 이벤트 계획이 필요합니다.</li></ul><ul id="fc193938-361b-4a82-9c6b-f8b8d818ff76" class="bulleted-list"><li style="list-style-type:disc"><strong>지리적 위치에 따른 서버 선택</strong>: 사용자 위치에 따라 가장 가까운 서버로 연결하여 레이턴시를 최소화합니다.</li></ul><p id="510454ea-bf22-4904-a310-39eb124ffa29" class="">이러한 시스템 구조와 소프트웨어 아키텍처를 통해 글로벌 웹 게임 서비스는 확장성, 성능, 보안을 확보하면서 다양한 지역에서 효율적으로 운영될 수 있습니다.</p></details></li></ul><ul id="159c0dbe-172d-461d-b319-4c5bd6120782" class="toggle"><li><details open=""><summary>검색 엔진 구성 및 성능 개선</summary><p id="b2b766c2-58ae-4ee1-939a-00ef1bf7535e" class="">검색 엔진 서비스는 대규모 데이터에서 빠르게 정보를 검색하고, 사용자가 쿼리를 입력했을 때 관련된 결과를 신속하게 제공하는 시스템입니다. 검색 엔진의 구조와 성능 개선 방안에 대해 아래와 같이 설명할 수 있습니다.</p><h2 id="87b0a115-776e-40f2-9b39-504561dac21a" class="">검색 엔진 서비스 구조</h2><h3 id="d4531a8e-8f78-4616-9519-9fd754a0b011" class="">1. <strong>데이터 수집 및 인덱싱</strong></h3><h3 id="2b4905ed-c5eb-467a-af3d-5993b6b6054b" class=""><strong>1.1 데이터 수집 (Crawling)</strong></h3><ul id="9722f9d0-7813-42e2-97a1-4a4f78ac2b35" class="bulleted-list"><li style="list-style-type:disc"><strong>웹 크롤러</strong>: 인터넷의 웹 페이지를 자동으로 탐색하고, 새로운 페이지나 업데이트된 페이지를 수집합니다.</li></ul><ul id="13417d9c-d579-481a-bcfb-388287fbdb78" class="bulleted-list"><li style="list-style-type:disc"><strong>API 데이터 수집</strong>: 외부 API에서 데이터를 가져오는 방법도 있습니다.</li></ul><h3 id="0b47411d-967f-4e85-89ef-fff7dc10ecba" class=""><strong>1.2 데이터 저장 (Storage)</strong></h3><ul id="74a3e7a6-1a3f-4e08-9e2b-d7c6b31ee295" class="bulleted-list"><li style="list-style-type:disc"><strong>문서 저장소</strong>: 수집된 웹 페이지나 문서 데이터를 저장합니다. 일반적으로 NoSQL 데이터베이스 (예: MongoDB, Couchbase) 또는 파일 시스템 (예: HDFS, S3)에 저장합니다.</li></ul><h3 id="d793dfec-5dec-4bfb-ba2e-5fe7fa308b9b" class=""><strong>1.3 인덱싱 (Indexing)</strong></h3><ul id="14340a84-2cf2-46db-9fe1-94b25bc9fa8f" class="bulleted-list"><li style="list-style-type:disc"><strong>역 인덱스</strong>: 문서에서 단어를 추출하여 단어와 문서 간의 매핑을 저장합니다. 이를 통해 특정 단어가 포함된 문서를 빠르게 찾을 수 있습니다.</li></ul><ul id="a6796f01-6857-4d1d-ac6e-b91b82eef945" class="bulleted-list"><li style="list-style-type:disc"><strong>키워드 인덱스</strong>: 검색 쿼리와 관련된 문서들을 효율적으로 조회할 수 있도록 키워드를 기준으로 인덱스를 만듭니다.</li></ul><h3 id="ea01d2c0-6dd4-4cbe-a9a9-f1d21ae560a1" class="">2. <strong>쿼리 처리</strong></h3><h3 id="9411489e-ea14-4825-89fe-00f7f3d1d2d5" class=""><strong>2.1 쿼리 분석 (Query Analysis)</strong></h3><ul id="71b8c6a4-43c1-49aa-a710-68fe9e02786f" class="bulleted-list"><li style="list-style-type:disc"><strong>토큰화</strong>: 사용자가 입력한 쿼리를 단어(토큰)로 분리합니다.</li></ul><ul id="b9ae0f85-2af2-46d3-9c04-f2ff79fee95b" class="bulleted-list"><li style="list-style-type:disc"><strong>어휘 정규화</strong>: 대소문자 변환, 동의어 처리, 오타 수정 등을 통해 쿼리를 정규화합니다.</li></ul><h3 id="7e2478c3-2501-44ab-aa01-8e7d4eaba2a5" class=""><strong>2.2 검색 (Search)</strong></h3><ul id="ac2fe691-d7a1-41d9-9e5e-dfaaee3bd618" class="bulleted-list"><li style="list-style-type:disc"><strong>인덱스 조회</strong>: 사용자의 쿼리를 기반으로 역 인덱스에서 관련 문서를 검색합니다.</li></ul><ul id="ceda81ba-deb3-4ffd-b505-d08636fbf73d" class="bulleted-list"><li style="list-style-type:disc"><strong>순위 매기기 (Ranking)</strong>: 검색 결과의 순서를 매기기 위해 검색 알고리즘을 사용합니다. 일반적으로 TF-IDF, BM25, 또는 머신 러닝 기반 알고리즘을 사용합니다.</li></ul><h3 id="e10ed119-a9e6-4409-8d8a-00c3bd894ae3" class="">3. <strong>결과 반환</strong></h3><h3 id="be8e3bde-271a-4a43-ad2e-36233ba8e713" class=""><strong>3.1 결과 포맷팅 (Result Formatting)</strong></h3><ul id="0d156a77-c453-4441-bee0-b8bfc2b3b290" class="bulleted-list"><li style="list-style-type:disc"><strong>결과 정렬</strong>: 검색된 문서들을 relevance score에 따라 정렬합니다.</li></ul><ul id="5bbe969a-fe47-4d93-80c6-7a8cf8cef328" class="bulleted-list"><li style="list-style-type:disc"><strong>결과 제공</strong>: 사용자가 이해하기 쉬운 형태로 검색 결과를 제공합니다.</li></ul><h3 id="80144ba2-9e35-4b6f-9f67-03224c1f2232" class=""><strong>3.2 캐싱 (Caching)</strong></h3><ul id="c757280d-9730-461e-a4cb-39740b36b5cb" class="bulleted-list"><li style="list-style-type:disc"><strong>쿼리 결과 캐싱</strong>: 자주 조회되는 쿼리 결과를 캐시하여 검색 속도를 개선합니다. Redis와 같은 인메모리 데이터베이스를 사용할 수 있습니다.</li></ul><h2 id="48c71779-2bfa-4f4e-b1b8-48d5dbcfd01c" class="">성능 개선 방안</h2><h3 id="bbf2d321-91c5-417f-b2fb-1bd32c5e77ac" class="">1. <strong>인덱스 최적화</strong></h3><h3 id="66dfd76a-6a7d-453b-a1e9-0224925c81c9" class=""><strong>1.1 인덱스 구조 개선</strong></h3><ul id="5f843fb4-2baa-4a24-868c-6bd2835ad64a" class="bulleted-list"><li style="list-style-type:disc"><strong>역 인덱스 최적화</strong>: 역 인덱스의 크기를 줄이기 위해 압축 기술을 적용하거나, 데이터를 효율적으로 분할합니다.</li></ul><ul id="f8e1127a-d80e-48b2-b7b9-19b9eb357c12" class="bulleted-list"><li style="list-style-type:disc"><strong>분산 인덱싱</strong>: 대규모 데이터의 경우 인덱스를 여러 서버에 분산하여 저장하고 검색 성능을 향상시킵니다.</li></ul><h3 id="fcdb6df5-a2a7-4f66-b1eb-b5513daf50f0" class=""><strong>1.2 인덱스 업데이트</strong></h3><ul id="71c4959a-78d1-4d5a-8527-42cf6731949c" class="bulleted-list"><li style="list-style-type:disc"><strong>리프레시 전략</strong>: 인덱스를 주기적으로 업데이트하여 최신 데이터를 반영합니다. 인덱스 리빌딩 대신 인크리멘탈 업데이트를 활용할 수 있습니다.</li></ul><h3 id="b9b31359-0a1b-415f-ad4c-fb1323347969" class="">2. <strong>쿼리 처리 성능 개선</strong></h3><h3 id="04e7787b-a085-4586-b633-40d0bc45a2ca" class=""><strong>2.1 쿼리 최적화</strong></h3><ul id="73e78690-bbbd-4143-9032-02208f51ab2d" class="bulleted-list"><li style="list-style-type:disc"><strong>쿼리 분석</strong>: 쿼리 실행 계획을 분석하여 비효율적인 쿼리를 최적화합니다.</li></ul><ul id="8b442ad2-5576-40ae-9c4a-8388bcc53b18" class="bulleted-list"><li style="list-style-type:disc"><strong>검색 알고리즘 개선</strong>: 최신 검색 알고리즘이나 머신 러닝 기반의 랭킹 모델을 도입하여 검색 품질을 향상시킵니다.</li></ul><h3 id="39b3d3a9-08e6-4bf1-b8a2-62932653ef61" class=""><strong>2.2 분산 검색</strong></h3><ul id="bcc877b4-6913-4f91-ac09-180da39378dd" class="bulleted-list"><li style="list-style-type:disc"><strong>샤딩</strong>: 검색 인덱스를 여러 서버에 샤딩하여 쿼리의 부하를 분산시킵니다.</li></ul><ul id="72f359e4-75b7-49b9-ac87-2a1256242691" class="bulleted-list"><li style="list-style-type:disc"><strong>리플리케이션</strong>: 검색 데이터를 여러 서버에 복제하여 가용성과 응답 속도를 개선합니다.</li></ul><h3 id="14e8446d-8410-4674-b87f-d23d053da42d" class="">3. <strong>캐싱 전략</strong></h3><h3 id="b9923bd7-8182-4736-a731-228d4784a6bc" class=""><strong>3.1 쿼리 결과 캐싱</strong></h3><ul id="a7135272-a653-4b21-973e-4b8d99dbacac" class="bulleted-list"><li style="list-style-type:disc"><strong>Redis</strong>: 자주 조회되는 쿼리 결과를 Redis와 같은 인메모리 데이터베이스에 캐시하여 검색 속도를 개선합니다.</li></ul><ul id="3071d2cf-2c96-4473-8252-261b1b6284ee" class="bulleted-list"><li style="list-style-type:disc"><strong>ElasticSearch</strong>: ElasticSearch는 쿼리 캐시 기능을 제공하여 검색 결과를 빠르게 제공합니다.</li></ul><h3 id="e3829595-0d6b-4fb3-b06c-ef8e50917168" class=""><strong>3.2 페이지 캐싱</strong></h3><ul id="1d4d645f-e9ce-45bb-b717-1ffbd5287695" class="bulleted-list"><li style="list-style-type:disc"><strong>HTTP 캐싱</strong>: CDN과 같은 웹 캐싱 기술을 사용하여 정적 페이지와 자주 요청되는 데이터를 캐시합니다.</li></ul><h3 id="7aaf0a4f-f746-4b77-abfd-00e404b19755" class="">4. <strong>하드웨어 및 클라우드 최적화</strong></h3><h3 id="2229cdae-3fbc-4a0c-8eaa-08e0605a557f" class=""><strong>4.1 하드웨어 스케일링</strong></h3><ul id="86fedb3e-17f1-48a4-8cc3-98b683568b06" class="bulleted-list"><li style="list-style-type:disc"><strong>수평 확장</strong>: 서버를 추가하여 처리 능력을 확장합니다.</li></ul><ul id="85c33c77-0109-4023-98e9-686a16b27f7f" class="bulleted-list"><li style="list-style-type:disc"><strong>고성능 SSD</strong>: 검색 성능을 높이기 위해 고성능 SSD를 사용합니다.</li></ul><h3 id="eeb13068-1729-4363-9aea-97c50cba9fe1" class=""><strong>4.2 클라우드 인프라</strong></h3><ul id="0b939e35-4497-465f-9f67-c01c5a230172" class="bulleted-list"><li style="list-style-type:disc"><strong>자동 확장</strong>: 클라우드 환경에서 자동으로 서버를 확장하고 축소하여 수요에 맞게 리소스를 조절합니다.</li></ul><ul id="8edcd62d-c784-4dff-a6fe-891bbfcf8a30" class="bulleted-list"><li style="list-style-type:disc"><strong>서버리스 아키텍처</strong>: 서버리스 컴퓨팅 서비스를 활용하여 인프라 관리의 부담을 줄입니다.</li></ul><h3 id="d7b6a1b5-121d-41d8-be89-a92827a1006b" class="">5. <strong>모니터링 및 로그 분석</strong></h3><h3 id="9c4178c6-207a-404f-be6f-c46ef3c96a7a" class=""><strong>5.1 성능 모니터링</strong></h3><ul id="f7bb1c40-8928-49c0-aee6-92bc3af651af" class="bulleted-list"><li style="list-style-type:disc"><strong>Prometheus &amp; Grafana</strong>: 시스템의 성능을 모니터링하고 대시보드를 통해 실시간 성능 데이터를 시각화합니다.</li></ul><h3 id="54f4f5c7-40eb-44a3-9d82-8c674a4ce590" class=""><strong>5.2 로그 분석</strong></h3><ul id="82fecfe4-de5f-4406-93a4-7907e46edf12" class="bulleted-list"><li style="list-style-type:disc"><strong>ELK Stack (Elasticsearch, Logstash, Kibana)</strong>: 로그 데이터를 수집하고 분석하여 시스템의 상태를 모니터링합니다.</li></ul><h2 id="55b03747-381f-4780-a72a-78271fabc199" class="">종합</h2><p id="462b9157-ec0b-4a9c-9de3-36a068024f6f" class="">검색 엔진 서비스는 복잡한 데이터 처리 및 검색 알고리즘을 필요로 하며, 성능 개선을 위해 인덱스 최적화, 쿼리 처리 성능 개선, 캐싱 전략, 하드웨어 및 클라우드 최적화, 모니터링과 로그 분석 등을 종합적으로 고려해야 합니다. 이를 통해 대규모 트래픽을 효율적으로 처리하고, 빠르고 정확한 검색 결과를 사용자에게 제공할 수 있습니다.</p><p id="65b64a0d-339b-4e81-94ea-4eb10d965728" class="">
</p><figure id="cb746418-ed0e-4513-8511-a43c76d3f13f"><a href="https://esbook.kimjmin.net/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Elastic 가이드 북 | Elastic 가이드북</div><div class="bookmark-description">이 가이드북은 출판을 위해 집필중이던 내용을 Elastic을 처음 시작하시는 분들께 도움이 되고 커뮤니티와 함께 완성 해 나가려는 목적으로 공개하게 되었습니다. 모든 문서에 대한 저작권은 저자인 김종민에게 있으며 허가되지 않은 무단 복제나 배포 및 출판을 금지합니다. 본 문서의 내용 및 도표들을 인용하고자 하는 경우 출처를 명시하고 김종민(kimjmin@gmail.com)에게 사용 내용을 알려주시기 바랍니다.</div></div><div class="bookmark-href"><img src="https://2678746270-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/spaces%2F-Ln04DaYZaDjdiR_ZsKo%2Favatar.png?generation=1567023677111208&amp;alt=media" class="icon bookmark-icon"/>https://esbook.kimjmin.net/</div></div><img src="https://esbook.kimjmin.net/~gitbook/ogimage/-Ln04DaZeyTl4HNuK8la" class="bookmark-image"/></a></figure></details></li></ul><ul id="cf99331b-9f2f-492c-9bfd-19bdcea743a8" class="toggle"><li><details open=""><summary>AIOps (Artificial Intelligence for IT Operations)</summary><p id="5d1dfe76-ba0b-42bd-899f-979d771567a6" class="">AIOps(Artificial Intelligence for IT Operations)는 인공지능(AI)과 머신러닝(ML)을 활용하여 IT 운영의 자동화 및 효율성을 향상시키는 기술입니다. AIOps는 대규모 IT 환경에서 운영 데이터를 분석하고, 문제를 식별하며, 이를 해결하기 위한 자동화된 조치를 취하는 데 도움을 줍니다. AIOps의 주요 구성요소와 활용 사례를 설명하겠습니다.</p><h2 id="ec17caf0-dda4-4579-8b10-fa5722201f74" class="">AIOps 구성요소</h2><ol type="1" id="eaaff038-e92c-4321-9c8f-c70ca7308662" class="numbered-list" start="1"><li><strong>데이터 수집 (Data Collection)</strong><ul id="894878b9-ee2f-4f82-941f-d988f9edff67" class="bulleted-list"><li style="list-style-type:disc"><strong>로그 수집</strong>: 시스템, 애플리케이션, 네트워크 장비 등의 로그 데이터를 수집합니다. 예를 들어, Elastic Stack (ELK Stack)이나 Splunk를 사용할 수 있습니다.</li></ul><ul id="3b599fe8-072d-461f-b709-ba72060af21b" class="bulleted-list"><li style="list-style-type:disc"><strong>메트릭 수집</strong>: 성능 메트릭, 이벤트, 트랜잭션 데이터 등을 수집합니다. Prometheus, Graphite, Datadog 등이 사용됩니다.</li></ul><ul id="4ff8a2d7-35a4-4030-8dd6-ede1b99a8ea9" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링 데이터</strong>: 실시간 모니터링 데이터를 수집하여 IT 환경의 상태를 감시합니다.</li></ul></li></ol><ol type="1" id="f07f5756-8499-4b3b-872a-4df3c3713cce" class="numbered-list" start="2"><li><strong>데이터 통합 (Data Integration)</strong><ul id="10d1a8a5-d075-4882-b787-532892b7d9f5" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 정제 및 통합</strong>: 다양한 소스에서 수집된 데이터를 통합하고 정제하여 분석 가능한 형태로 변환합니다. ETL(Extract, Transform, Load) 프로세스가 사용됩니다.</li></ul><ul id="92acb5ca-594c-4c23-acf4-d90c5f9367cc" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 스토리지</strong>: 데이터 저장을 위한 인프라로, 데이터 웨어하우스나 데이터 레이크를 사용할 수 있습니다.</li></ul></li></ol><ol type="1" id="239eb818-4780-4132-96b8-8c8f3be0000f" class="numbered-list" start="3"><li><strong>데이터 분석 (Data Analytics)</strong><ul id="97cbc080-52bd-4e04-90d6-9f0fa668a921" class="bulleted-list"><li style="list-style-type:disc"><strong>이상 탐지 (Anomaly Detection)</strong>: AI와 ML 알고리즘을 사용하여 비정상적인 패턴이나 이상 징후를 탐지합니다. 예를 들어, 시계열 데이터에서 갑작스런 변화나 트렌드를 감지합니다.</li></ul><ul id="d69b9f3c-b5ae-43cc-87ff-1d43dd41e616" class="bulleted-list"><li style="list-style-type:disc"><strong>근본 원인 분석 (Root Cause Analysis)</strong>: 문제가 발생했을 때 원인을 파악하는 데 도움을 줍니다. ML 모델을 사용하여 문제의 근본 원인을 분석합니다.</li></ul><ul id="6182c51b-6fd4-47a5-b23f-8535192c8676" class="bulleted-list"><li style="list-style-type:disc"><strong>예측 분석 (Predictive Analytics)</strong>: 미래의 사건을 예측하고, 잠재적인 문제를 사전에 식별합니다.</li></ul></li></ol><ol type="1" id="7dca1fb9-7b87-406b-b5ed-02ffbd401459" class="numbered-list" start="4"><li><strong>자동화 (Automation)</strong><ul id="4cd598a4-b777-475a-a9b0-75336c3d7e72" class="bulleted-list"><li style="list-style-type:disc"><strong>자동화된 대응 (Automated Response)</strong>: 문제가 감지되면 자동으로 대응 조치를 취합니다. 예를 들어, 알림을 보내거나, 특정 작업을 자동으로 실행합니다.</li></ul><ul id="e54081b5-d0cb-4018-a879-710c6d7fc4b9" class="bulleted-list"><li style="list-style-type:disc"><strong>운영 자동화</strong>: IT 운영 작업을 자동화하여 인적 개입을 최소화합니다. Ansible, Puppet, Chef와 같은 자동화 도구를 활용할 수 있습니다.</li></ul></li></ol><ol type="1" id="c8dee82f-1032-41ca-ab9b-d5727008e066" class="numbered-list" start="5"><li><strong>시각화 (Visualization)</strong><ul id="8de28188-de68-45b6-be94-7dd473145509" class="bulleted-list"><li style="list-style-type:disc"><strong>대시보드 및 리포팅</strong>: 수집된 데이터와 분석 결과를 시각적으로 표현하여 쉽게 이해할 수 있도록 합니다. Grafana, Kibana, Tableau 등이 사용됩니다.</li></ul></li></ol><ol type="1" id="b32dfe43-9c0e-44e2-8599-404ba4368299" class="numbered-list" start="6"><li><strong>통합 및 연동 (Integration)</strong><ul id="d85fa3fd-d06a-49b0-9e60-3270c27069f0" class="bulleted-list"><li style="list-style-type:disc"><strong>ITSM (IT Service Management) 연동</strong>: AIOps 플랫폼은 ITSM 도구와 통합되어 사건 관리, 문제 관리 등의 작업을 자동화합니다.</li></ul><ul id="2a14ff79-ad14-4e69-bdd6-fe8ae9c32169" class="bulleted-list"><li style="list-style-type:disc"><strong>CI/CD 파이프라인 연동</strong>: 개발과 운영의 통합을 지원하며, 배포 자동화와 연속적인 개선을 가능하게 합니다.</li></ul></li></ol><h2 id="b84c1d89-8bac-4e0d-93b0-144e8b0bdeff" class="">AIOps 활용 사례</h2><ol type="1" id="270aa08d-96f0-43ae-b424-690edb6f279a" class="numbered-list" start="1"><li><strong>예측 유지보수 (Predictive Maintenance)</strong><ul id="da307072-8967-4d1b-a9eb-001fb8ea7a83" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 제조업체가 기계의 성능 데이터를 분석하여 장비의 고장을 예측하고, 이를 바탕으로 예방 조치를 취합니다. 이를 통해 가동 중지 시간을 최소화하고 비용을 절감할 수 있습니다.</li></ul><ul id="3036447f-2c85-41be-9368-0fba7304006b" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: Splunk, Datadog, Prometheus와 같은 모니터링 도구와 ML 모델을 활용하여 장비의 이상 징후를 조기에 감지합니다.</li></ul></li></ol><ol type="1" id="d62afbe6-1e21-48db-bada-054ebdc3a638" class="numbered-list" start="2"><li><strong>자동화된 문제 해결 (Automated Problem Resolution)</strong><ul id="c6341589-5e32-4f00-9ca9-39fb771eaea6" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 웹 애플리케이션에서 발생한 성능 저하 문제를 AIOps 플랫폼이 자동으로 감지하고, 사전에 정의된 대응 조치를 실행합니다. 예를 들어, 서버 리소스를 자동으로 확장하거나, 재부팅을 수행합니다.</li></ul><ul id="a7982371-de1c-41d7-91ca-67e150306e4c" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: Ansible, Puppet과 같은 자동화 도구와 AIOps 플랫폼의 연동을 통해 자동 대응이 이루어집니다.</li></ul></li></ol><ol type="1" id="abb084e8-4f3b-4e1e-bb6a-db51cc2869cf" class="numbered-list" start="3"><li><strong>이상 탐지 및 경고 (Anomaly Detection and Alerting)</strong><ul id="3431a22b-4543-48ef-895b-01af4cb8336e" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 대규모 웹 서비스에서 트래픽 패턴을 분석하여 이상 트래픽을 감지하고, 이를 기반으로 실시간 경고를 생성합니다. 이상 징후를 조기에 탐지하여 서비스 중단을 예방합니다.</li></ul><ul id="7a783b84-c59c-4818-8835-c7cfdea6a871" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: Elastic Stack (ELK Stack), Datadog, New Relic 등을 사용하여 실시간 모니터링과 경고 시스템을 구축합니다.</li></ul></li></ol><ol type="1" id="0fde2d24-197a-4dd0-ad5c-2b450f0e1d29" class="numbered-list" start="4"><li><strong>근본 원인 분석 (Root Cause Analysis)</strong><ul id="47dc17e7-d2c6-412f-b831-ce7c621aa4ed" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 시스템 장애가 발생했을 때, AIOps 플랫폼이 로그와 메트릭 데이터를 분석하여 문제의 근본 원인을 식별합니다. 이를 통해 신속하게 문제를 해결하고, 재발을 방지합니다.</li></ul><ul id="6f70c308-6123-4edf-ad2a-be4d2280c039" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: Splunk, Kibana, Grafana와 같은 도구를 활용하여 데이터 분석과 시각화를 통해 문제를 파악합니다.</li></ul></li></ol><ol type="1" id="e5ae6776-4b4a-4e2b-a243-e277a4cb2483" class="numbered-list" start="5"><li><strong>성능 최적화 (Performance Optimization)</strong><ul id="b30d7e7c-5561-4adf-acb1-9958c6883b3c" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 애플리케이션의 성능 데이터를 분석하여 리소스 사용을 최적화하고, 성능 병목을 식별합니다. 이를 통해 응답 시간을 단축시키고, 사용자 경험을 향상시킵니다.</li></ul><ul id="62ed051f-a90b-42a9-a66c-55fdb6c06d7f" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>: Prometheus, Grafana, Dynatrace 등을 사용하여 성능 모니터링과 최적화를 수행합니다.</li></ul></li></ol><h2 id="939f2b8d-5432-486e-a83c-e24da6d48f5b" class="">결론</h2><p id="c9d11d22-e255-415b-abb2-4a064be98729" class="">AIOps는 IT 운영의 복잡성을 관리하고, 문제를 사전에 식별하며, 자동으로 대응 조치를 취함으로써 IT 환경의 안정성과 효율성을 향상시킵니다. 데이터 수집, 분석, 자동화, 시각화와 같은 핵심 구성요소를 기반으로 다양한 활용 사례를 통해 IT 운영을 혁신할 수 있습니다.</p><figure id="a8b08287-e33e-4c47-ab6d-2b600423b0e8"><a href="https://ten1010.io/product-aipub-ops" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">주식회사 텐 | AI 인프라 전용 MLOps 전문기업</div><div class="bookmark-description">AI가 모두에게 일상이 될 수 있도록 쉽고 간단한 AI툴과 환경을 만듭니다.</div></div><div class="bookmark-href"><img src="https://ten1010.io/favicon.ico" class="icon bookmark-icon"/>https://ten1010.io/product-aipub-ops</div></div><img src="https://ten1010.io/og-image.png" class="bookmark-image"/></a></figure><p id="e9e17195-ed03-4014-8d27-328fdf45fb50" class="">
</p></details></li></ul><ul id="2e420f47-3777-4bd2-8dde-f0d92ab81218" class="toggle"><li><details open=""><summary>AIDD (Artificial Intelligence Driven Development)</summary><p id="b3afdea5-fcf2-497e-a810-4e4a38faafb1" class="">AIDD (Artificial Intelligence Driven Development) 시스템은 인공지능(AI) 기술을 기반으로 개발 프로세스를 자동화하고, 소프트웨어 개발의 품질과 효율성을 향상시키는 시스템을 의미합니다. AIDD 시스템은 다양한 구성요소와 기술을 포함하며, 이들 구성요소가 연동되어 개발 프로세스를 최적화합니다. 아래에 AIDD 시스템의 주요 구성요소, 연동 구조, 활용 기술, 그리고 활용 사례를 설명하겠습니다.</p><h2 id="fc72788e-9148-487a-bc15-9e06838cb696" class="">AIDD 시스템 구성요소</h2><ol type="1" id="a47d69e9-6ce1-4f2e-96f5-0349847ebaa8" class="numbered-list" start="1"><li><strong>데이터 수집 및 전처리 (Data Collection and Preprocessing)</strong><ul id="b0ca9f6d-dcff-40b5-9f6a-4c6fe565e179" class="bulleted-list"><li style="list-style-type:disc"><strong>소스 코드 분석</strong>: 개발 중인 소스 코드, 기존 코드 베이스, 버그 리포트, 코드 리뷰 결과 등을 수집합니다.</li></ul><ul id="6a0acbc3-8c0a-4c9a-bba8-7164b802cf16" class="bulleted-list"><li style="list-style-type:disc"><strong>로그 수집</strong>: 개발, 빌드, 배포 과정에서 생성되는 로그 데이터를 수집합니다.</li></ul><ul id="6612160e-3e2f-43ee-9d19-960f0039105d" class="bulleted-list"><li style="list-style-type:disc"><strong>테스트 데이터</strong>: 유닛 테스트, 통합 테스트 결과와 같은 테스트 데이터를 수집합니다.</li></ul></li></ol><ol type="1" id="fd5b996e-f768-428b-a8ab-d9369c0ec0ce" class="numbered-list" start="2"><li><strong>모델 학습 및 훈련 (Model Training and Learning)</strong><ul id="5b1ca6f0-f7e0-4b63-9a06-bacc36d6263d" class="bulleted-list"><li style="list-style-type:disc"><strong>ML 모델</strong>: AI와 머신러닝 모델을 사용하여 코드의 품질을 분석하거나, 버그를 예측하거나, 코드 생성 및 수정 작업을 자동화합니다.</li></ul><ul id="4f500313-dd16-4e89-9491-6edf739cec9a" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 학습</strong>: 코드 및 로그 데이터를 기반으로 모델을 학습시킵니다. 이는 코드 스타일, 버그 패턴, 코드 복잡도 등을 인식하는 데 사용됩니다.</li></ul></li></ol><ol type="1" id="66faffa2-1c9a-483f-bd0b-cf83d3a84edc" class="numbered-list" start="3"><li><strong>자동화된 코드 생성 및 수정 (Automated Code Generation and Modification)</strong><ul id="02c04497-ae50-4c90-bd05-241f0a8cee55" class="bulleted-list"><li style="list-style-type:disc"><strong>코드 생성기</strong>: 주어진 요구 사항이나 기존 코드 패턴을 기반으로 자동으로 코드를 생성합니다.</li></ul><ul id="4716e652-2fdc-4b8f-9e11-6e9174a27848" class="bulleted-list"><li style="list-style-type:disc"><strong>코드 수정</strong>: 코드 품질을 개선하거나 버그를 수정하기 위해 AI가 자동으로 코드를 수정합니다.</li></ul></li></ol><ol type="1" id="c4b80f51-8857-4601-92fa-482d887db2fa" class="numbered-list" start="4"><li><strong>테스트 및 품질 보증 (Testing and Quality Assurance)</strong><ul id="3ba48679-7106-4d38-a055-4cf9fae14de8" class="bulleted-list"><li style="list-style-type:disc"><strong>자동화된 테스트</strong>: AI를 활용하여 테스트 케이스를 생성하고, 테스트를 자동으로 실행합니다.</li></ul><ul id="f313768c-683c-4c5a-8da1-1f4e959d3f8e" class="bulleted-list"><li style="list-style-type:disc"><strong>품질 분석</strong>: 코드의 품질을 분석하고, 코드의 결함을 예측합니다.</li></ul></li></ol><ol type="1" id="0f57ed8a-a402-497d-82b2-7d243281a82d" class="numbered-list" start="5"><li><strong>모니터링 및 피드백 (Monitoring and Feedback)</strong><ul id="6e642438-62e8-42ef-8f03-6398aea8bca1" class="bulleted-list"><li style="list-style-type:disc"><strong>실시간 모니터링</strong>: 개발 프로세스와 애플리케이션의 상태를 모니터링합니다.</li></ul><ul id="c2c49a77-221c-4388-be0c-ddbfc2737aa1" class="bulleted-list"><li style="list-style-type:disc"><strong>피드백 시스템</strong>: 모델의 성능과 결과를 분석하고, 피드백을 통해 모델을 개선합니다.</li></ul></li></ol><ol type="1" id="bc56374d-6ec5-4817-9eeb-0fc3b2c46741" class="numbered-list" start="6"><li><strong>통합 및 배포 (Integration and Deployment)</strong><ul id="3befa0ec-7098-4d66-b09a-7aeba51c2535" class="bulleted-list"><li style="list-style-type:disc"><strong>CI/CD</strong>: 지속적인 통합 및 지속적인 배포(CI/CD) 파이프라인을 통해 코드의 자동 빌드, 테스트 및 배포를 관리합니다.</li></ul><ul id="29696ac4-a79a-4470-bf69-d1815b5b1042" class="bulleted-list"><li style="list-style-type:disc"><strong>DevOps 도구</strong>: Jenkins, GitLab CI/CD, CircleCI 등을 활용하여 자동화된 배포 및 운영 관리를 수행합니다.</li></ul></li></ol><h2 id="c55a3adc-8d85-4453-8368-d13d0bd0bc2c" class="">연동 구조</h2><p id="5b4625cb-2569-4eb4-b02a-63fbace19d89" class="">AIDD 시스템의 구성요소는 서로 긴밀하게 연동되어 전체 개발 프로세스를 지원합니다. 연동 구조는 다음과 같습니다:</p><ol type="1" id="9a90b7b8-abe9-45c3-9c34-cb96715c235a" class="numbered-list" start="1"><li><strong>데이터 수집</strong><ul id="b889984a-cd8c-43dd-8f3a-6f16145f2900" class="bulleted-list"><li style="list-style-type:disc">코드 리포지토리, 로그 관리 시스템, 테스트 프레임워크에서 데이터를 수집하여 데이터베이스나 데이터 레이크에 저장합니다.</li></ul></li></ol><ol type="1" id="9eb73227-e16b-4996-8c69-6ee7f2e836c3" class="numbered-list" start="2"><li><strong>모델 학습</strong><ul id="8756db38-3bba-4998-b180-7e885e703436" class="bulleted-list"><li style="list-style-type:disc">수집된 데이터를 모델 학습 플랫폼(예: TensorFlow, PyTorch)으로 전송하여 AI 모델을 훈련시킵니다.</li></ul></li></ol><ol type="1" id="93e6b904-f156-4af5-b2b0-a699e6cb03c3" class="numbered-list" start="3"><li><strong>코드 생성 및 수정</strong><ul id="79a76931-e9de-41bb-a237-2f69b8506a98" class="bulleted-list"><li style="list-style-type:disc">훈련된 모델이 코드 생성기나 수정 도구와 연동되어 자동으로 코드를 생성하거나 수정합니다.</li></ul></li></ol><ol type="1" id="3f529798-e03a-47d1-8efc-b57260d37267" class="numbered-list" start="4"><li><strong>테스트 및 품질 보증</strong><ul id="40f14543-81c9-4232-9c97-67c7229c8723" class="bulleted-list"><li style="list-style-type:disc">자동화된 테스트 도구가 AI 기반의 테스트 생성 및 실행을 지원하며, 품질 분석 도구와 연동되어 코드 품질을 평가합니다.</li></ul></li></ol><ol type="1" id="1d84e3bd-28ed-4313-be9b-3421a1554040" class="numbered-list" start="5"><li><strong>모니터링 및 피드백</strong><ul id="13588fd8-a4d6-48cb-81c4-88c9dafb26c4" class="bulleted-list"><li style="list-style-type:disc">모니터링 시스템이 실시간으로 프로세스를 감시하고, 피드백 시스템이 모델의 성능을 분석하여 개선사항을 적용합니다.</li></ul></li></ol><ol type="1" id="32101464-e127-4551-b9ef-be9887536f19" class="numbered-list" start="6"><li><strong>통합 및 배포</strong><ul id="08cbec61-e6e5-4e78-8da0-e98cf333c0cb" class="bulleted-list"><li style="list-style-type:disc">CI/CD 파이프라인과 DevOps 도구가 AIDD 시스템의 결과를 자동으로 통합하고 배포합니다.</li></ul></li></ol><h2 id="9aa19728-b8d0-4589-9405-afea24c815e1" class="">활용 기술</h2><ul id="cec9c9ef-5690-4f31-925a-b8031010d199" class="bulleted-list"><li style="list-style-type:disc"><strong>머신러닝 (ML)</strong>: 코드 품질 분석, 버그 예측, 코드 생성 및 수정에 활용됩니다.</li></ul><ul id="5322a2ed-5f12-45ca-b72e-dda602cb5863" class="bulleted-list"><li style="list-style-type:disc"><strong>자연어 처리 (NLP)</strong>: 코드 리뷰와 문서화에서 코드 주석을 자동으로 생성합니다.</li></ul><ul id="2ffa5330-68d7-4e9c-b06c-ba5f50ea0d5f" class="bulleted-list"><li style="list-style-type:disc"><strong>딥러닝 (Deep Learning)</strong>: 복잡한 패턴 인식과 예측 분석에 사용됩니다.</li></ul><ul id="a16d0a44-1fa4-4bf3-9338-fcebef2a4631" class="bulleted-list"><li style="list-style-type:disc"><strong>자동화 도구</strong>: CI/CD 파이프라인, 테스트 자동화 도구, DevOps 도구 등을 포함합니다.</li></ul><h2 id="614f3e13-535e-4953-a839-1e1b7bb73a16" class="">활용 사례</h2><ol type="1" id="c4cb4f0e-65f2-4537-a03c-20a1b305edaf" class="numbered-list" start="1"><li><strong>자동 코드 생성</strong><ul id="d30e23a9-4852-4209-bccd-5e9156ec759f" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: AI가 주어진 요구 사항을 기반으로 코드 스니펫을 자동으로 생성합니다. 예를 들어, GitHub Copilot은 코드 자동 완성 및 생성 기능을 제공합니다.</li></ul></li></ol><ol type="1" id="8e586ac9-c94b-4b04-9f12-597a75247b4b" class="numbered-list" start="2"><li><strong>버그 예측 및 수정</strong><ul id="2d2c67df-0fa5-4d68-8e58-385cad418d86" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: AI 모델이 기존 코드의 버그 패턴을 학습하여 새로운 코드에서 발생할 수 있는 버그를 예측하고, 자동으로 수정 제안을 제공합니다.</li></ul></li></ol><ol type="1" id="e154acdd-5bfb-4b12-a028-81077074513c" class="numbered-list" start="3"><li><strong>테스트 자동화</strong><ul id="44cea153-4b27-48e2-b812-7de1663b95e9" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: AI가 코드 변경 사항을 분석하고, 자동으로 적절한 테스트 케이스를 생성하여 실행합니다. 이를 통해 테스트 커버리지를 향상시킵니다.</li></ul></li></ol><ol type="1" id="405a7778-b54d-465b-a06a-7cd0ba9bfec5" class="numbered-list" start="4"><li><strong>코드 품질 분석</strong><ul id="639e279c-4f37-410f-885b-170b4c6ad577" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: AI 기반 도구가 코드의 품질을 분석하고, 복잡도, 중복 코드, 스타일 문제 등을 식별하여 코드 리뷰를 지원합니다.</li></ul></li></ol><ol type="1" id="3823745d-f19e-44ce-ae28-5fc6e58dd83a" class="numbered-list" start="5"><li><strong>지속적 배포 (Continuous Deployment)</strong><ul id="7fc58130-15b9-4723-8869-2f367aa58fb2" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: CI/CD 파이프라인과 AI 도구를 연동하여 코드를 자동으로 빌드하고, 테스트하며, 프로덕션 환경에 배포합니다.</li></ul></li></ol><h2 id="9d826afb-3603-40c5-8eb9-3daffae9a6ca" class="">결론</h2><p id="6ce128c7-f910-4e54-81a3-343450ef8e9d" class="">AIDD 시스템은 AI와 머신러닝을 활용하여 소프트웨어 개발의 다양한 측면을 자동화하고 최적화합니다. 데이터 수집, 모델 학습, 코드 생성 및 수정, 테스트 및 품질 보증, 모니터링 및 피드백, 통합 및 배포 등의 구성요소와 기술들이 유기적으로 연동되어 개발 프로세스를 혁신합니다. 이를 통해 개발 팀은 생산성을 높이고, 소프트웨어 품질을 향상시킬 수 있습니다.</p><p id="cee96ffa-4398-4cc4-8b58-61962415cad5" class="">
</p><figure id="746a1279-b633-4328-974b-7ed03ab0a225"><a href="https://ten1010.io/product-aipub-dev" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">주식회사 텐 | AI 인프라 전용 MLOps 전문기업</div><div class="bookmark-description">AI가 모두에게 일상이 될 수 있도록 쉽고 간단한 AI툴과 환경을 만듭니다.</div></div><div class="bookmark-href"><img src="https://ten1010.io/favicon.ico" class="icon bookmark-icon"/>https://ten1010.io/product-aipub-dev</div></div><img src="https://ten1010.io/og-image.png" class="bookmark-image"/></a></figure></details></li></ul><ul id="d584a125-7641-4237-8e1b-788096c44f9f" class="toggle"><li><details open=""><summary>클라우드 AI Platform</summary><p id="8a80b60c-2722-4d5f-98ee-7ce31ea3c600" class="">클라우드 AI 플랫폼은 인공지능(AI)과 머신러닝(ML) 모델을 개발, 학습, 배포 및 운영하기 위한 클라우드 기반의 서비스와 도구를 제공합니다. 이러한 플랫폼은 다양한 AI 기능을 지원하며, 사용자가 복잡한 인프라 관리 없이 AI 솔루션을 구축하고 실행할 수 있도록 돕습니다. 주요 클라우드 AI 플랫폼에는 Google AI Platform, AWS SageMaker, Microsoft Azure Machine Learning 등이 있습니다.</p><p id="c85893d3-d9ac-49d5-81c6-ec31f2dc4285" class="">아래에서는 클라우드 AI 플랫폼의 주요 기능, 구성 요소, 그리고 주요 플랫폼의 예를 통해 설명하겠습니다.</p><h2 id="86ac5c42-5d81-46bb-a480-8790887c98ac" class="">클라우드 AI 플랫폼의 주요 기능</h2><ol type="1" id="a94fa325-6561-43e5-9660-f9010665749c" class="numbered-list" start="1"><li><strong>데이터 관리 (Data Management)</strong><ul id="fd227543-803f-459f-9956-e120360593c6" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 수집 및 저장</strong>: 클라우드 기반의 스토리지 서비스(예: Amazon S3, Google Cloud Storage)에서 데이터를 수집하고 저장합니다.</li></ul><ul id="118cfa39-b49c-4407-8bf7-ed12ea0b80d3" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 전처리</strong>: 데이터를 정제하고 변환하여 모델 학습에 적합한 형식으로 준비합니다.</li></ul></li></ol><ol type="1" id="eb4c803c-9523-42b3-8927-37495084fc05" class="numbered-list" start="2"><li><strong>모델 개발 및 학습 (Model Development and Training)</strong><ul id="b8b66711-52eb-499a-beaa-80b2c889b2fb" class="bulleted-list"><li style="list-style-type:disc"><strong>자동화된 ML (AutoML)</strong>: 비전문가도 사용할 수 있는 자동화된 머신러닝 도구를 제공하여 모델 개발 과정을 단순화합니다. 예를 들어, Google AutoML, AWS SageMaker Autopilot.</li></ul><ul id="558cb684-dee8-4266-9f48-a9fdd285a85f" class="bulleted-list"><li style="list-style-type:disc"><strong>맞춤형 모델 학습</strong>: 사용자가 직접 모델을 설계하고, GPU나 TPU와 같은 고성능 컴퓨팅 자원을 활용하여 대규모 데이터를 학습합니다.</li></ul></li></ol><ol type="1" id="f464fdc0-bae4-4f83-9fc4-ba7cdcab9aee" class="numbered-list" start="3"><li><strong>모델 배포 (Model Deployment)</strong><ul id="b098fb8e-421b-4688-bace-c317ed857571" class="bulleted-list"><li style="list-style-type:disc"><strong>서버리스 배포</strong>: 서버를 관리하지 않고 모델을 배포할 수 있는 기능을 제공합니다. 예를 들어, AWS Lambda와 Google Cloud Functions.</li></ul><ul id="d640a8a5-3c45-4498-a890-76bc43bb8746" class="bulleted-list"><li style="list-style-type:disc"><strong>엔드포인트 제공</strong>: REST API 또는 gRPC를 통해 모델 예측을 외부 애플리케이션에서 호출할 수 있는 엔드포인트를 제공합니다.</li></ul></li></ol><ol type="1" id="94b5fe69-e401-4a17-a3da-ffd8174746a1" class="numbered-list" start="4"><li><strong>모델 모니터링 및 관리 (Model Monitoring and Management)</strong><ul id="64f51f10-0853-48bf-a83a-1f255c1532cf" class="bulleted-list"><li style="list-style-type:disc"><strong>모델 성능 모니터링</strong>: 모델의 예측 성능을 모니터링하고, 필요에 따라 재학습 또는 조정합니다.</li></ul><ul id="dd709121-4e2a-44e2-b0cf-553656f98519" class="bulleted-list"><li style="list-style-type:disc"><strong>모델 버전 관리</strong>: 여러 버전의 모델을 관리하고, 배포된 모델의 업데이트를 쉽게 수행합니다.</li></ul></li></ol><ol type="1" id="3a97a6ce-0ae7-4211-933a-5cccc8897dad" class="numbered-list" start="5"><li><strong>AI 도구 및 라이브러리 (AI Tools and Libraries)</strong><ul id="458bd8ad-16d2-4269-868a-67a4b94a69b3" class="bulleted-list"><li style="list-style-type:disc"><strong>프레임워크 지원</strong>: TensorFlow, PyTorch, Keras 등과 같은 인기 있는 ML 프레임워크를 지원합니다.</li></ul><ul id="ab25453d-f2de-42e3-99a2-7a96f405e99b" class="bulleted-list"><li style="list-style-type:disc"><strong>API 및 SDK</strong>: AI 모델을 쉽게 개발하고 통합할 수 있는 API와 SDK를 제공합니다.</li></ul></li></ol><h2 id="a71c041e-96d9-481f-b565-c09ec69e0cfb" class="">주요 클라우드 AI 플랫폼</h2><h3 id="19780db3-267d-4590-a211-6db64b069fce" class="">1. <strong>Google AI Platform</strong></h3><ul id="73eabbd5-fb93-457e-a207-7a4b89d29fdc" class="bulleted-list"><li style="list-style-type:disc"><strong>구성 요소</strong>:<ul id="120dbf59-aa35-4ef0-8958-1a0af63d443d" class="bulleted-list"><li style="list-style-type:circle"><strong>Vertex AI</strong>: ML 모델의 개발, 학습, 배포, 관리 전체를 통합적으로 지원하는 플랫폼입니다.</li></ul><ul id="aa1f5191-c2b8-4627-9141-369e22f04a64" class="bulleted-list"><li style="list-style-type:circle"><strong>AutoML</strong>: 자동화된 머신러닝을 통해 모델 개발을 간소화합니다.</li></ul><ul id="0dc747ff-d64f-431a-aab4-af75e81e5069" class="bulleted-list"><li style="list-style-type:circle"><strong>BigQuery ML</strong>: SQL 쿼리로 머신러닝 모델을 만들 수 있는 도구입니다.</li></ul><ul id="a430b0f9-c14b-4ebe-909f-26036bd41671" class="bulleted-list"><li style="list-style-type:circle"><strong>TensorFlow Extended (TFX)</strong>: TensorFlow 모델의 프로덕션 환경 배포 및 운영을 지원합니다.</li></ul></li></ul><ul id="40f336e7-6822-4b38-9175-cabf3d478c11" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>:<ul id="0680e51b-2f67-48d2-8fe3-c8f508dac610" class="bulleted-list"><li style="list-style-type:circle"><strong>스케일링</strong>: Google Cloud의 강력한 인프라를 기반으로 대규모 데이터 처리와 모델 학습을 지원합니다.</li></ul><ul id="de061b98-b31c-481c-970c-d9e99e3a729e" class="bulleted-list"><li style="list-style-type:circle"><strong>통합성</strong>: Google Cloud의 다양한 서비스와 긴밀하게 통합되어 있습니다.</li></ul></li></ul><h3 id="fb35e427-aa1f-4469-9182-905b49618140" class="">2. <strong>AWS SageMaker</strong></h3><ul id="3d14c4fd-a343-49ff-ab04-d6a5b5d756ab" class="bulleted-list"><li style="list-style-type:disc"><strong>구성 요소</strong>:<ul id="24bf789e-330e-472e-8795-8afbe8990e12" class="bulleted-list"><li style="list-style-type:circle"><strong>SageMaker Studio</strong>: 통합 개발 환경(IDE)을 제공하여 모델 개발, 학습, 배포를 지원합니다.</li></ul><ul id="bfbd16db-afd1-43fc-884e-43d7b78450ee" class="bulleted-list"><li style="list-style-type:circle"><strong>SageMaker Autopilot</strong>: 자동화된 머신러닝 모델 생성 도구입니다.</li></ul><ul id="bc27078b-5543-4801-bd1f-491bbbdce2a9" class="bulleted-list"><li style="list-style-type:circle"><strong>SageMaker Neo</strong>: 모델을 다양한 하드웨어에서 효율적으로 실행할 수 있도록 최적화합니다.</li></ul><ul id="c9c4ddaf-a566-4bb1-8c3a-72acb8594614" class="bulleted-list"><li style="list-style-type:circle"><strong>SageMaker Ground Truth</strong>: 데이터 주석 작업을 자동화하여 데이터의 품질을 개선합니다.</li></ul></li></ul><ul id="823425d3-62f5-422b-80ec-7131b2a21ed5" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>:<ul id="e70a52b4-dfd7-442d-b441-f5e20089a42f" class="bulleted-list"><li style="list-style-type:circle"><strong>풀스택 솔루션</strong>: 데이터 준비, 모델 학습, 배포, 모니터링까지 모든 단계에서 솔루션을 제공합니다.</li></ul><ul id="2102d639-b5b8-48fe-a193-13ee95686ad2" class="bulleted-list"><li style="list-style-type:circle"><strong>AWS 인프라와의 통합</strong>: AWS의 다른 서비스(예: S3, Redshift)와 원활하게 통합됩니다.</li></ul></li></ul><h3 id="cf13dde5-36ba-4319-974a-a6c7e3dfa634" class="">3. <strong>Microsoft Azure Machine Learning</strong></h3><ul id="394bf2b1-5653-49ce-b6ca-310e1548d0df" class="bulleted-list"><li style="list-style-type:disc"><strong>구성 요소</strong>:<ul id="5104f983-8efa-431f-ba81-b36df3f0dd0c" class="bulleted-list"><li style="list-style-type:circle"><strong>Azure Machine Learning Studio</strong>: 모델 개발과 학습을 위한 사용자 친화적인 UI를 제공합니다.</li></ul><ul id="c5de80b6-3ad2-4a85-908c-f0fb4b9b9b49" class="bulleted-list"><li style="list-style-type:circle"><strong>AutoML</strong>: 자동화된 머신러닝 기능을 통해 쉽게 모델을 구축할 수 있습니다.</li></ul><ul id="18a71898-fb2c-4f85-9faa-d6fe80ec6ca7" class="bulleted-list"><li style="list-style-type:circle"><strong>Azure Cognitive Services</strong>: 사전 학습된 AI 서비스를 제공하여 이미지 인식, 텍스트 분석 등의 기능을 지원합니다.</li></ul><ul id="1fbf2eeb-18ec-4809-8193-f34be21fa511" class="bulleted-list"><li style="list-style-type:circle"><strong>MLOps</strong>: 모델의 배포, 모니터링, 관리 및 업데이트를 자동화합니다.</li></ul></li></ul><ul id="95645ba1-df04-4b24-9610-97f4c51ea7f6" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>:<ul id="6a522038-f0b1-4054-88f2-2e58c8e02d57" class="bulleted-list"><li style="list-style-type:circle"><strong>엔터프라이즈 기능</strong>: 대규모 기업 환경을 위한 고급 기능과 보안 옵션을 제공합니다.</li></ul><ul id="6ffcc5ca-688f-4f4d-b9da-78e1e196a72b" class="bulleted-list"><li style="list-style-type:circle"><strong>통합성</strong>: Azure의 다양한 서비스와 잘 통합되어 있으며, Microsoft 제품군과의 호환성도 뛰어납니다.</li></ul></li></ul><h2 id="472a6131-c82c-4b68-8310-6f755d9de240" class="">활용 사례</h2><ol type="1" id="3720c25c-fe2e-49ad-acfd-33e59c9ab2a1" class="numbered-list" start="1"><li><strong>개인화 추천 시스템</strong><ul id="77fef7fd-f409-470b-b05a-821375e9fcbe" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 전자상거래 사이트에서 사용자 행동 데이터를 분석하여 개인화된 상품 추천을 제공합니다. 예를 들어, Netflix의 추천 알고리즘은 사용자의 시청 기록을 분석하여 맞춤형 콘텐츠를 추천합니다.</li></ul></li></ol><ol type="1" id="e67d6eea-af69-4dd4-8477-2c6bbcda124c" class="numbered-list" start="2"><li><strong>자연어 처리 (NLP)</strong><ul id="d6a64590-b2b9-4e32-a5b0-0fbeb5af0573" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 고객 서비스 챗봇을 통해 자동으로 고객 문의를 처리합니다. AI는 사용자 질문을 이해하고, 적절한 답변을 생성합니다. 예를 들어, 은행의 고객 지원 챗봇이 있습니다.</li></ul></li></ol><ol type="1" id="a59fbdbe-485a-492b-9963-df2c297589f6" class="numbered-list" start="3"><li><strong>이미지 분석</strong><ul id="335b8e90-6931-4272-a2e9-4c3c5013d41b" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 의료 영상에서 질병을 자동으로 감지하고 진단합니다. AI는 MRI, CT 스캔 등에서 병변을 식별하여 진단을 지원합니다.</li></ul></li></ol><ol type="1" id="8a9be8e3-0a19-497b-ba9d-700a96088c9e" class="numbered-list" start="4"><li><strong>예측 분석</strong><ul id="d65df01d-071b-4d5d-95f1-3a915c308aa5" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 재고 관리와 수요 예측을 통해 공급망의 효율성을 향상시킵니다. AI는 과거 판매 데이터를 분석하여 미래의 수요를 예측합니다.</li></ul></li></ol><ol type="1" id="9d6c244b-a7ab-4d09-af93-c4301c3ffb78" class="numbered-list" start="5"><li><strong>자동화된 품질 보증</strong><ul id="2fba014e-b994-4ed0-ac9b-b2a3d35ca845" class="bulleted-list"><li style="list-style-type:disc"><strong>사례</strong>: 제조업에서 제품의 품질을 검사하고 결함을 자동으로 감지합니다. AI를 활용하여 고해상도 카메라로 제품을 검사하고, 불량품을 식별합니다.</li></ul></li></ol><h2 id="553e8297-bc0b-4a7f-a82d-1adc3a30a747" class="">결론</h2><p id="14d497f3-d468-4fa4-900a-13c5fb1fca2f" class="">클라우드 AI 플랫폼은 AI 및 머신러닝 모델의 개발, 학습, 배포 및 관리를 지원하는 강력한 도구입니다. 이러한 플랫폼은 데이터 관리, 모델 훈련, 자동화된 코드 생성 및 수정, 테스트 및 품질 보증, 모니터링 및 피드백, 통합 및 배포 등 다양한 기능을 제공하여 AI 솔루션을 효율적으로 구축하고 운영할 수 있도록 합니다. 다양한 클라우드 AI 플랫폼은 각각의 특징과 기능을 통해 다양한 산업과 용도에 맞는 AI 솔루션을 제공합니다.</p></details></li></ul><ul id="209e6337-4479-409d-a4d6-a7309bd4c30a" class="toggle"><li><details open=""><summary>클라우드 AI 플랫폼 활용 사례</summary><p id="69ef8822-d271-44a8-8d7f-2673122157ff" class="">클라우드 AI 플랫폼을 활용한 서비스 제공 사례는 매우 다양하며, 각 산업에서 인공지능 기술을 통해 효율성을 극대화하고 혁신적인 솔루션을 제공하고 있습니다. 여기서는 Google Cloud AI Platform, AWS SageMaker, Microsoft Azure Machine Learning을 활용한 구체적인 서비스 제공 사례를 소개하겠습니다.</p><h3 id="b3e92a5a-6a0d-4356-9de8-20b49721349b" class="">1. <strong>Google Cloud AI Platform을 활용한 사례</strong></h3><h3 id="165da6e4-8179-459e-93a0-37c0c49b4511" class="">*1.1. <strong>Netflix의 콘텐츠 추천 시스템</strong></h3><ul id="722014e5-f8b4-4c10-8f2e-0c83a303e8ca" class="bulleted-list"><li style="list-style-type:disc"><strong>문제</strong>: 넷플릭스는 방대한 양의 콘텐츠를 제공하며, 사용자가 개인 맞춤형 추천을 통해 콘텐츠를 찾는 데 어려움을 겪습니다.</li></ul><ul id="28e50741-016e-47c1-acef-a6fb6fa8c462" class="bulleted-list"><li style="list-style-type:disc"><strong>해결책</strong>: Google Cloud AI Platform의 AutoML과 Vertex AI를 활용하여 머신러닝 모델을 개발하였습니다.</li></ul><ul id="aa14ebe8-7e87-4611-9270-d8368c7247de" class="bulleted-list"><li style="list-style-type:disc"><strong>작동 방식</strong>:<ul id="9d50c774-7ef6-4e89-b262-814c7814cbce" class="bulleted-list"><li style="list-style-type:circle"><strong>데이터 수집</strong>: 사용자의 시청 기록, 평가, 검색 데이터 등을 수집합니다.</li></ul><ul id="93cb6633-8d70-4931-9f0a-19fcb505b16b" class="bulleted-list"><li style="list-style-type:circle"><strong>모델 개발</strong>: TensorFlow와 AutoML을 사용하여 콘텐츠 추천 알고리즘을 개발하고, 사용자 행동을 분석합니다.</li></ul><ul id="bc2f7752-128a-401d-bbeb-76a905af0a57" class="bulleted-list"><li style="list-style-type:circle"><strong>추천 제공</strong>: 학습된 모델을 통해 개인화된 콘텐츠 추천을 실시간으로 제공합니다.</li></ul></li></ul><ul id="b1832650-7720-45ab-9266-043b212a6fa0" class="bulleted-list"><li style="list-style-type:disc"><strong>결과</strong>: 사용자 맞춤형 추천 기능을 통해 사용자 만족도와 참여도를 높이고, 넷플릭스의 콘텐츠 소비를 증가시켰습니다.</li></ul><h3 id="29d64ffd-a97c-4b44-8437-9d28671999b2" class="">*1.2. <strong>L&#x27;Oréal의 피부 분석 및 제품 추천</strong></h3><ul id="be8e0a3e-f496-494a-9b2a-06c4e3f3a581" class="bulleted-list"><li style="list-style-type:disc"><strong>문제</strong>: L&#x27;Oréal은 소비자에게 맞춤형 피부 관리 솔루션을 제공하고자 했습니다.</li></ul><ul id="c4cae801-252e-4021-a743-5a7118ebc610" class="bulleted-list"><li style="list-style-type:disc"><strong>해결책</strong>: Google Cloud의 AI와 머신러닝을 활용하여 모바일 앱에서 피부 상태를 분석하는 솔루션을 개발하였습니다.</li></ul><ul id="8d011d7b-de46-4f87-8135-14cd4596d678" class="bulleted-list"><li style="list-style-type:disc"><strong>작동 방식</strong>:<ul id="de564d04-f91d-4558-9269-b21ca36bdf6c" class="bulleted-list"><li style="list-style-type:circle"><strong>이미지 분석</strong>: Google Cloud Vision API를 사용하여 사용자의 피부 사진을 분석하고, 피부 문제를 식별합니다.</li></ul><ul id="260c0e62-9ade-4d8d-a6d2-58e3e0a4ad2b" class="bulleted-list"><li style="list-style-type:circle"><strong>제품 추천</strong>: 분석 결과를 기반으로 맞춤형 제품을 추천합니다.</li></ul></li></ul><ul id="6faf7157-aec1-4de5-885f-9fcc9f4a4414" class="bulleted-list"><li style="list-style-type:disc"><strong>결과</strong>: 개인화된 피부 관리 솔루션을 통해 고객의 만족도를 향상시키고, L&#x27;Oréal의 제품 판매를 증가시켰습니다.</li></ul><h3 id="7e2ac18b-dfd3-4811-9b1a-bec34747b1bb" class="">2. <strong>AWS SageMaker를 활용한 사례</strong></h3><h3 id="8b3a8970-0459-4c01-9a9f-a60b13c10597" class="">*2.1. <strong>Airbnb의 수요 예측</strong></h3><ul id="78da768f-1c28-4025-b99a-f2d6a7fe9d6d" class="bulleted-list"><li style="list-style-type:disc"><strong>문제</strong>: Airbnb는 숙소의 수요를 예측하여 가격 책정 및 재고 관리를 최적화하고자 했습니다.</li></ul><ul id="b4b5d0ff-6f72-4a8f-a691-ab6c0cd156fd" class="bulleted-list"><li style="list-style-type:disc"><strong>해결책</strong>: AWS SageMaker를 사용하여 예측 모델을 개발하고, 머신러닝을 통해 수요를 예측하였습니다.</li></ul><ul id="966ffe25-2179-4cef-b77f-b28a3bacd097" class="bulleted-list"><li style="list-style-type:disc"><strong>작동 방식</strong>:<ul id="8d9d4c71-4267-43d3-9c53-3d262a1d08da" class="bulleted-list"><li style="list-style-type:circle"><strong>데이터 수집</strong>: 예약 데이터, 계절성, 지역 특성 등의 데이터를 수집합니다.</li></ul><ul id="b086487b-ba2c-4960-a568-c43268b79f6e" class="bulleted-list"><li style="list-style-type:circle"><strong>모델 훈련</strong>: SageMaker의 AutoML 및 통합된 학습 환경을 통해 예측 모델을 훈련시킵니다.</li></ul><ul id="dff83b1e-3a38-421e-b5f5-c70061df363f" class="bulleted-list"><li style="list-style-type:circle"><strong>예측 제공</strong>: 모델을 통해 미래의 수요를 예측하고, 가격 책정 및 재고 관리에 활용합니다.</li></ul></li></ul><ul id="dd905d07-8c6e-48b2-8760-e5d8a63ec97b" class="bulleted-list"><li style="list-style-type:disc"><strong>결과</strong>: 정확한 수요 예측을 통해 수익을 극대화하고, 고객 만족도를 높였습니다.</li></ul><h3 id="94e66ae8-d908-4ec6-9e03-381d41b80bf4" class="">*2.2. <strong>Johnson &amp; Johnson의 의료 영상 분석</strong></h3><ul id="d9adced0-8ca5-4c30-bad8-3a8b030b4560" class="bulleted-list"><li style="list-style-type:disc"><strong>문제</strong>: Johnson &amp; Johnson은 의료 영상에서 질병을 조기에 발견하고 진단하기 위해 AI 솔루션을 필요로 했습니다.</li></ul><ul id="791b0471-411e-4add-88d9-a463c2a20321" class="bulleted-list"><li style="list-style-type:disc"><strong>해결책</strong>: AWS SageMaker와 컴퓨터 비전 기술을 활용하여 의료 영상 분석 모델을 개발하였습니다.</li></ul><ul id="47d72929-17c0-43ab-86f2-b5bdc4640d4a" class="bulleted-list"><li style="list-style-type:disc"><strong>작동 방식</strong>:<ul id="9abbc290-2aae-4fd0-bc68-732f8ad40a48" class="bulleted-list"><li style="list-style-type:circle"><strong>이미지 데이터 수집</strong>: MRI, CT 스캔 등의 의료 이미지를 수집합니다.</li></ul><ul id="a9a62154-5312-4486-aea2-8db4eab35717" class="bulleted-list"><li style="list-style-type:circle"><strong>모델 학습</strong>: SageMaker를 사용하여 딥러닝 모델을 학습시키고, 질병 패턴을 인식합니다.</li></ul><ul id="1f25c8be-84d9-456f-a3b4-b90feeba6ab6" class="bulleted-list"><li style="list-style-type:circle"><strong>진단 지원</strong>: 모델이 자동으로 질병을 감지하고 진단을 지원합니다.</li></ul></li></ul><ul id="58b9ac61-e53c-438d-bee1-51c6508a6142" class="bulleted-list"><li style="list-style-type:disc"><strong>결과</strong>: 빠르고 정확한 진단을 제공하여 환자의 치료 시기를 앞당기고, 의료 서비스를 개선했습니다.</li></ul><h3 id="f590e398-ed74-4c3e-a9ed-d93434a0887b" class="">3. <strong>Microsoft Azure Machine Learning을 활용한 사례</strong></h3><h3 id="d3585ee5-100c-4953-87d1-5d914f48462b" class="">*3.1. <strong>KPMG의 금융 사기 탐지</strong></h3><ul id="7763b6fe-536a-44c5-9ab6-f7fa8b20bfbc" class="bulleted-list"><li style="list-style-type:disc"><strong>문제</strong>: KPMG는 금융 거래에서 발생할 수 있는 사기를 탐지하고자 했습니다.</li></ul><ul id="d5bfe893-d534-4021-a342-1017d3269360" class="bulleted-list"><li style="list-style-type:disc"><strong>해결책</strong>: Azure Machine Learning을 활용하여 사기 탐지 모델을 개발하고, 머신러닝 기반의 분석을 수행했습니다.</li></ul><ul id="eebcd03b-95a7-435d-a7f5-dcd2ab5df801" class="bulleted-list"><li style="list-style-type:disc"><strong>작동 방식</strong>:<ul id="b566c46f-5f87-436e-ab44-34eefa29bbc7" class="bulleted-list"><li style="list-style-type:circle"><strong>데이터 수집</strong>: 거래 기록, 사용자 행동 데이터를 수집합니다.</li></ul><ul id="335d6294-cd58-4735-a54c-7c7129810441" class="bulleted-list"><li style="list-style-type:circle"><strong>모델 훈련</strong>: Azure Machine Learning을 사용하여 사기 탐지 모델을 훈련시킵니다.</li></ul><ul id="b5b9191e-fa2a-490f-92c2-a6c056231e95" class="bulleted-list"><li style="list-style-type:circle"><strong>실시간 모니터링</strong>: 모델을 사용하여 실시간으로 거래를 분석하고, 의심스러운 활동을 탐지합니다.</li></ul></li></ul><ul id="372feda3-43ec-467a-8b66-5b3d1c18dfba" class="bulleted-list"><li style="list-style-type:disc"><strong>결과</strong>: 사기 탐지 정확도를 향상시켜 금융 범죄를 사전에 차단하고, 고객의 안전을 보장했습니다.</li></ul><h3 id="5bd87360-f3e9-42c1-85bf-4437d72702f1" class="">*3.2. <strong>PepsiCo의 판매 예측 및 재고 관리</strong></h3><ul id="00b58a0b-6de9-4ea8-983f-8085b5875f5c" class="bulleted-list"><li style="list-style-type:disc"><strong>문제</strong>: PepsiCo는 글로벌 공급망의 재고를 효율적으로 관리하고자 했습니다.</li></ul><ul id="bec70866-3be7-4399-9f17-c30077c60d3f" class="bulleted-list"><li style="list-style-type:disc"><strong>해결책</strong>: Azure Machine Learning을 통해 판매 예측 모델을 개발하고, 재고 관리를 최적화하였습니다.</li></ul><ul id="880eca0f-0954-45d2-b1e9-a3597eea1b4f" class="bulleted-list"><li style="list-style-type:disc"><strong>작동 방식</strong>:<ul id="d549a8ac-d6be-4ac1-90f9-597e1638cfe0" class="bulleted-list"><li style="list-style-type:circle"><strong>데이터 분석</strong>: 판매 데이터, 지역별 수요 패턴을 분석합니다.</li></ul><ul id="60c22498-c74b-4c7d-b9a0-50a61f1456e5" class="bulleted-list"><li style="list-style-type:circle"><strong>모델 학습</strong>: Azure Machine Learning의 AutoML 및 맞춤형 모델을 통해 판매 예측을 수행합니다.</li></ul><ul id="771a264a-fd4e-4091-86e3-d03b4801f2a0" class="bulleted-list"><li style="list-style-type:circle"><strong>재고 최적화</strong>: 예측된 데이터를 바탕으로 재고 수준을 조정하고, 공급망 관리를 최적화합니다.</li></ul></li></ul><ul id="a211f4c8-4983-4718-9edc-fba852c12351" class="bulleted-list"><li style="list-style-type:disc"><strong>결과</strong>: 판매 예측의 정확성을 높여 재고 부족 문제를 줄이고, 공급망의 효율성을 극대화했습니다.</li></ul><h2 id="aed140af-eaed-488b-bafc-6c41aa1f793c" class="">결론</h2><p id="7a95b535-1ad4-426a-b48b-fd54666a2cc0" class="">클라우드 AI 플랫폼은 다양한 산업에서 AI와 머신러닝 기술을 활용하여 복잡한 문제를 해결하고, 비즈니스 프로세스를 최적화하는 데 큰 도움을 줍니다. 위의 사례들에서 보듯이, 클라우드 AI 플랫폼을 활용하면 데이터 분석, 예측, 개인화 추천, 이미지 분석 등의 기능을 통해 효율성을 높이고, 고객 경험을 개선하며, 비즈니스 성과를 향상시킬 수 있습니다.</p></details></li></ul><ul id="1cc6a40d-69b7-4455-94eb-02cf477f07b8" class="toggle"><li><details open=""><summary>ktds - AI와 빅데이터가 결합된 최적의 솔루션 제공</summary><figure id="3e60e0b1-6e7e-4718-bf41-c142b595852d"><a href="https://www.ktds.com/competency/ai_bigdata.jsp" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">IT서비스 전문기업 kt ds</div></div><div class="bookmark-href">https://www.ktds.com/competency/ai_bigdata.jsp</div></div></a></figure></details></li></ul><ul id="b65c65da-27c8-4555-a399-ed203ee65618" class="toggle"><li><details open=""><summary>클라우드 기반의 생성형 AI 플랫폼</summary><p id="55e344d6-f486-4061-9935-864be6f938cb" class="">클라우드 기반의 생성형 AI 플랫폼을 오픈 소스를 활용하여 구축하려는 경우, 다양한 기술과 도구를 통합하여 유연하고 확장 가능한 플랫폼을 구현할 수 있습니다. 이러한 플랫폼은 여러 계열사가 공동으로 사용할 수 있으며, 생성형 AI 모델(예: GPT, Stable Diffusion 등)을 활용하여 다양한 기능을 제공합니다.</p><p id="3639877c-9b33-4faa-be89-d1f802b62670" class="">아래는 클라우드 기반의 생성형 AI 플랫폼을 구성하는 요소와 기능, 그리고 연동 구조를 자세히 설명합니다.</p><h3 id="f359654d-11de-4da4-a8ae-9ce1e72316ee" class="">1. <strong>구성 요소</strong></h3><ol type="1" id="7756125f-18b5-46c2-86e9-f6e5cdc4dc4e" class="numbered-list" start="1"><li><strong>클라우드 인프라 (Cloud Infrastructure)</strong><ul id="84175e9b-19e8-448e-9ca8-462c4dcf5da2" class="bulleted-list"><li style="list-style-type:disc"><strong>클라우드 서비스 제공자</strong>: AWS, Google Cloud, Microsoft Azure 등에서 컴퓨팅, 저장소, 네트워킹 자원을 제공합니다.</li></ul><ul id="19a92360-b8d8-4a37-8789-686fa65e5ef4" class="bulleted-list"><li style="list-style-type:disc"><strong>가상 서버/컨테이너</strong>: 생성형 AI 모델을 실행할 가상 서버 또는 컨테이너(예: Docker, Kubernetes)를 배포합니다.</li></ul></li></ol><ol type="1" id="d82952b8-4dbe-4331-aea0-35fe2ea87b15" class="numbered-list" start="2"><li><strong>데이터 관리 (Data Management)</strong><ul id="48606ccc-2885-4344-b00c-65f082bce5da" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 저장소</strong>: 데이터 웨어하우스(예: Google BigQuery, AWS Redshift) 및 데이터 레이크(예: Amazon S3, Google Cloud Storage)를 사용하여 데이터를 저장합니다.</li></ul><ul id="4b37a7d6-69b0-4ad4-87f0-48ba698dd3ea" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 전처리</strong>: Apache Airflow, Apache NiFi 등으로 데이터 파이프라인을 관리하고, 데이터 클렌징 및 변환을 수행합니다.</li></ul></li></ol><ol type="1" id="674369bb-0cbe-4094-8ece-7ca67d535999" class="numbered-list" start="3"><li><strong>모델 관리 (Model Management)</strong><ul id="f7ec5488-60ab-4aa7-ab81-c5e5dba0bfd9" class="bulleted-list"><li style="list-style-type:disc"><strong>모델 저장소</strong>: MLflow, TensorFlow ModelGarden, Hugging Face Model Hub를 통해 모델을 저장하고 버전 관리합니다.</li></ul><ul id="fab6f3bb-850f-4fc1-8a0f-2adf94ba412b" class="bulleted-list"><li style="list-style-type:disc"><strong>모델 훈련 및 학습</strong>: TensorFlow, PyTorch, Jupyter Notebook을 활용하여 모델을 훈련합니다.</li></ul></li></ol><ol type="1" id="0934b8ed-65e2-47b5-963a-8efc6a3e0210" class="numbered-list" start="4"><li><strong>API 및 서비스 (API and Services)</strong><ul id="cda2c6b6-a77e-4f1a-8481-a8c3a58ba742" class="bulleted-list"><li style="list-style-type:disc"><strong>API Gateway</strong>: API 요청을 라우팅하고, 인증 및 권한 부여를 관리합니다. (예: Kong, NGINX)</li></ul><ul id="16fab45d-0b59-4695-a6fe-daf8827be09a" class="bulleted-list"><li style="list-style-type:disc"><strong>서비스 메쉬</strong>: 서비스 간 통신을 관리하고, 모니터링합니다. (예: Istio, Linkerd)</li></ul></li></ol><ol type="1" id="297e6cc1-094e-47d2-8ed2-9686bb051029" class="numbered-list" start="5"><li><strong>인터페이스 및 애플리케이션 (Interface and Applications)</strong><ul id="d43b3592-2b9d-41c5-ba80-f77f2ea9387a" class="bulleted-list"><li style="list-style-type:disc"><strong>웹 인터페이스</strong>: 사용자와의 상호작용을 위한 대시보드와 관리 도구를 제공합니다. (예: Streamlit, Dash)</li></ul><ul id="41b67ca0-0354-4c4c-8d50-094043ef3f9c" class="bulleted-list"><li style="list-style-type:disc"><strong>모바일 애플리케이션</strong>: 모바일 환경에서 생성형 AI 기능을 제공하는 애플리케이션을 개발합니다.</li></ul></li></ol><ol type="1" id="0f0d5026-6171-449e-ae6a-00af2acee7c7" class="numbered-list" start="6"><li><strong>모니터링 및 로깅 (Monitoring and Logging)</strong><ul id="99d266d0-451b-4af6-91b3-b68e6add27d3" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링</strong>: Prometheus, Grafana를 사용하여 시스템 성능을 모니터링합니다.</li></ul><ul id="60031bff-b26e-4a09-a49a-3eafbca53532" class="bulleted-list"><li style="list-style-type:disc"><strong>로그 관리</strong>: ELK Stack (Elasticsearch, Logstash, Kibana) 또는 Loki를 사용하여 로그를 수집하고 분석합니다.</li></ul></li></ol><ol type="1" id="124d76e2-e1f0-47de-b57c-af044a85872f" class="numbered-list" start="7"><li><strong>보안 및 관리 (Security and Governance)</strong><ul id="7efccfd2-0682-40ef-99f2-a10a0ab0d4f8" class="bulleted-list"><li style="list-style-type:disc"><strong>인증 및 권한 관리</strong>: OAuth, LDAP를 사용하여 사용자 인증 및 권한을 관리합니다.</li></ul><ul id="ef24e513-f7fb-4944-9ea0-fcaba3ba03a1" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 암호화</strong>: 전송 중 및 저장된 데이터의 암호화를 관리합니다.</li></ul></li></ol><h3 id="2e283452-68b2-47f4-93cb-af5cf2aa296c" class="">2. <strong>기능</strong></h3><ol type="1" id="cc19b461-591c-4d30-bf4b-7b8a1dbcb7e9" class="numbered-list" start="1"><li><strong>모델 훈련 및 추론</strong><ul id="1dca9400-4309-4af5-b7cb-2b9faf24b94e" class="bulleted-list"><li style="list-style-type:disc"><strong>훈련</strong>: 대규모 데이터셋을 사용하여 생성형 AI 모델을 훈련합니다.</li></ul><ul id="01d22a16-0f8e-4fa4-94e8-88de65f47468" class="bulleted-list"><li style="list-style-type:disc"><strong>추론</strong>: 훈련된 모델을 사용하여 텍스트 생성, 이미지 생성, 자연어 처리 등의 작업을 수행합니다.</li></ul></li></ol><ol type="1" id="a7bc4bb6-d2cd-4831-80e4-28d3f4d4b9b0" class="numbered-list" start="2"><li><strong>데이터 전처리 및 후처리</strong><ul id="cd6af5f5-6453-45c0-8725-14743afd76d1" class="bulleted-list"><li style="list-style-type:disc"><strong>전처리</strong>: 데이터 정제, 토큰화, 임베딩 변환 등을 수행합니다.</li></ul><ul id="1c0ae813-93b6-4cac-b8de-009b412973ba" class="bulleted-list"><li style="list-style-type:disc"><strong>후처리</strong>: 생성된 결과물을 후처리하여 최종 출력 형식으로 변환합니다.</li></ul></li></ol><ol type="1" id="823447d7-b192-43a3-aaed-ac81f2e1cd8d" class="numbered-list" start="3"><li><strong>다양한 AI 작업 지원</strong><ul id="e774814d-0363-4ca4-963c-489f214974db" class="bulleted-list"><li style="list-style-type:disc"><strong>텍스트 생성</strong>: GPT-3와 같은 모델을 사용하여 자연어 텍스트를 생성합니다.</li></ul><ul id="1d482172-691e-47e7-b535-21274adbba59" class="bulleted-list"><li style="list-style-type:disc"><strong>이미지 생성</strong>: DALL-E, Stable Diffusion과 같은 모델을 사용하여 이미지를 생성합니다.</li></ul></li></ol><ol type="1" id="5c06ffb2-8670-40d8-9a59-2128526a6a19" class="numbered-list" start="4"><li><strong>API 및 서비스 제공</strong><ul id="783eaf6b-fbf1-4faf-b782-ff510f9e9801" class="bulleted-list"><li style="list-style-type:disc"><strong>RESTful API</strong>: 모델의 기능을 외부 애플리케이션에서 사용할 수 있도록 RESTful API를 제공합니다.</li></ul><ul id="f1dedc70-9044-47dc-92e1-955bc2e28ef1" class="bulleted-list"><li style="list-style-type:disc"><strong>WebSocket</strong>: 실시간 데이터 전송을 위한 WebSocket API를 지원합니다.</li></ul></li></ol><ol type="1" id="c9f70542-65bc-4b40-8535-a9d490f39bb5" class="numbered-list" start="5"><li><strong>사용자 관리 및 권한 제어</strong><ul id="b3d5fddd-d04f-4565-8204-42cf8a70a94c" class="bulleted-list"><li style="list-style-type:disc"><strong>사용자 인증</strong>: OAuth, JWT를 통해 사용자 인증을 관리합니다.</li></ul><ul id="aba10804-01f6-4579-9d76-ad3b152a4ab1" class="bulleted-list"><li style="list-style-type:disc"><strong>권한 제어</strong>: 사용자 역할 및 권한에 따라 접근 제어를 설정합니다.</li></ul></li></ol><h3 id="597e9804-5866-4a29-95b9-bb97cc656d1a" class="">3. <strong>연동 구조</strong></h3><ol type="1" id="6759e17e-8363-4f1e-b669-2d6293f10a20" class="numbered-list" start="1"><li><strong>클라우드 인프라</strong><ul id="af506482-3853-4c6f-8ffe-89879f2264dc" class="bulleted-list"><li style="list-style-type:disc"><strong>컴퓨팅 자원</strong>: 클라우드 서비스 제공자에서 제공하는 GPU/TPU 인스턴스를 활용하여 모델을 훈련하고 추론합니다.</li></ul><ul id="3b268065-24e6-4f72-8815-f0e02e4adc34" class="bulleted-list"><li style="list-style-type:disc"><strong>스토리지</strong>: 데이터를 저장하고 관리하기 위해 클라우드 스토리지 서비스를 사용합니다.</li></ul></li></ol><ol type="1" id="e61c7b1e-7ace-4a3e-baae-e570f05f4da6" class="numbered-list" start="2"><li><strong>데이터 파이프라인</strong><ul id="b70fe4f6-3013-4cf8-a3d5-623fea1b79f0" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 수집</strong>: 데이터를 수집하고 저장소에 업로드합니다.</li></ul><ul id="6d0ce986-0ead-4a57-9651-df9f40987a6f" class="bulleted-list"><li style="list-style-type:disc"><strong>데이터 전처리</strong>: 데이터가 저장소에 업로드되면, 데이터 전처리 파이프라인이 자동으로 실행됩니다.</li></ul></li></ol><ol type="1" id="cf4a01f0-e271-42fe-b303-c44e8a390705" class="numbered-list" start="3"><li><strong>모델 관리</strong><ul id="f5ace253-712d-471a-bba4-9bcc8093074f" class="bulleted-list"><li style="list-style-type:disc"><strong>모델 훈련</strong>: 클라우드 기반의 컴퓨팅 자원에서 모델을 훈련합니다.</li></ul><ul id="c292e5fd-587f-44dd-a7ff-7913df3689ec" class="bulleted-list"><li style="list-style-type:disc"><strong>모델 저장 및 배포</strong>: 훈련된 모델을 모델 저장소에 저장하고, API를 통해 서비스합니다.</li></ul></li></ol><ol type="1" id="ea78d8a4-ee68-476f-bd78-6318d3f62301" class="numbered-list" start="4"><li><strong>API 및 서비스</strong><ul id="adf2339e-4ada-4cda-a82a-2ba33b2157dc" class="bulleted-list"><li style="list-style-type:disc"><strong>API Gateway</strong>: 클라이언트 애플리케이션에서 모델 API를 호출합니다. API Gateway가 요청을 처리하고 적절한 서비스로 라우팅합니다.</li></ul><ul id="40da9a83-6208-4f57-8ce9-7a8dd8217c61" class="bulleted-list"><li style="list-style-type:disc"><strong>서비스 메쉬</strong>: 서비스 간 통신을 관리하고, 요청의 모니터링 및 로깅을 수행합니다.</li></ul></li></ol><ol type="1" id="8e6c2da2-af23-4144-a0c8-274fe67d3ad5" class="numbered-list" start="5"><li><strong>모니터링 및 관리</strong><ul id="4b2eef18-df4f-49dd-bf3c-bc1c3ffbb6c7" class="bulleted-list"><li style="list-style-type:disc"><strong>모니터링</strong>: 시스템 성능과 모델의 상태를 모니터링하여 이상 징후를 감지합니다.</li></ul><ul id="ea5a8dad-3b2b-4f05-926e-9b0905decac7" class="bulleted-list"><li style="list-style-type:disc"><strong>로그 분석</strong>: 로그 데이터를 수집하고 분석하여 문제를 진단합니다.</li></ul></li></ol><h3 id="aec2f983-5eac-4b51-899e-8aa6126e14e6" class="">4. <strong>활용 기술</strong></h3><ol type="1" id="ea8bb0fa-49db-4eeb-96e7-aa3066efbc83" class="numbered-list" start="1"><li><strong>컨테이너화 및 오케스트레이션</strong><ul id="515df789-b876-4b96-98de-d2af49a19d45" class="bulleted-list"><li style="list-style-type:disc"><strong>Docker</strong>: 애플리케이션과 의존성을 컨테이너로 패키징합니다.</li></ul><ul id="12034422-8e7b-4659-aa09-42cf5d7bf885" class="bulleted-list"><li style="list-style-type:disc"><strong>Kubernetes</strong>: 컨테이너화된 애플리케이션을 배포하고 관리합니다.</li></ul></li></ol><ol type="1" id="d99da175-810b-4b07-a5e0-0d81aeec7fb6" class="numbered-list" start="2"><li><strong>데이터 전처리 및 분석</strong><ul id="053cd3ec-1e05-4230-821f-96641695af7a" class="bulleted-list"><li style="list-style-type:disc"><strong>Apache Spark</strong>: 대규모 데이터 처리 및 분석을 지원합니다.</li></ul><ul id="2f8cc2de-e0af-4954-8eab-777268992c0d" class="bulleted-list"><li style="list-style-type:disc"><strong>Pandas</strong>: 데이터 조작 및 분석을 위한 Python 라이브러리입니다.</li></ul></li></ol><ol type="1" id="86edb0db-36e4-4e31-8581-789a5efe7060" class="numbered-list" start="3"><li><strong>모델 훈련 및 추론</strong><ul id="7b0ab227-c720-4b99-bce1-42a8e4771410" class="bulleted-list"><li style="list-style-type:disc"><strong>TensorFlow, PyTorch</strong>: 머신러닝 모델을 훈련하고 추론하는 데 사용됩니다.</li></ul><ul id="88fc5d68-d085-4136-a392-4efe29774b39" class="bulleted-list"><li style="list-style-type:disc"><strong>MLflow</strong>: 모델의 학습, 실험 및 배포를 관리합니다.</li></ul></li></ol><ol type="1" id="bf22c4ed-1ab9-4f9b-b372-f031b382a7f4" class="numbered-list" start="4"><li><strong>API 및 서비스 제공</strong><ul id="c591b8ad-545a-4f76-814d-ab237adb8d11" class="bulleted-list"><li style="list-style-type:disc"><strong>Flask, FastAPI</strong>: Python으로 API 서버를 구현하는 프레임워크입니다.</li></ul><ul id="0c6bd281-a288-4f3b-ad27-5be4352482e5" class="bulleted-list"><li style="list-style-type:disc"><strong>NGINX</strong>: 고성능의 웹 서버 및 리버스 프록시 서버입니다.</li></ul></li></ol><ol type="1" id="b4713545-6619-4069-a1e6-c4da4202dce7" class="numbered-list" start="5"><li><strong>보안 및 인증</strong><ul id="0a7b99c9-ef85-49f8-80a5-1c10ecda0f6f" class="bulleted-list"><li style="list-style-type:disc"><strong>OAuth, OpenID Connect</strong>: 인증 및 권한 관리를 지원합니다.</li></ul><ul id="46a7a35d-b4f6-44cc-8378-86a6a0bfbb59" class="bulleted-list"><li style="list-style-type:disc"><strong>TLS/SSL</strong>: 데이터 전송의 보안을 보장합니다.</li></ul></li></ol><h3 id="58e2c904-0e7b-4c62-8cdc-768ff614d5a0" class="">결론</h3><p id="96ca18bd-3882-44e3-b956-5bf3f27cb69d" class="">클라우드 기반의 생성형 AI 플랫폼을 오픈 소스를 활용하여 구축하면, 비용 효율적이고 유연한 AI 솔루션을 제공할 수 있습니다. 이러한 플랫폼은 여러 계열사 간의 협업을 지원하고, 생성형 AI의 다양한 기능을 활용하여 비즈니스 가치를 극대화할 수 있습니다. 각 구성 요소와 기술을 적절히 조합하여 강력하고 확장 가능한 AI 플랫폼을 구축하는 것이 중요합니다.</p></details></li></ul><p id="5924de87-8982-4df5-9725-0aedb6f4bfb5" class="">
</p><p id="c2321f72-e08b-4453-951c-4f672fe695bf" class="">Java</p><ul id="b4e2e12f-1362-42cd-9611-73c97637b174" class="toggle"><li><details open=""><summary>JVM 구조와 동작 특성</summary><p id="3a3bcd91-55a6-41dd-a74a-fe09f8153c60" class="">JVM (Java Virtual Machine)은 Java 애플리케이션을 실행하기 위한 가상화된 컴퓨터 환경으로, Java 프로그램이 다양한 플랫폼에서 일관되게 동작하도록 보장합니다. JVM의 구조와 동작 특성을 이해하는 것은 Java 애플리케이션의 성능 최적화 및 문제 해결에 중요한 도움이 됩니다.</p><h3 id="eb9ddb8d-3a40-4e00-9e36-15eeafdc520e" class=""><strong>JVM의 주요 구조</strong></h3><ol type="1" id="7fc0db19-bc2d-4daa-a6ee-338700205635" class="numbered-list" start="1"><li><strong>클래스 로더 (Class Loader)</strong><ul id="260f11b1-3517-4764-b21c-66551781205f" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: JVM에서 실행할 클래스를 동적으로 로딩합니다. 클래스 로더는 클래스 파일을 찾고 읽어 메모리에 로드합니다.</li></ul><ul id="49a20ebe-0f51-4636-95e1-51a973104a3b" class="bulleted-list"><li style="list-style-type:disc"><strong>종류</strong>:<ul id="9abcd60c-5e4f-4d65-af07-c83584fd83b3" class="bulleted-list"><li style="list-style-type:circle"><strong>부트스트랩 클래스 로더</strong>: JVM의 핵심 클래스 (예: <code>java.lang.*</code>)를 로드합니다.</li></ul><ul id="4a0a588b-4968-4e38-bfe3-5c40f2bd4c8e" class="bulleted-list"><li style="list-style-type:circle"><strong>확장 클래스 로더</strong>: Java의 표준 확장 라이브러리 (예: <code>javax.*</code>)를 로드합니다.</li></ul><ul id="f482b100-7f40-4673-ac6e-d991613c7319" class="bulleted-list"><li style="list-style-type:circle"><strong>애플리케이션 클래스 로더</strong>: 애플리케이션에서 사용하는 사용자 정의 클래스를 로드합니다.</li></ul></li></ul></li></ol><ol type="1" id="b053daa5-219e-4ed1-8cd5-03875274bbcd" class="numbered-list" start="2"><li><strong>메소드 영역 (Method Area)</strong><ul id="3b015f4f-a208-464a-b75b-d298a3e54e10" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 클래스와 메소드, 상수, 메소드 변수 등의 정보를 저장하는 메모리 영역입니다. 메소드 영역은 클래스 메타데이터와 런타임 상수 풀을 포함합니다.</li></ul><ul id="3af685de-ba7c-4e01-b520-d8a1eeebe388" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: 클래스 로딩 시 메소드 영역에 데이터가 저장되며, JVM 전체에서 공유됩니다.</li></ul></li></ol><ol type="1" id="2d8de0a5-ebc8-46c0-8e70-6c7044777a6d" class="numbered-list" start="3"><li><strong>힙 (Heap)</strong><ul id="317232f4-28d1-45f0-a622-a83624b15b7f" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 객체와 배열이 저장되는 메모리 영역입니다. Java의 가비지 컬렉터가 주기적으로 힙을 스캔하여 사용하지 않는 객체를 제거합니다.</li></ul><ul id="4adb8818-cef4-4aac-bfbb-73723e6bf1ad" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: 힙은 JVM의 모든 스레드에 의해 공유되며, 런타임 동안 동적으로 크기가 조정됩니다.</li></ul></li></ol><ol type="1" id="062c6d3f-ad27-4e9f-9e25-de7c892d4813" class="numbered-list" start="4"><li><strong>스택 (Stack)</strong><ul id="ed18a24c-6b9a-4755-a601-60545200416a" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 각 스레드에 대한 메서드 호출과 지역 변수를 저장하는 메모리 영역입니다. 각 스레드는 자신의 스택을 가지고 있으며, 스택 프레임을 사용하여 메소드 호출 정보를 저장합니다.</li></ul><ul id="01ec3211-40b1-4c17-b084-e47d3de3784b" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: 스택은 메소드 호출 시 생성되고 메소드 종료 시 제거됩니다. 각 스택 프레임은 메소드의 로컬 변수, 연산 스택 등을 포함합니다.</li></ul></li></ol><ol type="1" id="3000a762-4fc2-4bbd-a286-4ae6eb4dda34" class="numbered-list" start="5"><li><strong>PC 레지스터 (Program Counter Register)</strong><ul id="2642a245-c3ac-4771-909b-0245db84ae2a" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 현재 실행 중인 JVM의 명령어의 주소를 저장하는 레지스터입니다. 각 스레드는 독립적인 PC 레지스터를 가지고 있습니다.</li></ul><ul id="a00192c0-ed72-47bc-a4a6-a80388aae15d" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: 스레드가 메소드 호출을 시작하면 PC 레지스터는 해당 메소드의 첫 번째 명령어 주소를 가리킵니다.</li></ul></li></ol><ol type="1" id="a51596c2-eb6b-49db-92ed-b39ee79d70f1" class="numbered-list" start="6"><li><strong>네이티브 메소드 스택 (Native Method Stack)</strong><ul id="8e953efd-34b7-4960-b204-def6b8d5517d" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: Java 코드가 아닌 네이티브 메소드를 실행하기 위한 메모리 영역입니다. C나 C++로 작성된 네이티브 라이브러리와 상호작용합니다.</li></ul><ul id="6543adbd-a835-4bd5-ad4d-658b1a76beb0" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: JVM의 기본적인 네이티브 메소드 스택은 Java Native Interface (JNI)를 통해 네이티브 코드와 상호작용합니다.</li></ul></li></ol><h3 id="2812d73a-6855-4872-9c3b-5a81fc61063a" class=""><strong>JVM의 동작 특성</strong></h3><ol type="1" id="0373a581-b628-4bdc-96d3-958f068397e6" class="numbered-list" start="1"><li><strong>바이트코드 실행</strong><ul id="77bf1b94-8f51-44c6-bf03-15ebe4db4614" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: JVM은 Java 소스 코드를 컴파일하여 생성된 바이트코드를 실행합니다. 바이트코드는 플랫폼 독립적이며, JVM이 실행할 수 있는 코드입니다.</li></ul><ul id="e16af8d6-4f7b-4e9f-ba5e-ede6bc79bbe7" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: JVM은 바이트코드를 해석하여 명령어를 수행하며, Just-In-Time (JIT) 컴파일러를 사용하여 바이트코드를 네이티브 기계어로 변환해 성능을 향상시킬 수 있습니다.</li></ul></li></ol><ol type="1" id="2f0f421d-2df0-4162-afff-74c187ae11e0" class="numbered-list" start="2"><li><strong>가비지 컬렉션 (Garbage Collection)</strong><ul id="9cb7c9dd-05df-4cf5-a4dc-00f786094623" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 힙 메모리에서 더 이상 사용되지 않는 객체를 자동으로 제거하여 메모리 누수를 방지합니다.</li></ul><ul id="bdcd9357-14d2-45a8-a401-ce73bd9d7661" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: 다양한 가비지 컬렉션 알고리즘이 있으며, 일반적으로 Generational Garbage Collection을 사용합니다. 이 방법은 객체의 생애 주기를 고려하여 효율적으로 메모리를 관리합니다.</li></ul></li></ol><ol type="1" id="c64f72dd-1d51-4e90-ab0f-d3f10601db0b" class="numbered-list" start="3"><li><strong>멀티스레딩 지원</strong><ul id="90a23ed8-95b7-4089-af1d-600c9fc1fb24" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: JVM은 다중 스레드를 지원하여 동시에 여러 작업을 수행할 수 있습니다. 스레드는 독립적으로 실행되며 스택과 PC 레지스터를 가집니다.</li></ul><ul id="218fbddc-47ff-4ff0-9656-59e1f27a8b6b" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: 스레드 간의 데이터 공유는 힙을 통해 이루어지며, 스레드 안전성을 보장하기 위해 동기화 메커니즘을 제공합니다.</li></ul></li></ol><ol type="1" id="08a6b1ca-72bc-491a-9939-b55788498b03" class="numbered-list" start="4"><li><strong>동적 클래스 로딩</strong><ul id="b56d7523-492c-46bc-aaea-95908ee292b5" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: JVM은 실행 중에 클래스를 동적으로 로드할 수 있습니다. 이를 통해 클래스의 이름이나 메소드, 필드 등의 정보를 동적으로 바꿀 수 있습니다.</li></ul><ul id="7cd0eea7-930f-46b7-b176-35ea0343ec3a" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: 리플렉션과 같은 메커니즘을 통해 런타임에 클래스의 구조와 동작을 동적으로 조작할 수 있습니다.</li></ul></li></ol><ol type="1" id="ff78201d-acf4-43a3-8e15-e476f1a982f4" class="numbered-list" start="5"><li><strong>바이트코드 검증</strong><ul id="87913a65-a007-423e-8c1e-4ac61a605104" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: JVM은 로드된 바이트코드의 유효성을 검증하여 보안과 안정성을 보장합니다. 이 과정에서 무효한 바이트코드를 필터링하고, 보안 취약점을 예방합니다.</li></ul><ul id="58bfc1ae-a204-47a3-a967-993908a5b3bf" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: 바이트코드 검증은 JVM의 주요 보안 기능 중 하나로, 잘못된 메모리 접근을 방지하고 프로그램의 무결성을 보장합니다.</li></ul></li></ol><h3 id="e5762d1d-ff9d-456f-a9fd-c6f22783ea1d" class=""><strong>JVM의 성능 최적화</strong></h3><ol type="1" id="cbac9cd0-9a62-426c-8148-c91dd6f67fdf" class="numbered-list" start="1"><li><strong>JIT 컴파일링</strong><ul id="afc496ac-fd49-4390-a530-d2e42d91cd87" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: Just-In-Time(JIT) 컴파일러는 자주 실행되는 바이트코드를 네이티브 기계어로 컴파일하여 성능을 개선합니다.</li></ul><ul id="777aed3e-fad2-4bcd-b7fc-057ea4478ca8" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: JIT 컴파일러는 런타임 중에 바이트코드를 네이티브 코드로 변환하여 실행 성능을 향상시킵니다.</li></ul></li></ol><ol type="1" id="caa02610-f720-476c-a4b0-649ef8c0078f" class="numbered-list" start="2"><li><strong>메모리 조정</strong><ul id="c77f3d2f-e0df-4f81-b6c3-056ce4911939" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: JVM의 힙 메모리 크기와 가비지 컬렉션 전략을 조정하여 애플리케이션의 성능을 최적화할 수 있습니다.</li></ul><ul id="0a7b6249-6d62-463b-b8dd-efbd926a5154" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: 힙 메모리 크기, 가비지 컬렉션 알고리즘, 스레드 스택 크기 등을 조정하여 최적의 성능을 얻을 수 있습니다.</li></ul></li></ol><ol type="1" id="7dbe4d49-77ed-45bb-b759-086dd6bce028" class="numbered-list" start="3"><li><strong>프로파일링 및 모니터링</strong><ul id="54d2c3f7-f490-4819-a323-24b4b0a115f5" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: JVM 프로파일링 도구와 모니터링 도구를 사용하여 성능 병목 현상과 메모리 문제를 분석하고 해결합니다.</li></ul><ul id="166dca95-79cd-4a0b-b54d-1012df6aea0e" class="bulleted-list"><li style="list-style-type:disc"><strong>특징</strong>: JVisualVM, JConsole, YourKit 등 다양한 도구를 통해 애플리케이션의 성능을 모니터링하고 문제를 진단할 수 있습니다.</li></ul></li></ol><p id="21b70336-9605-4c0d-bb6a-6853f287a724" class="">JVM은 Java 애플리케이션이 다양한 플랫폼에서 일관되게 실행될 수 있도록 하는 핵심 요소로, 성능 최적화와 안정성을 위해 다양한 기능과 메커니즘을 제공합니다. JVM의 구조와 동작 원리를 이해하는 것은 효율적인 Java 애플리케이션 개발과 유지보수에 필수적입니다.</p><p id="d9b3ae33-ee8a-49e9-92d8-028e1935a218" class="">
</p></details></li></ul><ul id="0732d595-ae7c-4b02-8ce1-194883c0be40" class="toggle"><li><details open=""><summary>Java 어플리케이션 성능 분석</summary><p id="40ca5128-dcec-4f85-9d88-6db57d17db95" class="">Java 애플리케이션의 성능 분석은 다양한 도구와 기법을 사용하여 애플리케이션의 성능 문제를 식별하고 해결하는 과정입니다. 성능 분석을 통해 애플리케이션의 응답 시간, 처리량, 메모리 사용량, CPU 사용량 등 다양한 성능 지표를 평가하고, 병목 현상이나 비효율적인 코드 경로를 찾을 수 있습니다.</p><h3 id="eb550ae3-4889-4a57-8266-74c2259a2913" class=""><strong>Java 애플리케이션 성능 분석 방법</strong></h3><ol type="1" id="59c6a9a7-51d2-4d47-85c6-4bee09d674d6" class="numbered-list" start="1"><li><strong>프로파일링 (Profiling)</strong><ul id="30555aa1-eb4f-4e17-a073-dd59fc7728aa" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 애플리케이션의 실행 중 성능 데이터를 수집하여 분석합니다. 프로파일링 도구는 메소드 호출, 실행 시간, 메모리 사용량 등을 추적합니다.</li></ul><ul id="196837b8-329e-482c-a363-ba5b9b8b4fb8" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>:<ul id="385b8d94-411f-480e-8278-0fc1e1395887" class="bulleted-list"><li style="list-style-type:circle"><strong>VisualVM</strong>: JVM의 메모리, CPU 사용량, 스레드 상태를 모니터링할 수 있는 도구입니다. 기본적으로 JDK에 포함되어 있습니다.</li></ul><ul id="7127efdd-7f9b-4153-bad7-ceb46d081e50" class="bulleted-list"><li style="list-style-type:circle"><strong>YourKit</strong>: 강력한 프로파일링 도구로, 메소드 호출 트리, CPU 및 메모리 사용량 등을 시각적으로 분석할 수 있습니다.</li></ul><ul id="45d40393-4577-477d-96e3-bdbd55b2509d" class="bulleted-list"><li style="list-style-type:circle"><strong>JProfiler</strong>: 메모리 누수 탐지, CPU 분석, 스레드 분석 기능을 제공하며, 다양한 성능 이슈를 진단할 수 있습니다.</li></ul></li></ul></li></ol><ol type="1" id="e16553a0-7439-40d3-8730-296c18876f67" class="numbered-list" start="2"><li><strong>JVM 모니터링</strong><ul id="0be428ea-24aa-4f41-8eb7-b3083439cbe3" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: JVM의 성능 지표를 모니터링하여 애플리케이션의 상태를 실시간으로 추적합니다.</li></ul><ul id="5dc80f16-7cda-4a70-8b8f-a34f8fe5f706" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>:<ul id="2a6d4aad-767b-4f5c-9662-831798659270" class="bulleted-list"><li style="list-style-type:circle"><strong>JConsole</strong>: JVM의 메모리, 스레드, 클래스 로딩 상태를 모니터링할 수 있는 도구로, JDK에 포함되어 있습니다.</li></ul><ul id="016bd92b-82a5-4ef1-be42-b7bb41970466" class="bulleted-list"><li style="list-style-type:circle"><strong>JVisualVM</strong>: JVM의 성능을 실시간으로 모니터링하고, 메모리, CPU, 스레드, 클래스 로딩 등을 분석할 수 있습니다.</li></ul></li></ul></li></ol><ol type="1" id="e5aa6d96-57d7-4264-a7a0-f6f6f145cafb" class="numbered-list" start="3"><li><strong>GC 로그 분석</strong><ul id="12bd861e-f4d3-4472-afcf-6d99c3571a30" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 가비지 컬렉션(GC) 로그를 분석하여 메모리 관리와 관련된 문제를 진단합니다.</li></ul><ul id="6ca974ff-f2e3-46cd-9b2d-10baeaf01bec" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>:<ul id="2018bac5-e56f-4d69-82d1-5c20edbf2bc2" class="bulleted-list"><li style="list-style-type:circle"><strong>GCViewer</strong>: GC 로그를 시각적으로 분석할 수 있는 도구로, GC의 성능과 힙 메모리 사용을 모니터링합니다.</li></ul><ul id="38fdccd2-4575-4258-a99e-13565e0fc7cf" class="bulleted-list"><li style="list-style-type:circle"><strong>GCEasy</strong>: GC 로그 분석 도구로, GC의 성능, 메모리 사용 패턴을 시각화하여 문제를 진단합니다.</li></ul></li></ul></li></ol><ol type="1" id="d05ef56e-4a76-49dc-9fa4-a7b6618faedf" class="numbered-list" start="4"><li><strong>애플리케이션 로그 분석</strong><ul id="b7030e18-52e3-4fb6-8cfc-821b038743f9" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 애플리케이션의 로그를 분석하여 성능 문제의 원인을 파악합니다.</li></ul><ul id="677737f6-0066-49b2-b6b3-5699a7d43b1d" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>:<ul id="339b8c0e-3143-4171-90d5-2bf3357529d6" class="bulleted-list"><li style="list-style-type:circle"><strong>Log4j</strong>: 로그 기록 및 분석을 위한 프레임워크로, 로그 수준, 로그 출력 형식 등을 설정할 수 있습니다.</li></ul><ul id="7b708c12-d602-4010-8c9e-337e743fb3a6" class="bulleted-list"><li style="list-style-type:circle"><strong>ELK 스택 (Elasticsearch, Logstash, Kibana)</strong>: 로그 수집, 저장, 시각화를 위한 통합 솔루션으로, 대규모 로그 분석에 유용합니다.</li></ul></li></ul></li></ol><ol type="1" id="c2ec4b35-2a79-48d1-b474-1563c6fad418" class="numbered-list" start="5"><li><strong>성능 테스트 및 벤치마킹</strong><ul id="4cacb593-3ead-45cd-8827-6d62c4d8356f" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 애플리케이션의 성능을 정량적으로 평가하기 위한 테스트를 수행합니다.</li></ul><ul id="a6bb9dc2-2fb6-48c2-b42c-c172b4b4e920" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>:<ul id="99695c13-fe91-495f-820a-fd0f2cf63b13" class="bulleted-list"><li style="list-style-type:circle"><strong>JMeter</strong>: 웹 애플리케이션의 성능 테스트를 수행하는 도구로, 다양한 부하 테스트를 지원합니다.</li></ul><ul id="198b6a09-e303-449f-9682-958e8cebd0ed" class="bulleted-list"><li style="list-style-type:circle"><strong>Gatling</strong>: 고성능 부하 테스트 도구로, HTTP 기반 애플리케이션의 성능을 테스트할 수 있습니다.</li></ul></li></ul></li></ol><ol type="1" id="b26ec0e0-95a9-4759-8de4-cf495148d09a" class="numbered-list" start="6"><li><strong>코드 분석 및 리팩토링</strong><ul id="d17623f6-ad2b-433d-9bcf-f5ff0bc7d0ae" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 소스 코드에서 비효율적인 부분을 식별하고 개선합니다. 코드 분석 도구를 사용하여 성능 병목을 찾아낼 수 있습니다.</li></ul><ul id="2cc206bd-73bb-48e3-957f-c97871afee80" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>:<ul id="9b3f7df7-a41d-4d7c-9c45-245a34e1b5f0" class="bulleted-list"><li style="list-style-type:circle"><strong>FindBugs / SpotBugs</strong>: 코드의 버그와 비효율성을 찾아주는 도구로, 성능 최적화와 관련된 문제를 식별할 수 있습니다.</li></ul><ul id="352de0cd-7265-4f1f-9443-7bf8eeaaa82a" class="bulleted-list"><li style="list-style-type:circle"><strong>SonarQube</strong>: 코드 품질과 보안 취약점을 분석하는 도구로, 성능 개선과 관련된 문제를 발견할 수 있습니다.</li></ul></li></ul></li></ol><ol type="1" id="d25ce100-9bd0-41a5-ae3f-0b57caa7bda1" class="numbered-list" start="7"><li><strong>스레드 덤프 분석</strong><ul id="695a81b4-3bb8-4a1f-bf07-bbce3976c4de" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: 스레드 덤프를 분석하여 애플리케이션의 스레드 상태와 병목 현상을 식별합니다.</li></ul><ul id="38f99d5f-cab3-4b64-bf01-ccd673dd751f" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>:<ul id="06281b18-6336-45f2-9687-76313941476a" class="bulleted-list"><li style="list-style-type:circle"><strong>jstack</strong>: JVM 스레드 덤프를 생성하고 분석하는 도구로, 스레드의 상태를 시각화합니다.</li></ul><ul id="fcc607c8-9e80-4720-8a85-b50289f32fd3" class="bulleted-list"><li style="list-style-type:circle"><strong>Thread Dump Analyzer</strong>: 스레드 덤프를 분석하여 스레드의 상태와 잠금 문제를 파악합니다.</li></ul></li></ul></li></ol><ol type="1" id="3a316ba4-eaef-4eee-b953-c8604edf57b3" class="numbered-list" start="8"><li><strong>JVM 옵션 조정</strong><ul id="3c7b5dfb-85f9-43de-bd55-8543dcf135f7" class="bulleted-list"><li style="list-style-type:disc"><strong>역할</strong>: JVM의 설정을 조정하여 성능을 최적화합니다. 힙 메모리 크기, 가비지 컬렉션 옵션 등을 설정할 수 있습니다.</li></ul><ul id="b0bfad75-83e8-4fb5-857a-e50afeecfb4e" class="bulleted-list"><li style="list-style-type:disc"><strong>도구</strong>:<ul id="e6f04390-180c-4f52-b27f-5f5be4707427" class="bulleted-list"><li style="list-style-type:circle"><strong>Xmx / -Xms</strong>: JVM 힙 메모리의 최대 및 초기 크기를 설정합니다.</li></ul><ul id="fdaabe66-0eeb-47a7-926c-b59e7bc83df6" class="bulleted-list"><li style="list-style-type:circle"><strong>XX:+UseG1GC</strong>: G1 가비지 컬렉터를 사용하여 메모리 관리를 최적화합니다.</li></ul></li></ul></li></ol><h3 id="e3ef5361-0655-40e6-a72e-fdf7bdfe2172" class=""><strong>성능 분석 절차</strong></h3><ol type="1" id="9b24f198-4520-4056-b46a-4da5af71305a" class="numbered-list" start="1"><li><strong>문제 정의</strong>: 성능 문제가 발생하는 구체적인 상황을 정의합니다 (예: 응답 지연, 높은 CPU 사용량 등).</li></ol><ol type="1" id="10cec5ee-e9c3-4320-b0d3-305698ed032b" class="numbered-list" start="2"><li><strong>데이터 수집</strong>: 위의 도구와 기법을 사용하여 성능 관련 데이터를 수집합니다.</li></ol><ol type="1" id="820f8646-adbd-4353-b13f-d751b0dbaddd" class="numbered-list" start="3"><li><strong>문제 진단</strong>: 수집된 데이터를 분석하여 성능 병목 현상이나 비효율적인 부분을 식별합니다.</li></ol><ol type="1" id="33d24967-74c5-4c5b-a87f-8a0fd4f4e87b" class="numbered-list" start="4"><li><strong>문제 해결</strong>: 분석 결과를 바탕으로 문제를 해결하기 위한 코드 수정, 시스템 조정, 구성 변경 등의 작업을 수행합니다.</li></ol><ol type="1" id="45094749-8319-4736-ac53-6c70295b23ab" class="numbered-list" start="5"><li><strong>검증</strong>: 성능 개선 조치를 적용한 후, 애플리케이션을 다시 테스트하여 문제가 해결되었는지 확인합니다.</li></ol><p id="88803a58-5fc4-49b9-bf05-c82e6785918f" class="">Java 애플리케이션의 성능을 분석하고 최적화하는 과정은 시스템의 성능을 향상시키고, 사용자 경험을 개선하며, 안정성을 높이는 데 중요한 역할을 합니다. 다양한 도구와 기법을 활용하여 성능 문제를 체계적으로 해결해 나가야 합니다.</p></details></li></ul><ul id="5c89d5f8-8b9c-4e82-b83b-6e4dc27378bd" class="toggle"><li><details open=""><summary>Java 애플리케이션의 성능 관리를 위해 메모리 관리</summary><p id="16685a2d-2ac7-4e06-a431-f44ee1dd5b38" class="">Java 애플리케이션의 성능 관리를 위해 메모리 관리는 매우 중요한 작업입니다. Java 애플리케이션에서 메모리 관리는 주로 힙 메모리와 스택 메모리, 그리고 가비지 컬렉션을 포함한 여러 측면을 다룹니다. 적절한 메모리 관리는 애플리케이션의 성능과 안정성을 보장하는 데 중요한 역할을 합니다. 다음은 Java 애플리케이션의 메모리 관리를 효과적으로 수행하는 방법입니다.</p><h3 id="b7e886b0-2457-4ef5-ad09-2e64e76c5a11" class=""><strong>1. 힙 메모리 관리</strong></h3><h3 id="39a5041b-a9ce-4f0e-9353-57252dcc673d" class=""><strong>가비지 컬렉션 (Garbage Collection)</strong></h3><ul id="2908a0c3-eb08-4668-a7ad-da5c2de73b15" class="bulleted-list"><li style="list-style-type:disc"><strong>가비지 컬렉션 기본</strong>: Java는 자동으로 메모리를 관리하는 가비지 컬렉션을 사용합니다. GC는 사용되지 않는 객체를 식별하고 메모리에서 제거하여 메모리 누수를 방지합니다.</li></ul><ul id="81eb26b7-9bb1-4ab5-acdd-dc10c81fd787" class="bulleted-list"><li style="list-style-type:disc"><strong>GC 유형</strong>:<ul id="cea41dce-6305-4444-ac5d-48bb08479973" class="bulleted-list"><li style="list-style-type:circle"><strong>Serial GC</strong>: 단일 스레드로 모든 GC 작업을 수행합니다. 단일 스레드 환경에 적합합니다.</li></ul><ul id="6be51489-49b7-4837-b758-d9b0d94bb250" class="bulleted-list"><li style="list-style-type:circle"><strong>Parallel GC</strong>: 여러 스레드를 사용하여 GC 작업을 병렬로 처리합니다. 다중 코어 시스템에 적합합니다.</li></ul><ul id="f15f2a33-f990-4689-8d32-1c1c88589e64" class="bulleted-list"><li style="list-style-type:circle"><strong>Concurrent Mark-Sweep (CMS) GC</strong>: 애플리케이션의 중단 시간을 줄이는 동시에 GC를 수행합니다.</li></ul><ul id="b4d5c628-b54f-41d6-82bc-63c54cb126a8" class="bulleted-list"><li style="list-style-type:circle"><strong>G1 GC</strong>: 큰 힙 메모리에서 성능을 개선하도록 설계된 GC로, 힙을 작은 영역으로 나누어 효율적으로 관리합니다.</li></ul></li></ul><ul id="ed570d13-7cb2-4569-a497-6a2ec9ca4697" class="bulleted-list"><li style="list-style-type:disc"><strong>GC 튜닝</strong>: GC의 성능을 조정하려면 JVM 옵션을 조정하여 GC 동작을 최적화할 수 있습니다. 예를 들어, <code>XX:+UseG1GC</code>를 사용하여 G1 GC를 활성화하거나 <code>Xmx</code>와 <code>Xms</code>를 사용하여 힙 메모리의 최대 및 초기 크기를 설정합니다.</li></ul><h3 id="b79e1187-e254-4757-8b04-91b984e20bd5" class=""><strong>메모리 분석</strong></h3><ul id="fa95e8da-c610-4fc6-882e-1970ae19a438" class="bulleted-list"><li style="list-style-type:disc"><strong>힙 덤프 분석</strong>: 애플리케이션의 힙 메모리 상태를 스냅샷으로 저장하고 분석합니다. 이를 통해 메모리 누수, 객체의 수명, 메모리 사용 패턴 등을 파악할 수 있습니다.<ul id="9f6804ec-fe31-4509-9ede-95ed68697e92" class="bulleted-list"><li style="list-style-type:circle"><strong>도구</strong>: Eclipse MAT (Memory Analyzer Tool), VisualVM</li></ul></li></ul><ul id="fb38b96e-ff28-4709-b1b8-7e40a79c2c2f" class="bulleted-list"><li style="list-style-type:disc"><strong>메모리 누수 탐지</strong>: 사용되지 않는 객체가 메모리에 남아있는 경우 메모리 누수를 조사합니다.<ul id="b8627da8-7c88-46fd-8415-2bbbb28e191e" class="bulleted-list"><li style="list-style-type:circle"><strong>도구</strong>: YourKit, JProfiler</li></ul></li></ul><h3 id="3d9dde2b-fe6b-48ae-aa28-b61ba6227c86" class=""><strong>2. 스택 메모리 관리</strong></h3><h3 id="64faa200-3008-476d-8320-bef61484f9ae" class=""><strong>스택 오버플로우 방지</strong></h3><ul id="1d85842f-0ef7-4563-bacc-26c3dde1dcd3" class="bulleted-list"><li style="list-style-type:disc"><strong>재귀 호출 최적화</strong>: 깊은 재귀 호출로 인해 스택 오버플로우가 발생할 수 있습니다. 재귀 호출의 깊이를 줄이거나 반복문으로 대체하여 스택 사용을 최적화합니다.</li></ul><ul id="a19f365b-575e-4312-b758-93d9afee4462" class="bulleted-list"><li style="list-style-type:disc"><strong>스레드 덤프 분석</strong>: 스레드 덤프를 분석하여 스레드가 너무 많은 메모리를 사용하고 있는지 또는 스택 오버플로우 문제가 발생하고 있는지 확인합니다.<ul id="66ea04e3-53de-4c03-be66-fcea8e59893f" class="bulleted-list"><li style="list-style-type:circle"><strong>도구</strong>: jstack, Thread Dump Analyzer</li></ul></li></ul><h3 id="71efb7dd-1365-40d4-9e7b-62afaaa1b211" class=""><strong>스레드 상태 모니터링</strong></h3><ul id="96013d6f-5b79-4a7f-8a3f-62c5cbe73e20" class="bulleted-list"><li style="list-style-type:disc"><strong>스레드 모니터링</strong>: 스레드의 상태와 스택 사용을 모니터링하여 성능 문제를 파악합니다.<ul id="0f0d35bb-877f-46e3-80f6-4a95b437c87c" class="bulleted-list"><li style="list-style-type:circle"><strong>도구</strong>: JConsole, VisualVM</li></ul></li></ul><h3 id="38c3ae8a-72d9-4e49-a086-b9a417e92919" class=""><strong>3. 메모리 설정 및 조정</strong></h3><h3 id="f7ed2004-95b3-42da-93e9-84421804529e" class=""><strong>JVM 메모리 설정</strong></h3><ul id="e4108235-6d73-4428-a8bc-eab13f67f8cf" class="bulleted-list"><li style="list-style-type:disc"><strong>힙 메모리 크기 조정</strong>: <code>Xms</code>와 <code>Xmx</code> 옵션을 사용하여 초기 힙 메모리 크기와 최대 힙 메모리 크기를 설정합니다.<ul id="b5690b50-3fd1-4685-8672-698ba87285d7" class="bulleted-list"><li style="list-style-type:circle">예: <code>Xms512m -Xmx2048m</code></li></ul></li></ul><ul id="c180add5-52f1-4547-b4bd-e52337d77f8b" class="bulleted-list"><li style="list-style-type:disc"><strong>Young Generation과 Old Generation 설정</strong>: <code>XX:NewSize</code>, <code>XX:MaxNewSize</code> 등을 사용하여 Young Generation의 크기를 조정할 수 있습니다.</li></ul><ul id="e87058e8-c148-45a5-a431-14865d0b3744" class="bulleted-list"><li style="list-style-type:disc"><strong>GC 로그 활성화</strong>: <code>Xloggc:&lt;file&gt;</code> 또는 <code>XX:+PrintGCDetails</code>와 같은 옵션을 사용하여 GC 로그를 활성화하고 분석합니다.</li></ul><h3 id="ab0c072f-609f-4d95-b5e8-e719d2ee47aa" class=""><strong>메모리 관리 정책 설정</strong></h3><ul id="6aa710b3-3f9e-4661-86bc-559897a3ecc7" class="bulleted-list"><li style="list-style-type:disc"><strong>Heap Dump 설정</strong>: OutOfMemoryError 발생 시 힙 덤프를 생성하도록 JVM을 설정합니다.<ul id="efb63529-ba0b-4298-82d3-63c38896a8af" class="bulleted-list"><li style="list-style-type:circle">예: <code>XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path/to/dump</code></li></ul></li></ul><ul id="d3846b55-947c-4f9f-8a50-f70783ba3fd2" class="bulleted-list"><li style="list-style-type:disc"><strong>PermGen/Metaspace 조정</strong>: Java 8 이전에는 PermGen을, Java 8 이상에서는 Metaspace를 조정합니다.<ul id="a4f95a0e-c597-47d3-be48-ca7362e5e198" class="bulleted-list"><li style="list-style-type:circle">예: <code>XX:MaxPermSize=256m</code> (Java 7 이하), <code>XX:MaxMetaspaceSize=256m</code> (Java 8 이상)</li></ul></li></ul><h3 id="e6b4f21d-3ac1-405b-801a-ee96ee973caf" class=""><strong>4. 성능 테스트 및 벤치마킹</strong></h3><ul id="f783680c-9872-4325-95c3-b40c02f53922" class="bulleted-list"><li style="list-style-type:disc"><strong>성능 테스트</strong>: 애플리케이션의 성능을 측정하고, 메모리 사용량과 GC 성능을 분석하여 병목 현상을 식별합니다.<ul id="e4383cf5-bbb3-477a-9ac2-b74bf22cc4a2" class="bulleted-list"><li style="list-style-type:circle"><strong>도구</strong>: JMeter, Gatling</li></ul></li></ul><ul id="d1fa9777-8e24-4793-8c21-b904de6aae66" class="bulleted-list"><li style="list-style-type:disc"><strong>벤치마킹</strong>: 애플리케이션의 성능을 다양한 환경에서 테스트하여 메모리 사용의 효율성을 평가합니다.</li></ul><h3 id="7b287092-a3c3-4f1b-8d5d-56f128e711fb" class=""><strong>5. 코드 최적화</strong></h3><ul id="c597c2c2-0aa5-4efa-8546-c36b294df412" class="bulleted-list"><li style="list-style-type:disc"><strong>객체 풀링</strong>: 자주 사용하는 객체를 재사용하여 메모리 할당과 해제를 최소화합니다.</li></ul><ul id="cef79e05-6631-41a8-b07b-d416970a5b49" class="bulleted-list"><li style="list-style-type:disc"><strong>불필요한 객체 참조 제거</strong>: 사용이 끝난 객체에 대한 참조를 제거하여 가비지 컬렉터가 메모리를 해제할 수 있도록 합니다.</li></ul><ul id="37056f18-96bd-415d-9ec8-1aca61914005" class="bulleted-list"><li style="list-style-type:disc"><strong>효율적인 데이터 구조 사용</strong>: 적절한 데이터 구조를 사용하여 메모리 사용을 최적화합니다.</li></ul><p id="e3a2c3e2-f8d4-486a-84f4-77a0bb31344a" class="">Java 애플리케이션의 성능 관리를 위해서는 힙 메모리와 스택 메모리의 상태를 적절히 관리하고 분석하는 것이 중요합니다. 이와 함께 메모리 설정을 조정하고 성능 테스트를 수행함으로써 최적의 성능을 유지할 수 있습니다.</p></details></li></ul><p id="1583a4cc-090a-8025-9d78-e4292521b37f" class="">
</p><p id="6d5ed97c-45e9-4631-8fd6-fd571210c53d" class="">Project Management</p><ul id="07888d5b-e706-4594-a6a9-60b316cc2121" class="toggle"><li><details open=""><summary>kanban 기반 프로젝트 관리</summary><p id="7f6a8bb2-cde1-4087-afff-8e9b79480d1d" class="">
</p><ul id="81ab7393-bc1a-4842-8f82-112859b15d44" class="bulleted-list"><li style="list-style-type:disc">교육 니즈 조사 및 실시간 소통/피드백<ul id="860d6c1d-7281-4823-9a60-48eaf711a6c9" class="bulleted-list"><li style="list-style-type:circle">bit-ly/ktc-kanban-1</li></ul><ul id="4bd9e0d3-9254-4ada-9cf4-520e39c4ae4d" class="bulleted-list"><li style="list-style-type:circle"><a href="https://prjresearch-my.sharepoint.com/:x:/g/personal/peterkim_projectresearch_co_kr/EfcvEkf14yJMhGApe-6YR8EBgy7ykNTAxqg1BahgUEBG0A?rtime=LeZrJ3lI3Eg">https://prjresearch-my.sharepoint.com/:x:/g/personal/peterkim_projectresearch_co_kr/EfcvEkf14yJMhGApe-6YR8EBgy7ykNTAxqg1BahgUEBG0A?rtime=LeZrJ3lI3Eg</a><figure id="fa48aad8-79d2-43f6-be25-5f65b3e63af1" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-20_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.09.28.png"><img style="width:652.0051879882812px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-20_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%258C%25E1%2585%25A5%25E1%2586%25AB_11.09.28.png"/></a></figure></li></ul><ul id="871827fb-fce7-4c0c-aeb9-3481b3a7a548" class="bulleted-list"><li style="list-style-type:circle">Chat GPT 활용 요약</li></ul></li></ul><ul id="f0670422-faf7-4fd5-8b6e-4a02a057b377" class="bulleted-list"><li style="list-style-type:disc">기본기가 탄탄해야 성공한다<ul id="f036c0e7-6e94-4fdc-9f75-6a56ec7b8f74" class="bulleted-list"><li style="list-style-type:circle">Agility(민첩성) <ul id="7b222130-823d-4064-9ee9-59381964d2a6" class="bulleted-list"><li style="list-style-type:square">프로젝트 관리의 궁극적 목적</li></ul></li></ul></li></ul><ul id="35ec607c-ea24-42d3-8625-6b56d63bbfab" class="bulleted-list"><li style="list-style-type:disc">KT AICC 사례<ul id="ddeeb3d2-a4fd-42fa-b13b-3fbfbabb5f2e" class="bulleted-list"><li style="list-style-type:circle">risk 발생 가능성이 있는 것, issue 발생 한 것</li></ul><ul id="f5a5a97e-e75a-426d-a789-bbc211154706" class="bulleted-list"><li style="list-style-type:circle">분석, 설계, 구현, 시험, 전환, 관리</li></ul><ul id="307171dc-cc9c-4e44-9c57-adffce01fda4" class="bulleted-list"><li style="list-style-type:circle">RFP 항목과 설계/개발/시험 항목 매핑 관리</li></ul><ul id="1cdb757a-0f72-400d-ba2f-f18937ced662" class="bulleted-list"><li style="list-style-type:circle">QA 공정 품질 관리, QC 만들어진 제품 품질 관리</li></ul><ul id="9ab4551b-20de-4a01-b855-4c7a0d404d7c" class="bulleted-list"><li style="list-style-type:circle">일일보고 자동화,  MS 문서 작성 제거(Visual PMO문서작성기능), 이메일 사용 금지</li></ul><ul id="43a4eddc-e9d6-4f17-8cf5-8359892d3fb3" class="bulleted-list"><li style="list-style-type:circle">일일보고: 지연업무, 리스크/이슈, 진척 진행 현황</li></ul></li></ul><ul id="2f8ccf34-751a-4baf-ae7a-3c2106ee56e8" class="bulleted-list"><li style="list-style-type:disc">C-Hub<ul id="fe167cc6-c108-475f-b34c-38a4d6d73bff" class="bulleted-list"><li style="list-style-type:circle">Demo 시나리오 기준 스프린트 1개월 구분</li></ul></li></ul><ul id="41c7a995-ffc4-4849-a9d2-4551229ab14b" class="bulleted-list"><li style="list-style-type:disc">Naver<ul id="55cf0149-9056-4ccf-a3a2-37bad2fd207d" class="bulleted-list"><li style="list-style-type:circle">Project Layer, Product Layer (요구사항, 개발범위, 테스트 케이스, 품질검사)</li></ul><ul id="da676840-4ddf-4e3c-8119-2d4cdea21676" class="bulleted-list"><li style="list-style-type:circle">Git-Hub, Genob plugin 칸반 지원</li></ul><ul id="92e9d58d-fa72-4434-b1a8-e0a8dfde3f68" class="bulleted-list"><li style="list-style-type:circle">아이디어/가설 → indepth interview → 기존 가설 검증 및 새로운 가치/방향성 발굴</li></ul><ul id="83be4af5-6372-440e-8543-1cd2a09bcb7f" class="bulleted-list"><li style="list-style-type:circle">Epic - feature, 개발 우선 순위 지정</li></ul><ul id="bf6cb59d-8d1a-407d-8de4-8733a7708c31" class="bulleted-list"><li style="list-style-type:circle">ATDD (Acceptance test driven development) → Jira Base Workflow / FDD</li></ul><ul id="7db91b05-6be3-4dfd-ae7a-4982859ebfa4" class="bulleted-list"><li style="list-style-type:circle">uiux, 개발은 네이버, 품질/ops는 외주(트라이잼, )</li></ul></li></ul><p id="2385bc7e-9572-4068-a31d-9412296780f0" class="">
</p><ul id="de19d023-8034-4488-bc4e-120537964562" class="bulleted-list"><li style="list-style-type:disc">실습<ul id="2b57aaf5-7d0a-4008-a36b-e6fa0a92cb25" class="bulleted-list"><li style="list-style-type:circle">칸반 운영, 스크럼 개발</li></ul><ul id="8d0ea627-68d1-4dd1-9809-a8364c62d24b" class="bulleted-list"><li style="list-style-type:circle">엑셀 - Jira 용어 개념<ul id="dfdf0683-d5fe-4b6a-8643-4fbf7af9b0c2" class="bulleted-list"><li style="list-style-type:square">문서/시트 - 프로젝트/컴포넌트</li></ul><ul id="6cbdee66-b351-47c3-a9d1-f058617a90c5" class="bulleted-list"><li style="list-style-type:square">행/raw - issue</li></ul><ul id="a554a19f-0e55-4750-967b-48cf1c37fd20" class="bulleted-list"><li style="list-style-type:square">컬럼(Task 속성: 담당자, 우선순위, 시작일, 종료일, 산출물) - 필드(이슈 유형: 좌동)</li></ul><ul id="09986cfd-72e1-4d34-9412-eb8955f3d2f5" class="bulleted-list"><li style="list-style-type:square">필터 - 필터(저장 가능)</li></ul><ul id="4d7a8a38-7c7f-466c-847a-c079d9144700" class="bulleted-list"><li style="list-style-type:square">피벗테이블 - dashboard</li></ul></li></ul><ul id="61260978-0127-45c1-8784-540e93446497" class="bulleted-list"><li style="list-style-type:circle">Waterfall - Agile<ul id="31acf706-b1c7-4ef6-a898-3d95c848a691" class="bulleted-list"><li style="list-style-type:square">WBS - Product Backlog</li></ul><ul id="6859a15e-1175-4adb-8f3a-1861d18bf02e" class="bulleted-list"><li style="list-style-type:square">Gant (마일스톤, weekly, 진도율) - Bun (release, sprint, task 수)</li></ul></li></ul><ul id="82cc7122-c1f2-4a10-beaa-aa296cb04fd3" class="bulleted-list"><li style="list-style-type:circle">Epic - 카테고리명, 필드를 구분</li></ul><ul id="ec9e2ff1-4b2f-4751-9f03-49d6719193f6" class="bulleted-list"><li style="list-style-type:circle">Epic(feature)→ Product Backlog(할일) → 스프린트 Backlog (주간계획) → Daily Think(댓글, Todo-Doing-Done) → 스프린트 Review (종료) → 스프린트 회고<ul id="3e36e20f-36c7-44ff-80ed-4e1ecb1c2779" class="bulleted-list"><li style="list-style-type:square">2주 단위 반복, 5번 반복 시 10주 마일스톤</li></ul><figure id="5daf24bd-57ba-4f36-8775-a4e4632a3ca1" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-20_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.02.56.png"><img style="width:593.0078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-20_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.02.56.png"/></a></figure></li></ul><ul id="dd4164ad-74bb-481d-8884-baa9b192d4ec" class="bulleted-list"><li style="list-style-type:circle">Design Thinking<ul id="1c0fccf7-86da-4ce0-8e0f-5bee2554c72b" class="bulleted-list"><li style="list-style-type:square">Agile Game: 쓰기, 이야기, 공감</li></ul><figure id="1bc4cde4-47de-4c73-833b-b615fda799a3" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-20_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.46.14.png"><img style="width:593.0078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-20_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_3.46.14.png"/></a></figure></li></ul><ul id="011fafa2-7e6b-4dc3-8817-cd3067fff9e1" class="bulleted-list"><li style="list-style-type:circle">Product Backlog (명사로 정의)<ul id="dbdf95e7-e1aa-4ea9-9d99-0c08531f2d3d" class="bulleted-list"><li style="list-style-type:square">무인키오스크 WBS ⇒ PBS(제품 분류, 아키텍트), FBS(기능 분류, SW)</li></ul><ul id="0f030f57-bd93-47c8-aba7-1ecf3d6326b5" class="bulleted-list"><li style="list-style-type:square">Agile은 명사로 정의</li></ul></li></ul><ul id="c7c82fbc-2e43-41dd-8070-0f0044b5ad62" class="bulleted-list"><li style="list-style-type:circle">PBS, FBS 로 Backlog 작성<ul id="35ed8890-88f9-4422-bcef-55c501d108a3" class="bulleted-list"><li style="list-style-type:square">Epic, Feature, Acceptance creteria, backlog item, DoD</li></ul><ul id="626745e5-a937-4402-9180-332f714f12fb" class="bulleted-list"><li style="list-style-type:square">상기 PBS와 FBS 정보를 기반으로 한 카페 런칭 프로젝트의 Product Backlog를 Epic, Feature / acceptance criteria, Backlog, Definition of Done (DoD) 형태로 재분류하는 예시는 다음과 같음:</li></ul></li></ul></li></ul><p id="6eb1c196-f194-47c1-8b83-4e91dbed08fd" class="">
</p><ul id="774506f4-1b0b-455d-b9e7-5a48667d79bb" class="bulleted-list"><li style="list-style-type:disc">Confluence<ul id="7bb9b369-dfb0-4a59-b261-ebc1efae38af" class="bulleted-list"><li style="list-style-type:circle">Word - Confluence<ul id="858da329-dc0c-46e7-985e-8e08ce6b2bf8" class="bulleted-list"><li style="list-style-type:square">폴더/문서 - 스페이스/페이지</li></ul><ul id="960cd14d-a0ee-4c2a-b651-0470485ca561" class="bulleted-list"><li style="list-style-type:square">혼자 - 같이</li></ul><ul id="4fa0a20f-8b41-477f-b5d9-7e701c6a1b72" class="bulleted-list"><li style="list-style-type:square">버전: 파일명 - 버전: 내장</li></ul><ul id="38180194-1ba7-4733-be6c-59e7d9acb3f7" class="bulleted-list"><li style="list-style-type:square">링크: 메뉴얼 - 링크: 자동</li></ul><ul id="e047c3ba-f97c-4593-a9a3-2d43d2d35537" class="bulleted-list"><li style="list-style-type:square">-  댓글/소셜</li></ul><p id="5178336e-c50e-4020-89ad-098a9fe2fda8" class="">
</p></li></ul></li></ul><ul id="3470284b-ebe4-4b86-931c-19ec22b0f5a6" class="bulleted-list"><li style="list-style-type:disc">Dashboard <ul id="2f69d28a-858d-461a-b43c-93d8a987d015" class="bulleted-list"><li style="list-style-type:circle">filter → dashboard<figure id="075d67d9-255f-4695-adc1-f2004b302679" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-21_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.16.12.png"><img style="width:623.0078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-21_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.16.12.png"/></a></figure><p id="012f9347-ab9b-476a-8fa9-95e51385dd12" class="">
</p></li></ul></li></ul><ul id="36c43e0b-dc1d-4593-a738-5a5147722bb1" class="bulleted-list"><li style="list-style-type:disc">회의록<ul id="954c3994-017e-4354-8104-45f29f6eb99b" class="bulleted-list"><li style="list-style-type:circle">이슈 생성</li></ul><ul id="edb2590f-287e-44e9-a1a1-97057fe3a735" class="bulleted-list"><li style="list-style-type:circle">confluence 문서 링크<figure id="6a0a2e1b-6401-4804-9c72-4ed90dbf698b" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-21_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.17.33.png"><img style="width:623.0078125px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-21_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.17.33.png"/></a></figure></li></ul><p id="f465d7d4-47e3-42c6-bf74-087d314a4435" class="">
</p></li></ul><ul id="a0408f20-c602-450f-baf1-866bc2ef024c" class="bulleted-list"><li style="list-style-type:disc">personal data 관리(로컬)<ul id="db717efd-0cd8-4097-b0f1-25edc0151ea9" class="bulleted-list"><li style="list-style-type:circle"><a href="https://logseq.com/">https://logseq.com/</a></li></ul></li></ul><p id="3d3a087c-80a1-45a7-b43c-db136a201059" class="">
</p><ul id="18cf9e26-03d6-4a10-bf7c-6912ded552e1" class="bulleted-list"><li style="list-style-type:disc"><a href="https://miro.com/app/board/uXjVKe1HCvU=/?moveToWidget=3458764583062826359&amp;cot=14">https://miro.com/app/board/uXjVKe1HCvU=/?moveToWidget=3458764583062826359&amp;cot=14</a><figure id="e93ec708-e2f6-4233-b8ab-04eaa26972a3" class="image"><a href="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-27_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.44.36.png"><img style="width:680px" src="IT%20Tech%20f69f800e7bec4c648ffdf4a3cb6c0a79/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-03-27_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_4.44.36.png"/></a></figure></li></ul><p id="612b456b-e251-4385-98b4-6a5519bad80a" class="">
</p><p id="fd2fea35-486e-4df3-9de1-01cb57b066c0" class="">
</p></details></li></ul><p id="4024d546-ccca-4200-a247-769cf0e5d31f" class="">
</p><p id="bb758aed-58f2-4408-9fd0-57564c4c54dc" class="">Link</p><figure id="e6438817-ba4e-4769-b03c-38bdb3990243"><div class="source">https://github.com/devSquad-study/2023-CS-Study</div></figure><p id="6669fce0-ecac-4f65-bf4d-e673d61c78b7" class="">
</p><p id="0ffa1314-3fcd-4d72-805c-ab41d68d438b" class="">
</p><p id="da4db115-5d5d-45c4-9171-8803c5ee18e1" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>